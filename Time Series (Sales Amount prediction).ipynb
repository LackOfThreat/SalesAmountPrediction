{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Units</th>\n",
       "      <th>Stock</th>\n",
       "      <th>SKU</th>\n",
       "      <th>Retailer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>SKU_126</td>\n",
       "      <td>RETAILER_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SKU_126</td>\n",
       "      <td>RETAILER_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SKU_126</td>\n",
       "      <td>RETAILER_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SKU_126</td>\n",
       "      <td>RETAILER_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SKU_127</td>\n",
       "      <td>RETAILER_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>SKU_127</td>\n",
       "      <td>RETAILER_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SKU_127</td>\n",
       "      <td>RETAILER_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SKU_127</td>\n",
       "      <td>RETAILER_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SKU_128</td>\n",
       "      <td>RETAILER_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SKU_128</td>\n",
       "      <td>RETAILER_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SKU_128</td>\n",
       "      <td>RETAILER_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>SKU_129</td>\n",
       "      <td>RETAILER_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SKU_129</td>\n",
       "      <td>RETAILER_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>2.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SKU_129</td>\n",
       "      <td>RETAILER_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SKU_129</td>\n",
       "      <td>RETAILER_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>43.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>SKU_14</td>\n",
       "      <td>RETAILER_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>29.49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>SKU_14</td>\n",
       "      <td>RETAILER_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>SKU_14</td>\n",
       "      <td>RETAILER_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>3897.33</td>\n",
       "      <td>151.0</td>\n",
       "      <td>8562.0</td>\n",
       "      <td>SKU_14</td>\n",
       "      <td>RETAILER_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>212.07</td>\n",
       "      <td>8.0</td>\n",
       "      <td>347.0</td>\n",
       "      <td>SKU_14</td>\n",
       "      <td>RETAILER_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>2954.65</td>\n",
       "      <td>222.0</td>\n",
       "      <td>6982.0</td>\n",
       "      <td>SKU_14</td>\n",
       "      <td>RETAILER_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>-12.36</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>SKU_14</td>\n",
       "      <td>RETAILER_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>1774.70</td>\n",
       "      <td>97.0</td>\n",
       "      <td>3626.0</td>\n",
       "      <td>SKU_14</td>\n",
       "      <td>RETAILER_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>346.94</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>SKU_14</td>\n",
       "      <td>RETAILER_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>23.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>SKU_24</td>\n",
       "      <td>RETAILER_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>802.14</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1066.0</td>\n",
       "      <td>SKU_24</td>\n",
       "      <td>RETAILER_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>52.87</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>SKU_24</td>\n",
       "      <td>RETAILER_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>4371.35</td>\n",
       "      <td>172.0</td>\n",
       "      <td>7983.0</td>\n",
       "      <td>SKU_24</td>\n",
       "      <td>RETAILER_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>458.66</td>\n",
       "      <td>16.0</td>\n",
       "      <td>526.0</td>\n",
       "      <td>SKU_24</td>\n",
       "      <td>RETAILER_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>4307.16</td>\n",
       "      <td>161.0</td>\n",
       "      <td>22196.0</td>\n",
       "      <td>SKU_24</td>\n",
       "      <td>RETAILER_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>416.93</td>\n",
       "      <td>16.0</td>\n",
       "      <td>517.0</td>\n",
       "      <td>SKU_24</td>\n",
       "      <td>RETAILER_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>2638.28</td>\n",
       "      <td>107.0</td>\n",
       "      <td>5404.0</td>\n",
       "      <td>SKU_24</td>\n",
       "      <td>RETAILER_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>195.73</td>\n",
       "      <td>8.0</td>\n",
       "      <td>352.0</td>\n",
       "      <td>SKU_24</td>\n",
       "      <td>RETAILER_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SKU_34</td>\n",
       "      <td>RETAILER_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>SKU_34</td>\n",
       "      <td>RETAILER_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SKU_34</td>\n",
       "      <td>RETAILER_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>16.27</td>\n",
       "      <td>5.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>SKU_34</td>\n",
       "      <td>RETAILER_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>17.40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>SKU_34</td>\n",
       "      <td>RETAILER_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SKU_34</td>\n",
       "      <td>RETAILER_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SKU_25</td>\n",
       "      <td>RETAILER_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>12.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>SKU_25</td>\n",
       "      <td>RETAILER_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>12.77</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>SKU_25</td>\n",
       "      <td>RETAILER_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>764.46</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3299.0</td>\n",
       "      <td>SKU_25</td>\n",
       "      <td>RETAILER_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>125.61</td>\n",
       "      <td>5.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>SKU_25</td>\n",
       "      <td>RETAILER_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>622.44</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1528.0</td>\n",
       "      <td>SKU_25</td>\n",
       "      <td>RETAILER_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>67.88</td>\n",
       "      <td>3.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>SKU_25</td>\n",
       "      <td>RETAILER_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>SKU_226</td>\n",
       "      <td>RETAILER_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>SKU_73</td>\n",
       "      <td>RETAILER_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SKU_74</td>\n",
       "      <td>RETAILER_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>SKU_74</td>\n",
       "      <td>RETAILER_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SKU_75</td>\n",
       "      <td>RETAILER_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>SKU_75</td>\n",
       "      <td>RETAILER_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>SKU_76</td>\n",
       "      <td>RETAILER_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>3.32</td>\n",
       "      <td>2.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>SKU_77</td>\n",
       "      <td>RETAILER_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SKU_77</td>\n",
       "      <td>RETAILER_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SKU_140</td>\n",
       "      <td>RETAILER_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SKU_140</td>\n",
       "      <td>RETAILER_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SKU_140</td>\n",
       "      <td>RETAILER_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>SKU_140</td>\n",
       "      <td>RETAILER_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SKU_140</td>\n",
       "      <td>RETAILER_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>SKU_140</td>\n",
       "      <td>RETAILER_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SKU_140</td>\n",
       "      <td>RETAILER_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SKU_141</td>\n",
       "      <td>RETAILER_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SKU_141</td>\n",
       "      <td>RETAILER_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SKU_141</td>\n",
       "      <td>RETAILER_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>SKU_141</td>\n",
       "      <td>RETAILER_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SKU_141</td>\n",
       "      <td>RETAILER_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>SKU_141</td>\n",
       "      <td>RETAILER_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SKU_141</td>\n",
       "      <td>RETAILER_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SKU_110</td>\n",
       "      <td>RETAILER_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>SKU_110</td>\n",
       "      <td>RETAILER_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SKU_110</td>\n",
       "      <td>RETAILER_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SKU_110</td>\n",
       "      <td>RETAILER_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SKU_110</td>\n",
       "      <td>RETAILER_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SKU_111</td>\n",
       "      <td>RETAILER_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>SKU_111</td>\n",
       "      <td>RETAILER_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SKU_111</td>\n",
       "      <td>RETAILER_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SKU_111</td>\n",
       "      <td>RETAILER_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>44.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>SKU_13</td>\n",
       "      <td>RETAILER_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>1952.80</td>\n",
       "      <td>75.0</td>\n",
       "      <td>3049.0</td>\n",
       "      <td>SKU_13</td>\n",
       "      <td>RETAILER_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>72.68</td>\n",
       "      <td>3.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>SKU_13</td>\n",
       "      <td>RETAILER_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>8170.03</td>\n",
       "      <td>320.0</td>\n",
       "      <td>10994.0</td>\n",
       "      <td>SKU_13</td>\n",
       "      <td>RETAILER_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>420.28</td>\n",
       "      <td>15.0</td>\n",
       "      <td>562.0</td>\n",
       "      <td>SKU_13</td>\n",
       "      <td>RETAILER_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>8203.84</td>\n",
       "      <td>314.0</td>\n",
       "      <td>35316.0</td>\n",
       "      <td>SKU_13</td>\n",
       "      <td>RETAILER_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>1284.61</td>\n",
       "      <td>51.0</td>\n",
       "      <td>929.0</td>\n",
       "      <td>SKU_13</td>\n",
       "      <td>RETAILER_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>5623.42</td>\n",
       "      <td>221.0</td>\n",
       "      <td>11620.0</td>\n",
       "      <td>SKU_13</td>\n",
       "      <td>RETAILER_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>556.67</td>\n",
       "      <td>22.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>SKU_13</td>\n",
       "      <td>RETAILER_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>26.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>SKU_47</td>\n",
       "      <td>RETAILER_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>971.77</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1502.0</td>\n",
       "      <td>SKU_47</td>\n",
       "      <td>RETAILER_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>25.90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>SKU_47</td>\n",
       "      <td>RETAILER_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>6114.23</td>\n",
       "      <td>250.0</td>\n",
       "      <td>9631.0</td>\n",
       "      <td>SKU_47</td>\n",
       "      <td>RETAILER_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>454.81</td>\n",
       "      <td>16.0</td>\n",
       "      <td>522.0</td>\n",
       "      <td>SKU_47</td>\n",
       "      <td>RETAILER_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>5113.35</td>\n",
       "      <td>228.0</td>\n",
       "      <td>28128.0</td>\n",
       "      <td>SKU_47</td>\n",
       "      <td>RETAILER_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>533.73</td>\n",
       "      <td>22.0</td>\n",
       "      <td>518.0</td>\n",
       "      <td>SKU_47</td>\n",
       "      <td>RETAILER_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>3019.22</td>\n",
       "      <td>123.0</td>\n",
       "      <td>7309.0</td>\n",
       "      <td>SKU_47</td>\n",
       "      <td>RETAILER_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>201.56</td>\n",
       "      <td>8.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>SKU_47</td>\n",
       "      <td>RETAILER_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>17.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>SKU_102</td>\n",
       "      <td>RETAILER_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>388.45</td>\n",
       "      <td>15.0</td>\n",
       "      <td>717.0</td>\n",
       "      <td>SKU_102</td>\n",
       "      <td>RETAILER_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>37.37</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>SKU_102</td>\n",
       "      <td>RETAILER_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>2026.86</td>\n",
       "      <td>77.0</td>\n",
       "      <td>2903.0</td>\n",
       "      <td>SKU_102</td>\n",
       "      <td>RETAILER_3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date    Sales  Units    Stock      SKU    Retailer\n",
       "0   2014-02-06     0.00    NaN     -0.0  SKU_126  RETAILER_5\n",
       "1   2014-02-06     0.00    NaN      0.0  SKU_126  RETAILER_6\n",
       "2   2014-02-06     0.00    NaN      0.0  SKU_126  RETAILER_7\n",
       "3   2014-02-06     0.00    NaN      0.0  SKU_126  RETAILER_8\n",
       "4   2014-02-06     0.00    NaN      0.0  SKU_127  RETAILER_0\n",
       "5   2014-02-06     0.37    0.0      4.0  SKU_127  RETAILER_5\n",
       "6   2014-02-06     0.00    NaN      0.0  SKU_127  RETAILER_6\n",
       "7   2014-02-06     0.00    NaN      0.0  SKU_127  RETAILER_8\n",
       "8   2014-02-06     0.00    NaN      0.0  SKU_128  RETAILER_6\n",
       "9   2014-02-06     0.00    NaN      0.0  SKU_128  RETAILER_7\n",
       "10  2014-02-06     0.00    NaN      0.0  SKU_128  RETAILER_8\n",
       "11  2014-02-06     0.00    NaN     -0.0  SKU_129  RETAILER_5\n",
       "12  2014-02-06     0.00    NaN      0.0  SKU_129  RETAILER_6\n",
       "13  2014-02-06     2.19    0.0      0.0  SKU_129  RETAILER_7\n",
       "14  2014-02-06     0.00    NaN      0.0  SKU_129  RETAILER_8\n",
       "15  2014-02-06     0.00   43.0    141.0   SKU_14  RETAILER_0\n",
       "16  2014-02-06    29.49    1.0    143.0   SKU_14  RETAILER_1\n",
       "17  2014-02-06     0.00    NaN     11.0   SKU_14  RETAILER_2\n",
       "18  2014-02-06  3897.33  151.0   8562.0   SKU_14  RETAILER_3\n",
       "19  2014-02-06   212.07    8.0    347.0   SKU_14  RETAILER_4\n",
       "20  2014-02-06  2954.65  222.0   6982.0   SKU_14  RETAILER_5\n",
       "21  2014-02-06   -12.36   -1.0      1.0   SKU_14  RETAILER_6\n",
       "22  2014-02-06  1774.70   97.0   3626.0   SKU_14  RETAILER_7\n",
       "23  2014-02-06   346.94   19.0     19.0   SKU_14  RETAILER_8\n",
       "24  2014-02-06     0.00   23.0    170.0   SKU_24  RETAILER_0\n",
       "25  2014-02-06   802.14   30.0   1066.0   SKU_24  RETAILER_1\n",
       "26  2014-02-06    52.87    2.0     45.0   SKU_24  RETAILER_2\n",
       "27  2014-02-06  4371.35  172.0   7983.0   SKU_24  RETAILER_3\n",
       "28  2014-02-06   458.66   16.0    526.0   SKU_24  RETAILER_4\n",
       "29  2014-02-06  4307.16  161.0  22196.0   SKU_24  RETAILER_5\n",
       "30  2014-02-06   416.93   16.0    517.0   SKU_24  RETAILER_6\n",
       "31  2014-02-06  2638.28  107.0   5404.0   SKU_24  RETAILER_7\n",
       "32  2014-02-06   195.73    8.0    352.0   SKU_24  RETAILER_8\n",
       "33  2014-02-06     0.00    NaN      0.0   SKU_34  RETAILER_0\n",
       "34  2014-02-06     0.00    NaN      1.0   SKU_34  RETAILER_3\n",
       "35  2014-02-06     0.00    NaN      0.0   SKU_34  RETAILER_4\n",
       "36  2014-02-06    16.27    5.0     86.0   SKU_34  RETAILER_5\n",
       "37  2014-02-06    17.40    1.0     58.0   SKU_34  RETAILER_7\n",
       "38  2014-02-06     0.00    NaN      0.0   SKU_34  RETAILER_8\n",
       "39  2014-02-06     0.00    NaN      0.0   SKU_25  RETAILER_0\n",
       "40  2014-02-06    12.00    1.0     18.0   SKU_25  RETAILER_3\n",
       "41  2014-02-06    12.77    1.0     63.0   SKU_25  RETAILER_4\n",
       "42  2014-02-06   764.46   28.0   3299.0   SKU_25  RETAILER_5\n",
       "43  2014-02-06   125.61    5.0     63.0   SKU_25  RETAILER_6\n",
       "44  2014-02-06   622.44   25.0   1528.0   SKU_25  RETAILER_7\n",
       "45  2014-02-06    67.88    3.0     91.0   SKU_25  RETAILER_8\n",
       "46  2014-02-06     0.00    NaN      3.0  SKU_226  RETAILER_7\n",
       "47  2014-02-06     0.00    NaN      3.0   SKU_73  RETAILER_5\n",
       "48  2014-02-06     0.00    NaN      0.0   SKU_74  RETAILER_0\n",
       "49  2014-02-06     0.00    NaN      3.0   SKU_74  RETAILER_5\n",
       "50  2014-02-06     0.00    NaN      0.0   SKU_75  RETAILER_3\n",
       "51  2014-02-06     0.00    NaN      1.0   SKU_75  RETAILER_5\n",
       "52  2014-02-06     0.00    NaN      3.0   SKU_76  RETAILER_5\n",
       "53  2014-02-06     3.32    2.0     26.0   SKU_77  RETAILER_5\n",
       "54  2014-02-06     0.00    NaN      0.0   SKU_77  RETAILER_6\n",
       "55  2014-02-06     0.00    NaN      0.0  SKU_140  RETAILER_0\n",
       "56  2014-02-06     0.00    NaN      0.0  SKU_140  RETAILER_1\n",
       "57  2014-02-06     0.00    NaN      0.0  SKU_140  RETAILER_2\n",
       "58  2014-02-06     0.00    NaN      4.0  SKU_140  RETAILER_5\n",
       "59  2014-02-06     0.00    NaN      0.0  SKU_140  RETAILER_6\n",
       "60  2014-02-06     0.00    NaN      1.0  SKU_140  RETAILER_7\n",
       "61  2014-02-06     0.00    NaN      0.0  SKU_140  RETAILER_8\n",
       "62  2014-02-06     0.00    NaN      0.0  SKU_141  RETAILER_0\n",
       "63  2014-02-06     0.00    NaN      0.0  SKU_141  RETAILER_1\n",
       "64  2014-02-06     0.00    NaN      0.0  SKU_141  RETAILER_2\n",
       "65  2014-02-06     0.00    NaN      7.0  SKU_141  RETAILER_5\n",
       "66  2014-02-06     0.00    NaN      0.0  SKU_141  RETAILER_6\n",
       "67  2014-02-06     0.00    NaN      2.0  SKU_141  RETAILER_7\n",
       "68  2014-02-06     0.00    NaN      0.0  SKU_141  RETAILER_8\n",
       "69  2014-02-06     0.00    NaN      0.0  SKU_110  RETAILER_0\n",
       "70  2014-02-06     0.96    0.0      2.0  SKU_110  RETAILER_5\n",
       "71  2014-02-06     0.00    NaN      0.0  SKU_110  RETAILER_6\n",
       "72  2014-02-06     0.00    NaN      0.0  SKU_110  RETAILER_7\n",
       "73  2014-02-06     0.00    NaN      0.0  SKU_110  RETAILER_8\n",
       "74  2014-02-06     0.00    NaN      0.0  SKU_111  RETAILER_0\n",
       "75  2014-02-06     0.00    NaN      6.0  SKU_111  RETAILER_5\n",
       "76  2014-02-06     0.00    NaN      0.0  SKU_111  RETAILER_6\n",
       "77  2014-02-06     0.00    NaN      0.0  SKU_111  RETAILER_8\n",
       "78  2014-02-06     0.00   44.0    303.0   SKU_13  RETAILER_0\n",
       "79  2014-02-06  1952.80   75.0   3049.0   SKU_13  RETAILER_1\n",
       "80  2014-02-06    72.68    3.0     87.0   SKU_13  RETAILER_2\n",
       "81  2014-02-06  8170.03  320.0  10994.0   SKU_13  RETAILER_3\n",
       "82  2014-02-06   420.28   15.0    562.0   SKU_13  RETAILER_4\n",
       "83  2014-02-06  8203.84  314.0  35316.0   SKU_13  RETAILER_5\n",
       "84  2014-02-06  1284.61   51.0    929.0   SKU_13  RETAILER_6\n",
       "85  2014-02-06  5623.42  221.0  11620.0   SKU_13  RETAILER_7\n",
       "86  2014-02-06   556.67   22.0    349.0   SKU_13  RETAILER_8\n",
       "87  2014-02-06     0.00   26.0    193.0   SKU_47  RETAILER_0\n",
       "88  2014-02-06   971.77   36.0   1502.0   SKU_47  RETAILER_1\n",
       "89  2014-02-06    25.90    1.0     49.0   SKU_47  RETAILER_2\n",
       "90  2014-02-06  6114.23  250.0   9631.0   SKU_47  RETAILER_3\n",
       "91  2014-02-06   454.81   16.0    522.0   SKU_47  RETAILER_4\n",
       "92  2014-02-06  5113.35  228.0  28128.0   SKU_47  RETAILER_5\n",
       "93  2014-02-06   533.73   22.0    518.0   SKU_47  RETAILER_6\n",
       "94  2014-02-06  3019.22  123.0   7309.0   SKU_47  RETAILER_7\n",
       "95  2014-02-06   201.56    8.0    173.0   SKU_47  RETAILER_8\n",
       "96  2014-02-06     0.00   17.0    165.0  SKU_102  RETAILER_0\n",
       "97  2014-02-06   388.45   15.0    717.0  SKU_102  RETAILER_1\n",
       "98  2014-02-06    37.37    1.0     38.0  SKU_102  RETAILER_2\n",
       "99  2014-02-06  2026.86   77.0   2903.0  SKU_102  RETAILER_3"
      ]
     },
     "execution_count": 645,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://drive.google.com/uc?id=17FVoLMgvnQSXhHXQsK8URL0SWrpUlpto'\n",
    "\n",
    "data = pd.read_csv(url)\n",
    "data.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Units</th>\n",
       "      <th>Stock</th>\n",
       "      <th>SKU</th>\n",
       "      <th>Retailer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>-12.36</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>SKU_14</td>\n",
       "      <td>RETAILER_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>SKU_52</td>\n",
       "      <td>RETAILER_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>-5.75</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>SKU_51</td>\n",
       "      <td>RETAILER_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>SKU_51</td>\n",
       "      <td>RETAILER_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>-6.06</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>SKU_51</td>\n",
       "      <td>RETAILER_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114133</th>\n",
       "      <td>2017-10-19</td>\n",
       "      <td>-2.99</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>SKU_122</td>\n",
       "      <td>RETAILER_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114167</th>\n",
       "      <td>2017-10-19</td>\n",
       "      <td>-9.67</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>SKU_43</td>\n",
       "      <td>RETAILER_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114169</th>\n",
       "      <td>2017-10-19</td>\n",
       "      <td>-8.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>SKU_43</td>\n",
       "      <td>RETAILER_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114190</th>\n",
       "      <td>2017-10-19</td>\n",
       "      <td>-3.04</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>SKU_31</td>\n",
       "      <td>RETAILER_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114195</th>\n",
       "      <td>2017-10-19</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>SKU_41</td>\n",
       "      <td>RETAILER_5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2613 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Date  Sales  Units  Stock      SKU    Retailer\n",
       "21      2014-02-06 -12.36   -1.0    1.0   SKU_14  RETAILER_6\n",
       "114     2014-02-06  -0.58   -0.0    1.0   SKU_52  RETAILER_5\n",
       "127     2014-02-06  -5.75   -0.0    1.0   SKU_51  RETAILER_6\n",
       "134     2014-02-06  -0.29   -0.0  251.0   SKU_51  RETAILER_4\n",
       "136     2014-02-06  -6.06   -0.0    2.0   SKU_51  RETAILER_6\n",
       "...            ...    ...    ...    ...      ...         ...\n",
       "114133  2017-10-19  -2.99   -0.0    1.0  SKU_122  RETAILER_4\n",
       "114167  2017-10-19  -9.67   -0.0   42.0   SKU_43  RETAILER_1\n",
       "114169  2017-10-19  -8.78    0.0   63.0   SKU_43  RETAILER_3\n",
       "114190  2017-10-19  -3.04   -0.0   40.0   SKU_31  RETAILER_5\n",
       "114195  2017-10-19  -0.90    NaN   14.0   SKU_41  RETAILER_5\n",
       "\n",
       "[2613 rows x 6 columns]"
      ]
     },
     "execution_count": 646,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['Sales'] < 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fact that we have negative Sales and Units is strange but I will leave it due to the fact that negative Sales could mean amortization fees for an item and/or purchase of this item (in case if we have negative Units -> we buy instead of selling).\n",
    "\n",
    "No need to drop NA values as for prediction we will use the sum of all sales. Thus, we make a dataframe which is grouped by the weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Date'>"
      ]
     },
     "execution_count": 647,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJcAAAHgCAYAAAAYFow2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAEAAElEQVR4nOz9eZQk+Vkfen9/GZF77Wsv1dPLdE/PvmhmpJGENtC+IAG2hEELNiDb7LavbXy4r8UrWz4C35d7ERfLCBAgkEFIlpDQNhJCG2hGUs9o9qW7p6e3qq4tq7Jyz4jIiPePiF9kZuUWmZVbVH4/58yZ7qwtu5aoiCee5/sIy7JARERERERERETUicCgnwAREREREREREfkXi0tERERERERERNQxFpeIiIiIiIiIiKhjLC4REREREREREVHHWFwiIiIiIiIiIqKOsbhEREREREREREQdUwf9BLptbm7OOnbs2KCfBhERERERERHRvvHQQw9tWpY1X+9l+664dOzYMZw5c2bQT4OIiIiIiIiIaN8QQlxq9DKOxRERERERERERUcdYXCIiIiIiIiIioo6xuERERERERERERB3bd5lLRERERERERER7pes6rl69ikKhMOin0leRSARLS0sIBoOe34bFJSIiIiIiIiKiXa5evYrx8XEcO3YMQohBP52+sCwLiUQCV69exfHjxz2/HcfiiIiIiIiIiIh2KRQKmJ2dHZnCEgAIITA7O9t2txaLS0REREREREREdYxSYUnq5N/M4hIRERERERER0ZD6wAc+gFtuuQW333477rzzTnz3u99t+Lo/8zM/g0996lN9fHY2Zi4REREREREREQ2hBx54AJ///Ofx8MMPIxwOY3NzE5qmDfpp1WDnEhERERERERHRELp27Rrm5uYQDocBAHNzczh06BDe//73495778Wtt96K9773vbAsq+ZtH3roIbziFa/A3Xffjde97nW4du0aAOBDH/oQbr75Ztx+++34yZ/8ya48T3YuERERERERERE18f/92yfx1Eqqq+/z5kMTeN9bbmn6Oq997Wvx/ve/HzfccANe/epX4x3veAde8YpX4Jd+6Zfwn//zfwYAvOtd78LnP/95vOUtb3HfTtd1/PIv/zI++9nPYn5+Hp/4xCfwG7/xG/joRz+KD37wg3j++ecRDoeRTCa78m9hcYmIiIiIiIiIaAiNjY3hoYcewre//W18/etfxzve8Q588IMfxPj4OH77t38buVwOW1tbuOWWW6qKS88++yyeeOIJvOY1rwEAlEolHDx4EABw++2346d/+qfxtre9DW9729u68jxZXCIiIiIiIiIiaqJVh1EvKYqCV77ylXjlK1+J2267DX/wB3+Axx57DGfOnMGRI0fwm7/5mygUClVvY1kWbrnlFjzwwAM17+8LX/gCvvWtb+Fv//Zv8YEPfACPP/44VHVv5SFmLhERERERERERDaFnn30W586dc//+yCOP4PTp0wDs/KVMJlN3O9zp06exsbHhFpd0XceTTz4J0zRx5coVvOpVr8Jv/dZvYWdnB5lMZs/Pk51LRERERERERERDKJPJ4Jd/+ZeRTCahqipOnjyJj3zkI5iamsKtt96KAwcO4N577615u1AohE996lP4lV/5Fezs7MAwDPzar/0abrjhBrzzne/Ezs4OLMvCr/zKr2BqamrPz1PUSxT3s3vuucc6c+bMoJ8GEREREREREfnY008/jZtuumnQT2Mg6v3bhRAPWZZ1T73X51gcERERERERERF1jMUlIiIiIiIiIhqoK1s53Pa++3FuLT3op0IdYHGJiIiIiIiIiAbquY0M0kUDFzazg34q1AEWl4iIiIiIiIhooHbyOgCgoJcG/Eyq7becai86+TezuEREREREREREA5Vyikt5bXiKS5FIBIlEYqQKTJZlIZFIIBKJtPV2ao+eDxERERERERGRJ8PYubS0tISrV69iY2Nj0E+lryKRCJaWltp6GxaXiIiIiIiIiGigkjmnc0k3B/xMyoLBII4fPz7op+ELHIsjIiIiIiIiooGSnUv5IepcIu9YXCIiIiIiIiKigRrGsTjyjsUlIiIiIiIiIhqonSEM9CbvWFwiIiIiIiIiooHiWJy/sbhERERERERERAPFsTh/Y3GJiIiIiIiIiAaKxSV/Y3GJiIiIiIiIiAZGL5nIOVlLHIvzJxaXiIiIiIiIiGhgZNcSwEBvv2JxiYiIiIiIiIgGpqq4pJsDfCbUKRaXiIiIiIiIiGhgZHFpPKwyc8mnPBWXhBC/KoR4QgjxpBDi15zHZoQQXxVCnHP+P+08LoQQHxJCnBdCPCaEeEHF+3mP8/rnhBDvqXj8biHE487bfEgIIZp9DCIiIiIiIiLaH3ZydnHpwGSExSWfallcEkLcCuDnAbwQwB0A3iyEOAng1wF8zbKsUwC+5vwdAN4A4JTz33sBfNh5PzMA3gfgRc77el9FsejDzseQb/d65/FGH4OIiIiIiIiI9gHZuXRgMsJAb5/y0rl0E4DvWpaVsyzLAPBNAD8O4K0A/sx5nT8D8Dbnz28F8DHL9iCAKSHEQQCvA/BVy7K2LMvaBvBVAK93XjZhWdaDlmVZAD62633V+xhEREREREREtA/I4tLiRISB3j7lpbj0BICXCSFmhRAxAG8EcATAomVZ15zXWQWw6Pz5MIArFW9/1Xms2eNX6zyOJh+jihDivUKIM0KIMxsbGx7+SUREREREREQ0DNzOpYkIioYJ07QG/IyoXS2LS5ZlPQ3gtwB8BcCXATwCoLTrdSwAPf3qN/sYlmV9xLKseyzLumd+fr6XT4OIiIiIiIiIumgnryMWUjAeUQEABYPdS37jKdDbsqw/tizrbsuyXg5gG8BZAGvOSBuc/687r74Mu7NJWnIea/b4Up3H0eRjEBEREREREdE+kMzpmIoGEQkqAMDROB/yui1uwfn/dbDzlv4XgM8BkBvf3gPgs86fPwfg3c7WuPsA7DijbfcDeK0QYtoJ8n4tgPudl6WEEPc5W+Levet91fsYRERERERERLQP7OR1TESDiMriEkO9fUf1+Hr/WwgxC0AH8IuWZSWFEB8E8NdCiJ8FcAnA253X/SLsXKbzAHIA/jkAWJa1JYT4LwC+77ze+y3L2nL+/AsA/hRAFMCXnP8AoNHHICIiIiIiIqJ9IJXXMRkNIhKyi0sF3RzwM6J2eSouWZb1sjqPJQD8SJ3HLQC/2OD9fBTAR+s8fgbArV4/BhERERERERHtDzt5HUdnY27nUoGdS77jaSyOiIiIiIiIiKgXdpzOJY7F+ReLS0REREREREQ0MMm8hqlYENGQXaJgoLf/sLhERERERERERANRNEoo6CYmo0GEVXYu+RWLS0REREREREQ0EDt5HQDssbgQM5f8isUlIiIiIiIiIhqIlFNcmqjIXGJxyX9YXCIiIiIiIiKigajqXJKB3sxc8h0Wl4iIiIiIiIhoIJI5u7g0FQu5Y3F53RzkU6IOsLhERERERER7djmRw9efXR/00yAin6nsXAqrzrY4jsX5DotLRERERES0Z3/wrefwq3/5g0E/DSLymcrikhAC0aDCzCUfYnGJiIiIiIj2bCNdRLpowLKsQT8VIvIRWVyaiKgAgEgwwMwlH2JxiYiIiIiI9iyR1WBZHGchovbs5HWMh1Woil2eiAYVHkd8iMUlIiIiIiLas0SmCADIFnlRSETe7eR0TESD7t8jIY7F+RGLS0REREREtGebGQ0AkC0aA34mROQnO3kdkxXFJWYu+ROLS0REREREtCcFvYSMU1TKsLhERG2oV1ziWJz/sLhERERERER7kshq7p9zDOIlojbUFJdCCgO9fYjFJSIiIiIi2hOZtwRwLI6I2rOT1zEVKxeXwqqCvG4O8BlRJ1hcIiIiIiKiPUlkyp1LWY3FJSLyLlmnc4mZS/7D4hIREREREe3JBjuXiKgDBb0EzTCrtsVFgwEWl3yIxSUiIiIiItqTys6lTJEXhUTkzU5eBwAGeu8DLC4REREREdGeJDJFhFT70iLHziUi8qhecSnCQG9fYnGJiIiIiIj2JJHVsDAeRkgNIMPMJSLySBaXKgO9o0EFRcOEaVqDelrUARaXiIiIiIhoTzYzRcyOhTEWVpHjWBwReZTM1elcCioAgILBY4mfsLhERERERER7spnRMBcPIR5WGOhNRJ41ylwCwNE4n2FxiYiIiIiI9iSRKWJuLIx4SEWGxSUi8qhZcalgmAN5TtQZFpeIiIiIiKhjpmlhK6thdiyEeFhFjt0GROSRLC6NR6oDvQF2LvkNi0tERERERNSxVEGHYVqYHQsjFlLYuUREnqXyOiYiKpSAcB9zO5d0Fpf8hMUlIiIiIiLq2GamCACYGwvZgd7cFkdEHiVzGiYrNsUBFZlLLC75CotLRPuEUTLxyTNXuLKTiIiI+mozowEA5sbCiIVUZLktjog82snrVXlLABAN2WUKjsX5C4tLRPvEP5zfxL//1GN4+PL2oJ8KERERjZCEU1yaHQthLMyxOCLyrl5xKayyc8mPWFwi2ifkXcMsK/xERETUR4msPRY3Gw87gd4sLhGRN/U7l5i55EcsLhHtE9tZu7jEgzARERH102ZGgxDAdCyIeFiFXrJQNHg+QkSt7eQNTEZDVY8x0NufWFwi2ie2cnZxqWiYA34mRERENEo2M0VMx0JQlQDiTsdBjrlLRNSCZVnYyWu1nUsy0JsTGb7C4hLRPsHOJSIiIhqERKaIuTG78yAWVgGAuUtE1FJeL0EvWQ3H4vI6b5r7CYtLRPvEllNcKrK4RERERH2UyGiYjYcBAGNOcSnL3CUiamEnrwNAnUBvZ1scr2t8hcUlon1iy+1cYoWfiIiI+ieR1TDrdC7FZXGJY3FE1IIsLk3FqotLQghEggFOZPgMi0tE+0Q5c4kHYSIiIuqfzUwRc2N255LMXMpyLI6IWtjJ1e9cAuzcJWYu+QuLS0T7xDY7l4iIiKjPCnoJ6YLhZi7JzqUcx+KIqIVkg7E4wC4usXPJX1hcItoHSqblHpx5ECYiIqJ+kWP5s27nkgz05vkIETXXKHMJACIhhZlLPsPiEtE+sJPXYVn2nwsciyMiIqI+SWSc4lJcdi5xLI6IvEk5xaUJdi7tCywuEe0D8q4hABQ5FkdERER9spktAqjoXOK2OCLyaCevIyCAcee4USkaZOeS37C4RLQPbOfKxaWCweISERER9YfsXJKZS2E1ACUg2LlERC3t5HVMRIMIBETNy6IhBnr7DYtLRPuA7FwSgplLRERE1D+bGbtzSW6LE0IgHlKQZeYSEbWQzOl185YAIKwqyHMiw1dYXCLaB2RxaX4sjCI7l4iIiKhPEpkiIsEAYiHFfSweVtm5REQt7eQbF5eiIWYu+Q2LS0T7gCwuHZyK8iBMREREfZPIaJiNhyFEeawlHlaZuURELTUtLgUDvK7xGRaXiPaB7ayGaFDBVDSIIg/CRERE1CebWc3NW5LsziWejxBRc6mmxSUGevsNi0tE+8BWTsNMPISwGkCBs8lE1KHf/NyT+PITq4N+GkTkI4lM0d0UJ9mZS+xcIqLmmnUuRRjo7TssLhHtA9tZu7gUCSooGjwIE1Fn/ur7l/GNZ9cH/TSIyEc2M8X6nUu8KCSiJizLajEWp6BomDBNq8/PjDrF4hLRPrCV0zEdDyESZOcSEXWmoJdQ0E22oBORZ5Zl2ZlL7FwiojZltRIM02rcuRS0lwQUeOPcN1hcItoHtrMaZmJBRIIKD8BE1JFkTgcA5NhtQEQepfIGDNPCbLxe5hKLS0TU2E7ePu9o1rkEgKNxPqIO+gkQ0d5tZTVMx0NQA4JbFYioI9s5e+skjyFE5NVmtggAmNvVuTTGbXFE1MKOc1NrKta8uFQwOJXhF+xcIvK5olFCpmhgJiYzl0xYFmeTiag9snOJdwiJyKtExi5K7y4uxUIqCroJo8SLQiKqT3YuTTQJ9AZ4XuInnopLQoh/I4R4UgjxhBDiL4UQESHEcSHEd4UQ54UQnxBChJzXDTt/P++8/FjF+/lPzuPPCiFeV/H4653Hzgshfr3i8bofg4jK5AXhtBPobVmAxpM5ImrTTt6+SORYHBF5tZmxO5dmawK97YvCHDshiagBr2Nx7Kj2j5bFJSHEYQC/AuAey7JuBaAA+EkAvwXg/7Ys6ySAbQA/67zJzwLYdh7/v53XgxDiZuftbgHwegD/QwihCCEUAL8P4A0Abgbwz5zXRZOPQUSOrax9QTgTDyGs2j/SDPUmonZtO4VqnsQRkVeJhsUlO3mDuUvepQq6OyZENArkTa2WmUs8L/ENr2NxKoCoEEIFEANwDcAPA/iU8/I/A/A2589vdf4O5+U/IoQQzuN/ZVlW0bKs5wGcB/BC57/zlmVdsCxLA/BXAN7qvE2jj0FEju3K4pJzEC7yIExEbWKgNxG1a9MZi5uJsbi0V7/xmSfwK3/1g0E/DaK+adm5FLJLFRyL84+WxSXLspYB/F8ALsMuKu0AeAhA0rIs+RvjKoDDzp8PA7jivK3hvP5s5eO73qbR47NNPkYVIcR7hRBnhBBnNjY2Wv2TiPaVrVy5uBRxOpeKDL4jojYlnTuIvENIRF4lskVMx4JQlepLijFnLC5b5PHEq410ARvp4qCfBlHfpPIGAsJeAFBPWGXnkt94GYubht11dBzAIQBx2GNtQ8OyrI9YlnWPZVn3zM/PD/rpEPWV7FyadgK9AY61EFH7klkn0JvHDyLyaDOt1YR5A3agN8DOpXboJYuZmTRS0gUd45Eg7IGlWtEQr2v8xstY3KsBPG9Z1oZlWTqATwN4KYApZ0wOAJYALDt/XgZwBACcl08CSFQ+vuttGj2eaPIxiMixlS2v8SwXl3hyQkTtkZ1LmmGiZHLjZLvWUwVuxqKRk8gWa/KWgHInQpbjLJ5phgmNnec0QtIFA+OR+l1LAAO9/chLcekygPuEEDEnB+lHADwF4OsA/onzOu8B8Fnnz59z/g7n5X9v2XvRPwfgJ51tcscBnALwPQDfB3DK2QwXgh36/TnnbRp9DCJybGWLmIioCCoBN9C7aPAgTETtSVYEybJ7qT05zcAr/vs38LlHVwb9VIj6KpHRMFu3c0mOxbFzySu9ZEJngZpGSKqgYyJSP28JqAj0ZpHaN7xkLn0Xdqj2wwAed97mIwD+I4B/K4Q4Dzsf6Y+dN/ljALPO4/8WwK877+dJAH8NuzD1ZQC/aFlWyclU+iUA9wN4GsBfO6+LJh+DiBxbOR0zcfuuITuXiKhTVcUlnsi1JVM0kNdLWGdeCo2YzUwRc/HGnUsZFpc8Y+cSjZpUq86lkMxc4s+FXzT+alawLOt9AN636+ELsDe97X7dAoB/2uD9fADAB+o8/kUAX6zzeN2PQURl21kN025xya4Xs32UiNqVzGsIKgJ6yWJxqU16yR4jLPIEmEaIZphIFYy6nUtyW1xOY3HJK63E4hKNllRex9J0rOHL5UQGu6n9w8tYHBENsa2shtndnUsciyOiNiVzOg5MRgDwRK5dunNBqJX4eaPRkcjanXr1Ar3lOEuG2+I800smihyLoxGSLhiYiDbudRFCIBIM8Ka5j7C4RORz2zkN0zG7uORmLvHuORG1Ia+VUDRMHJyI2n/niVxbZE4Kj700ShIZewlAvUDvQEAgHlKQ41icZ3Iszo6dJdr/0i0ylwC7UM1uav9gcYnIxyzLwlZWq81cYucSEbVBboo7OGV3LnGUpT1yfTjXiNMo2czIzqXa4hIAxMIqsjyWeCbHa+X/ifYz07SQLhqYaJK5BNjFJXYu+QeLS0Q+ltftbgM3c0lloDcRtU+GeR+ctDuXeCLXHnkxyLwUGiVu51K8diwOsEO9ORbnnSxOc2McjYKsZsCygPEWnUuRkMJuah9hcYnIx+SJ3Ywci2OgNxF1YDvndC7JzCWNFzftcMfiWFyiEeJmLo3XLy7FwxyL88qyLLc4zSI1jYJ0wT42NNsWB7BzyW9YXCLyMXlBKDuX3MwlnpgQURt23M4ljsV1QudFIY2gzYyGsBpA3FkXvlsspCLD4pInhlkeheN4LY2CVME+75iIeshcYnHJN1hcIvKxrazTuRS3D8xCCITVAIo8CBNRG5J5+yTv0BTH4jqhuZ1L/LzR6NjMFDE3FoYQou7Lx8Iqcgzi9aRyFI5FahoFnjuXQgz09hMWl4h8THYuzVTkHUTYPkpEbZLHkgNyLI7HkLbIzCV2jZLfPXx5G3e+/ytIOGHdzSQyWt1NcVIspCDLziVPKgtKPI7QKEg7nUutMpfCqoI8s2R9g8UlIh/bytoHZpm5BNijcQz0JqJ27OR0hNUApp1jCbsN2sPMJdovnlxJIZnTcXkr1/J1E9kiZuONi0t2oDeLS15o7FyiEZPK28eGltviQgonMnyExSUiH9vOalACoqqlNBJUOJpBRG1J5nRMxYJQAvZoLTuX2iOLS7woJL/bchaFpAqti0LbWd0tSNcT51icZ7L70f4zjyO0/3ntXIoGeU7iJywuEfnYVk7DdCyIQKCcdxAJsnOJiNqzndMwFbUvEqMhBQVeELZFFpXYuUR+J0dkd5wctmZSeb1pGG88pDjrxq2Gr0O2ysI0A71pFKTa2BbH4pJ/sLhE5GPbWa3mrmEkqKDAziUiakMyb3cuAfaJHLsN2iO7DjQee8nnEs6ikFSL4lLJtJAuGphsVlwKq7AsZrh5wUBvGjWpgo6QGkAkWH/bpBRhoLevsLhE5GOJrIbpXXkH9rY4npgQkXc7uYriUoh3CdvljsWx44B8bitrB3m36lxKe1gjHgvbHQnMXWqtqnOJxSUaAemC0TJvCbBveBUNE6bJDkg/YHGJyMe2s1pVmDfAziUial/VWFyQdwnb5QZ6s7BPPpdwM5eaF5dk8alZ59JY2O5IyBZ5PGmlsjDN8VoaBemC0TJvCYDb2cRrG39gcYnIx7Zz9TqXFGYuEZFnlmXZY3Hx8lgcO5fao7FzifYJmbnUaizOS3EpHrK7ErLsXGpJZ+YSjZhUXvfcuQSAN718gsUlIp8yTQvbOb1mDXAkGODKTiLyrKCb0AyzKtCbxaX26Ibdrs/OJfIzy7Kw5WYuNS8IyZe3ylwCWFzyorKgpLNziUZAuqB76lyKup1L/LnwAxaXiHwqXTBQMq26nUtsqSYir2SnQmWgN+8QtoeZS7QfpIuGG07fKnNJvnwi2rjzQBaXuCCgtapAbx5HaASkCkbLTXGAHegNsHPJL1hcIvKpLeeCcCZeXfWPBAMosOuAiDxK5uyLxGkGendMXhiWTAsGLwzJp7adriXAe3Gp+VicfVHIQO/WNMOq+DOPIeRvn31kGVe2ck1fJ13QMdFO5xLPS3yBxSUin5Kt69P1Ar15ACYij5J5+1gy6YzFxbj2t20auw5oH0g45xUTEbUrgd4ci/Ou6hjC4hL5WNEo4dc+8Qj+4ruXmr5e2mPnkpu5xGsbX2BxicinZHFppk7mEueSicgr2bkkx+IiHItrW+VIC3OXyK+2nE1xx+fHWnYupQo6gopwL/zqcYtLPJ60xEBv2i/WU0VYVnnzZD16yUROK2GiSXFaiobscgXPS/yBxSUin9pu0LkUVhWOZhCRZ+WxuIrOJd4hbIvGC0PaB+RNq+OzMaTyOizLavi6O3l7pEUI0fB15FgcO5daqypQ8wYh+dhaqgCgfDypJ1OwjwleOpfCKjuX/ITFJSKfKmcu1XYuAdyqQETe1Av0Nkyr6mKHmpMhyABHWsi/5HnFsbk4TKt5VtJOXm86EgcAqhJAWA0gq7G41ErVtjgee8nH1lJFAOUx23rSbnHJS+cSM5f8hMUlIp/azmoIqwHEQtUt6REG3xFRG3byOsJqwD12yP9zw5N3WlXXAT9v5E9bznnFwckIAHubUyOpvO5ppCUeVtm55EFV9yML1G37zc89iU98//Kgnwah3LmUyBQbvo7MdJtoI3OJ1zX+wOISkU9tZTXMxEM1Lelh1f6xZls1EXmRzGlV47WxkH2yxxM57yrzUnjsJb9KZDTMxkNuR9JOrnHuUspD5xIAxMMKskUeS1qR3Y/RoMLiUge+8Pg1fOvs5qCfBgFYS7cei5PFJU+dSzLQmze8fIHFJSKf2t51QSixc4mI2rGd092ROIDhmZ1gXgrtB1vZIqbjIXc9eLONcTteO5dC7FzyQhaU4mGVxaUO5IoGchy/HArrzlhcTis1vBZJt5G5JMfi8lyW4QssLhH5lOxc2k0G37G4RERe7OSqOxCiHItrGzOXaD/YyumYiYfcolGzjXF25lLrC8N4WGXmkgd6yYQSEIiGAlwK0CbTtJDTS9xKOCRWdwrunxvlLqWcY4uX7kc5kcFAb39gcYnIp7ZzOqbrFJfcQG9W+InIg2S+ugsy6ozF8UTOO61kIqRwJJn8bStbrBqLSzUoLlmWhVTB8DgWp3IszgO9ZCKoCISUAAvUbSoYJVgW2Lk0JNbSBfdapFHuUjudS0IIRIIB3jT3CRaXiHwqkSliJlZ7Yic7lxgqS0Re1IzFcbS2bXrJRDxsf954YUh+tZXRMBMPt+xcyhQNlEzLW3EppHAszoOiYSKoBBBU2LnULlm8zLGIORTWU0WcPjABoHHnkiwujYVbF5cA+7yE5yT+wOISkQ/pJROpgtG0c6nIziUiasGyLOzkdExVdi5xLK5tesnEmHMHloV98qOCM1Y0Ew9iPKxCiMbb4uTjEx7CeLktzhu9ZCKsBhBW2bnULtmxxN9Zg5cpGsgUDdx8cByAXbCuJ1XQEQ8pUBVvpYhoUGEOpE+wuETkQ0lng8ts3eISuw6IyJu8XoJWMncFeivuy8gb3bAQd8YJeWFIfrSdsy8CZ+JhBAIC42G14Vic3CLnpXNpLKwyC8cDzelcCrG41DbZucRsr8FbT9l5SzcdtDuXGm2MSxd0T5vipEhI4TmJT7C4RORD8iSwfueSU1zi3XMiamHbuUicitYWlwq8IPRML5ludgQvDKkXskUDmw3yS7ohkZHFJfu8YiIabFxcaiOMN+aMxVmW1fJ1R5mdueQUlzgW15ZsRecSv88Ga83ZFHdyfgwhJYDNbOPMJS95SxLH4vyDxSUiH5J3AmZi9bbFcSyOiLxJOoXq+mNxvAvslVYyEQ/LsTgee6n7fvvLz+Adf/BAz96/PK+YHbOPBZPRYMPMJfn4hMdAb8O0WDBpQS9ZCKkBBnp3QI5dlkyLx98BW3M6lxYnI5iJh5qOxXk5fkjRIDuX/ILFJSIf2s566FziQZiIWpDjLZVjcTF3LI4n6V7pJdMNJuWFIfXCxUQOz21ke5Y74nZEO4XmiUgQqUL94pJ83GugNwBujGuhyLG4jlVmLTF3abDc4tKEU1xqEujdTudShJlLvsHiEpEPbeWq29cryUDvAk9OiKiF7TrFJdn9mGfnkmd6yXKLSwz0pl6QF2kXE9mevH85FiezHJt1LqXa7FwCwFDvFvSSiZAiuC2uA5XfW+y4Hay1VBHxkIKxsIrZsVDTbXFtZS4FFd7w8gkWl4h8SHYuVV4QSmGVnUtE5E0yX92tAABCCLagt0k3TERDCoRg5xL1RsLJW3p+szfFpa2sBiUg3G6kiaiKVL7+hfpOXocQwLiHNeKy6Mqw5eb0kmmPxbFzqW3sXBoea+kCFiciAOwb4IkGmUupvI6JdjKXQgqKPCfxBRaXiHwomdMRCyluIamSEhAIKoJz50TUUrLB1qcYN7O0RZMXhkqAx17qOsuysOncVOpVcSmR1TAdCyIQEABaZy5NRMqv20yMnUueyG1xYQZ6t62ycMnvs8FaTxWwMBEGAMzGw3UzlyzLartzKRoM8JzEJ1hcIvKhVME+sWskonKrAhG1lsxpiAQDblabFAkqvAPcBnukxe46YHGJui1TNNxulgsbvSkubWe1qg7GiUgQeb1Ut4smldcxEfXWdTAWZuaSF3pFgZqdS+3JFdm5NCzWUkW3c2l2LISsVqq5HikaJrSS6fkYAjDQ209YXCLyoVTeaHpQDgcVFDibTEQtJHN61QWlFA2xQO1VybRgWnC6DhQWl6jrKkNxn9/M9OxjVOY4Tjpj9/VCvXfyuqcwbwCIhdi55IVWshjo3aHKziUWlwbHsiyspqrH4gDUhHrLY0pbmUshBnr7BYtLRD7UsnMpGGCoLBG1lGxwkRjjiZxnujPC4o608MKQumzTGS05PBXt4VhcEbNj1Z1LQDm8u1I7xSWZuZRhcakpzSi53Y8ci2tPdecSv88GZSevQzPMlsWldMH+GrWVuRS0b9yYptWlZ0u9wuISUYXtrIaza+lBP42WWq3wDKsBFNm5REQtJHNa3cUAHIvzTnOLS4J5KdQTMsz77qPT2M7p7lKPbqrpXHKKR/Vyl9opLsltcTyeNKeXLITUAIJKACXTQokX0Z5lNAPxEMcvB20tZR+nFp3MpTmnWL2ZqQ71drdNtrktDgAKvHE+9FhcIqrwu187h3/y4e8M/S/1VEFvugI4EuRICxG11nAsjscQz3SnU0lueuJGG+o2uc773mPTAIDnE93tXiqZFpJ5HTOVmUvO6H2qUNsJkioYni8MY85FPzuXmtNLJoKKQEgNuH8nb3JFA/PjdkGDnUuDs5YqAEBF55L9NWnUudTsJvluUVlc4o3zocfiElGFC5tZpAoGzq/3JtOgW1L5VmNxCqv7RNRSMq/X7Vzitjjv9JJ9M4KbnqhX5MXZ3UdnAADPdznUO5nTYFnoSedSWA1ADQhe9Lcgt8WFFPvSjNlt3mW1kltcYufS4LjFpXFvY3HtbYuzi0s8Lxl+LC4RVbi6nQMAPHolOdgn0kR5hSfH4oioc5ZlIZnTMBmt37nEMRZvKjOXQjz2Ug9sZooYC6s4tTgGJSC6nrskL/5mxsLuY40ylwrOBrlm3dOVhBCIhRRe9LegOdviwk7nErPbvMtpdiddSA0gp7OIOSjraXv8bcEZi5uIqAgqwu28lGSgdzvb4iJOBySzIIcfi0tEDsuysJLMAwAeuZoc7JNpIq+XYJhW67E4di4RURM5rQS9ZGG6TucSt8V5V525pLBziboukdEwOxZCUAnguplY14tL8uJvNl45Fle/c0n+3WvnEmCHenMsrjm9ZLqB3gB4HGlDrlhCLKwiHlKqwr2pv1Z3CpiMBt18JCEEZuIhNzNOSnewLa48Fsev77BjcYnIkchq7izvMHcupfJyy0LzbXGcSyYaHv/zm8/h8as7g34aVZLORWK9sbhokNvivJIdBvLCkJs6qdsS2aI7YnJ8Lo4LXS4uyYDwyvy1SFBBSA24XQaSG8bbRnEpHlY5FteCOxbHzqW2ZZ1A71hIRZbfZwOzlirggJO3JM3Ew3XH4gICbgi7FxyL8w8Wl4gcV7ftrqUbD4zjmdX00F5YlSv+jdtJIyq7DoiGRUEv4YNfegafeujKoJ9KFXlBWXcsLqQgp5dgWcO93GAYVI3FKQFeFFLXJTIaZp1w3ONzcVzczHZ1JbfbuTRWfSyYjAZrxuI66VyKhVVk2FHSUMm0YFpwt8UBLC61I1csIRZSEQ+zc2mQ1tJFdyROmo2Hasfi8jrGI0EIITy/70jQ/rkY1mszKmNxicix7BSX3nTbQZRMC0+uDFeXgVSeVW58YhcOBhgGSTQk5LitXNM7LORFYqOxOMtiqKwXbnFJDfDYSz2RyGruWu/jc3Hk9RLW0oWuvf+tOp1LgJ2ZIrulpc7G4hTkOBbXkCwkVQZ6c1ucN5Zl2Z1LYQXRkIocb6wOzHqq4G6Kk2biobqdS+1sigPgjtqxc2n4sbhE5FhO2mHeb7z9IADgkSEdjSuPxTUL9GbnEtGwWEnaF4Grqe5dDHZDMifH4uoHegPMN/BCM+S2OMHOJeo607SwldXcrqITc3EA3d0Yt5XVMB5R3ZEsaTIa7ErmUizEzKVmKnPb5NeARWpvioYJ07K/x+zMJX6fDYJpWlhPF7G4q3PJzlzaHehttJW3BNg3vACek/gBi0tEjqvbeYxHVFw/P4bDU1E8OmT5KFLKQxBeJKhwYxHRkJCdS+tDVlzaztknfI0ylwBwY5wHssMgpNidSywuUTft5HWUTAszcixu3i4udTN3aSuruZlOlSbqFJfczKU2Og/GwszCaUYeQ8IqM5faJYuW8bDMXOLvrEFIZDWUTKumc2luLIRM0ajKIkwV9LaOHwBvePkJi0tEjuXtPJamYwCAO45M4pEr2wN+RvWlCk7nUpMVnpFgAFrJRKmLmQxE1JllWVxKF7uak7JXzToQ5F1CtqC35haX1ABCisKOA+oqmVcix+IWxyOIBpWuboxrVFyajAZrAr13ZPd0W4HezMJppnIsLsxtcW2R31du5hKLmAOx5tw8WxivDfQGUDUal+6kc0mOxbF4OPRYXCJyLCfzODwVBQDcsTSFK1v5mvWZw6B817BJ5pJqH4R554to8GTnkmFa2MppLV67f5I5DdGg4mYZVOKJnHeVgd7sXKJuk+chMtA7EBA4NhfvanEpkdUwW69zKVJ/LC4eUtzgaS/iHItraneBGuD5m1eyI87dFsci5kDI4lK9sTgAVaNx6U46l9wbXvy5GHYtfzMIIU4LIR6p+C8lhPg1IcSMEOKrQohzzv+nndcXQogPCSHOCyEeE0K8oOJ9vcd5/XNCiPdUPH63EOJx520+JJz4+EYfg6jbLMvC1e08lqad4tKRKQDAY0M4GpcuGAgpgboXhJLcqsD2UaLBk51LALC6Mzyjcds5ve5IHMDOpXZoJZm55GyLK5lD1aFG/lZvk9uJLheXtpt1LuX1qq2RO3m9rbwlAIiHVRQNEwa7ceqqLFAHVXuDFotL3shOpXhYRSykIM/OpYGQC0sOTFZ3LsnjVuXGuFReb6vzEYDb0cdzkuHXsrhkWdazlmXdaVnWnQDuBpAD8BkAvw7ga5ZlnQLwNefvAPAGAKec/94L4MOAXSgC8D4ALwLwQgDvqygWfRjAz1e83eudxxt9DKKuSuUNZIqGW1y67fAkAmI4Q71TBb3pSBxQ3qpQMHgQpt5aSxVw5uLWoJ/GUFtJlgvX613c8LRXyZxeN8wbAGIhdi55pRvVmUsAR1qoe8qdS+Wf1eNzcVzeynVlo5hl2YHh03Uzl1SYFqq6jnY6uDCUxxPm4dRX5La4jslOpXhYsQO99RKL+wOwlipACGBurLpzSR63trL2ccw0LWSK7W+LE0JgPKwiOUTd31Rfu2NxPwLgOcuyLgF4K4A/cx7/MwBvc/78VgAfs2wPApgSQhwE8DoAX7Usa8uyrG0AXwXweudlE5ZlPWjZt0Y+tut91fsYRF111dkUJ8fi4mEVNyyO49GryQE+q/pSeb3pSBxQ7lxiqDf12h988wJ+7mNnBv00hpZpWljZKeAF19n3UuTdvWGwk9cw1eAikWt/vXO7DlThXhgyd4m6Rd7xn95VXCqZFq5s5fb8/jNFA1rJrDsWJzuUZNaj/ef2i0tjYftCMsvRuLp0p/uRgd7tk51LsZCKWFiFZfHG6iCspwuYjYdrxmXlOK8ci8tqBkyrebRHIycWxnB+PbP3J0s91W5x6ScB/KXz50XLsq45f14FsOj8+TCAKxVvc9V5rNnjV+s83uxjVBFCvFcIcUYIcWZjY6PNfxKRvSkOAA473QWAnbv06JVkVTv4MLCD8JpX/GXmEn/BUq9tZYs1YxNUlshq0AwTdxyZghA+Gotj5pJn1ZlLzEtpV8m08PHvXuLnrIFERsNULFh10SY3xnVjNE4G7crg3UryAnAnV85dSnU4FgeAYcsNVB5DZHGpyM4lT9zOpZCKuOyQY+5S362lijV5S4Dd/agGhHucSTuF6nY7lwDghoUxnF1jcWnYeS4uCSFCAH4UwCd3v8zpOOrplUWzj2FZ1kcsy7rHsqx75ufne/k0aJ9alsWlqYri0pEpbOd0XO7CncFu8nLXsJy5xJMT6q1Uwb4LxU6N+mTe0tGZGGbjYR+Nxdknfuxcaq0ycynsdi7x8+bVI1e28RufeQLfPsebg/UkssWarqITc90vLjXvXCoXlzrJXJIXknLTHFUrb4sTCDPQuy1u51JYQVT+3uJNkb5b3SlgcSJS87gQAtPxkNu5VC4utd+5dMPiODYzxarNczR82ulcegOAhy3LWnP+vuaMtMH5/7rz+DKAIxVvt+Q81uzxpTqPN/sYRF21nMwjGlSqAi3vODIJYPhylzyNxcnOJV4YUo/J7YU5nszVJTfFHZqKYnEiPDRjcZZlIZnTWnYu8evamrvpSeFISyfkNrLtnN7iNUfTZkbD7K4ck6lYCNOxIC50sbhUP3PJ6VzK76245Bap8vwa16NVbovjMaQtMserqnOJHXJ9t54u1O1cAuzCtRzvlYXqVtmx9dxwYBwAcHYt3eGzpH5op7j0z1AeiQOAzwGQG9/eA+CzFY+/29kadx+AHWe07X4ArxVCTDtB3q8FcL/zspQQ4j5nS9y7d72veh+DqKuubudweDoKZ1EhAOD04jgiwQAevTJcG+NSBaPlQVmOZrCbhHpNnihw3KE+WVw6PBXF4kRkaMbisloJhmk1zlwKceOkV3pl14HKQO92yTvZDGqtbyur1e0qOj4Xx/Mbey8uJbx0LjlFIb1kIqeV2s5LkR2SyTy/xvXoFYHeQYXb4tqRLRoQwu7Yj3H8ciD0konNjFa3cwmwN8bJQO+0c87YWefSGADgHItLQ81TcUkIEQfwGgCfrnj4gwBeI4Q4B+DVzt8B4IsALgA4D+APAfwCAFiWtQXgvwD4vvPf+53H4LzOHzlv8xyAL7X4GERdtZzMV43EAYCqBHDb4Uk8cmV7QM+qvnRBb3lQlhc4vDCkXpMXhuxwqW85mcdYWMVEVMXiRGRoxuLkhfx0g7G4kBKAEhAcL/BAL5kQAlACopyXwpFkz+QxZIddLXUlMkV3nXel43NjXc5cat25JItMk212HcgidpLdaXVVdi6pSgABwW1xXmWLJcRDKoQQzFwakI20XThqVFyaiYe7krl0YCKC8bCKZ1lcGmqevrKWZWUBzO56LAF7e9zu17UA/GKD9/NRAB+t8/gZALfWebzuxyDqtuXtPO5Ymqp5/I6lKXzswUvQS2bNBoRBKBolFHQTEy0OynLTE4tL1Gsci2tueTuPQ1MRCCGwOBHGZkYbiuPJdta5SGwwFieEQDSo8OvqgVayEFQCEEK4yxTYueQdi0uNGSUT2znd3bhU6cR8HP/74avIFg03MLsT21kNYTWAmHNhXmk8rEKI8rY4+TVqdNxoZILFpaYqR2sBu8jEY4g3Oc1wv3dlViA7l/prLWXfNGs6FudkLslzxk62xQkhcMOBcYZ6D7nBXy0TDVi2aGA7p1dtipPuODIFzTDx7OpwVMnlSbjXQG/ePadeMkqmm3eQ44rpulZ28jjkdEXKu3ryLt8gbTot6nNj9U8GAbtIzUDv1vSSWXVRCPDY2w45JsHCQ60tp8Nwrm7nkh3qfTGxt+6lRFbDTDxUFQsgBQIC42HVvSB0i0ttZi4pAYGJiMoCYgO64SwFcI4fISXAsTiPsloJY05xVRaZeFOkv2SW5MJ4o86lENJFA0Wj5BaqO+lcAuzRuHNraW4oHmIsLtHIW07WboqT7jwyBWB4Qr29tpNG3Mwl/oKl3pHfjwBP5hpZSRYqikt2IWc1NfjRuM20LC7VH4sD7BN1dj+2Znei2Rfm5cwlft68yjiF6SQLDzXKI2u1ReDjXdoYt+UUlxqZiAbd4pK8MOyk62AqFmKuVgPFUjm3DQBCqsLMTI9yRQOxsNO5FJaB3jz+9lO5c6lx5hJgd0ynCwZCSsC9TmnXqYVxbOd0bGQGf5OO6mNxiUbe8rZdXFqajtW8bGk6itl4CI8OSXHJaztpOXOJJyfUO5XFJW5nqZXXStjKam7hWp54rQ9BcUmG+DbrXLLH4vh1baVyzJGdS+1zx+JYeKghR0nqZS4dm3WKS3sM9W5VXJqMBt2Oo047lwBgKhZkAbEBGegdVuwL7rDKziWvsprhjsPF5VgcO6n7ai1VgBoQdZcCAOVlAYlsEamC3tGmOOm0szHuHEfjhhaLSzTyrm7nANiFpN2EELjjyNTQdC6VV3i2Gotj5hL1nvx+BMDg5zpWdqq7ImVxSbaQD9Jmumhv16mTsyJFQgryLJK0pBmWW1zitrj2ybE4jkzV2sw07jCMhhQcmox0pXOp0UUhYN/MShX2XlyqLFJRNXm8CKp251JQETyGeJTTSm6QdzTIzqVBWEsVsTAeRiBQO1oLlDsvExkN6YLR0aY46ZSzMe4sQ72HFotLNPKuJvMIKQHMN7iDf8fSFM5vZNwT4EHyOhYXdDY9FTgWRz2UqrhQ4MlcLdkVKcfiZmIhBBUxFGNxiayGubFw3ZwVKRZUUODXtSW9ZLodS+xcap/8vcaullpu51KdsTgAOD4fx4UuFJemPXYuud3THXUuhbDDXK26ZOdSZXabzs4lT7JFAzEncykQEIiFFOTZcdtX6+kCFhqMxAHlTZRbWc3ZeN1559L8WBhTsSCLS0OMxSUaeXKbU6OK+82HJmBZwHN7bD3vhna2LITVAC9wqKcqO5fYhl5rJSmLS/ZJVyAgsDAecfMJBmkzU8Rsk5E4wO6MyOn8urZSmbnkFpfYdeBZ5bY402RIa6VEtgglIBp2Ch2fi++pc6lolJApGs07l6IqUnn7a5TK6wipneWlTEU5FteIXjIhhB18DnBbXDuyxXLnEmBnBfJmV3+tpQoNN8UB5c7LRFZDKq93lNkmCSFwwyI3xg0zFpdo5F3dztfdFCfJA+YwbHjyOhYH2KNx7FyiXpIXHACQ4whmjZVkHgFRHXK5MBHG+jCMxWU0zDcJ8wbs4hLHHVurzFwKq/ZFDvNSvEsX7d9rlgWkWaSuspXVMB0LNbz5dXxuDDt53Q3+btd21v7c1wsMl3ZnLnUyEgc4mUs5jQXEOorOMUR2knJbnHeVmUsAEAupvNnVZ2upYsMwb8C+Ia4EBLayRWcsrvPOJcDeGHeWG+OGFotLNPKWk/m6m+Kk+fHhKS6lCwYCAlV3aRqJqAEGelNPyWKnEhA8matjOVnAgYmIW3gAgMUh6VxKZIoNR22kaFDhMcSDomHWZC5xU6d3mYLhZn9xbKraZkZrutHx+nk71Pu5jc7u4iey9nlN021xkSDyegmaYe6puDQZDcK0gAxHlmrohoVwxe+JEAO9PbEsy85cCrNzaVAKegk7eb1pcSkQEJiOhSoyl/ZaXBpHumAMRcQA1WJxiUZaQS9hI12suylOktuU1tODP4il8jrGI8GmOSlSJMhVttRbqYIBIeyW5xxP5mosJ3Nu3pK0OBEe+AmRaVp25tJ4i84lbovzRC+Z5awU5/+8MPTGsiykC4a7UCOZ58a4SolMse6mOOnU4t42J8mOp6bb4mJ2MSlV0PdcXAJYQKxHL5kIqpXFJYWjtR4UDRMl06rqXIqHVXbc9pG8WbYw3vxm1Ww8ZI/FFfY2FgfYxSUAHI0bUiwu0UiTmSjNOpeCSgAz8dBQdC6lCobnFZ4hNcBtcdRTqbyO8bCKsbDK4lIdK8lCbXFpMoJ0wRho0WYnr6NkWi07l2IhBXkeQ1rSS5a75SkQEAgqgoV9j4qGCcO0cMS5wZNk4aFKIqs1/Tk9NBlBPKR0HG7rpbgkLwRTed25MOys62AqZn8Mfo1raUY5tw0AQopggdoDed4xFq4ci1OQ5U2Rvrm8ZW/cPjDZuHMJAGbH7OuonFba07Y4oFxcOsdQ76HE4hKNtGVZXGqSuQTYFfn1ISgupQs6xsPeDsqRoMLiEvVUqmB30sVCKjtcdjFNC9d28rXFpXH7BGyQuUvuevMWdxojzlgcM1Kaq8xcAuzcJV4YeiNHa2XnElfVV9vKaE0LP0IInFwYw/n1vXUuNQv0djuO8nvrXJpyOqDYnVarcuMk4GyLY+dSS1lnHD+2K9A7V+S5b7985ck1RIIBvOC66aavNxMP4VLCXj7g9SZ5s/c1NxbCs6ssLg0jFpdopMlV4Ustikvz4+Hh6FzKe+9cigS5LY56y/5+DDLjoI7NTBF6yaopXMtcgkGOxm06683nmlxQAnagNwAuBmhBM6qLSyE1wMwlj+SmODmazm1iZQW9hHTRaJq5BAAnF8Zxbr3zzqWAQNOCkTznSBUM7OT2UFxy3o6dS7W0XQVqBnp7IzuX4hWdS/GQys6lPjFKJr70xDX88I0LVV+DembjIWw7P/t77VwC7O6lsx0W1am3WFwacf/p04/jbx9dGfTTGJir23koAYEDTYLogCEqLrUxq2xnLvECh3on7YxIxLhVrIbbFTlVfWw5MGl3Cw0y1Ft2Ls2OtR6LA8CvbQu7uw7CDOP1LOMUl47MOJ1LOXa1SG5XUYuf01OLY1hLFTvq+trMFDETb7yNDigXnpI5Demi0Xnmktu5xOLSbppRzm0DGOjtlSwiVXUuhRWO6ffJd5/fwmZGw5tvP9TydSs3Uu410Buwi0vn1tLsrB5CLC6NuL/5wTK+dXZj0E9jYJaTeRyYiEBVmv8oyOLSoNde2lsWvJ3YhbktjnrMzgALIhbmncLdZHFp91jcwsTgx+ISciyuRUdEJOgUlzhe25ResmouDJm55I3sXJqJhxELKRyLq5DItB5ZA4BTC2MA0NFo3HMbWRydjTd9HXlD6+p2HpYFTOw50JsFxN3qjcVpHItrSY6/7e5c4ph+fTnNwP/4xnl3nHCvPv/YCmIhBa86vdDydSsXE+w10Buwi+o5reSea9HwYHFphGmGibxeGumLwuXtfMu8JQBYGI9AK5kDP/FN5fU2xuIUjrNQT9nbC1XEguxc2m2lQXFpPKwiGlQG3Llkj8LIgN1GokF2LnlhZy5VhvGy68CrtJO5NBZWMRkN+nJk6tEryZ78PCeyssOwVXHJDrc938Fo3HPrGZycH2v6OrKYdHU7V/X3doVVBbGQ4suvca/pJWvXWBxz27zI1MlciobsrMASO1pqfPWpNfz2l5/F737t3J7fl14y8aUnVvHqmxbdEfpmKovk3ehcOi1DvTscCabeYXFphMmTuuwIB99d3c5hqcmmOGneCb4d5GhcybSQLhrex+JUBnpTb8kxzXhY7dqdsP1iJVnAeFit+XkVQmBxIjzQzKVEtoiZeBhKk1EYoGIsjseRpmoCvYMsLnmVdo4b4xGnuOTDzqWf/bPv479+4emuv99y51LzsbjD01FEggGca3Mt93ZWQyKr4eRC8+JSJKggpAZwZcsumHc6FgfYuUt+/Br32u5tcUGV2+K8kB1K8VB151Lly6jsyZUUAOCj//D8njet/eP5TSRzOt58+0FPr1+5mKA7nUt2cenZVeYuDRsWl0ZYymlHH9UDsF4ysZoqeOxcsk/uBrkxTmZTeK34R4IczaDeMU0LmaI9Fhflyvoay8nGXZGLE5GBjsVtpLWWI3FAuXOJ+RXN1QR6Kzz2eiXH4iYiQUzFgtjxWVdLQS9hM6Phgec2Ox6bf+C5RN3NYF47l5SAwPXzYzjX5ljc+Q379VsVlwC7oHTF6VzaS3FpMhYaeAf4MNJKJkJqufsjrNhjcYOOYhh2cpFILFyduQTw91Y9Tyzv4MRcHLGQgvd97sk9fX99/rFrGA+reMXpeU+vXzUWt8dtcYB9HFqcCO+5SEbdx+LSCEs5v+AzI9q5tLpTgGm13hQHDEfnklzZ7LUlPRxk5xL1TkYz7PyNiIp4SIFesnintcLydr5mJE5anIhgLT3YzqW5FiHBABBh55InesnaFejNkRavZAd1PKxgMhr0XeFBFok3M1rbxR3Azkn6Z3/4ID72wKWalyUyGkJqAGMttjABdrhtu5lL8vW9FJcmIqq7XXcvXQdTUf8VEPvBDvSuGK11jid6icWlZnJO5+NYuF7nEn9vVbIsC0+upPCiE7P4P153Gt95LoEvPH6to/dVNEq4/8lVvOaWRYTV1iNxQHWgt5djmhf2xjgWl4YNi0sjTBYrRrVz6eq23OYUa/m65c6lwV0QusUlz2NxdqA373xRL8jitN25ZJ8oMJunbGUnj0NT9bdQLk6EsbpTGNjPZiKjteyGAMpjcQV+XZuqyVxSA9zU6VGmYCAWUqAqAUxFQ0jm/RX2XDne+sBzibbf/qlr9pjKFx6r3dqbyGqYjYcgRPPxVcAuEC0n824GjRfn1zOIBAM47CEaYDIahOFk2Mitb52wRx/99TXuh3qB3gAY6t1CVitBCDsGQpK/tziqX205mcdOXscthybw0y86ilsOTeC/fv7pjj5P3z67iXTBwFs8bImTpqJBBATc43032BvjMszXGjIsLo2wVN4+oIzqAdhdFe6hc2ksrCISDAy2c8n5enltJw07Iy08OWktWzRGemtiJ9zvR6dzCcBILweolC0aSOb0pp1LRcN0P4f9tpnx1rnEsbjWTNOCYVaH8Ya5Lc4zewOq/TttKua/QG8Z5B1UREfFpbOr9l33hy8ncW2neutRIlP0VAQGyhvjnmuje+n8egYn5sYQaJG9BlR3TO8pc8mHX+N+2J3bJrdPsgOyuVzRQCyoVH0Px9i5VNcTy3Yh+9bDk1ACAu9/661YTRXwe39/vu339YXHr2EyGsRLT855fptAQGAmHupK3pJ0w+IYioaJK1u5rr1P2jsWl0ZYasQDvWWLd6PugkpCCCyMRwaauZRut3PJuTAs6Dw5aeWzj6zg3R/9HrazvKPqVWUnndwUwpM5m7xIbNQRsDhhH3MGMRqX0wzktJKni1Z3WxzH4hrSTfv4WnVhqDLQ26t0UXdHJCZjQRQN01fj3LK49MrTC3jw+QTMNu+gP7uWdos1X35itepldudS6yIwUA63PdtG/sj59YynkTigXFBSAsK9mdCJyZgd6M2O6mo1uW1OJw6PI81ltRJiu0asZOYSb3ZVe2plB0pA4MYD9rHi7qPT+Cd3L+GP/+ECntvwXpQu6CV89ak1vP6WA1Xddl7MxENd2RQn3dDBcY96j8WlESaLFXm9NJIthVe3c1gYD3ueF54fDw84c6kcfOpF2DnoF310oj4o8mehnZGCUecG8UaD3M6yS3nktnlxaXWn/8UluYHKU+eSHIvjMaQhmYkSUqozl9i55I3duWT/TpMFDD/lLq2niwirAbz+lgNI5nQ8s9reRc7ZtTR+6NQcTi+O40uP7youeRxfBYAj01GE1IDn3KWcZmA5mfdcXJLnHRMR1dOYXiNT0RA0w+RNr120XbltcsyWxaXmcppRU+x0z0dG9MZ5I0+spHD9fNy98QwAv/6GGxEJKvjNNsK9v/HsBjJFA2++w9uWuEpL0zH3/KcbOimqU++xuDTCKkcyRvGisNk2p3oWxsMD7VwqZ9x43RbHziWv5IUgc1K8c78fI0E344CdS7aVpF00ajwWZxd21lL9Ly5tZuxjmJdtcRGOxbWkG7JzaXfmEo+7XlSNxUXt70k/jU2t7hSwOBHBi6+fBQA8cMH7aFxOM3B5K4fTi+N4w20H8P1LW1h3jgmWZXkO3gcAVQngxFzcc6j4hY0sAG9h3kC58LeXkTjAHosDwNylXfSSWVWgLmcu8djbTLZYcsfgpPL5yOhd1zTz5MoObj00WfXY3FgY/+41N+Db5zbx//nsE3jayYBr5vOPrWA2HsKLT8y2/Rw++BO34f/39jvafrtGxsIqDk9FcXat/WUK1DssLo0wOdYCjOZo3GqqgEOT3otLg+5ckp0iXrcsRIJO5xILJi3JzgwW4ryTx4/xiOq2pfNkzraSzEMJCHcRwG7yzt0gitWbbXQuBZUAgorgWFwTcoV8UK3OXNJ43PUkU6zOXAKAZM4/hYe1VAGLE2Ecmori2Gysrdylc2sZWJY92vGm2w7CsoD7n7S7l3JaCQXdxEzcW+cSYN/FP+dxc5Icg/HcueTc1NpzcSkqv8b+KSD2gz0WVy5Qy85zzRi9qYJ2ZIsG4uHqziXe7Kq1kS5iLVXEzYcmal72zvuO4sfvOoy/+t4VvOF3v403/u638cf/8Hzd652cZuBrT6/j9bce6CiUe2E80tXOJQA4fWDcXYxAw6F7g4/kO6mK1vNRnE1O5fW2tp4sjIexk9dR0EtVbaX9kiroiLexZUGO+7Fg0prsMuD4j3ey83E8ovJkbpeVZB4HJiINf1YjQXvt+iA6lxJO59Ksx46IaFDhFsAm5MKE3YHeXKTgTbqgYzzs77E4ecH24utn8fnHrqFkWlA8hGQ/64xynD4wjuNzcZxcGMMXH1/Fu158zB1fnW2nuLQwhs8/toKcZtR0c+x2fj0DJSBwbDbu6X3Lr83EHotLkzEWl+rhtrjO5DQDU7Hqn5G4c7NrFK9rGnlyZQeAHea9m6oE8DvvuBP/55tvxuceWcanf7CM//L5p/Dfvvg0Ts6PIRpSEA0qiIbsc4G8XsKb29gS12t3H53G3z+zjq2s1lYxnnqHnUsjTGb4AKO3Mc6yLKTyRltbC+adLgQ5VtJvqbze1omd7Fwq8A56S7K7i4U47yqLnW5xaQQ7IOtZTuZbrvdenAgPJHNJHr+8XrTKE0qqr17mkhyLY2hxa+mCgbFIdVdM0ifFJcuysJYq4IBzJ/6+E7NIFww8teLtLvrZ1TQiwQCum4kBAN546wF89/kENjNFbGbl+Kq3IjBgF5csqzzy1sz59QyOzsQ8B/K6mUt77lyyjzs7HItz1ds4GVIY6O1FVivVdC6F1QACgucjlZ50jkn1OpekmXgIP/PS4/jcL/0QvvpvXo73vvwEjs7GMB5RYZgm1tMFrKcLeNmpObzw+Ey/nnpL9x6zn8v3L24N+JmQxM6lEZbK61ACAiXTGrmxuKJhQiuZnvOLALudE7DvVC5Nx3r11BqqzKbwopy5NFpf207IohLHf7xLF8rFzhgDvassJ/O45+h009dZnIhgrQdjcZ88cwXJnI6ff/mJui/fzGgYD6ueuy+jQYU/F03oDTqXLAvOBWPn4cf7Xcm0kNNKNWNxOz7paskU7c2LMkNNZpA8cGETty3Vdgjs9uxaGqcWxt0upzfcdhAf+vvzuP/JVSw65xteA70B4NSiPeJ2bj1dt0Oh0vn1DK73OBIH9CBzySdf436o1/3odi6xuNRUrmi4Ad6SEALxkMpO6gpPruzgupmY5xvqpxbH8R9ff2OPn1V33L40iZASwPef38Lrbjkw6KdDYOfSSEsVdPeO26h1LlWGEXslO5fWUwPqXCrobT3fiDMWV2Q3Tksci2tfZeef7FzK8mQOJdPC6k6hYZi3tDgRccN7u/mxf/v+Z/GRb19o+DqbmWJbF6zRkMriUhNag0BvAAz1biFTkKO19nFkLKxCCQjfhD3LsVaZIbIwEcH183F8x2Pu0rOraXeVNgDceGAcJ+bi+NLjq0g4nUvtjHkcnY0jqAicaxFua5RMXExkPectAeWOpe4FerO4JMkCdbjuWByPvc3YnUu1N11jYYU3uyo8uZLCrYcbdy35WSSo4M4jU+xcGiIsLo2wVN7AgUmnuDRiB2EZRtxOi7cM590Y1Fhcob2xuDDH4jwrB3rzc+VVqqC7HQeyDZ3jU3ZwpmFaHopL9vbJktm90anvPp/ARrqIjXSxYShyIqO1NWoTDQb4dW2ifqA3R1q8cJcCOBeHQghMRoO+yVxac240ya5mwM5d+v7zW+73RSPbWQ3r6SJOHygXeIQQeMNtB/DAhYRbIJqNe/9ZDSoBHPewMe7SVg56ycLJ+f53LkWDCkJKwDdf436Qo7WVnUuyWM1jSHN2vlhtF24spPJmlyNV0HEpkcMth1p3U/rVvcen8cRKauQaJYYVi0sjLFXQcVAWl0ZsLG7HCSOeaGPMbCYeghDAxgBCeIEOxuIY6O2Z27nEEznPKoudsg191IrU9Swn8wCAw9OtO5dKpuV2KHTD3z56zf3z+QYXmO12LsXYudRUo8wlgJs6W8kUy0sBpKlo0DcjU7JzSd6kA4AXn5hDVivh8eWdpm971gnzruxcAoA33HoQJdPCp3+wjHjIDtFtx6mF8YY/+5J8eTudS4sTka5krQghMOGjr3E/lLsfq0drAUArMbetEc0woZes+p1LIQU5FhoAwM2Au6VJ3pLf3XtsBiXTwg8uJwf9VAgsLo0svWQip5Xc4tKotY920rmkKgHMxsOD61zKtzkWJzuXeGHYUtH5HBX5ufIsXTCqirMMfra5xSUPY3FA98Zs9ZKJLz9xDXddNwWgcXEpkW2vcynCbXFNNb0wZLG6qfSusTjA3ibml66WcudS+efpvhN28eWBFqNxsrh044HqC75bDk3gupkYtrKa542OlU4ujOFSItv09748NrSTuRRSA/jzn30RXnBd8yw5L6ZiQQZ6V5BdblXb4hjo3ZK8bqnXucSbXWVPusWl/du5dPfRaQQE8D2Oxg0FFpdGlMw6kBc4mRGr8HeSuQTYuUuDyFyyLAupgtFWAHnYCexl7kdrBWYutW339sJ4mG3oALDiFJcOVnQz1COPvWtd6oT8x/Ob2M7p+Jcvvx7RoFJ3NMYomdjOtXfRGg0x0LuZcqA3M5falXZu8ozt6lzyT3GpgPGwWtU5MTsWxunFcTx4oXlx6dm1NCYiqhsGLgkh8MbbDgJoL29JOrU4BrPFxrjn1jM4OBnBWJ2Oj37wU3daP2hNjiEsLjUmzzd2B3oDduYSb4rYnlzewcJ42M2N3Y/GI0HcdHAC33veW94d9RaLSyNKdu5Mx0KIBAMjt1Uh5RTX2inWAPYdykF0LuX1EkqmVXWHtxV595wFk9aKbuYST+S8kMXOynGWaFBBnncKsZLMYyKitvxZlReVq10qLn3+sWsYD6t41Y3zuH6hfu7KVk6DZQHz7YzFsXOpqbqbnhReGHpRbyxu0keFh7VUAQsTtRdsL75+Fmcubjf9+j+7msbpA+MQonab4BtvszcezbXxcyqdWrDH7M6tpxu+zvmNTFsjcd02FfPP17gf5PdJ3UBvjtY2JPN1YuFGnUv83AEyzHv/di1J9x6bwQ8uJ/l7dwiwuDSiUjJzKBrEWFhl55JHg+pccr9ebRaXhOColxfcFteenGYXOyu/H+NhZeSy2+pZSeZbhnkDwNxYGEKUR2v2omiUcP+Tq3jtLQcQVhU7d2Wt9uIykbFHUdi51D31RlrYNepNqlAncykWahhGP2zWUoWqvCXpvhOzyOslPHo1WfftLMuq2RRX6bbDk7jxwDhONXh5M8fmYlACouFYrGVZeG49g+vbCPPutsloyDfdaf2g1ytQu5lLPIY0IotL9TqXosxcAmCf057fyOzrvCXpRcdnUDTMlnl31HssLo0oN3MooiIWUkfuIJwq6AipAUSC7YVlLoyHsZkpwuzihicvyhlR3juthBAIqwFe4HggC3C8iPamXmZZNKQix88flpMFLLUI8wbsC4m5sTDWu9C59K2zm0gXDLzlDnuc5uTCGFZ2CjU3DTadrktmLnVP3QtDhYHeXqTdbXEVmUvRIFIFo6tbFHtlLVXE4ni94tIMhGicu7SWKiJVMHD6QP3ikRACn/ulH8J/eN3ptp9TWFVwdDbmbpvb7dpOAVmtNASdS/4oIPZDvdw2botrTU5c1M9cUti5BOCZ1TRKpjUSxaV7jtl5d99n7tLAsbg0otzOnWgQ8bCKzIh1HKTyRttdS4DduWSYFrb7fGLknoS3+ZwjQYXdOB6UO5d4IueFDOKt6lzinUIAwPJ2zlPnEmCPxnVjLO5vH13BdCyIl56cAwCcci4cn9vVvVDuXGpnW5wCrWTC4B30unRDrhEvjzeFgxyL8yJTMKAGhLt8Aiivupe/84aVaVpYTxewMFFbXJqKhXDzwQn84/nNum/7bINNcZVCaqDuyJwXpxbGGo7FdbIprtumokFktRJ/Phxa3UBvbotrxe1cqrctLqzypgiAJ1fsLp79HOYtzY+HcWIuju8/z+LSoLG4NKIqOw/iIWUkt8W1m7cEAAvOXcp+5y6Vx+Lae85hNcCCiQeyAFdgp4En5eJ09ba4Uctu2y1d0JEqGJ6LS0dn43hiObWnwk1eK+Hvnl7D62896N75lheOu3OX3M6leBtjcU53Z4EXgnU1uzBk12hz6YKBsYhaVUSZitnFpWHP5NnOadBLVk0gt/TqmxbxvYtbuLBR20F0dtUu/JzuYOzNixsWx3ExkatbvBmK4pLzNeZonE0vyQJ1+RgihEBICbAA14Q836hXXIo7N0VG/fP3xHIKk9Ggp27q/eDeYzP4/sWtvk+XUDUWl0ZUZbEiHlbdOwCjIpXXO+5cArq3PtyremNIXkSCCgsmHsiLQOZTeZOq00kXD6kjV6Te7dqO3YXktbj05tsOYjNTxHdarC1v5u+fWUdOK+Ettx90H7tuJoaQEqjpXtjMaAgqoq3CesQZORj1r20jbuZSxYVhhJ1LnmSK1UsBgIri0pAXHmRW2oE6nUsA8NP3XYdgIIA/+ceLNS97ZjWNhfEwpjvYBufFyYUxlEwLFxO1G+POb2QwFQtitkcf24vJmP2xd/IcjQPKx4nKYwhgF6x5DGksq8nMpdqxuKiTwzTq3UtPrezglkMTHXdB+s29x2eQKhhudygNBotLIypV0BEQ9gVhPDx6s8mpgtF2oQawM5cAYCPd784leTHfXudSRFVQZOdSU0bJhOHc5WCXlzf1OulizDjAcjIPADjssbj0qhsXMB5R8Tc/WO74Y/7toyuYGwvjRSdm3cdUJYAT8/GasbjNTBGz8XBbJ5ox2bmk8WejnvqZSwz09iJd0KvylgA77BnA0GfyrKXtQnK9sTjA7nJ+652H8MmHrtT8W86upRvmLXWD3Bj38KXtmpedX8/g5PzYQC82p6L+6E7rl3pLAeTftdJo/05tJufEecQadC4B5QLUKNJLJp5eTY9E3pL0QuYuDQUWl0ZUKq9jPBJEICDslZ0j1rmUzuttj5gBFZ1L/S4u1cm48SISDLBzqYXKC0DmU3lTr5MuFlKhGaOdzbO83V5xKRJU8KbbDuLLT6521BmULuj4+rPrePPtB6EEqi8Wr18YqxmLS2SKmBtvr2MhKjuX9NH6HeFVvZEWZi55k3LG4irJzKVhH5lac7oUG43FAcDPvuw4CrqJj3/3svtYybRwbr3xprhuuGFxDLcensAHvvA0nts1lvfcemagI3GAf0Yf+6VcoK4+hnMsrjlZOIrWWcwjC06j3HH73EYGmmGORN6SdGQmisWJML7H3KWBYnFpRNmdO/bBdyTH4gp6R51L8bCKeEjpf+dSh9vtwioDvVupKi6xEOdJus4K8XhYFiFG93O4ksxDDQi3CO3F2+46jJxWwlefWmv74/3d02soGibeXDESJ51aGMPlrVzVz/9mRsNsG3lLQPnEfdTHCxopb3oqXxhyW5w3mYJRc5PHL3k8cixuoc62OOnGAxN42ak5/Nl3LrrfJ1e2cijoZs/ylgC7c/EP3nUPQmoA7/3YGTccfTurIZHVBl9cisqxuOH+GvdLsc62OAAIqoLFpSZyWgnRoFJzYwUody6Ncg7kk8spAMCth0enc0kIgRcen8X3L27Bspi7NCgsLo2oVL7cji7H4kblB9GyrI63xQF2G/x6eu8bntrR6fMNBxno3UrlxTc/V96k8jrCagBhtVzslB0uo1yEWEnmcWAyUvdkt5EXHpvBockIPtPBaNznH72GQ5MRvOC66ZqXnVoYh2WhqnMhkSlibqzN4pL8uo5w0bAZvWQiqIiqMSN2LnmTLuo1G1AnfTIytZYuYDYeqhll2u1nf+g41tNFfP6xFQDlTXG9HIsD7O7J3//pF+BiIod/84lHYZoWzjvHgusHXFxyv8YsLgEody6Fd4/FKQG3M5JqZYqGe1Nrt5iTuZQdsU3YlR64kMBYWMXxucH+vPfbC49NYy1VxJWt/KCfyshicWlEpSs6l2IhFSXTGpl8iKJhQiuZHW2LA4D5sXDfO5fShc7G+CJBZWS+rp2Snx8lIHpeGNnJ67jvv30NZ3w+D16v8y/unsyNVhdkpZVkwXOYtxQICLz1rsP49rnNto4ra6kCvnl2A2+54xACdYpZpxbtE0q5HcqyLGxmNMyNtTkWx86lpuziUu1FIcDiUivpgoGxXXkpQSWAsbA69F0t66lCw7ylSq+4YR6nFsbwR99+HpZl4VlnU5z8+eyl+07M4j+/+Wb83dNr+N2vnStvipsf7MXmeESFEMDOkOdq9YveoHMppPL8rZlc0XCLSLvFRnwRRaZo4IuPX8Obbqsdmd/v7j1u5y59z+fn2X7G4tKIShXK29Lkyd2oXBS6a9Q77Fyan+hdcelTD13F6k5tV1SqYGC8gzG+SFDhBrQW5OjKZDTY8zGWlWQeq6mC7zdZ2J101Sd1UbahYzmZx1KbxSUA+PG7DqNkWm53gxcff/ASSpaFn3rRdXVffmw2DiUg3AvKdNGAVjLZudRlesmquShUlQACgoHezViWhUyhdlscYB+Lh75zKVVsmrckCSHwsz90HE9dS+GBCwk8u5bGdTOxhhfF3fbuFx/FP7l7Cb/7tXP4iwcvIRpUPGfC9UogIOyv8ZAXEPtFk5lLdQO9eQxpJKuVEK8T5g2Ux/RHdcnIFx5bQU4r4e33Hhn0U+m7GxbGMRkN4nvPd76Fl/aGxaURlcqXOw9iI3ZRWC+MuB296lxaTxXwf3zyUfze35+reVmqwwDysBpg5lILchRuMhrs+VicLODmfN6q3axzaVSOI7sZJROrqfY7lwDg1OI4bjk04XlrXNEo4ePfvYwfuXEBR2fjdV8npAZwdDaGc2t2cWnTOWbNsnOpq7Q6nUuAnXfHC8PGCrq9pXP3WBxgH4uHfU39aqqAxSZ5S5XedtdhzMZD+ONvP4+zq70N895NCIH/+rZbccfSJJ5cSeHEfLxup2O/TfmggNgvcvQttOs4ElYC0Jjb1lBOM9xspd1k8TY/op1Ln/j+FVw/H8cLrpsa9FPpu0BA4J6j0/j+xdptmdQfLC6NqFTBqOlcyoxI59JOnTXq7ViYCCNdNLp+sSW7Wb761BpMs3rOPl3RadYOe1scL3CakZ1ddnGptydy8mfM7+txK48fUnTE29DX00WUTKuj4hIA/Nhdh/Ho1Z2a7U71fP7Ra0hkNfzMS443fb1TC2M4t24fVxJZ+2KdnUvdpRsmQkrtxXpIDbBrtAkZMr17Wxxgh3oPc+HBKJnYzBSxOOmtuBQJKnjnfUfxtWfW8dxGBqcP9HcsLRJU8D/fdTfmx8O4fWk4NkdNxkLsXHLUWwoAOJ1LPH9rKFssuVvhdouPcObS+fU0Hr6cxDvuPVKVBThK7j42jec3s0hy9HYgWFwaQUbJRKZYkbk0Yis7u9G5BKDr3UtnnQ6D9XQRj1xNVr2scrtfOyIqx+JakcW3qVgQhmnB6GG3gTzR8Xt3Tzqv14yzuNvifP5v69RK0g6PPDTl7YJzt7fccQgBgZbdS5Zl4U+/cxEnF8bw0pOzTV/35MIYLiVy0AwTiQw7l3pBL5k14yyA3TXKzqXG0sXGN3nszqXhLTxsZjRYFjyNxUnvvO8oQmoApoW+di5JByej+Nq/ewXe95Zb+v6x65mKBpm55NBKJkJKoKYQEFQEjyFNNOtcGuWbXX995irUgMCP3bU06KcyMDcs2MfY5zayA34mo4nFpRGUcU/qZOeS4jw+GhcPe81ckiGe3d4Yd24tjfGwCjUgcP+Tq1Uvs8fiOtwWxztfTcni25RTbOzl50uOxfk936zeWFwsONpjcctOcWlpurPOpcWJCF56cg6f+cFy082dD19O4vHlHbznJcda3pU8tTAOw7RwKZHFRsa+kJtvt3MpyM6lZuplLgGyc4nH3kbSBfsYuDvQG3A6l4a4uLSWsn/3ex2LA4D58TB+7M7DAHq/Ka6RiUgQkWD9i/F+G/avcT/phlnTtQTYxxDd4La4RrLFUsPsspAaQFARI5e5pJdMfPrhq/jhGxcwP97e7/r95MS8HRdwwUMnOHUfi0sjKCXHwtzMJeei0OcXvF6lCvLf3/m2OKAXnUtp3HRoAi++fhZfeXLNvcAsGiUUDbNu8GkrEVVBybTcVbdUS4buyvXIvRyNk3fr/V6AsQO9dxWXwqN7pxAoF5cOTnYelvu2Ow/j6nYeD11qnBXwp9+5iPGIih+/63DL93fSWTl+bj3jdi5Nx9vrXAoEBMJqgJ1LDTTOXAqgyONuQ3Isrn7mUgg7Ob1pkXWQVmVxycO2uEr/7nU34P980004PYDOpWHDzKWyRt2PIea2NZXTDLdjup5YSB2Z6xrpa0+vYzOj4R0jGORd6chMDGpA4PlNdi4NAotLI8gdC3OKFaOWubT3ziW7uLTexeKSZVk4t5bBDYtjeO0tB/D8Zra85alQXQxsh7xLya1FjRUqMpcq/94L+6FzqaCXoJXMmuLsqC0G2G0lmcdULNhwe40Xr7/1AKJBBZ9pMBq3lirgS49fwzvuOeLp41w/PwYhgHNrGWxmipiKBesWQlqJhhR2LjWglxplLinsXGoi4/xeq3fTZCoWhFYyPS9YeORKEv/mE4+gZPanGLUui0uT7XUGLIxH8HMvOzGyOSiVJmMhpAp6375mw0yOxe0WUvqbubSZKeLVv/NNnPXJNttmnUsAEA8pI3c+8skzV7AwHsYrbpgf9FMZqKASwHUzMVzgWNxAsLg0gtziyghviwupgY7bw2diISgB0dXOpdVUAemigRsWx/HamxcBwB2N20sxLBK0f8S5Ma4xt3MpZnd09KO45OeftVSDjoOIqkCI0emA3G0lWcChPXQtAUA8rOK1tyzic4+u4NEryZqXf/zBSyhZFt794mOe3l80pGBpOorzGxkkMlrbYd5SLKiwc6kBvUnnErsOGms2FicL/UmPG+O+9MQ1fOYHy9jMdH+Laz1rqSKUgMBsfHTHTvZqKhqEZZU72EaZZjQZre1jcenxqzs4v57B09dSffuYndIME1rJbJi5BNh5sn4+12rXWqqArz+7jp+4ewlqBzeR9psT83Fc2ORY3CB4+u4TQkwJIT4lhHhGCPG0EOLFQogZIcRXhRDnnP9PO68rhBAfEkKcF0I8JoR4QcX7eY/z+ueEEO+pePxuIcTjztt8SDi3dRp9DNqbcueSfQIXH7nOpdqRnnYEAgJzY6GuZi7JMO9TC+NYnIjgruumcP+TawDKJ+GdjMWFVfsXL4tLjdV2LvXuZG4/bItLNdi2GAgIRIOjd6dQWknmO94UV+kXX3USY2EVP/Hh7+D3v37evbNfNEr4+Hcv40duXMR1szHP7+/UwjjOraWxmSlits2ROCkSUpDjMaQuvcmFIdeIN5belf1YSebfeR2burSZAwBsZfsTEL2WKmB+LAwlwA6kTk3F2vsa72dayUSo0VKAPh5DLibsLg8//A6XNzsabYsD7Bvnfj7XatenHroK0wLefs9oj8RJJ+bHcDGRY3fkAHgtbf4ugC9blnUjgDsAPA3g1wF8zbKsUwC+5vwdAN4A4JTz33sBfBiwC0UA3gfgRQBeCOB9FcWiDwP4+Yq3e73zeKOPQXtQzlyyD8phNQAlIEYmK8UOI+58dAWwwzm72bl0zmlDvmHRzkh57c0H8PjyDlaS+T1ttwu7nUu8g96IvDM41cexuJyPw/ObfT/GQqrvAjS79fVe3s53HOZd6YbFcXz5V1+O1996AP/9/mfxzz7yIK5u5/D5R68hkdXwMy851tb7O7UwhgubWaylipjrMOAzFlJQ8NnXtV+0JtviOI7cmOxYGau3La7NwoO8KO5XcWk1VWhrUxzVkjdzhnkrYL/oRv2xuH5vi7uUsIu0figuyaLRWNPMJaVv51pPraTwmt/5Jrb7dAzazbIsfPLMFbzw+AyOz8UH8hyGzfG5ODTDdDf5Uv+0LC4JISYBvBzAHwOAZVmaZVlJAG8F8GfOq/0ZgLc5f34rgI9ZtgcBTAkhDgJ4HYCvWpa1ZVnWNoCvAni987IJy7IetOz0xo/tel/1Pgbtwe6xFiEE4iHFXZO+33W6ea3Swnikq5lLZ9fSmI2HMOuMrbzuFns07itPrlZ0iuwlc2k0vradkBeAsjOMnUvNNRvTjIUU5H30b3v6Wgq3vu9+PHghsaf3kyroSBcNHJpqL+C3kclYEL/3z+7C77z9Djx1LYU3/D/fxu989SxOLozhpSdn23pfJxfGoBkmLm/lMNdh51I0yMylRjSjfuaS3XXA4lIj6YKBWEip2/0zFbW/T70UHizLcotLiT5d2K2nim2HeVM1t3OJxSUn0LvBtrhS/7ou5M+RHzrd5c3w5plLKnJ6f85HvnVuA+fWM7gwoADp7z2/hYuJHLuWKpxwimzPcWNc33npXDoOYAPAnwghfiCE+CMhRBzAomVZ15zXWQWw6Pz5MIArFW9/1Xms2eNX6zyOJh+D9iBVMCAEMF7RThoPq74OGW5HqmB01AVUaX6su51LZ9cyOOV0LQF2O+ephTHc/+RaxVadDrbFBeVYHC9yGinqJYTVgHuS0ssTq8w+yFxyA+brfD/abej++bc9s5qCYVr48Dee29P7kXfGujEWJwkh8OMvWMKXfvVlOH1gHMvJPH7mJcfaDgOWG+MAdJy5FBnhccdWGmUu9TsvxW8yBaPh7zTZubTjIXNpLVV0f79t9StzKV1gcWmPJp0CYjI3mE6PYdJo42RIsbf99mus57LbuTT81wLyZnjTbXFhtW+dSzIE3csxqxc+ceYKxsIq3njbgYF8/GF0Yt4+92God/95KS6pAF4A4MOWZd0FIItd42lOx1FPj37NPoYQ4r1CiDNCiDMbGxu9fBr7QiqvYyysIlBxxzAeVn3dTdGOdF6ve2HcjoWJMDYzxa780rcsC+fXM7hh13ri196yiO9d3MKlLfsXfkdjcc64RtEHd6IGpWiYCKuBcvh5D7u85AmRH07eGmk+Fuev4OeVpJ2b9s2zG3h2tfMNOb0oLklHZmL4q/feh7967334qRde1/bbVxaXZjsN9PbZ17WfGgd6K+xcaiJd1GuWAkjtZC7JbgsA2OpDfk9BLyGZ0zkWt0dTMY7FSVqDsTiZw9SP44hRMnFl239jca22xfXrukZudx5Ehli6oOOLj1/DW+441PTzMWrmxkIYj6h4fkDdZKPMS3HpKoCrlmV91/n7p2AXm9ackTY4/193Xr4MoLIvb8l5rNnjS3UeR5OPUcWyrI9YlnWPZVn3zM+P9vpFL1KF2rGwkRqLK+h771waD8O0upPxsLJTQKZo4NSu4tLrbjmAkmnhc4+sICDQdCtGI27nEsfiGiroJUSCSl+6vGR3YEE3fRsy2GxM029F6tWdAuIhBdGggj/89oWO38/ytl1cWupBcQkAVCWA+07MVt0Q8Go8EsTBSbvLYm6ss7G4mXgIiWx/ukL8Ri81CPRWAhxHbiJdMOpuigPsYmZQEZ5Gpi46Fw5CAFt9+B6VHcsL7Fzak8k2Q9v3M71BoHc/i0vXdgruCJ4fbiTIjqR4k2JKtE+ZS6Zp4dza4IpLf/voNRR0E2+/Z6n1K48QIQROzI9xY9wAtCwuWZa1CuCKEOK089CPAHgKwOcAyI1v7wHwWefPnwPwbmdr3H0AdpzRtvsBvFYIMe0Eeb8WwP3Oy1JCiPucLXHv3vW+6n0M2oNUvnYsbFTG4izL2vO2OABYcIJxu7ExTrbT3lDRYQAAtx2exMHJCJaTeYxHgm2PwwBwu3GKHItrqGiYCAcDFeHnvR+LA/zbvZQq6Agqwv3eqhT12cr6azt5HJmJ4e33LOGzjyxjLdXZz/NysoCgIjoeO+s12b3UaefSockoNjOaL7I4+s3e9FQncynIzKVm0k3G4oQQmIwGPXW1XEzkEFICODYb70ug96pzjDjA4tKeBJUAxsIqi0twjiFNOpeKpd4fdys7AH3VudRkLC4esm922YMvvbOczLuZhIPoxPvEmSu4YXEMdx6Z6vvHHnYn5uIcixsAr9vifhnAx4UQjwG4E8B/A/BBAK8RQpwD8Grn7wDwRQAXAJwH8IcAfgEALMvaAvBfAHzf+e/9zmNwXuePnLd5DsCXnMcbfQzaA7tzqfqkzo9bnjpRNExoJbMr2+IAdCV3qbwprrpzSQiB195sx4x1+nwjKjuXWikaJUTUys6l3m6Lizofxw8ncPXIQPx6xU6/dS6tJAs4NBXFv/ih4yiZFv70Oxc7fD95HJyMdtRZ1A+yuDTfaXHJ6ci6trP3Yvp+0zBzSWHmUjPpOh3UlSajQex4KDxcSmRxZCaKubEQEpneF5dkAZqZS3s3GQ0iOaCMmmGiG426H+3fJ/0oUl908pamY0FfLG/IeuhcioUVmBY8H4eNDjfzyRvEQP+LS8+upvHolSTefs+Rjm5A73cn5uK4tlPw7c1cv/JUXLIs6xFn7Ox2y7LeZlnWtmVZCcuyfsSyrFOWZb1aFoqcLXG/aFnW9ZZl3WZZ1pmK9/NRy7JOOv/9ScXjZyzLutV5m19y8pXQ6GPQ3qTytWNhY2FlJDqXmm26asfCuH1i2Y2NcWfXMpgbC2O6zian191ih/N1+nzL3Ti8yGmkoNudS24hrkcnVqZpIauV3KwOv/68Nes4iPosm2c1VcCByQiOzsbx+lsP4OMPXqrqLvNqJZnv2qa4XnjV6QXcfHACi5N7LC5xpW+NRmvE2bnUXLOxOACYioU8FR6e38zi2GwcM/EQtvsQDr2Wsn/nM3Np76Zi3gqI+529La5x51I/NsZd2swirAZwfC7ui9/hOY+dS/brtv73bGc13Pn+r+LTD19t+bq7nXVG4qZjwb4H1P/1mSsIKgI/dtfh1q88gmSoN3OX+str5xLtI+lC7VhYLKyORGW3WRhxOxYnIpiMBvG1p9f2/JzOraVxw+JY3Zfde3wGk9FgR5viAPS8YLIfFI0Swqqd8REQvSvEyY4eWZj0bedSk8wyP2W3FfQStrIaDjl5RD//shNIFQz89fevtHjLWnZxqTd5S93w8hvm8cVffRnCavu5bQDcwtkyi0s19JJV/8JQUWD0aNPT73zlWfzhtzrPCBsGmWLjIjVgh3q36gKwLAuXEjkcm4tjJh7uy1jceqqAkBpwM4Ooc1OxoKdcrf2u2CjQW7GP1/3qXDo6G0PcJ9cC8jwjFmyyLc7JKfVyI+/7F7eQKRr4/a+fh9nmMfvcWhqLE2EcmYn19ftZM0x85gfLePVNix2PvO93J+bjALgxrt9YXBpBdudS9UndWFjt6I693+y4YcR7G4sLqQG8+8VH8ZWn1twtEZ0wTQvn6myKk4JKAB/4sVvxL19xfUfvX456cTyjsYJuIhIMQAiBSFDpWSFOngzN+7xzSY7F1RMNqcjrpbZPzgZh1RnxOjBpF4Xuum4a9x6bxh//w/NttcfrJROrqULPwryHwQGnACe365HNsqzGa8R7GMb7N4+s4O+6cGNjUIySiZxWwliT38OT0WDLPJ71dBF5vYRjszHMxkPYzuk9P/aspgo4MBHhCEoXTEVDfe/0GEZ6g9y2fgZ6X0pkcXQ2jkhQ8cWNr5xmIBIMQK1z7JVibXQuPXR5GwDw3EYW3zzX3tbxs+tp3LA47umY1U1fe3oNW1kNb7/3SOtXHlHHZllcGgQWl0ZMybSQLtbpXAopvt5g5VW3OpcA4GdecgxhNYCPfOu5jt/HcjKPnFZqWFwCgDfffgivOr3Q0fsPqwEoAeGOA1It2bkE2MW4XuVTyeKtDIP3wwlcPamC0TADTG409ENmw8qO3YUjO5cAu3tpOZnHl55Y9fx+1lIFmBaGunNpr8KqgvnxMFbYuVTFcH5fymyUSuEeXRiapoVrO3mkC/4sTgPlY+F4s8wlDyNTclPc0dk4puMhlEzL/R3fK2upAkfiumQy5i20fb9rmNsmjyE9DvQ2TQuXt3I4NhtDLKT44vd3VjOa5i0B5ZE5L51YD1/axm2HJ7E4EcZH/+F5z8/DNC2cX8/g1MI4pmKhvn4/f+LMFRyYiODlp7glvZFoSMHhqSg3xvUZi0sjRp7U1WYu2QdpP4XxdqJbmUuAvXnpHfccwWd+sIxrO51ddJ1bl2He9cfi9ioQEDg4GeFFYRNF3XQvBCNqoHdjccXqsTi//qylCzrGw/V/fmQbei8KZ1e2cnjz7327KyH6AHDN6cI5WFEUevVNizg+F8dHvnXB84YZ2c2zn4tLgP3vW+nwOLdf6U6HW7MLw2KXi9WbmSL0kuXrTmNZGGs+FhdCumg07SKUG66Oz8Ux62QWJno8GreeKmKBYd5dITs9er3Na9hpDcfi5DGkt51La+kCioaJo7NxxEI+6VwqlprmLQHeM5c0w8SjV3dw34kZvPvFx/Dtc5t4ZjXl6Xlc2c6hoJu4YXHM0yhvt1zbyeNbZzfwT+5egjKki0SGxYn5ODOX+ozFpREjiyu7T+rc9lGf5KV0KlWQxbW9jcVJP/eyEzAttHWno5IMAjzVpHNprw5PRXF1mxeFjRSMkjs+GAn1bixOXgzKu95+/VlL5Rt3LpXb0Lt/4fvIlSSeWE5VbWbZi3orxQMBgZ972XE8vryDBy942x8hC7f7vbh0eIpF6t10w74orldcCqu9uTCUuVf7orjUJNB70jnGpJp0aF1M5BBU7BsoM05xqde5S2upAhbHWVzqhqloEIZp+aKY0UsNc9vU/myLu7hpb4o7NhtHNKii4IOvh6fOJY+ZS0+s7EAzTNx9dBo//aLrEAkGPJ/TV57D28VSraPR3FRBx3Mb3rtr/vdDV2FawD+9Z6ntjzVqTszFcWEjO/JF7H5icWnEuGNhuzp34s4dAD+fsHrRzc4lADgyE8Nbbj+I//Xdyx1lB5x1ggB7GQ66NB1jEG8T1Z1LSs86lzL7oHNJM0zk9VLDn59edi7Jn690l8ZeVpJ5TMeCiIaq737+xAuWEFYDnsP65c/W4X1eXDo4GcVKssATtAqa7Fxqsump28Wla05WWLrg344PL2NxUzG7WNTs9+qlRBZHZmJQlYBbXEpkeldcShf0qo2ftDdTMfvrP8qh3k1z2/oU6H0pIcdL7bG4nF4a+mNLTiu55xuNeD0fefiSnbf0guumMRUL4SdesIS/eWQFm5nWXdJy+uDU4himYkGYFpDp4Nzud75yFm/83W97moIwTQt/feYq7jsxg6NOphA1dnwujkzR6FrXO7XG4tKISeXrd+7Ee9hxMExSBR0hNeB2qnTDv3rl9chqJfz5A5fafttza43DvLtlaTqK1VSBa7EbKBpmuXMpGOj6GIvkjsVN+DdzKd0isywW7t1xZCtrf+xmnQztWN0puGHelSJBBUdnY7i0lfP0fpaTeczEQzVFqv3m0FQUeb3U18DSYSfH4upnLvXmwlB2j+kly7eLGuRxpNlY3KSHwsPzmzk3sFUWl7Z7GBAtRysOTLJzqRsmo60LiPudXrKLOOEmBWr5Or0iOwAPTUURDSkomZZbOB9W2aKBeJPORwDuy1vdyHvo0jaOzETdcdd/8UPHoRkm/uLB1uf059YyODgZwUQk6N4kbpUVV88PLm+jaJj40NfOtXzd7z6/hctbObyDQd6enJi3Y0eeY6h337C4NGIady7ZB+H937lUG2a+VzcemMCrTs/jT79zEfk2CgaVQYC9dHg6Cssqb8eiagW9VO5cCiptfQ3bIYtLU7Eggorw5ba4VmOlvexckheN3QqnX9kpVIV5Vzo6G3fv5rZ8P8k8Dk3t/4vNw86/kV2QZc0yl8I9ylyq/Pz7NdRbPu9m2+Km5IVag593y7JwKZGtKS71cizuk2euIqQGGKDbJbJzqZOL8f2ifAxpsi2ux4HelxJZHJmOQQkIRJ0bbb06D+qWbNF751Kzf4tlWThzaRt3XzftPnb9/BhedXoef/HgpZYxCWfX0m6sRbnbsr3vZ71k4unVNKJBBX995mrL8bi/PnMF4xEVb7j1YFsfZ1SdmLd/RzB3qX9YXBox8sJs9xiWHIvzaw6MV6mC3rW8pUr/+pUnkchq+ORDVzy/zdXtPPJ6qWdh3tLSdNT5eN46MUaJZdl3/yuLS73bFme/37GwiqhP1v3u5nYctAj0zvbgOLLtjsV1q3Mp37AD4dhsDJcSOU/ZCSvJPA7V6YDab2Sm1DUWqV1eiku96lwC/HszKF1sHejdqgtgI11ETivh2FwMgH3sjoeUno3FZYsGPvODZbz5toOYdgpZtDcciysfH5pui+t15lIih6Oz9s9RL28QdZO3zCWnc6nJ+cjV7Tw20kXcfXS66vGf/aET2Mxo+NyjKw3ftuTeILbP4d1iaZvfz2fX0tAME//h9acRVgP4na+cbfi6z21k8MXHr+FH7zjU1QmM/ezQZBSRYAAX2si0or1hcWnEuJ0HDTqX/JgD045UXu965xIA3HtsGncfncZHvnWh6XabSjKYuJdh3gBwZNo+aWCody05VhKuGIvr5ba4gACiQQXxsOrPziV3rLZRcck+juT17v/btp2LzG4Ul/JaCds5vWEI99HZOIqGibV080KKZVlY3s7v+zBvwM5cAsBQ7wpak0DvctdBt4tLBcjlQBnfdi61zj5slbl0MWHfLKnMHJmOh7CV7U2uxt88soxM0cBP33e0J+9/FE05Y3GjfExxR2vrjcUpvS8uyQ5A+XMkx7vzPVps0i05rfW2OCUgEAkGmo7pP3zZyVvaVVx66clZ3HhgHB/9h+cb5k9d2cqhaJjuDWLZbZnMt1fgfvzqDgDglacX8HMvO4EvPH4Nj11N1rxepmjgX/75Q4iHVfziq0629TFGWSAgcGw2jgvsXOobFpdGjOxc2t2OHvdQ4d8PUgWj4YXxXggh8K9ecT2ubufxhceveXqbsxVBgL10YDKCgACujvAJXCNucakq0Lt32+LiYRVCCDc002/csdoG3X/xHnYuyYvMVBcCvWVo5sGGnUv2ibbcotNIKm8gq5Xc7sD9bDYeQkgNjPSF4G7lC8PGIy3FLherV5J5HJuzvz+7FW7fb+mCATUg6ubMSBPOOUqjrpaLzoXC8Yri0mw8hK0ejFhZloW/ePAybjo4gRdcN9X19z+q5sZCuH4+jg9+6Rn80bcvDH2IdC9oTbofZXGpl9lqmxnN7gB0O5ecG0TD3rnkIXMJsP89zW6aP3RpG/GQgtO7bvIKIfAvXnocz6ym8Z3nEnXfdvcNYtlt2e5Y3OPLOxgPqzg6E8PPv+w4pmNB/Pf7n616Hcuy8O8/+Sie38zi//2pu0bihlY3nZiPcyyuj1hcGjGpgo7xsAolUH0yLMfi/NhN0Y50XndPWrvtR25cwIn5OP7ye5c9vX5lEGAvBZUADkxEOBZXh8xDke3F4WBvt8WNOSdD8bCKnA9/1lptW5SB3r04MZVZKt24oJb5Y43G4uSIQKvcJZl/MwoneoGAwKHJCDOXKjQfi3MCvbvYuVTQS0hkNfdCKO3DYwhgd1yNR+xCeyOqEsDhqah7V3+3i4ks1ICoyjub6VHn0sOXk3j6WgrvvO+6ps+Z2qMqAXz6X78UP3zjAv7rF57Gz3/soZEL99Z23eCq1Kvux0rupjinYC0zl4Z5LM4omSgaZsuxOMAe82v2b3no0jbuvG4Kap1j+I/eeQhzYyH8yT8+X/dtz63bY1ZyLG6iRU5cI08s7+DWw5MIBATGI0H84qtO4tvnNvGP5zfd1/nwN5/Dl55YxX96w414yfVzbb1/Ak7MjeHyVo6LjfqExaURk8rX79xxZ5P3+1hcQe9J5xJgX3y96vQCHr6c9NT9UhkE2GuHp6Mci6tDdhWUM5cCKPaoo6jyTlsspCA7xCdvjaRabHmSJ6a9OI4kuzgWt+IUlxplJR2aiiKoCDzfori0MkLFJcD+dzJzqaxp10EPAr3l515uGPXzWNy4h5sqr7/1AL59brNut+KlRA7XzcSqLgpn4mFs9SBz6eMPXsJYWMXb7jzc9fc96iZjQfzBu+7G+95yM755dh1v+tA/uKNKo0Bugmt2DNGN3nV0yfHSY7vG4oZ5c7Ts+m4V6A3YUxmNsmQzRQNPX0tVhXlXigQV/OS91+Frz6zjSp3tsWfX0jg0GXGPZZGggmhQaatAqhkmnr6Wxm1Lk+5j77zvKA5NRvDbX34GlmXhW2c38H/d/yzecsch/OwPHff8vqnsxHwcJdPCZY9bgGlvWFwaMamCXvfCUG6J2M+dS5Zl9WRbXKUXn5iFZpj4weVk09eTQYA3LPR2JE5amo5hmcWlGvLCT2YuRXsa6F0uLsVD6lCfvDWSLti5UY3uGJYzDrr7OdQM0w0v7sZY3KozFteoc0kJCByZieFSi7G4lR1ZXNr/2+IAO3eJY3FlzS4MexHoLT/3Nx5wOpd8PBY35mGk5U23H4RWMvF3T63VvOz5zazbYSjNxINIZLWujldtZzV8/vFr+LG7Dnsaw6H2CSHwz196HJ/6Vy+BEMDb/+cD+PTDVwf9tPqiWfejEhBQAqKn2+IuJbJQAgKHnRskXjasDZq8Tol56VwKKw1vdj16JQnTqs1bqvRTL7oOAsDHv1s7kXB2LVNzg3gqFmyrc+nsWhpaycSth8vFpUhQwa+95gY8enUHf/Tt5/Erf/UDnFoYx2/9xG3snOzQiXn7Wouh3v3B4tKISTfp3ImH/dlN4VXRMKGVzJ5si5PuPT6DgAAeuFB/RlsqBwH2p3NpaTqK1VTBc9j4qJAjcJGKbXF6yerJ5ylbNDDmjJ/Gwo3vpg2zVN7uOAgEGp/gxHpQOKu8E9itzqWZeKjptpVjs3FcbNG5dGEji1hIwVw8vOfn5AeHpyJYSxXcC6JRpzuFo1DTzqXufa7kSKK8oPHztrhmm+Kku45M4dBkBF94rDrHUIYQy+wpaSYeRtEwuxpG/MmHrkAzTLyTQd49d8eRKXzhV16Gmw9N4Pf+/vygn05fyONDvUBvwD629HKU52Iih8NTUffjx3wQ6C27mOV2tmbsG3n1/y0PXdqGEMBdDTqXALtb9zU3L+Kvz1ypmkgomRae28jUbHuejAbbylx6Ytke+729orgEAD9+12GcXBjDB774NEzTwh+8625PxTSq77jzu4K5S/3B4tKIsTt3GoTx+nSDlVet8mK6YTIaxC2HJvFgi+LSY84vlNMH+jQWNxVFybSwmuJIS6XdnUuRoH1ILPTgZK4qcynU+G7aMLMD8Vut/1W6XjiTm+KmY8GuFJeuJfMNw7ylo7MxXErkmnZBPLWSwo0HxpsW2/aTQ1NRmBawxuMIgIqugzqB3r3qXBICuG4mhpAa8G3mUrrgrbgkhMAbbzuIb53bqOoG2MgUkdVK7iiPNBu3t48lujQaZ5oWPv7dy7j32HTfflePusloED/xgiU8v5l1Q9v3s3LnUv3fISG1t8Ule1NcuQOwPBY3vMUlmb844/y8NxMNNZ7IeOjSNm5YGHeDuBt5133HsJXV8MWKZT2XEllohlnTuTQZDTZcQlDPY8s7GI+oNV2YqhLAb7zxJoyFVfw/P3lnTSGd2jMZDWJuLIQLG/v/mDIMWFwaMamC3rC4Eg+p+3pbXHnTVW8DtF98/SweaZG79NWn1jAbD1W1wvbS0rT9i4u5S9WKdTqXAPRkY1y2WKrIXPJv51Kr4myrAM1OyJPJ62bjSBf0PY+9XNsptCwuHZuNI6+XsJGuHxBsWRaeXk3h5kMTe3oufiKzpVaSLC4BXjOXultcWhgPI6QGMBFRu1JoHQSvmUuAPRqnl6yq0bhLTk5M7VicfbEpjxd79Q/nN3EpkWPXUp+98vQ8AOAbz64P+Jn0nrtxss4xBLCPLb0K9LYsq2a8VOYmDvNYXML5+Z4ba11ciocUpPK15wymaeHhy9tNR+Kkl56cxYn5OD72wCX3MRnmvXv6YCoWxE6bnUu3HpqsO+72qhsX8Mh/fg1++MZFz++PGjsxN4YLmxyL6wcWl0ZMKt9iLM6nd0K92Mnb/7ZebYuTXnxiFlrJxMOX6odSFo0Svv7MOl5z82LN1r5eOeysSmdxqVphd+eS2rviUvW2OLtzyW+rl710HLRa/dsJORZ3dCYGvWTteaOfXVxqHsItT7hl4OluV7fzSBcM3HRw9IpL13Z4HAHKXUl1x+J6sEZ8JVn+vh0Lq74N9M54HIsDgDuPTOHwVBRfqOgakKMNx3fdzZ+WxaUubRz7iwcvYTYewutvPdCV90feHJ2N48RcHF9/dmPQT6XntBZjcWE10NVjSKVkTke6YFR1AMrRq2HuXEpk7Bs+Mx7G0e8+NoOVnQI++OVnqh4/v5FBumDgbg/FJSEE3nXfUTxyJelurzy3lgYAnNyVmzoVDSGZ93b80QwTz1xL4/alxjeZ622xo86cmI+zc6lP+F07QkzTQrrYfCzOjyHDlR69ksTLf/vr7i+fSv3qXLrn2DSUgGiYu/TAcwlkigZee0v/7kbIwGGGelfbvS0uLMfi9li82M2yrF3b4lSYVncvPPshmdc8dS51+66nvFi8bsYu+OwlyDinGdjJ6w3DvCV5wt0od+mpaykAGLHiknMcYag3gOaB3kKIro+0rCTzbvDuWET1ZaC3ZVmeA70BORp3AN+uGI27lMhCrQghluRYXDc2xl3byePvnl7DP73nCMJq661U1F2vPL2ABy8khrqDphuaBXoDdtFJHme67dKW7AAsF5eUgH3cyunDey2wldUQEMCUh3P5d77oOrzrvqP4g29ewEe+9Zz7+EPOzV8vxSUA+Im7lxANKvjzBy8CsMO8D09Fa45jUzHvmUv1wrypd07Mx5HIam11llFnWFwaIRnNgGU1Lq7EQ6pvA0Klhy9v4/JWru62tn5kLgHAeCSIWw9P4oHn6heXvvLUGuIhBS+5fq6nz6NSWFWwOBHG1W2u4awkO5cibuZSbzqXioYJw7SqOpcA+K5TcCNdxPx487uFdudSdz9/8mRNFpdSe+jYkOvcW214OzwdhRIQuNSguPT0tRSEKG/uGgWxkIqpWJAb4xyt8lLsroPu/CxYloXlZN79vh0PB335+7qgmyiZluexOAB40+2HoJcsfNUZjbuYyOHITKzmrv7MWPfG4j72wCVYAH7qhdft+X1R+155eh5Fw2yZX+l3WpMCNSADvXtTYJO/247tGi/txQ2ibkpkNczEQ56yDoUQ+M0fvQVvvv0g/tsXn8Enz1wBYBeXZuKhmn97IxORIN5212F89pEVJHMazq6lcWqxdtvzZCyIomF6Ood83MlevY3Fpb44PudsjONoXM+xuDRCWhVX4uHuZ6X027qTj/K001VQSV6Q9nJbnPTiE7N49GqyphPMNO0T5FeeXmi6qaoXDk9FORa3y+7OJfk16dYFoSSLSGMVnUvAcLee71Y0StjO6VicaF6UsU9Mu3vRu53VEAspbmErtYeOjWtOXtCBieZjcUElgCPT0YZjcU9fS+H4bHzkNrgcmowyc8lRDvRuPNLSrc6l7ZyOomG6o4ljPs1ckt1WXsfiAOCOpUl7NO6xFQDAxV05MdJ4WEVQEW4mS6d28jr+/IFLeONtB3Gdx4tP6q4XHp9BNKjg6/s8d0keH8KNtsX1MND74mYOQgBHZnYVl4JDXlzKFD2FeUtKQOB33n4nXnZqDr/+6cfxd0+t4aFL23jBddN1s44aefeLj6JomPir71/BhY1s3W3PU1H7ee14CPV+vEGYN/XG8Tn783ypwTkddQ+LSyMklW9eXIntg86l9ZRTXFqtU1zqU+cSANx3YgZ6yXJbb6UfXEliI13s60ictDQd4zjLLsVdJ3Yy2LvbY3Hy5ypesS0OgK82xslg64UWnUt2nlT3x+KmYyH3gnQvF9UyL6hV5xJgjws07lxKj9RInHRoKsrOJYfWIow3pHQvL0V+zmVxadynxSV5k6ed4pIQAm+6/SD+4fwmdnI6LiVyNZvi5OtNx0LY3mNx6c8fuIhM0cAvvPL6Pb0f6lwkqOAl18/iG89u+C6bsB1exuJ6Feh9KZHFwYlIzY3OSEhBrge5k92y5XQutSOkBvA/33k3bj00gV/4Xw/j+c2s55E46aaDE7j32DR+/+vnoZVMnFqo07nkTIZ4GY17YnkHtx2uH+ZN3VdebMTiUq+xuDRC3MyhBsWVsbCKnFby9S/y9bR9R/3pa+mal6UKOkJqoC8dQ/cem4EaEDWjcV95chVBReBVNy70/DnstjRtXxSWTP9+fbtNti7L7wm5hrfbY3EZt3Op+uP4aTuj7Aps1bkUDapdv+uZzOmYigXdUZq9ZM3IsbhW/w7AHhe4tJmrOSamCzoub+Vw08HRGYmTDk1FWFxy6EbzkZZwUOla14G8MSBzhsbD/rwZJJ9zO8UlAHjTbfbWuP/1vcvIFI2G4ywz8dCeOpdymoGP/uNFvOr0PG45xHGVQXrljQu4vJXDhc39G8Irjw+NRmuDiuhd51IiW5W3JA39WFxGw+xY6zDv3eJhFX/yz1+II86CmxdcN9X2+3jnfUfdon7dzqWYLC41PwbJMG+OxPVPJKhgbizMCY4+YHFphLidOw0yl2JhBSXT8l3IcCXZuXQxka0ZSUvljb50LQH2L7Hblyar8gIsy8L9T67ixdfP9e15VDo8HYVhWm4Bjup0Lsk1vF0uLskiktu5FJZjcf65OFxP2d83rTKXerEJT96plF2XsguzE9d2CpiNhzwVmY/OxpEuGjUZLs+s2sXrmw+NZudSqmD4Mky62/SSCSUgGm79tDuXunMs2d25NBaxi0t+uxlUHotr73fg7UuTWJqO4o//4QIA4Ohc7UUxAMyOhbCVrV3o4dVffe8KtrIafumHT3b8Pqg7XnnDPADgG/t4a5zsXGq0LS6kdq9AvdulRA7H5mqLtLHgcC/3SWQ1N7y/XTPxEP7i516E//j6G3HPsZm23/4Ntx7EnFPY2r0pDqjoXGoxFscw78FYmmY8SD+wuDRCZLW9WecS4L+Q4Urr6QIWJ8KwrPIFoJQq6H3JW5LuOzGLx67uuJ/Pc+sZXEzk8Nqb+z8SB1S2hPLAKhX0EtSAcINhI6rsXOruyVx211hczOlc8lPmkufOpZACq8ub8JI5DVOxUJc6l/I46GEkDoB74r07d+npEdwUJ8nihuwAG2V6yWzYcQDY2ye7dWG4kswjrAYw7dwZH48EUTKtrhfCe02eh3jdFicJIfCm2w5i09kEd7xOxwVgryfvNNBbM0x85FsX8KLjM7j7aPsXntRdR2ZiOLkwhm/s49wlrdVYnBJwQ7+7KVXQkchqdTuXokPcuaSXTOzk9bbH4iodnIziX7/y+oY3BZoJqQH86o+cxBtuPeCez1WSnUutMpdkmPftSywu9ZNdXOJYXK+xuDRC3LG4JplLgL9GdSrJwOFXOHe7dod6p/J6XzuGXnz9LAzTwhknd+krT64CAF4zoOKSHKfggbWsaJhVQZqRoMxc6s1Y3LibueS/zqW1VAFKQLS8YxgPdb9IvZ3TMRMLIh5SEBB7zFxKFlqGeUvyxHt37tJTKylMxYI44GG0br857BTmOBpnXxg2uigEup25VMDhqaibzyGLMxmf5S5lOshckt5420EAdkDv4en6P8MzsWDHxaVPP3wVq6kCfvFV7FoaFq86PY/vXtjy9U3PZmTxuVFum70UoPvn5JedGyZHZ+p0LoWUoS1ayzy1TsbiuuVdLz6GD7/z7rovm4o5gd4tMpceu7qDiYjqbsCl/pDZsybjQXqKxaURIkdJGt0xlHkwfgoZriQDh++6bhrjYRXPXNvduWQ0HAnshbuPTiOolHOX7n9yDXddN+Up66UXlpyT8WV2LrmKRgnhivEo+edeFZfczqWwDzOXUkXMj4Vbrv+Ndrkry3DuVE7FQhBCYDwS3HPnkpcwb8D+mQmI+p1LNx+cGMkgzoOT9nGEG+Psu+iNLgqB7nYuLSfzbtcYUC7OpH120Z3qcCwOKI/GLU1HGxb1ZuJhpAqGO27klVEy8eFvPofbDk/iZafm2n5u1BuvPL0ArWTW5FfuF3rJhBoQDX+v9irQW27Mqtu5FBzezdEyT63Tsbhei4cUqAGBZL55gfuJ5R3cyjDvvluajkIvWW4nPvUGi0sjJFXQ7QNfg5OyWA86DvpJHiwOTERw48Hxms6ldF7HRAd3SzsVC6m4Y2kKD1xIYCWZx+PLO3jtzQf69vF3Y5hdrYJuuhvigHLnUrdzx3aPxfmycyldxOJE67uF5X9bd05OZXt5eRxIdTdOtStbNJAqGDgw6a24FFYVHJqKVnUulUwLz66N5qY4wN4WqAQEO5dgB3q36lzq1oXhSrK6KNqNzYmDsLpTQFgNuF2c7RBC4L++7Vb8+utvbPg6M2P2RWe7G+O++MQqLiVy+MVXXc8LviFyz7FpxEMKvr5PR+P0kodjSA8yly46v9OO1gnGH+axuK0hLy4JITAZDTbdFlc0SnhmNYXbOBLXd/ImOyc4eovFpRGSyutNO3fkhW+314j3S2Xg8E0HJ/DMarqq9dHOXOpvkPaLr5/FE8s7+MwPlgEAr7tlMCNx0uHpqLt1iJyxuIrOpZASgBA97FxyunqiQT92LhUwP966KFPOk+rORe+2s3Vl2jmZ3EvnkswJOjTpbSwOAI7Nxqs6l57fzKKgmyNbXFKVAA5McGMc4GQuqU0yl1QFxS7kt2mGiY1MsapzaSxs/y7z21jc2fUMTi6MteyAbOSVpxfwBmc8rp4ZZyxlq8W2pkqWZeF/fP08Ti6MDfQGENUKqwpecnIO33h2w3fh9V5ohtkwzBsAgmpvtsVdSmQxPx6umxsUCw1v59Jmxr6JPDs2nMUlAJiMBZsGep9dzUAvWdwUNwBHZpg92w8sLo2QVKF55lDcHdXx18mqJDuXFibs4lKmaLgHEMuy+rotTrrvxCxKpoUPf+M5nFwYw4n52u0S/cRNCdUKeqkqc0kIgYiqdL24lC0aiAQDbtdgICCcEzj//Kyte+xc6nZY+XZOdi7ZJ5MTe+hcurZjf+8f9Ni5BNh3dis7l55yOiJvHtHiEgAcmoqwSA0PmUtdGmlZSxVgWag/FuezrX3n19J1V3h3iwz63cp4Ly79/TPreGY1jV945fUdF72od151egHLyTzOr2cG/VS6rnVuW2+2xV1M5HCsTtcSAERDKvJ6aShzaWTn0kx8cJlLrUxFg00zl2SYN4tL/SezZ69ssXOpl1hcGiGpvNF0W1ovgnj7aT1VdAKHw25XgbwQLBomtJLZ121xgJ27FFICyBSNgXctAcDSVBTL2wyzk3Z3LgH2aFy3t8VliiW300CKhVTfdAlqhomtrIYFT51L3R2L23ZPJsudS6kWm1gauebkBB1ss3MpmdORdDohnr6WQlARddcQj4qDk1Fui0PrzKWQGkCxC4VqWcir7LiT2Yl+ylxKF3Ss7BRwarF3PzuyoyHRxljcX37vMg5NRvCWOw716mnRHrzytL2kZT+OxumGiVCTjZMhNQC9B9viLiWydfOWgPINom7HA3TDVlZDQNgFnGE1FQs13Rb3+DLDvAclElQwP854kF5jcWmEtO5c8ndxaS1VwNxYCEpA4PTiOAKivDFOXoz2u3MpElRw53VTADAU7fZL01FoJdNtLR51xV2dS4A9stbtTSnZouEG5kvxsIKcT37WNpzvF0+dS+HejMXJFb8TEbXjnBlZEFmc9H7XU2ZSyADUp6+lcP38WNNRhv3u0FQU13ZYpG6VlxLuUueSHEGsl7nkp7G4c07nyamFPnQueSwuWZaFR64k8ZKTc02/ljQ4h6aiOL04jm88uzHop9J1Wqn5WJzsfuzmSGBOM7CWKjbuXAp293d4N21mNMzEQ0PdYTgVDTYN9H5yhWHeg7Q0HcXVJDuXeom/SUdIq8whdyzOJ90Uu62ni25nRTSk4NhcvFxcckYH+p25BAA/ftdhvPjELG4fgvC+pWn7ZOIKq/YAgIJhIlLTudT9sbhM0ajJNvBT59Kak2e2MAxjcdG9ZC7lMTcWQlhVWr+y49icfXdXBqA+tZLCzYdGdyQOAA5PRaCXrJEvUuslE8EWXQfdyFwqF5fqdC75qbi0Zm9wvaGHnUuyo8FrcWk5mcdmRsMdR6Z69pxo7156cg5nLm3vu9wlvcVYnLz51c2NcZe3Gm+KA7q/8bWbtrJFt4A8rCaaBHpbloULG1mcGuHO50Fbmo6xc6nHWFwaIXbmUOOxsJASgBoQvu5cquysuOngBJ5etYtLO3n739TPbXHST77wOvzle+8birsUh7kpoUq9zqVwUOnBWFxtcSnuo8yl9ZSTZ9bGWFy3jiPbWQ0hNeAWrcYjKtJFo6OumWs7hbZG4gC4reuXEjkkMkWsp4sjnbcElIsco567pBmtLgwVFLtwUbicLGA2HqoqhKtKANGggkzRP5lLZ9cyiAQDODLdu3EQVQlgKhb0XFx69Iqdf3LHENz8ocaWpqPQDLPpFi4/0jxsnLRfr3vnJLIL91iLsbhud3B3QyKjYXaI85YAu8s6XTBg1Dn2b2Y0ZIqGe9OK+m9pOoqVZB6lEe+87iUWl0aEZVlIt+hcEkIgHlaH8m6FFxvpYtU2q5sOjOPKVh7pgj7QzqVhcpgXhVW0up1LARSNXozF7epcCqu+2Ra3nm6/c6lbq4y3cxqmY0G3ODseUWFZQLaDwty1nTwOtBHmDdidbAcnI7iYyOLpa3bnxahuipNkcWnUc5d0LyMtxt5HWlaS+aquJWksorqbKP3g7Fp6T5vivJqJhzwXlx67mkRICeDGA6P9Mz3s5HF7NbW/jjmtxuJkZ2R3i0t2F+51Dcbiut193E1bWQ0zQ7wpDih3T9ZbPCI/940Ke9R7S9NR6CXLPa+l7mNxaURktRJMq3XmUDyk+OpkVdJLJhJZDQvj1Z1LAPDsanpgmUvDJh5WMR0LsiXUsXtbHICebYvze+eSDMtvJagEEFICXRv5287p7kgcUP4Z7mQc6FqygENtFpcAuTEuh6eu2V0OI19ccrq/Vka8SO0lcwnY+0jLtZ18Vd6SNL6HzYmDcH4909O8JWk2HkIi621k85ErSdx8aGKkM9T8QHalr+2z4pId6N2sQG0Xero5FncxkcN0LIjJBjdbo0H7XKVbN4i6KZHVMDvkY3FTzvlKvVDv5zed4hI7lwZGxoPwOqh3+Nt0RLjFlRbb0uzOJf+crEobaRk4XNG55FwAPn0t5Z6A93tb3DBamo5hmQdVAM62uN3FpZ5ti6v+3ouGFN90LlWG5XsRDSnIdyvQO6tVFZfGI/KuYHvjEemCjnTRwME6HSCtHJuN45LTuXRgIjL0mQ+9NhFVEQ8pI98B2SpzyS0u7aHrwLIsLG/n645zjodV3wR6pwo6rvV4U5w0HQthO9v6+FAyLTy+vMOROB+QI9lyRHu/0Esmgmrz3DYA0I3ujfA02xQHVI7FDdexRS+Z2MnrQz8WN+ksH5EbZitdTGShBASWpts/D6HuWGI8SM+xuDQi5IXYeIvOnVhYRcYnF7yV1tMyE6b8S+fgZAST0SCeusbOpUpL01EeVB0FvdSXQO+62+JC/inkrqeLVYXbVuIhpYudSxqm4+WfW7klq1nn0nMbGTx8uTr8ddUZ4TrYUedSHJsZDd+/uIWbDva+82LYCSFwaCo68p1Lmscw3r2s9E4VDGS1kjvSXGk8EvRNp/G5NXtT3A396FwaCyHhYSzuuY0MclqJYd4+sLBPO5e0UqvOJdn92L1zkoubuYab4oDhDfTedn6m/TIWl6zTuXRxM4cj01Fuphwg+bv06tZon7/0Er+7R0TKDbRuXlwZG/B6dM0w8W8/8Qi+f3Grrbdbr7PNSgiBmw6OO51LOkJqoKaQMIoOT0WxnMzvu60rnajfuaSg0MXMJaNkIq+XarfFhbtXgOm1tVTBU5i3ZHcu9WYsrlxcatyZ8B8+9Rh+/H98B2/9/X/E5x5dgVEy3XygdgO9Abgn4le38yM/Eicdmooyc8nrheEeikv1NsVJY2G1482J/VbeFNf74tJMPITtnNYy9P+RK0kAwO1LUz1/TrQ3YVXBTDy0/zKXWiwFkMeXvRSoKxWNElZ28k07l6LB4SwuyYLx3JB3Dstxw5064fMXW3SNUe9FggoWxsO4wpvsPcPi0ojwOhYXCw02IPRiIotP/2AZ7/no9/C9570XmNbqjMUB9mjcs6tpJLM6u5YcS9NRFHTT053d/cwomTBMq2YtfSQYQF7r3licLCDtHouLh1Rohll3o8iw2UgXPYV5S/Gw2lHg9m6maSGZqx6Lk6H8zTqXlrfzuPHAODIFA7/ylz/AK/77N/Bn37kIoPPOJenmQywuAcChqcjIdy7prTY9daFzqVxcqv2+HYv4ZyxOborrxzjITDyMkmm1zGV79EoS42EVJ5h/4gsL42Gs7bOxuFaB3t0Yra10ZSsPywKOzTXuXOr2Uo5uSWSczqUhLy7JzKXdY3GWZeHiZhbHebwZOHuCY7TPX3qJxaUR4W5La9m5NNhtcZtOkSggBH7mT77nuYNpI1WAEKgJ+rvp4ATyegmPL+8wb8nBMDubvOCLBGs7l4pdHIvLOsXams4l2Xo+hOt+K2mGXYhcbKdzKah05TiSLhgwLWA6Xtu5lKrTcg7YBanNTBE/fOMC/u7fvgJ/9O57sDQdxdeeWYcSEG2N90lHK0YI2LlkOzQZxWZG6/oIqZ9oLfJSZOG6G51L9cfi1I6C7Qfh3Hp/NsUBwIwzRtsq1Puxqzu4/chkX54T7d3iRGTfbXhq1f0oi9fdKi7JbWXNM5fs37HD17lk/zzPDvlY3IRzjrJ7LG4jU0RWKzUdSaT+WJqOjfw1UC+xuDQiyp1LLTKXQop7MTwIGxn7l8dH3nU3DkxG8DMf/R7OeCgwraeLmBsLQ931S/pmGeq9mmLnkuMww+wAlItLvR6Lkz9PNZ1Lzt9zQ55xJn8m2+1c6kae1JZz5286Vv7ZnYg0XvMr38YwLSxORBAICLz65kV84l++GH/7Sz+EP/3n93a0FSoeVjE/HkYkGOAKYcfpA/Z4UzsdpvuN7nmkpfOf8eVkAUFFYG6s9udvPKwioxktx7+Gwbm1TF/ylgC7cwmw15Y3UtBLePpaiiNxPrI4EXaz8/YLr92P3doWdylhn/c1+z0mb7jlh+zGgexcGvZAb1UJYDyi1myLu7jpfO7ZuTRwS9N2ZmTJB787/YjFpREhL8TkXf9Gxro0ztKpTeeXx00HJ/BXP38fFicieM9Hv4eHLjW/gLEzYWp/4ZxcGIMSELCs1oW1USGLS6O+MU52XNQEeqsK9JLVtV86mQbFJdm5NMifNy9kntliG8WlWKg7nUvbbnGpfKcyrAYQUgINOzbkNqHdx4PblibxslPzHT+X04vjuP3wlOeNefvdy2+Yx0RExd/8YHnQT8WV10pIZPo3NtMqjDcc7E7m0sHJaN3umrGICssa/u7HnbyO1VQBp/qQtwSUO5ibjX4/dS0Fw7RwB4tLvnFgIoLNTNEXo+RetRqLc7fFda24lMV4RK26YbObEALRYPc2vnbLVlaDEhBuptEwm4oFazKXLjpdY7xBNXhL0zEYprXvFgQMCxaXRkQqryMWUlpuKIiFVBT0weXAJDJFqM4vj4WJCP7yvfdhYSKC93z0+274Zj3r6WLd4lIkqLh5ChMtCmujYiISxEREHfmWULdzqWYszv57t8Z9Mg3G4uIhf3QurbnFGu/jZLGQ0pV/l9wOUzkWJ4TAeER1R313W0vXhvt3w++8/Q783k/d1dX36WeRoII33nYQ9z+5OjTZHO///FP4sf/xnb4tK9BbbIvrRhjvtZ18w5wwuf112EO9z6/LMO+xvnw8mcmy3aS49JhzPnEnN8X5xsJEBKbVvGjoN167H7s1FncxkcPR2RiEaH6TpFs3iLopkdUwHQv6Yox1KhqqGYu7uJmFGhB9yZ2j5pbcCY7Rvg7qFRaXRkSq4C3QOh4ebA7MZqaI2bGQ+8tjcSKCv/z5+xANKfh///58w7dbSzVelS4zUti5VLY0HcPlrVEfi7O/x2sDve2/d6u4VM5cqv44sbA/Opc2OijWxELdGYvbdu787b7L2ixrZqODYpgXCxORjvKa9rO33nkYWa2Erz69NuinAtO08NWn1nB5K9eX0N+SacG00PTCMBzsRuZSoW7eElDuhhz2UO+zaxkA/dkUB5SLS82KEI9e3cHCeBgHOgj4p8GQx9/91G3QKretG0sBKl3yuK2smxtfuyWRKQ79SJw0GQ3WBHpfTGRxZCZWE99B/bfEeJCe4nf4iEjlDU+B1rK7YlC5S5sZrSZb4sBkBC+5fhZPrezUfRujZCKRrd+5BFQUl5i55LrjyCTOXNwa6TDegt4o0NvpXOrSyVym2HhbHICuFGF6aS1VREC0l3Mg73p66SC5sJHBcoOtY/LkbHpXUP9ENNiwW0MGvs43OB5Q97zo+AwOTkaGYjTuqWspbDojcY9dTfb848kxlaYjLXvsXDJKJlZTBRxqUFySY+7pAeYkenF2LY1oUGlYJOu2SFBBLKQ0zVx69GoSd7BryVfkaPZ+yV2yLAtayUS4WYG6i9vi9JKJq9t5T4HSw9i5tJXVhn5TnDQZC9Z0Lj2/mWOY95CQv1PZudQbLC6NiHTRa+eSLC4NsnOp9qLwlkMTWNkp1G1zT2Q1WBYw37Bzyb5bym1xZa+75QCyWgn/eH5z0E9lYORGuH51LtUGejudS0M+FreeLmB+PNxW1lA8rMIwrZYhpJcTObzt9/8Rv/6/H6v78q2sBjUgML7rczceURtui1tPFzEZDdZkaVH3BQICP3rnIXzr7EbTC/l++Na5Dfs5CeDx5fo3IrpJfm8HlSbb4oJ7C/TeyBRRMq2G3TVucWnIO5fOrWX6tilOmomHGn5P7uR1XNjIciTOZw7IzqV0/3LVeqlkWrBadD+62+K6EFWxkszDMC2PnUvq0AV6b2U1zAz5pjhpKhqsOkexLMtz1xj1XiSoYGE8zM6lHmFxaUTYnUseiksyZHhQnUvpIubq/PK4+eAkAODJlVTNy2SL9GKDToXbDk8irAZwZJp3DKSXXD+H8bCKLz+xOuinMjCyM2l355IsNvU6cynmo86ldkfMok5hp1lbfUEv4Rf+10NIFQw8eiVZt8tpO6djKhasyYcYDwcbXlA3Cven3njbnYdhmBa+8NjKQJ/HN5/dwM0HJ3DD4jgeu9r74pJueO9c6rTr4JrToXFoqv7P31jY/p0+7GNx59bTONWnvCWpWXHpcef74/alyX4+Jdqj2bEwAqK8ZMLv9JL9Oy/oIdC7G51LFz1sipOiwcDQjcVtZoqY80nn0lQsiGROd89rNtJF5LQSjnNT3NBYmo7iyhY7l3qBxaURYWcutTEWN4ALXsuysJnRMN+gcwkAnqwzGuduh2rQuTQ7FsY//voP4023Hezis/W3kBrAD9+0gL97em1fbV5pR+POpe4GemeLBtSAcNvbJTkWN/ydS8W2NsUBFV1ZTU5O/8vnn8ITyym85uZFpApG3fbkZE6r2hQnTUQbZy6tp4tdD/Omxm46OIEbD4zjMwMcjUsXdDx0aRuvOD2P25cm8cTyTs9Dvd0LQw8jLZ2OxV1L2hfRByebj8VlisMb6L2T17GWKvYtb0lqVlx61BmbvP3wVP+eEO2ZEhCYHw/vm8wlWTBqtnGym9viLrnbyryMxanI6cNTtNZLJlIFAzM+yVyaioZgmJZ7DvT8pvO5Z3FpaCxNx3A1yc6lXmBxaUSk8rq7WaaZQV7wpgoGtJJZk7kE2JkrhyYjdTuX1tP1V49XmhsL+2LDRD+9/pYD2M7p+N7FrUE/lYFwt8XtKvpE3bG4bmUuGYiH1Zrum6jTJTjsnUvrqULDwm0jUec40ugi4LOPLOPj372Mf/mKE/jlHz4JoP4o01a2fnFpPNIkc6mDTivam7feeRgPX07icmIwJ2oPPJeAYVp4+al53LY0hURWw0qPc1l0dyyuWXFpb4He13bsgmujbXFjPhiLO7fW301xUtPi0pUkTszFMdlkHTsNp8WJCFb7ENjfD+5obQ+7HytdSuQQDSqe8gijQ5a5JCMxZn0yFjfpTIrI3MhLzu/G4xyLGxpHZqK4liyM7A32XmJxaQRYloVUwWug9+AueGUY69x4/V8eNx+arNu5JC9gGeDbnlecnkdYDeD+ER2Nk51Ju7N5up25lCkaNXlLgH1HMqiIpt09g6aXTCSyWttjZrcdnkQkGMBP/+F38ftfP1+VOXN+PY3/9OnH8cJjM/j3rz2NGxbHoQYEnqhTXErmdEzHay8AxyMqslqp5qTAsixspBuH+1Nv/OidhwDYRcNB+ObZDcRDCu4+Oo3bD9ujTo/3ONTbS+bSXjc9re4UEAkG3AuV3eTNoGEuLslNcacW+tu5NBsPIZGtX4R49GqSI3E+tTgR2UdjcbJzqfExRB5fulNcyuLobKzmRlc9seBwbYvbzDjFJZ+MxcnCddLZePt8Igs1IBqOOFP/LU3HYJjWvslwGyaeiktCiItCiMeFEI8IIc44j80IIb4qhDjn/H/aeVwIIT4khDgvhHhMCPGCivfzHuf1///t3XeYJHd9J/73t3P3TE/35Dw7s6vNUdIqERRBEggQ2CDkABgbY2OwfefzGWz/zunMHT7f2fjsszHJBmMbkZERIJBQQAKFVdicd2d3cuiZzrn7+/ujqnpSh+qejjPv1/PMo5nq6u7aUU111ac+4bwQ4n3Lll+vvv4F9bki33tQccLxFFJpWVRD72ANei7Nq3/g2TKXAKU07tJ8aE3gazYQQ3uTJe8dZFrLYTHhth2dePTkDNLpypaQ1KNcmUu2MmcuhWLJTNB2NYfFhHAdT3qaU/8mu4vMXBrpaMIP//NtuG1HJ/7y0bO456+fxhNnZhGKJfHrX3oZDosRf/vz18JkNMBmNmJ7txMnsmQlLuQqi1OPZauPU75IAvFUuuhMK1qffrcdN4204ZuvTlS8HG01KSWeOjeH11zTAYvJgJ09SrCy0n2Xli4MK9cvZcoXRZ/LnvNi0GgQaLbmLhGtB9WeFKdpbbIgmkivuUCe9kUx449xUlyD6m7ZgGVxeTKXhBCwmAyIlSG7YtQT1tVvCVCmxdVTQ28tC7FRpsW51RsCPrWp9+h8CENtDph4nVI3BlrViXELazOuv3d8Cv/07OVqb9KGUcxefoeU8pCU8rD688cAPC6l3A7gcfVnAHgTgO3q1wcB/AOgBIoA/DGAmwDcCOCPlwWL/gHAry573r0F3oOK4FfLR3Q19FaDS+EalMV51A+PfMElKYEz04EVy+fUaVZUvHv29mDaH8WxKkxXqjdaZpJ1TeZSuXsupbJmLgFKA/16zlzSTuJLyQQabHPgU++5Hl/85RthMAi8/59fxBv/6ilcnAvibx68dkXAan9/y5o+OVJKeMNxuLOWxWXP2JjxFy6Rpcp4+7X9uDQXwomJtUHCSro0H8L4YgS37ugEoASHd/Y4Kz4xLpEs3HPJaBAwGQTiqdL+xqd8kZyT4jTNVlNd91y6MBvE9u7qTooDljIcVmcvaf2WGFxqTN1OGxbDiZInMNYTPaW1gBLAXm/mUiotcdUTxhYd/ZYAwFZnZXHa33G2adL1SDtv0YJLl+dD7LdUZwbUIU+r+30uhOL4r187hj/9j1N45vzmnai9HusJod4P4Avq918A8PZly78oFc8BcAshegHcA+CHUsoFKeUigB8CuFd9rEVK+ZxUriy+uOq1sr0HFcEfUS7A9GQuOdQL7ZpkLgULZC71Z58YN+OPFZ1ZQYq7dnfBZBCbcmpcwcylMp28aj2XsnFYTXWVer7abImZS8vduqMT3//tW/GxN+1CIJrE792zC6+9pmPFOvv6XVgIxTPTsQClGXgiJdGWtSxu5V3Bpe0tPRhG6/Pmfb2wGA34VpVL454+NwcAuG17Z2bZgQEXjo1Xtqm3nn4pgHJ8iZWYBTntixYMLjltppp8Xut1biZQ9ZI4AJnGv6v7Lh0d88JkENjT21L1baL10z6LZjdA36WYjobegJLZtN7g0rQ/ingqjS16M5fMJsSTaaTqJKvd02Blce5lZXFSSlwpImuMqkMrUVwdXPrUUxcRiifR67LhD755vK7P0euV3uCSBPADIcRLQogPqsu6pZRT6vfTALrV7/sBjC177ri6LN/y8SzL870HFWEpc6lwzyWDQcBhMdam51IgBiFyp732uWxw2c04tarv0myAo8dL5XZYcMu2djx6crrq5Sy1ljO4ZCp/Q+/8mUv1e2E4u47MpeUsJgN+/bZtOPrHd+NDt29b8/jePiVwvLzvktbAM1vmknYsW525VGhyJFWOy2HGHbs68fDRyapekDx1bg5bO5owtOyO/P5+N3yRREXHDCd09FwC1AvDEkpaUmoviL4ck+I0zbb6LYvzhROYDcSq3swbWDqP+N2vHsVv/vsr+MtHz+ChF6/imQvz2NXrXNNrjxpDtxps3QilcQmdAepyZC5dmdc/KQ5QyuKA+hk4shCKw2gQOfvP1ZtMQ+9IHLOBGCKJFIY79P3uqTqsJiO6W6wYX1wqi5v2RfGFn4ziHdf24/88cBBXF8L45OPnariVjUlvcOl1UsrroJS8fVgIcevyB9WMo4qeTeZ7DyHEB4UQR4QQR+bm5iq5GQ3Jr97d15O5BCh9YII1KIubC8bR5rDAmCN9XgiBvX0tKzKXUmmJ+WCco8fX4Z69Pbg8H8L52WCtN6WqYokUrCbDmn4m1rKXxeXJXLKYalKCqtdsIAaDKF8qeq7SmD29LTCIVcEldcpKW56eS6snxumZHEmV8/ZD/ZgLxPDcJU9V3i+aSOG5S55MSZxGa9Z8bMJbsffW03MJUE5gS8lcmgvEkEpLXWVx9RpcOjerlLBvr0FwaV9/C375tSPoctpwdMyLTz11CR/9+nEcG/fh+iG272xU3eq53kyezKVHjk01RNPvREq5pNGTuZRYZ8+lUXVa2RadpVnaNNt6ydrwhGJodVgaZuqzzWyE1WSAL5zA5Uxgj5lL9Wag1bEic+lvf3QeaSnxn9+wA6/Z1oEHbxjEZ398OevAGcpNV3BJSjmh/ncWwDeh9EyaUUvaoP53Vl19AsDgsqcPqMvyLR/Ishx53mP19n1aSnlYSnm4s7Mz2yqbmnbiqafnEgA0W2uUuRSM5SyJ0+zta8GZ6UDmg9YTUk7AWRZXurv3dEMIbLrSuFgyvSZrCYAacKr8tDhAmc5Yz5lLM/4oOpqtOQO+5WK3GHFNV/OKpt5aOUuuaXEA4F/TcymKZqspZzCPKuuWbe0AgNNT1em79OLoAqKJNG5bFVza0e2ExWjA8Qo29dbdL6XEzKUpn3LC21sguNRiM9dtWdy5GTW4VIOyOKvJiD966x586QM34enfuwNn//u9+PHv3YEvf/Bm/Jd7dlZ9e6g8up35M5fmAjF8+N9exu985WjdZ2PraeitPV7KMWS5K54QLCYDenWeKy9lLtVJcCkYb5iSOI3bYYY3nMCoGlwaYc+lujPQaseYmrl0xRPCQy+O4cEbhjDYpmSZ/f6bdqOtyYKPfv3YmunElFvB4JIQokkI4dS+B3A3gBMAHgagTXx7H4Bvq98/DOC96tS4mwH41NK2RwHcLYRoVRt53w3gUfUxvxDiZnVK3HtXvVa296AiZMribPouuBwWE0LLTlbnAjH8+XdO4Rc/+3xFmyjOB2PocOb/8Njb50I8mcbFOSXLZpYNfNetq8WG64Za8ejJzRVciiZSa5p5A0qGnNVkKEtwSUqJUJ7gksNiqpuTt2xmA9XrZ7avz7Xi7pA2wjd7Q+/smUtzgRiPBTXkdljQYjPhimft9JVKeOrsHCwmA27a2rZiucVkwO5eZ0UnxsV1NPQG1J5LJXxuav3HeguVxVlNa/4O6sX5mSAclupPisvGZDRgsM2Bm7e2687ipvrjdphhMRlyBpdOqG0Tnrkwj0dPzlRz04pWzYbeVzxhDLU5dGf+2NVzo3qZGLcQijfMpDiN226BL5LAqCcMs1EUvFFA1TfQaseUL4pkKo1PPnYeJqPAb955TeZxl8OMP33bXpyc9ONzz3B6nF56Mpe6ATwjhDgK4AUAj0gpvw/gEwDeKIQ4D+AN6s8A8F0AlwBcAPAZAL8BAFLKBQD/HcCL6tefqcugrvNZ9TkXAXxPXZ7rPagIWlmcU+cJVbPVhFAshflgDP/ju6fx+v/1I3z2mct45sI8Jr2VSzXWm7kEAKfUDAetgW+nkwft9bh3bw9OTvoxlmUk50YVS6Yzk+FWs5uNZem5FE2kkZbImUnTZDWuCOTWG6VZfnWCNXv7XZgNxDLlDPnK4nJNi5vl5MiaG2p34GqVjiNPnZvDTSNtcFjW/n3tH1CClekK9X/KlMWZ8l+sOSzGksrMl4JLBcribCYE67AsTkqJI1cWsKPb2TClLFT/hBDobrHmDC5p54ZbO5rw54+cKlsGciXEdfZtM5sMmR6RpRr1hHT3WwKWyuLq5eaXJxRHe3NjBZdcDjO8kThG50MYbHPAVCCISNU30OpAKi3x9Pk5fOvVCbzvNcNrena+aV8P3rinG3/1w3OZLDTKr+CeLqW8JKU8qH7tlVJ+XF3ukVLeJaXcLqV8gxYoUqfEfVhKuU1KuV9KeWTZa31eSnmN+vVPy5YfkVLuU5/zEbW/Us73oOL4o0nYzcaCqbcah9WIExM+vP4vnsBnf3wJb97Xi//2lj0A1k5nKqf5QLxgcGlrZzNsZkOm75KWuVStC+CN6p69PQCwqbKXYskUrKbsTV1tZmNZTkq1cpVma/b3qffMpblAtGqB2/3qNEjtzvNiKA4hspfzmo0G2M3GrD2X2My7tra0NVUluDTpjeD8bBC3bs9eCn+g341ALIlRT2VOBvVmHXQ0W+EJFj/ZatoXgdVkyEwdysVpMyEUT9XNVCfN85cXcGLCj5+9fqDwykRF6HbacvZcOjnpw1CbAx9/x36ML0bwqacuVnnr9IvnGCqymnWdmUvatDK9k+IAZAL2ddNzKRhrvLI4u1oW5wlhhP2W6tJAq5JV+9++dRLNFhN+/da1A2eEEPjv9++DxWjAH3zzeMnltr5Iou4+pyuFYdRNwB9JZO7069HTYkMonsQ9e7vxw9+5DX/17kM4NOgGAHjD8fxPLlEolkQkkSoYXDIaBHb1tOCkegGqNfBltsL6DLU7sLu3ZVMFl6KJ3JlLNrMR0XXeKQSWgks5M5fUaXH12BsikUpjPhivWuB2j5qVeGJCCRwvhhNw2c05+z05bSb4I0sZG1JKzPpj6OaxoKYG2xwYXwxX/CTq6XPK8I7bdmYPLu1Xm3ofr1AjzmKCS3OB4oNLk74oel22NQMHVtNKbuut79Knn76EtiYL3sXgEpVZd4stZ+bSyUk/9va14JZt7bjvQC/+4cmLK6ZB1ZNK923TzGnTyorIXKqnaXHxZBr+aBJtTY312e52mLEYjitZY+y3VJcGW5W/iQlvBL9661a05ghg9rhs+N17duInFz34ycXSBpb82X+cwh3/+8lSN7WhMLi0CfijCd3NvAHgD+/bjWc/dic++eC12NapTHnR7p5WKnNpXr2z26Ej7XVvXwtOTfohpcSMPwq3w5wzA4X0e+PuLhy5slgXJxPVkC9zqVw9l0IFgksOqwlSoiwleOWm/U12VSlzqdlqwtaOpkzfpYVwPGtJnKbFbkYgtnQ8CqgBak6OrK0t7Q4kUjLTkLoSkqk0vn9yGr0uG7Z3ZZ9Etr2rGVaToWJ9l+IpfT2XOpwWeELxosvzpn3Rgv2WgKXJifUUXDo/E8CPzszivbdsgS1LXzui9ejKURbnjyZwxRPOtE/4wzfvhhDAxx85Xe1N1KWY4NJ6psVpk+KGisieyUyLq4OyQq1EvuHK4uxmzPhjiCbSRQX2qHp63TYIAbQ1WfDLrxvJu+6DNw6i02ktORvy6Lg35/nKRsPg0ibgjyR1N/MGlN5Mq09qXfZKB5eUD48OHVkHe/pa4I8mMb4YURoOs99SWezpc0FK4MJssNabUhWxRPZpcUD5y+KceTKXANTlxLiZGpSc7utfaurtDcfzlgQ5bStHsC819+fxoJa2qFNWrlagqXcknsIXfzqK2//3k3jy7BzedrAvZ2aPyWjA3r6Wik2MS2iTnnRkLqXSEt4iPzun1cylQpoz/cfqp6n3p5++BJvZgPfeMlzrTaENSMmuT60JqJ5W2yXsVUus+9x2fPj2a/C9E9N49sJ81bezEN3T4tZZFqeVBhfVc0lr6F0HZXEe9fqg4crilt0cY+ZSfbKajHjg+kH88Vv35By8s3zd9792GD8+P5+pntHLH03g4lwQB9UqoI2OwaVNoNjMpWy04JI2wanctCyJzgJlcYAyMQ5QauuVHivMVCiHHd1KRP3sdKDGW1Id0WQq5111m9mAWBmyiQpmLql9DcIlNPytNK2xdjWDNfv6WzDpi8ITjGExlMg7HcZpM2eGFQBLzf05La62tBG+5ey75Asn8LePn8dr/+JH+KNvn0SX04rPvPcwPnrvrrzPOzDgxslJX0VK9DLNeAs09NZKveeL6LuUSitZuT16gktaWVydNPWe8UfxrVcn8K7rBxtuuhM1Bm2C6erspRNacEnNXAKAX711K4baHPiTh0+uK/unEvRmP1pM6wsuXfGEYDKIoqY2OuqoobcnpBw723VcH9QT17LrrmH2XKpbf/HOA7j/UL+udX/hpi1oshjx6acvFfUeJ8Z9kBIMLtHG4Y8k1j1612w0oNlqqnhwqVDPJQDY1eOE0SBwctKPWX+UmQplsqW9CRaTAedmNkdwqVDmUjnSwQv1XHLUc+ZSoAaZS5nAsR+L4fiKO3+rtazKXNL62jDYXFt9bjtMBoErZQouzQaiuP1/P4H/88NzODToxld+7RZ8/UOvwRv3dBecQrav34VQPIXL8+XPxtQyl/T0XAKA+SL6Ls0HY0imJXp1XAxmJifWSVncPz07ilRa4gOvz19iQFQq7Rg/41sZXDo56UOn07rinNBmNuK/vWUPzs8G8cWfXin42um0xFPn5pCsQiAqM3GywDHEvM7MpYuzIfS32ouaVlZPZXELIXVybIMFq7XMa4vRgL4iAntUv1x2M37+piF859hUUb3cXh33AgAOqr0gNzoGlzYBfzSJFrv+srhcXHZlrGYlzAf0f3jYzEZs61R6s8wxc6lsjAaBazqbcW5mc5TF5c1cMpV7WlzunktAfTTNXG3WH4VBVPduoVbOcHzCh8VwHK15y+LM8C8LLml3sTktrraMBoGBVnvZMpe+/tIEFsMJfPXXb8Hnf+kG3DjSVrDJteaAeiJXib5L2oWhqUCAq9OpfKbNFZG5NKVeNPfq2JczwaU6yFwKxpL41+ev4N59PUVNpiIqRiZzKbAyuHRKbea92ht2d+H6La34+kvjBV/7yXOzeN/nX8Dvff1Y0X3SiqW7LG4dDb0j8RSePj+HW7a2F/U8i9EAo0HUxblJw5bF2ZXtHWyz5xxMQo3n/a8dgQDwuWcu637O0TEvhtsdeW+YbiQMLm1wUsqyZC4BSnDJX8GG3i67ueCHrGZvnwsvXF5AMi1ZBlNGO3uczFyCUhYXTZazoXf2IFam51JdlsXF0NFsrepJkctuxlCbA0dGFxBNpHNO7gCUzCX/sj4zs/4YbGZDzv5WVD1D7U1l6bkkpcRXj4zhhuFW3DDcVvTzt3U2w242ViS4FE9JWIyGgoGupbI4/TdmptVm6PrK4tSG3nUQXPryC1cRiCbxwSzjnInKZaksbilgG02kcH42mDW4JITAzVvbcHYmUPCm0StXvQCAb7w8gT/9j5MVneSaSKVhECj4GWs1GRArMXPph6dnEI6ndJf9aIQQcJiNdVMWZzSIFWVmjUDb3hH2W9pQ+tx2vO1QH778whgWQ/o+14+O+TZNSRzA4NKGF02kkUzLdfdcApQUz0qWxemZFKfZ29eCkPqh181MhbLZ3t2MKV90xUX7RhVL5g4u2S3GskxwC6pBoyZLgZ5LdXB3cLWZQLQmWYH7+lvw/OUFAEBrgWlx8WQaMTUIOBuIoctZeHQ7Vd6WNkdZMpeOXFnEpfkQHjg8WNLzjQaBff0tOD5Rmcwls7Hwvuaym2E2ikzZph6TXiUjQ08phZa5FIzV9pidSKXx+Wcu48aRNhzaRCfRVH3NVhOaraYVPZfOzQSQSstMT87VDgy4kUpLnFT7MuVydNyHXT1OfOB1I/jCT6/g//zgXFm3fbl4Kq3rhup6psV9+5UJ9LTYcNNI8cF5m6U8GdzrtRCKo9VhKVgGXW+0sjj2W9p4PnjrVkQSKXzpucKlttO+KKb9URwccFd+w+oEg0sbnBYkKEfmktthLnrijV5KcEn/heyeZXenmLlUPju7nQCUUdIbXTSRuyzOWqayuFAsiSaLMedJkZbRVA93B1eb9ddmEuO+flfm95EvuLS6HGg2EOWxoE4MtTngiyTgW+fNiIdeHEOTxYj7DvSW/Br7+5Wm3uXuoZJIpWHWcWEohEBHs7Woht7T/igsJkPeslCNw2KEQdS+LO47xyYx6Yvi127dWtPtoM2hq8W6IrikBY325QguaRd2R8e8OV9TSolj414cGnTjD+/bjQdvGMTfPXEB/1ji6PFC4sl0wZ5tQOnT4hZDcTx1bg5vO9RXUmDGYamTzKVgvOFK4gCg02lFv9uOm4osSaT6t6unBbfv7MQXfjpa8FrhqNZvaRPddGFwaYPTytjK1XPJV7HgUhwdRVwY7uldHlxi5lK57FCDSxu975KUMm/mks1sLNu0uFzNvIGlzKVQHZzArTYbiNakf9Hyi4P8PZdWB5fYf61eDKkjr68shEp+jUA0gUeOTeGtB/syfyel2NffgmgijcvzpW9LNolUumAjXk2xwaUpXxS9Ln1ZeEIINFtNNQ8ufebpy7imqxl37Oyq6XbQ5tDTYltRFndiwgenzYTBtuzZfj0uG7qcVhxTL/SyuboQhjecwMFBN4QQ+Pg79uMtB3rxP793Bv/6fOEMhWLpPYZYTAakJYoOkD9yfArJtMT9h/pK2j573ZTFxdFeRGVDvbCZjXj2Y3fijXu6a70pVAG/dus2zAfj+PrL+Xu5HR3zwmQQWUt2NyoGlza4cmYuuewW+MKJitSgzwdi6Cwic8ntsGTGqvKCsnz63XY4LEacnd7YmUta/wJrrobeZqWB5npHmAdjyZzNvIFlmUt1MulJk0il4QnFa5IJtK9/WXApb88l5ZimBdBn/TEGmuvEUJsSXFpPadwjx6YQSaTwwA2llcRphtV+F+VqMK6JJ6WurAMA6Gi2FBdc8kbQq6PfksZpM9c0uBRNpHBqyo+3HSwtQ4KoWN0ttjWZS3t6W/IGZA8MuPP2X3tVzWrSBgEYDQJ/9cAh3LGzE//ft07gqXNz5dl4VTypryxOmyobLPI84duvTmB7V/OKm7HFcFiMiNRBcGkhFG+4SXG08d28tQ0HB1z4zNOX8l4rHB33YlevM2elxEbE4NIG548oH0baXf71cDvMiKfSZR9NGk2kEIgli+q5BCh9l1pspk31B1tpBoPA9q5mnJ/dJMGlPJlLynrr29eDBTKXbCYjhKi/zKVzMwFIuRQkqKa2pqXAcf6yOCW4FIgmEY4nEYwlGWiuE9p+c2UdTb0fOjKG7V3NuHadqeTlCHRlk9DZLwVQM5cC+ht6K5lL+kdXN1tNNe255FGbmrIslaqlq8WKWX8MUkqk0hJnpv05+y1pDg64cGk+lDMD/+iYDzazIZPBDShZQ//wi9fDYTbiiTOzZf03JFL6AtSDJRxPxxfDeHF0Efcf6iu5D6HDYqqLfpDzwVhDlsXRxiaEwAdv3YZRTxiPnZ7Juk46LXFszLfp+hAyuLTBZTKXytDQW5t8UO7SOO3EtJieSwDw22/Yjk/87IGybgsppXFnpzd2WZwWNMqZuaReNK73rp1SFpc7+GkwqBNZ6ixz6UenZyEEcOuOzpq8v5Y+7NZVFpfArFoewcyl+tBkNaGj2YKxEgM652cCeOWqFw8cHlx3g/b2JgscFmNFgkt6GnoDQIfTCk8opivrN52WmPFHdU2K0zhtpqKzGsrJo2ZltRf5GU5Uqm6nDfFUGovhBC7NBRFNpAuWnWg9T07kaPB/bNyLfX2uNQEfm9mIgVYHJryRsmy7Jq7zGKJNGxv16C/tffjoJAAUPSVuOVsdlMXFk2kEokkeW6gu3bO3G51OK756JHtp3KX5EAKx5KZq5g0wuLThZXoulaOhtxpcKvfEuHl1ik6xwaW9fS68eX/pjV4pux3dTswHY1jQOWKzEWn9lGwFMpeiJY7/1QRjqcyo8FwcVlPdZS49dmYWBwfc6KxRJsJbD/bhnr3dee/qagFzfzSB2YAWXOIJaL0YanOUnLn0lSNjMBkE3nFd6RdGGiEEhtocJQe6clGCS/ozlxIpqevGzHwwhmRaoq+I4FKzrbY9lzxB5bOiEfuiUGPSgq8z/mimmffe/vzBJa3c7WiWvkvJVBonJn04kOMisL/VjonFMgeXkmlYTIUz74faHBACuDSnP7j07Vcmcf2W1kzWUykcdTAtbjGsHFtYFkf1yGQ04Geu7ccTZ2ezToTVBggwc4k2FH+0fGVxLkeFgkuZu5788KgHO3q0pt4btzSuYOaSFlxa54lVKJZEc57MJQBoshjrIvVcMxuI4uiYF3ftql1j3rce7MM/vudw3nWWN/TWem+wLK5+bGlvKilbKJ5M4xsvT+ANu7uLvuGQy2Cbo/w9l3SWtADIlHxnO/lcbcqn7Ms9xZbF1TC4pH2GF9M3kWg9utVjvRJc8sFiMmBbZ3Pe57gdFmxpd+DY2NrMpXMzSvbTwcHspXX9bnvZM5eUht6FM5dsZiP63XbdmUtnpv04OxMouZG3ph6mxWnHlmLbZhBVyzuvH0AqLfHtVyfWPHZ03ItmqwlbCxybNhoGlzY4fyQBq8lQlr5ElSqLW/rw4IlpPdjRrRwEz2/g4FK0YOaSQV2vHGVx+QO7DosJoVj9ZC49eUZpWnrX7vqecNJsMUEIJYCuZS51syyubgy2OTDlixQ9QvtHZ2bhCcXxwA0DZduWITW4VM5hFImk/mlxWgbgnI6m3lpwqeiG3jUsi5tn5hJVmVYCPeuP4cSEH7t7nLqCvUpTb++a5Zlx4Xkyl3yRRFnLT4vJfhzpaNI98fJbr0zCaBC4b52Z/fY6aOitZdC3NfH6gOrT9m4nDg668dUj42vOMY6OebG/3wXjJht0weDSBuePJsrSbwlQ7voAgC9S3nIp7cS0ViU4tFJPiw1OmwlnN3BwSX/m0nrL4vJPiwOUiXH1lLn02OkZ9Lls2N3rLLxyDRkMygh2fySB2UAUFqMhb48mqq4tbQ6kpdJYthhfOTKG7hYrbt1evn5fQ20ORBNpXcEdvRKpNMwmfSeMWkaP9lmXz5RPyY4otudSIFrDht7BGOxmIxyW9WdIE+mhZalO+ZTMpT0FmnlrDg64MOmLYjYQXbH82LgXLrsZW9qzl5FpQybKWRqnd1ocoAaX5kIFA+TptMTDr07g1u0d6+5T5LAYEU6kKjIhWi+tnyLL4qievev6AZydCeDEhD+zLJZUpqge3GQlcQCDSxueP5JESxlK4oDK9VyaC8TQbOXUt3ohhMCObifOzWzcpt5az6WC0+LWkbmUSKURS6b1ZS7VSc+laCKFZy7M487dXetupFwNLeoI9jl/DJ1Oa0Ns82Yx1F78lLZpXxRPnp3FO68fgEnnHX1d26L2HSln36Viey4BS/0F85n2KYHSYqYjOa0mRBNpJFLrC4aXyhOKM2uJqspqMqKtyYKXry7CH00WbOat0XoqrS6Ne3XMhwMDrpyfIf2tanDJW75jSDGltcPtTQjEkpkBOLkcubKISV90XY28NQ6LCam0RLxGxxUA+OpLY+hpsdVkci2RXm892AeLyYCvvjSWWXZ6KoBESuJQjlLbjYzBpQ2unJlLDosRZqOoSFkc66nrixJcCtT0jlUlRdXMpVwBzaWG3qUHfUJq+nyhzCWHpX6mxT13yYNwPIW7dtV3SZxGy9iYDcSY+VhntrQVH1x67PQM0hL4mevKVxIHLI3yLmffpWIuDF12M0wGkSkBz2fKp0yKKyZQ2qzeQArV6DgyH4xxmhNVXZfTip9e8gCA7uDSvv4WGARWlMZF4imcmwnkbbo7UIHMpUSyiLK4TmViXKHSuG+9OgG72Yg37ln/Z3jmPChem+DSS1cW8NylBXzg9SO6M7yIasFlN+OevT349quTmcoIrZk3M5dow/FHk2WZFAcoGS0uuxneigSXeGJaT3Z0N8MbTuhqQNuICmcuaT2XSj+pCuoOLplq3jRT86Mzs7CbjbhlW3utN0UXpzola8Yf5aS4OtPptMJmNuBqERPjTk/54bSZsFUdvV0uA612CAFc9ZTxwjClv+eSwSDQ3mzRGVyKFFUSBywdY2o1Mc4TjKODZStUZd0tNsSTaRgEsKtHX3DJYTFhR7cTR8eXMpdOTvqQSsuck+IAJfvQYjRgvIxNveOpdM5zkNVG2gsHl6SU+P6JabxhT3fBjGk9HBYluBRO1Oa48vdPXESrw4yfu3GoJu9PVIx3XT8AXySBx07NAgBeHfOiy2lFT8vm6wXK4NIGF4iUL3MJUKKzvjKXxXmCcQaX6szObm1i3MYsjdMyknIGl9TxwOtpZqk16S50ktdkNSJUBz2XpJR4/PQsXntNR8OUqLbYzPCrmUvdm/ADvJ4JITDU5sCVIrKFzk4HsKvHWfbyRpvZiJ4WW1kzl5SyOP3b2dFs1dlzKYq+IoNLTvUGUs2CS6EYy+Ko6rSJcds6m2G36P/MOjDgwrFxbyYzWws0HRzIXb5iMAj0uW3lzVwq4hgy0GqHySDyBpeuLoSxEIrjNWW6OZQJLtXg5tfpKT8ePzOL9792pCyBMqJKe+01Heh12fA1tTTu6JgXBwfdm7JdA4NLG5w/mihbzyVAaepdkbI4J09M68l2Nbi0UZt6a5lLlSyL0zKXmqz5T3odFhPCdTAt7uxMABPeCN6wu6vWm6Kb02aCJxiHL5Jg5lIdGmpr0t3nSEqJszMB7OypTCP5wTZHeXsuFVHSAijBpUKZoOm0xIw/ih6Xvahtcdq0zKXqN/WWUsITjLMsjqpOywjY119cT5MDA24shhMYVwNFR8e86HXZ0FXgBkV/qx0TZcxcShTR0NtkNGCo3YHRPMElrZnwPp3NzQuxm9d/k61U//DkRTRZjHjfLcNVf2+iUhgNAj9zXT+eOjeH8zMBXJoP5S213cgYXNrApJTwR5KZu5rloJTFlW9aXCKVxmI4wcylOtPRbEFbkwXnN2pwKVk/ZXFNFiPiqdo149U8flpJ5b1zVyMFl8yY9itTf7TpQVQ/htocuLoQ1tW7bdIXRSCaxE6d5S2lbku5xFMS5iL6gCiZS/mDS55QHImURG+JZXHlHJOulz+SRDIt+RlOVacFg/T2W9IcVMvfjqp9l46NezPL8ul328s7La6IoQCAUhqXL3Pp+IQPZqPAjp7mcmxeZvpjtTOXRudD+M6xSfziLVvg4gRYaiA/e90A0hL40/84BQC6jisbEYNLG1gsmUY8lUaLvYyZS3ZzWafFLaiTL3jXs74IIbC9q3nDZi5FEzobeq9jWlymoXeBzEGHtTYncKs9fnoGBwZcBe/e1pPlx7YuZ+Ns92axpd2BcDylqxzs7LRy131XhTKXhtocmPZH1/U3vVwxPZcApQeVJxjPG2ib8ikXrsUGl7TMpVoEl+ZDSsCMQzmo2gbUCW75eiVls7PHCYvRgGPjPnjDcYx6wjigY6JTv9uB2UAs07B3veJFZj+OdCjBpXQ6+zHk5KQPO7qdsJrKU9ZutyjbFinTMVOvf3z6IkxGA37ldSNVfV+i9dra2YzDW1rxzIV5AMD+PKW2GxmDSxuYXy1fK1dDbwBwOcxlLYvTygQ6eWJad3b2OHF+JrghJ8YVylzSlsfWcVKVKYuzFM5cAoBwDfsuzQdjeGXM2zBT4jTLszKZuVR/hjJT2vJPOAKAM9NKIHtHd+WCSwAypTDrVXzPJQviqTT8kdx/51M+JQuvt8iyOC2A7a9Bz6V59TO8vYl/f1Rdt27vxL994CbcMNxa1PMsJgN297Xg6JgXx9R+S4d0BKj63ErQd8obLXpbs0mkpO6G3gAw3NGEWDKdydZdTkqJ4xM+7C+yRDAfu1k5rkSqeG4y7Yviay+N44HDA7xhRA3pXYeVabdbO5vgKmPP40bC4NIG5lf7L5S7oXcgmkSyTCU8WpkAU+rrz/ZuJ4KxJCZ95TmRqiexZApGg4Apx11DIQRsZgOiydL3c29YydZwF0jr1jKXQjXsu/Tk2TlICdzVQP2WgKWMDYCZS/VoqF0J6FzRMTHu7HQAfS5bxU7GBtXgUrn6LiWKLGnpVHuCzeUpjZtWj7XFTovTbiAFaxBc8mSyj3mDiKrLYBB4zTUdJTXMPTjgwvEJH1656gUA7NORYdCvZkqVo+9SLJlCJJHKlJ7poU3RzFYaN+GNwBtOFN1/Kp9aNPT+zI8vIS2BX7t1W9Xek6ic3ry/F3azEdcNFRf03kgYXNrAfOod0rI29FZP/Mt1h1Qrl2Bwqf4sTYzTVxp31RPGj8/P1aSpbLGiiTRsBe4Y2szGdZXQeEJxWIwGXT2XgNpmLj1+egbdLdaie1fUmnZRbTQItHMUet0ZaLVDCOjqdXR2unLNvIHlWVTrDy6l0xKJlCy6oTeAvH2XJn0RWIyGovdlq8kAk0EgGKv+sdej/nsYXKJGcmDAjXA8hW++Mo5tnU26MvwH3MoxpBx9l7TXGGzTn6U4nCe4dGJCycBq5ODSQiiOf3v+Ku4/2Je5GUDUaJw2M772oVvw0Xt31XpTaobzHTewSmQuuR3KCaQ3HEdbGS7mMplLnPRUd3Z0K00hz00HcMfO/BktUkr88hdexIXZIAwC2N3bghuG23B4uBU3b22vu+BhLJmCNUe/JY3NtL7g0kJQ+RspdFdVu3NZq8yleDKNp8/N4W2H+htuZKqWudTRbIHB0FjbvhlYTUb0tthwtUDmUjyZxsW5IG4vcJxZj45mC+xmY9HBpW+/OoHHT8/ibx48lPn7SKSVjEa9k56U9y8cXJr2RdHtsha9Lwsh0GwzIVCLsjj1BlGbg8ElahyH1B5Lo54wfubafl3P6XHZIAQwXobMJe04VEwQpafFBpvZkDW4dHzCB6NBlLVnnd1S3Wlx//LTK4gkUvjQ7cxaosa2t0wTGxsVM5c2MO1Es6w9l9RAVbn6Ls0HYrCZDZnsDaofbocFXU4rzs0EC6777AUPLswG8Ru3b8Nv3rkdbocZD704ho/82yu44y+fLFsDzHLRl7lkWNe0OE8orutufpO1tplLR0YXEIqn8IYGK4kDlnousSSufg21F57Sdmk+iERKVqyZN6AEYEqZGPf46Vk8fHQSz11ayCxLpJQ+dMX2XAKWehRlM+WLoreluH5LGqfNVKOyuBhaHeacJcZE9WhrR3Mmq/igznHhFpMB3U5bWTKXxrTMpVb9wSWDQWC4vQmjWTOX/Nje1ZxzSEkp7OprVauh908uzuPQoBvbK9R3j4iqg5lLG1imoXcZp8VpY0G9ZQoueUJxdDRbGy5jYrPY0e3UVRb3hZ+Oor3Jgt+6a3vm5CaRSuNzz1zGJ753BlPeaCalux7EkunCmUtm47pOqjwhfdl9mcylGk2L0xopH9J5gl1PXOqxrZvNvOvWUJsDT5ydy7vOWXUf3NVb2YuKwTZH0T2XZgNKH6Qv/nQUt2xrBwAk1F5sxZTFtTosMBpE3p5LU75IyX0amq1mBGowLc4TjHPaKzUcg0FgX38Lnru0gANFTHTqb7Vjwrv+0trxhTAsJgO6iszaH+loyhwvNVJKnJjw4c5d5b1BZDIaYDEaqlIWJ6XE6Sk/3nKwr+LvRUSVxVtNG1imLK6MmUtazyVfuEyZS8FY3ZVM0ZId3U6cnw3kHH0LKA1yHz89gwdvHFxx18xsNGQCFuWa0FQusUSq4JQW6zp7Li2EYrp6p2Qyl2pwYQgo6fnNVlNZylyrTctc6mTmUt3a0t6EuUAsb2nFmekATAaBrR3NFd0WLXOpmAmY2kTTH5yawaRaDpNIFR9cMhgE2posmA/Esz6eTkvM+GJFN/PWOK2mmvS78wTjmawsokZy43AbmixG7O7V32uw320vS0PvqwthDLTaiy6BHelowtWF8IqhOtP+KDyheFn7LWnsFmNVpsVN+aLwR5NF/b8govrE4NIG5o8kYTEZypomW+6yuLkAg0v1bEd3M6KJNMYWc9+p+9LzVyCEwC/ctGXNYwOZ6SrlmdBULlE9mUsmA2LrKItTei4V3rdrnbl0dSGMwTZHQ2YPttjMMAigt8QLcqq8QR2NtM9OB7Cts7moHkalGGqzIxxPZSac6TEbiOENu7sgpcSXnrsCAIirF3aWIkvBOputOXsuLYTjiKfS6G0pMbhkMyFYgwD1fCjGzCVqSL9xxzX4/n+6tahz5P5WO6a8UaTy3HDTY2wxXFRJnGa4ownJtFxxw+74ePmbeWscFmNVMpdOT/kBALsrWBpNRNXB4NIG5o8mypq1BCwFl7xly1ziXc96dq1aovH5Zy5nfTyaSOGhF8dw955u9LnX9grpabHBaBANmblkMxsRLbFXVDSRQiie0tVzKTORpUaZS1c8IWxp0MksdosRn/+lG/Cem9cGNqk+aPvWFc/aPiGaSk+K0wy1FzcxLppIIRBN4tqhVrxhdze+/OIYoolUpudSscGwDmfu4NKUVym/63GV1nOpVg29PcE4Ohow65HIZjYWPZWs321HMi0z5bKlGluIFDUpTrM1y8S4E5N+GASwpwJZP3aLEeEq9FzSyvOr8TlARJXF4NIG5o8kytpvCVBqsJ1WE7wR/Xd+c0mlJRZCzFyqZzt7nHj/a4fxhZ9ewVPn1vZNefjVSXjDCbz3luGszzcZDehpKU8DzHKKJtMF71YqDb1LO6laUDMj9JSamdW+BrXIXEqnJcYWI9jS3pjBJQC4fWcXWnlxW7e2FAjo+KMJTHgj1QkuqReSevsuaSVxnU4r3veaYSyE4vjOsamSyuIApam3Nl1ttSsLysWilu1ZrFo09I4n0/BFEsxcok2jX8vGXsc5jS+SgC+SyByPijGcLbg04cM1Xc2Z6W7lZDcbqzIt7tSUH4Nt9kypOxE1LgaXNjB/NFmRA7XLYS5LWdxiOI60BDOX6txH792F7V3N+K9fPYrFZeUkUkr8809GsbPbiZu3tuV8fn+rvXEzl0osiysmuAQADquxJtPiZgJRxJPpou/eEunlspvhtJlwcS771MlzWjPvKgSXBtQylKsefcElLTuh02nFa7a1Y3tXM77wk1HEMw29iysl7Wy2Yi4Yy9rz6ZWrXlhNBuwocVJSi035XF7ei6XStOOcngxNoo1gwK2V+pd+TqMFt0spi2tvssBpM60ILh2f8FWkJA5QMqurEVw6M+XH7h72WyLaCBhc2sD8kQRabOUfCOiym8vS0FsrD+gocloGVZfNbMQnHzyExXAcf/DN45kLo5evLuLUlB/vfc2WvP16BsrUALOc4sl0weCSfR0NvbWeLnoaegNK1kG5+pgV44p6kd3ImUtU34QQeP32Dnz/xDRiWcpMq1kOYTMb0d1i1V0Wp2UudTmViabvfc0wjk/48PzlBQCAudiyuGYr4sl01qluR64s4uCAu+S+Uzt7nEimJc7PZg/iVYL2Gd6uo7cc0UagZS6t54bZuNrDspSbOkIIbO1owqhaZjzrj2IuEMO+vsoEl+wWU8XL4qKJFC7Ph7CLzbyJNgQGlzYwfzSBFnv5M5fcDjO8ZbgQ1qbmsCyu/u3tc+F33rgT3zsxja+/PAEA+OefXIHTZsI7ru3P+9yBVjum/dGq3lEvJJpI6SiLW0dwSb3o0pu5NNjqyAR6qkm7yC4lPZ9Ir3ffMITFcAI/PDWz5rGz0wE4rSb0Z+nZVgnaxDg9ZpeVxQHAz1zbD6fVhH96VulBV2xD7w6ncjzQglaaSDyFkxM+XD/cWtTrLadlLhyf8JX8GsXSgujMPqbNwmExodVhXmfmkvLcUjOGhzuacGlOCS5pf+/7ByqUuWSu/LS4czMBpCWbeRNtFAwubWD+SLLsDb0BwG23rDvL4sJsAP/8E+UEvZOZSw3hg7duxY0jbfiTh0/ipSsL+N7xKTxweDAz7SyX/lY7UmmJKd/6GmCWU0xH5pLVbFh3WZzeO/ojy+5EVtNVTxhGg8jajJ2oXF53TQf63XY89OLYmsfOTPuxo8dZtWmFg22OonouGcTS33GT1YR3Hh7IZC0U33NJeZ35VcGlY+NeJNMSh7eUHlwaaW9Cs9WUmRxVDVoQnT2XaDPpb7Wvq+fS1YUwWmymzICcYo10NGHSF0E0kcKJCT9EhZp5A9WZFpeZFMfMJaINgcGlDUzJXCp/WVyL3VzytLjj4z586Esv4Y1//TSeveDBh+/Ylpl+QfXNaBD4qwcOQgD4+c88j5SUuqZ0aX1OSrnT9+LoQtZG4usVTaRgNRXIXDIZEU+lSxo57AnFYTII3X9/Ix1N8IYTK3paVcPVhTD63LaiL5KJimE0CLzr8AB+fH5+RWBHSokzVZoUpxlqc2DKH81aorfarF8ZOGE0LAW+lg8vKLbnUia4tKqp95EriwCA64ZKDy4ZDAL7+ltwrJqZS0H2XKLNp3+dpf5ji+F19Tkc6WiClMrn9/EJH7Z2NKHJWv5zfQCwVaHn0umpABwWIzOoiTYIXlFsUNFECvFkujKZSw4zfJF41qakuVyaC+I9n3seb/27Z/DMhXl85I5r8MxH78B/vWdX1e5Y0/oNtDrwp/fvRSyZxu07OjOTS/LRyl1K6VHwB984jj/9j5NFP6+QWDINm7lwQ29l3eJPrBaCcbQ1WXTv2yPaBJgqZy9dWQhjSxuDu1R5DxwehBDAV48sZS9N+aIIRJNVaeatGWpzQEp9055mA9E1mbUjHU24bUcngOIzl7TX0noVaV66sohtnU3rnnq4v9+F01P+zDS7SpsPxWAxKRNkiTaLfrcDE4uRos6BlxtbCJfUzFujnS9cmgvh5KQP+yvUzBtQy+Iq3HPp9JQfO3ucMBh4LUC0ETC41OD+x3dP44NfPLJmeUAdSVyRnkt2MxIpWdQHzv/83hm8ctWLj967Cz/52J34L3fvZCp9g3rHtf34P+86iD+7f5+u9XvdNghR/OjeS3NBnJ8NruskLptkKo1kWhbOXFKDT6WUxnlCcd39loBl44XnqhtcuuoJYYjNvKkK+tx23LajE185Mp7JBjybmRRXvXII7e64nr5Lc8EYurKUbf/G7dvQ67IVXU7a6rDAIFYGl9JpiZevLuLwltwTN/XaP+BGPJnGuZnAul9LD08wjo4iguhEG0F/qx2RRKqkDP50WmJ8MbKuz13tfOGlKwuY8kUrNikOUKfFJVJlPQdbTstereZnABFVFoNLDe6Fywt4/Mwsgqumz/ijyodepabFAdD9wSqlxCtXvbh7bzc+dPs2OCuQTUXVI4TAz14/oDut22oyostpzUxI0Utr/htLpteUkaxHTB0jrjdzqZSm3guhWFGlIoOtDhgNoqp9l/zRBBbDCaaiU9U8eMMgpv1RPK2WumYmxXVXN3MJgK6+S7P+WNaegDdtbcdPf/+uogLIgFIe2NZkXRFcujQfhDecWFczb80Bral3lfoueYIx3iSiTUfLxi6lNG4uGEMsmcZga+l9DltsZnQ0W/CdY1MAUNHgkt1igpSl3WTTY9ofhS+SwJ5eNvMm2igYXGpwU74IUmmJl9SeDRq/2nC7UtPiAP3BpUlfFPPBGA4Nusu+LdQYSulR8INTM5leJ8UGpvLRgkuFGnovZS6VElyKo62I8dwWkwEDrXZcms8fXLo0F8SH//XlkqfYLXdVnU63hcElqpI7d3Wjo9mCL794FQBwdtqPXpcNLkf1bjh0Oq2wmgwFM5dSaQlPKI4up62s79/RbMFcYClYfmRU+ey+fh3NvDVb2h1w2kxVmxg3H4yz3xJtOgOtpZf6a0HtgXV+7o50NGWGpOztq1zWj8Oi3GQLV2hinNbMexebeRNtGAwuNbBEKp0Zlfz8Jc+Kx/xaWVwFsoRcduVkUu/EuKNjXgDAwQF32beFGsNAq6OoE7HZQBQvX13EPXu7AZR2hzAXLTBjNRdu6K2sX1pZXHuRWQ0jHU0YLRBc+u7xKTxyfKosZS/aSe56GosSFcNiMuBnrxvA46dnMRuIVr2ZN6BkXg61OXDFkz+4tBCKI5WW6Gopb2ZOp9OKuWWZSy9dWURbk6Usgy2EENjf76pacMkTjOmeiEm0Uawnc2lMvVG23ozh4XbleDHS0VTRagC7WQsuVabv0ukpNXu1yp8DRFQ5DC41sBl/FFoZ9POXF1Y8pmUuuSowLU4ri/NF9JUqHR3zwmI0cMzoJtbfas9k2enx+OlZSAm8/7UjAEq7Q5iL7rI49Y5dtMiG3vFkGoFosuiSmeH2JlyeD+XtbaCdiE2WIdh2RQ0usecSVdMDNwwimZb4yotjuDgXrMlFxVCbo2Dm0mxAyQroLHPZV0ezFfOBlcGl64Zay9a3aP+AC2emAognK9vUW0qJ+VAcHcxcok3G7TDDYTEW3UcSAK56lOf0F9mvbbWRTiW4VMmSOACwW0pvD6DH6Sk/BlrtFbkRTkS1weBSA1ueEnts3LtiXKjWc6kSdzSKLYt7ZcyLPX0tsBQoQ6KNa6DVjkRKZi7YCvnByWkMtTlweEsrWmymkk7ictGmvxVs6K1lLhV5x24hpARdiw0ube1sQjiewlwglnOdU2oK+aRX3+8xnyueMFodZp7UUVVt62zGjcNt+MenLiGRklWdFKcZbHNgbCGcN5Cr/R2WO3Opo9mC+WAMUkp4gjFcmg+VpSROc6DfjXiq8k29g7Ek4sk0y+Jo0xFCqKX+xZfrjy2G0d1izfR0LNWImrm0r4IlccDysrjKBJfOTAd445log+HVfgPTshfecW0/Eill4ozGH6lcWVwmuKSjLC6ZSuP4uI/9lja5TBq5jiBRMJbEsxc8uHtPN4QQakld+XouaWVuhRt6qz2Xisxc8oSUi9Jiy+K0NPdcfZfC8WSm4Xc5MpfGFsIYal9/KQ5Rsd59wyAC6hCKnd3Vv7AYanMgFE9lAsHZaCXnnc3l7rlkRSyZRjCWxMtXvQCAw2Vo5q3RxpIfq3BTb486ZIFlcbQZ9bcW30cSUD93y1CKfu1QK/rddty2s3Pdr5WPvYLBpWgihUtzQexmSRzRhsLgUgPTMpfeerAPBrGy75I/moDZKApeQJfCbjbCbBS6ei5dmAsikkjh4GBlU3epvg20KidTesrbnjo7h3gqjbv39gAo/SQul1hCZ+aSemcxEi+uvES7YC12itKI2nMlV9+lM9OBTBms9re/HlcWQmzmTTXx5v29cFpNMBoEtnVVP8CpXdzlK42rVOaSNn1uPhjHkSsLMBtFJiBUDoNtdrjsZhyf8JbtNbPRgugdWabpEW10fW57SRnV44sRDLau/3O3x2XDsx+7E7t6Kp25pLTWiCTK39D7/EwQaclm3kQbDYNLDWzKG4HTZkJ3iw37+l14blnfJX8kgRabuWx9HJYTQsBlt+gqi9OaeR8aLN+dWWo8xTTA/MGpabQ1WTKlIgOtdowvRvKWsBQjqnNaXJ9L2eZCvVlWK7Usrs9th8VowOUcwSVtqsqWdse6g22JVBqT3mhZ7qASFctuMeKXXzeCu3Z1FQzyVoLWZ6xQcMlpM627fGW1jmYtuBTDS6OL2NfvKut7CCFwYKDyTb3nM5lLLIujzaffbcdiOFHUFLV4Mo1JX2Tdk+KqqZiG3qen/Pitf39Fd7837ZyGZXFEGwuDSw1s0hfNXADfNNKGV696M033/NEkWuyV66Xidph1NfR+dcyLFpsJw2wavKnZLUZ0NFsKZi4lUmn86Mws7trVBaNBCYz2u+0Ix1O6e3wVomUuFbqgcznM6HfbcXKyuIs0T4kXXUaDwJZ2R87g0qlJP5w2E24YbsOUb33BpUmv0lydzbypVv7zG3fg0+89XJP3HmpzQAhgdD53cGk2EM1kGZWTFlya9EZwbMKHw2Xst6TZ1+/C2elAxZrwAkvHuY4yNzwnagQDrfpL/TWT3gikBAZb19fMu5qK6bn07Vcn8fDRSZyd1tfv7fS0H3azkTe5iDYYBpca2JQvgl630g/ippF2xFNpvKL2cAhEE2ixlX9SnMZtN+sqi3t1zIeDg+6KZFBRY+l32wv2Tnr+0gIC0WSmJA5YKqkrV2lcTGfmEqA0yz816S/q9RdCcRgNIjNVsRjDHU15M5d297agz23HbCCGRKr0aVDaGHae1NFmZDMbMdBqx4W5YM515gIxdFUiuORUgs5Pnp1DPJnG9Vvayv4eB/pdSKSk7ou8UniCSllcsRmaRBuBlo09XsR5ydhi433uFjMtTrsRd2Za3znT6Sk/dvY4MzcSiWhj0B1cEkIYhRCvCCG+o/48IoR4XghxQQjxkBDCoi63qj9fUB8fXvYav68uPyuEuGfZ8nvVZReEEB9btjzre5BiyhtFr5q5dMNIG4QAnr+s9F3yRxIVzVxy2c0FM0nC8STOzQRwLZt5E/T1TvrBqWnYzUa8fntHZpl2h7BcTb2jOjOXAGBvnwuXPSGEYvpT3z2hOFodZhhKOGHa2tGEKwthpNIrSwDTaYkz0wHs6W1Bv9sGKYHpdfRd0sqBtjBziTapbZ3NuDibO7g0G4ih01neZt4A0OawQAjgsdMzAFDWSXGa/QNKD6dKlsbNB2NosZk4BZY2pf4SMpe0z93BBgou6c1cklJmjjdndAS1pZTqpDg28ybaaIo5K/htAKeX/fwXAP5aSnkNgEUAv6Iu/xUAi+ryv1bXgxBiD4AHAewFcC+Av1cDVkYA/w/AmwDsAfBz6rr53mPTiyZS8ITi6HMpJ78uuxm7e1rw/CWl75I/mqzoiHGXo3Bw6cSEH6m0xEEGlwhKBtJEnt5JUkr84OQMbt3RsSLwsxRcqk3mkpRLvQH0WAjFSr6bP9zRpPRlWBWEu7IQRjiewu5eZyagvJ6m3lcXwrCYDOiuwMUzUSPY1tmMS/NBpNNrj0dSSsz6K5O5ZDIa0OawIBBNYku7oyKld/1uO1odZhyv4MS4+VCcJXG0aXU5bTAZRFEZ1WMLEZiNAt0tjfO5azPpCy5NeCOZawI9GZPT/ii84QT7LRFtQLqCS0KIAQD3Afis+rMAcCeAr6mrfAHA29Xv71d/hvr4Xer69wP4spQyJqW8DOACgBvVrwtSyktSyjiALwO4v8B7bHrahWWve6l2++at7Xj56iJiyZSauVTJsjgL/AXK4rRm3gcG3BXbDmoc/W47Ysl0phHsascnfJj2R3H3np4Vy112M5osxgoEl3RkLvUrJz4niyiNWwjFSw4uZSbGeVaWxmnBrT29LvSpf/OrA1DFuOoJY7DVXlJ2FdFGsK2zGdGE0mB3tVA8hUgiVZHgErDUp6gSWUuA0tR7/4Abx7JkLi2E4viZv38W3z8xta738ARjaG9mMjltTkaDQK/bVlTm0thiGAOtjoYqAzMYlKnTkQKNy09MKOco13Q168pcOjOlrFPpaXdEVH16M5c+CeD3AGhNPtoBeKWU2tFmHEC/+n0/gDEAUB/3qetnlq96Tq7l+d5j05tSLyy1zCUAuGlrG2LJNI6N++CPJiqbuWQ3IxBL5u378uq4F/1ue0XuzFLjKVTe9oOTMzAaBO7c1bViuRBCV0mdXlpZnNVc+PDX02JDW5OlqKbenmAc7U2l7fNacGl136XTU34YDQLbu5vRp/ZZy3ZRrNeVhTC2tFd/BDxRvdjWqez/F+fW9jib9Ss3byr12aX1XTpcgX5LmgP9LpyfWdnUO5WW+O0vv4KXr3rx0ItjeZ5d2HqOc0QbwXB7k+7+QgAwvhDOnAc1kvYmKyYLZEqfmPDBaBB4x7X9mA/GMj3Zcjml3jDbxbI4og2n4NWVEOItAGallC9VYXtKIoT4oBDiiBDiyNzcXK03pyoms2Qu3TisnKj++Pw8ool0xafFAcibvXR0zItDQ+6KbQM1lkyPghxBoh+cmsaNw21ozZL1M9DqqElZnBACe/taispc8qwjc6nLaYXDYlwTXDo16ce2zibYzEY4LCa4HeaSM5eklLjqCTVUU1GictvW1QwAWfsuzQWUC6OuCpWNdlY4cwlQ+i4l03JFSe8nHzuHH5+fx9bOJvzkomdd0+Q8oTgzl2hTu31nF87NBHExz2CA5a4uhBuq35Lm8HArXri8kLOlAQCcmPRhe1czDqqVCoVK485MB9Dvtlf0JjgR1YaezKXXAnibEGIUSsnanQD+BoBbCKHVXQ0AmFC/nwAwCADq4y4AnuXLVz0n13JPnvdYQUr5aSnlYSnl4c7OTh3/pManZS71Lstcam2yYFePEz88pTQKdVZyWpwaXMo1MW4+GMP4YgSHWBJHqsx0lSxBovMzAZybCeKevd05nztRpobesUQKFpNB9wTDPX0tODcTQDxZeDpbIpWGL5IoObgkhMBw+9qJcdqkOE2vy44pb2k9lxZCcYTiKQaXaFNrb7LAZTdnvTCcVYNLlcpc2t7tRL/bju1qgKsS9vevbOr92KkZ/O2PLuCBwwP4k7fuRSyZxk8veUp67WQqjcUwey7R5vbm/UoJ//eOFy4xDcaSWAwnGvJz96aRdswFYjkn2UopcWLCh719LuzsUTKRCpXGrT6nIaKNo2BwSUr5+1LKASnlMJSG3D+SUv4CgCcAvFNd7X0Avq1+/7D6M9THfySVcPfDAB5Up8mNANgO4AUALwLYrk6Gs6jv8bD6nFzvselN+qJoa7KsmXh100hb5k5lJe8IaFlR3hzBJa3fEpt5k8ZpM8NlN2ftUfAfx6ZgEMCbD/Rmfe5Aqx3+aBL+aP4+X3rEkmnYiphwtLdPGet9frZwH4HFsNJPqmMdd/RHOpswuuwkzhuOY9IXXXEi1u+2lVwmeGWh8cYhE5WbEALXdDXnDS5VqufSr9+2DT/8nVsr2vOs12VDR7MFx8d9uOIJ4T9/5VXs7WvBn92/DzeOtMFuNuLJM7MlvfZiOAEp13ecI2p0vS47rhty45Hj0wXXHdMmxbU23ufuTVuVqogXLi9kfXw2EMN8MI59/S3odFrR3mTJWy7oDcdxcS6IA+pUSyLaWNYzQ/ajAH5HCHEBSn+kz6nLPwegXV3+OwA+BgBSypMAvgLgFIDvA/iwlDKl9lT6CIBHoUyj+4q6br732PSmfJEVWUuam7a2Z76vbENvNXMpx8S4o2NeGA0C+/p5Z4KW9Lvta3ouSSnxnaOTuGmkPWcZSiljf3OJJVOwmgs389bs7dPf1HshpASX2tbRi2SkvQlji5FMP7PTauPLPaszl0qcFqed5G5pb7yTXKJy2tbZlLXn0lwgBrNRZDJ0y81oEHBYKvf5DKhNvftdeOnKIn79Sy/DIAQ+9YvXw2Y2wmY24jXb2vHE2bm8pS65eEJK8K2dmUu0yb15fy9OT/lzZvVormrBpbbG67m0taMJHc1WPJ8juKRNpdSyJXf2OPOWxR0ZXYSUwI0jles5R0S1U1RwSUr5pJTyLer3l6SUN0opr5FSvktKGVOXR9Wfr1Efv7Ts+R+XUm6TUu6UUn5v2fLvSil3qI99fNnyrO9BwJQ3mhlJvtzyg3UlM5fcDuWOZa6yuFfHfdjR7az4CTQ1loEsjblPTflxaT6Etx7sy/M8JRBSjuBSNJGGTUczb81IexMcFiNO6QkuBbXg0joylzqakErLTBBIa3y5PHOpz22HL5JAKJZ/gks2VzzaSS6DS7S5betsxlwgtuZzbDYQRWezVXfpbL3a3+/CpfkQzkz78ckHD634m799VxeuLoRxqcBFcTYe9TjXvo7jHNFG8Ob9Srb1dwuUxjVy5pIQAjeNtOH5S56swegTkz4IsXSOsrPHiXMzQaTT2QPXL4wuwGI04BArG4g2pPVkLlENTfoimalRy3U0W3GN2sehkg29XVpZXHjtWHkppdLMe5Apr7RSf6sdE4uRFSco/3F0CkaDwL37enI/z51/0lwxFkJx2Ez6M5cMBoHdvS26JsZ51Myl9TS6HV41Me70lB8dzdYV/V+0v/2pEibGXV0Io7vFuqaklmiz2dapNvVeVRo3F4ihs6Uyzbyr6dohpWH4b925HXfsXDmF8/YdSn/KJ0oojZsPMnOJCFBu9Fw75MYjx/IHl8YXI3BaTRXLhqy0m7a2YdIXzdoz88SEH1s7mtBkVW4m7+5pQSSRymRrrfbC5QUcHHTxHIRog2JwqQEFY0kEosmsmUuA0ncJqHDPJbVZeLaeS6OeMHyRRGZqBJFmoNWBUDwFr1pOKaXEd45N4nXXdOTN9ulotsBqMpTcZ0hzYTaAp8/P4c7dXYVXXmZvXwtOTfpz3onTLJXFlR5c2poluLSnb2V5qfa3P1lCU++rnjC2tDWVvH1EG0WuiXFzgVjF+i1V0207OvHQB2/Gb9+1fc1jg20ObO9qxpNni5+wOx9cf285oo3ivv29ODXlX9ErcbWrC2EMtDkaNhvyphGl5Ua20rgTEz7s61+6mZyvqXcolsSJCR9uGGZJHNFGxeBSA9ImxWXLXAKAn7txCG8/1FexSTcAYDIa4LSZspbFac28Dw25K/b+1Ji0DCQtSPTqmBfjixG8JUcjb40QAv2t9qx3zYrxycfOw2E24tdu3VbU8/b2tSAUT2HUk7+ExBOKQwig1VH6RVerOsXq8nwIiVQa52eC2N3rXLGO9rc/WUKw7cpCiCVxRAAGW+0wG8WavkuzgVhFPz+rxWAQuGlre87G4Xfs6sLzlz1Fl9d6gjGYDIJjxIkAvEktjXskT2nc2EIYg62N129Js72rGW6HGc+vmjA5F4hh2h/N9FsCgB3dTgiBrH2XXrnqRTIt2W+JaANjcKkBTaqNfHNlLu3rd+GTD14LYwUn0QBKaVy2ht6vjnnhsBixvcuZ5Vm0mQ20rixv+86xKViMBty9N3dJ3NJzHevKXDo7HcAjx6fwvtcMF51ZtLdPOXEq1NTbE4zBbTev+29vuKMJo54QLs4FEU+lVzTzBoDuFhuEWDoW6BVNpDDjj7GZNxGUmyTD7U0ryuISqTQWQvENkblUyO07O5FISTx7Yb6o53mCcbQ1WSo67Y6oUfS77Tg06M7Zd0lKifHFSENPaDUYBG4cbluTuaS1C9DOkQDAbjFiS5sj68S4F0YXYBDA9VtaK7vBRFQzDC41IC1zKdu0uGpyO8xZy+JeubqIff2uige3qPEsBZciSKclHjk2hVt3dGZ6eOWjTJorPbj0N4+fQ5PFhF99/dain7u9uxkmgygYXFoIxddVEqfZ2tGEy3MhnFabea8OLpmNBnQ7bUVnLmlNRRv5JJeonLZ1Nq8ILmn9hDZC5lIhh7e0odlqwhNFlsZ5QjF0sN8SUcZ9+3txctKPK1mym+eDcUQSqYbPGL5pazuuLoRX9HrUzon2rpoMnWti3AuXPdjT1wInsx6JNiwGlxrQpC8KIYCeWgeX7JY1ZXHPXpjH0XEf7txVXE8b2hxcdjOarSaML0Zw5Moipv1RvPVg/pI4zUCrHQuhOMLx4ieknZ7y47vHp/H+1w6jtYTgj9VkxPZuZ8Gm3p5QHO1N67/oGm5vwqQvipeveGExGTDSsbZHUq/bVnRDb63B5hAzl4gAANu6mnDVE0YilQYAzPqV4FKXs/EbehdiMRnwums68OTZ2axToHKZD8bXNbSAaKN5034l+3p1aZyUEv/2/FUAaPiMYa2f6wvLspeOj/sw3O5YUyK7s6cFo54QoolUZlksmcIrV724cbi9OhtMRDXB4FIDmvJG0NlshdlY2/99Lod5xbS4RCqNP3n4JIbaHPil1wzXbsOobgkh0O+2Y8IbwX8cnYTNbMAbdnfreq6W9TRRQvbSJx87B6fVhA+8rvisJc0+tal3vouwcmUujXQqwaRHT05jZ7cTpix/631ue9ENva94mLlEtNy2zmYk0zLztzEX0IJLmyMz545dnZjyRXF2Zm2WQS7MXCJaaaDVgYOrSuNSaYn/9u0T+OvHzuGtB/vwums6ariF67e7twVOmwnPXVoKLp2Y9GFv/9rJ0Lt7nEhL4PzMUlboiQkfYsk0+y0RbXAMLjWgKV8Uve7aNwZ02c0rMpe+8JNRnJ8N4o/esocjRimn/lY7rnrC+N6JKdy1qzszvrbg89R9frzIUrATEz48enIGv/L6EbjWMQZ4b18LPKE4ZtTMhmwWQuW5oz/SrgSXZgOxNSVxmj6XUhZXTMbB1YUwmixGtJchAEa0EWzrVCfGqaVxs4HNUxYHALfvVLKMnzijvzTOE4zzGEK0yn37e3Biwo+rnjAi8RR+7V9ewpeeu4pfu20r/ubdh7LeJGokRoPADcNteOGy0tTbG45jfDGCfX1rg0tLE+OWWglo/ZpuGGa/JaKNrLGPdJvUpC+CvhqXxAGA226GN5yAlBKzgSg++dh53LGzE3cVOeadNpeBVjvOzgQwH4wXnBK38nlKtk2xmUuffOw8Wmwm/PLrRop63mra3blcpXGptMRiuDwXXcMdS5lFqyfFafrcdsSSSvNhvUY9IWxpb2rYcchE5bata2VwSctc2iyZOd0tNuzpbcETZ2d1rR+OJxGOp9C+SX4/RHq9aZ9yPvMvz43i5z7zHB4/M4M/u38vfv9NuzdM8/ubRtpwcS6EuUAs029pf5bMpS3tTbCZDSv6Lr1weQHXdDXz2EG0wTG41GCklJjyRnNOiqsmt8OMZFoiHE/hE987g3gyjT96615euFJeWgZSk8WIO4rozdXltMJsFEU19T4+7sNjp2fwq6/fuu6x2bt7WyBE7olx3nAcUqIsZXFOmzlzcbs7R+aSdgyYKmJi3Oh8KGv/JqLNqtlqQk+LDRdnlUa8s4EoWh1mWEyb5/Tojl2deOnK4poeitl4gkowmz2XiFYabHPg4IALn/nxZZye8uNTv3g93nvLcK03q6xu2qr0S3rh8gKOT2iT4taeoxgNAtu7nDijBpdSaYmXRhdZEke0CWyes6cNwhdJIJJIoc9d+8wlbcLX42dm8Y2XJ/CB14/wwpUK0jKQ3rinu6jySYNBoE/t16TXJx87B7fDjF967XCxm7lGs9WE4famnJlLWgZRW5nuym1V/5Z2ZzlxA5aCdHp/H4lUGmOLkRVZUUSkNPVeXha3GZp5L3fHzi6k0hLPnJ8vuO5sQAlmsyyOaK333DKMfrcd//7Bm3HP3p5ab07Z7e1rgcNixPOXPTgx4UO/255zSMrOnqXg0ukpPwKxZKYpOBFtXAwuNRitgW9fXfRcUj5Q/uThk+h12fCRO6+p8RZRI9jV64RBAO+8frDo5/a77RhfDOtaN5FK46lzc3jX9QNlG3u7p68lZ+aSRw0uleui69ohN/b0tuTMuOpVA8xTOoNL44sRpNISw+0MABMtt62zGRdng5BSYi4QQ1fL5irbODTohstuxo/OFC6N+8GpGRgNAvsH1pbCEG1277x+AM9+7E5cN7Qx+wqZjQZcv6UVL1xewMlJf9aSOM2uHifmgzF4grHMhLkbhhlcItroGFxqMNro8d566LmkNkdeCMXxB2/eDYdFX2Nm2ty2dTbj1T++G6/bXvzklIFWu+6eS1cXwkimJXb1ZM/8KcXevhaML0bgC68tH9HKRcpRFgcAv3fvLnzjN16T8/H2JgssJoPusrjReaXsZ5jZhUQrbOtsRiCWxFwghrlADJ2brCeIyWjA3Xu68b0TU/BHc5fGJVJpfP2lcdy1q2vTZXcRkeLmre04Mx3A5fkQ9vXnPr/Szr3OTgfwwuUFDLTa6+LGOBFVFoNLDWbSV0+ZS0pw6eatbUU1ZiYqtf9Rv9uB2UAM0USq4LqX5pRgytbO8gVT9qpTUU5OrS2NWwgpjYDLlblkNIi8ZYNCCPS5bLrL4i5rwSVmLhGtoE2MuzAbVIJLmyxzCQDee8swwvEUvnZkPOc6j5+exXwwjgdvLD7rlIg2huV9k/bmyVzSJsadng7gxdEF9lsi2iQYXGowU94ITAZRF5Nsrulqxi/ePIRP/MwBNvGmqhho1d/E+pLaQ2WreuFYDlrjylNZSuO0srhc/Qcqoddl15+55Amh2WpCBxvxEq2wrUsJuL58dRHxVHrTZS4BwP4BF64bcuOLPx1FOi2zrvPQi1fR02LDrds7q7x1RFQvDgy4YFUHHuzryx1c6nRa0d5kwXePT8ETiuNGlsQRbQoMLjWYSW8E3S02GOtgrKnZaMCfv30/y2yoavrV4JKevksX54LoaLZkMuzKoaPZin63Hc9cWNv4diEUR4vNBLOxeofVPrcdkzozl0Y9YQx3OBgIJlqlp8UGh8WIn17yAAC6WjZnydf7XjOMUU8YT52bW/PYpDei9LA7PABTFY9xRFRfrCYjrt/Sil6XDZ3O/IH4nT1OvHRlEQCYuUS0SfAMocFM+qJ1MSmOqBYyE9J09F26NBfC1o7yZS1pfva6fjx1bm5NOZonFK96RmGf24YZfxTJVLrguqPzIZbEEWUhhMC2zubMRVBXgQumjepN+3rR6bTin38yuuaxr700jrQEHjjMkjiize7P7t+Lv/v5awuup5XGdTRbOU2aaJNgcKnBTPki6HXVvt8SUS30upSsPT19hi7NhzLlLuX0wA3KxdVDL46tWL4QjJetmbdefW470hKYCcTyrhdPpjG+GObJHVEO2zqbEE0oQdpCd+M3KovJgF+4aQhPnZvLlBUDQDot8dCLY3jdNR0YbHPUcAuJqB5c0+XE9VsKZyLtUoNLN460MmuaaJNgcKmBpNMS075oZgQ50WZjMhrQ02LDeIHMJW84joVQvCKZSwOtDty2oxNfeXFsRcbQQqj6wSVtauRUgWDb2GIYaclm3kS5bFvWm22zZi4BwM/fNASzUeCLP72SWfbsxXlMeCN49w3MWiIi/Xb3Kn0q2W+JaPNgcKmBzIdiSKQk+pi5RJtYf6u9YFncxQpMilvu524cwrQ/iifPLvUm8YTiaK9ys+xMmWCB4NKoNimOmUtEWV3TpQSXbGYDmq2mGm9N7XQ5bbhvfy++9tI4grEkAODLL47B7TDj7r3dNd46Imok+/td+Ot3H8S7bxiq9aYQUZUwuNRAprzKVCgtW4FoMxpw2ws29K7EpLjl7tzVhS6nFf/+wlUASlbhYrgGmUtufdPzLqvBJZbFEWW3TQ0udTltm758432vGUYwlsQ3Xh7HQiiOH5ycxs9cOwCryVjrTSOiBiKEwDuuHYDdwmMH0WaxeW/PNaApn5Kd0Odm5hJtXgOtdkz7o0ik0jkns12cC8FsFBhsrczfitlowAOHB/H3T17ApDcCu9mIVFqiram65TTNVhNabKaCE+NGPSE4bSa0Oso3OY9oI9nS7oBBbO6SOM21Q604OODCF34yilgijURKsiSOiIiICmLmUgOZZOYSEa7pdiItgbPTgZzrXJoLYqjNUdGR2e++YRASwFeOjMETigMA2qucuQQowWbt2JDL6LzSzHuzZ2QQ5WI1GbG9y4khNqwGoGQvXZwL4W8eP49rh9yZqU9EREREuTC41ECmfBFYTYaql94Q1ZPrhtwAgJevLuZc59J8aEWD3koYbHPg9ds77MHzoQAAF9xJREFU8dCLY5hTp7XV4m+z12XLZDXmMuoJsZk3UQH//Ms34I/euqfWm1EX7jvQi45mC4KxJB5k1hIRERHpwOBSA5n0RdHrYj8I2tz63XZ0Oa14+Ur24FIylcYVT6hi/ZaW+/kbBzHli+Kbr4wDqE1wSclcyh1ciiVTmPRG2MybqIBelx1uB2/eAEom1/tfO4L2JgvuO9BX680hIiKiBsCeSw1kyhtBLyfF0SYnhMB1Q614KUfm0vhiBImUrNikuOXu2t2NjmYrvvHyBABUfVocoASXFsMJROKprE0zxxbCSEtgpIPlPkSk32/cvg0feP0IG3kTERGRLsxcaiBTvih63ey3RHT9llaMLUQy5WjLXVQnxW2rQnBJaew9gGRaAqhV5pJyTJjMURp3eV6ZrMeyOCIqhhCCgSUiIiLSjcGlBpFIpTHjj6KPmUtEuG6LG0D2vkuX5kIAgK0dlS+LA4AHbxgCADitpppciGnZjFM5mnqPziu/jxGWxRERERERUYUwuNQgZvxRpCXQX6HR6kSNZG+fC2ajyB5cmg+ircmC1iplEQ21O3Drjk70uWvzt9mvvu/l+WDWxy97QnA7zOwlQ0REREREFcOeSw1iYlEpeemv0QUsUT2xmY3Y2+fK2tT74lwIW6ucpfN/HzyEYCxZ1ffUDLTasaXdgR+cmsF7bhle8/joPCfFERERERFRZTFzqUFo/VSYuUSkuH5LK46N+xBPplcsvzQXqkoz7+XcDgsGWmvTMFsIgbcc6MVPLnrgCa7tQXXFE2ZJHBERERERVRSDSw1Cy1xizyUixXVDrYgl0zg95c8s80USmA/GsLWzOv2W6sV9+/uQSks8enJmxfJoIoVJXwRb2jkpjoiIiIiIKofBpQYx4Y2gvcmSddQ40WaUran3JXVSXLXL4mptd68TWzua8J1jkyuWX10IQ0o28yYiIiIiospicKlBTHijLIkjWqbXZUevy4aXriwPLimT0bZ1ba7MJa007rlLHswFlkrjLquT4thziYiIiIiIKonBpQYxsRhmSRzRKtdtacUrV72Zny/NB2EyCAy1bb4ysPsO9CEtge+fmMosG9WCS8xcIiIiIiKiCmJwqQFIKTHJzCWiNa4basWEN4IZfxSAkrk01OaA2bj5Dm07uptxTVczvnNsWXDJE0JbkwUuu7mGW0ZERERERBvd5rsCa0CL4QQiiRT63AwuES133ZAbAPCyWhpXi0lx9UIrjXthdAGzarDt8nwIw2zmTUREREREFcbgUgPQJsX1M7hEtMLePhcsJgNeurKIVFrisie06SbFLXff/l5ICXz3uJK9NDofZkkcERERERFVHINLDWDCqwSXBlgWR7SCxWTAgX4XXr66iInFCOLJ9KabFLfc9m4ndnY78cjxKUTiKUz7oxhhM28iIiIiIqowBpcagBZcYlkc0VrXbWnFiQk/zkz7AWy+SXGr3XegFy+OLuL5yx4AbOZNRERERESVx+BSA5j0RmA3G9HqYFNeotWuG3Ijnkrj4aOTALCpM5cAJbgEAH//5EUAwMgm/30QEREREVHlMbjUACYWI+hz2yCEqPWmENWd64ZaAQA/ODUDl92MtiZLjbeotrZ1NmN3bwteuLwAANjCht5ERERERFRhDC41gAlvBP2tvEAkyqarxYaBVrvSb6mziUFYAG9Rs5c6mi1w2pjxSERERERElcXgUgOY9EY4KY4oDy17aWvH5u63pLlvvxJcGmYzbyIiIiIiqgIGl+pcJJ6CJxRHv9tW600hqlvXDbkBANu6GEwBlCbe9+ztxh27umq9KUREREREtAmYar0BlN+kT5kU19/KzCWiXG7Z1gEhgP39rlpvSt34x/ccrvUmEBERERHRJsHgUp2bWFSDS272XCLKZWePEz/52J3oaWGGHxERERERUbUxuFTnJrxKcKmPZXFEefW6mN1HRERERERUC+y5VOcmvREYBJiRQURERERERER1icGlOjexGEFPiw0mI/9XEREREREREVH9YcSizk14I2zmTURERERERER1q2BwSQhhE0K8IIQ4KoQ4KYT4U3X5iBDieSHEBSHEQ0IIi7rcqv58QX18eNlr/b66/KwQ4p5ly+9Vl10QQnxs2fKs77GZTHgj6HczuERERERERERE9UlP5lIMwJ1SyoMADgG4VwhxM4C/APDXUsprACwC+BV1/V8BsKgu/2t1PQgh9gB4EMBeAPcC+HshhFEIYQTw/wC8CcAeAD+nros877EppNIS074o+hhcIiIiIiIiIqI6VTC4JBVB9Uez+iUB3Anga+ryLwB4u/r9/erPUB+/Swgh1OVfllLGpJSXAVwAcKP6dUFKeUlKGQfwZQD3q8/J9R6bwmwgimRasiyOiIiIiIiIiOqWrp5LaobRqwBmAfwQwEUAXillUl1lHEC/+n0/gDEAUB/3AWhfvnzVc3Itb8/zHpvCxGIEAJi5RERERERERER1S1dwSUqZklIeAjAAJdNoVyU3qlhCiA8KIY4IIY7Mzc3VenPKZsKrBJcGGFwiIiIiIiIiojpV1LQ4KaUXwBMAbgHgFkKY1IcGAEyo308AGAQA9XEXAM/y5auek2u5J897rN6uT0spD0spD3d2dhbzT6prWnCJmUtEREREREREVK/0TIvrFEK41e/tAN4I4DSUINM71dXeB+Db6vcPqz9DffxHUkqpLn9QnSY3AmA7gBcAvAhguzoZzgKl6ffD6nNyvcemMLEYgdthRpPVVHhlIiIiIiIiIqIa0BO16AXwBXWqmwHAV6SU3xFCnALwZSHEnwN4BcDn1PU/B+BfhBAXACxACRZBSnlSCPEVAKcAJAF8WEqZAgAhxEcAPArACODzUsqT6mt9NMd7bAqT3gj6mbVERERERERERHWsYHBJSnkMwLVZll+C0n9p9fIogHfleK2PA/h4luXfBfBdve+xWUx4Ixhub6r1ZhARERERERER5VRUzyWqHiklJhYj7LdERERERERERHWNwaU65Y8kEYqnMNDK4BIRERERERER1S8Gl+rUuDcMgJPiiIiIiIiIiKi+MbhUpya9UQBgQ28iIiIiIiIiqmsMLtWpiUUlc6mfZXFEREREREREVMcYXKpTk74orCYD2psstd4UIiIiIiIiIqKcGFyqUxOLEfS77RBC1HpTiIiIiIiIiIhyYnCpTo17I2zmTURERERERER1j8GlOjXpjbCZNxERERERERHVPQaX6lA0kcJcIMZm3kRERERERERU9xhcqkPTvigAsCyOiIiIiIiIiOoeg0t1KJZM49CgGyMdTbXeFCIiIiIiIiKivEy13gBaa2ePE9/68GtrvRlERERERERERAUxc4mIiIiIiIiIiErG4BIREREREREREZWMwSUiIiIiIiIiIioZg0tERERERERERFQyBpeIiIiIiIiIiKhkDC4REREREREREVHJGFwiIiIiIiIiIqKSMbhEREREREREREQlY3CJiIiIiIiIiIhKxuASERERERERERGVjMElIiIiIiIiIiIqGYNLRERERERERERUMgaXiIiIiIiIiIioZAwuERERERERERFRyRhcIiIiIiIiIiKikjG4REREREREREREJWNwiYiIiIiIiIiISsbgEhERERERERERlUxIKWu9DWUlhJgDcKXW21EmHQDma70RVBe4L5CG+wItx/2BNNwXaDnuD6ThvkAa7gu0XKn7wxYpZWe2BzZccGkjEUIckVIervV2UO1xXyAN9wVajvsDabgv0HLcH0jDfYE03BdouUrsDyyLIyIiIiIiIiKikjG4REREREREREREJWNwqb59utYbQHWD+wJpuC/QctwfSMN9gZbj/kAa7guk4b5Ay5V9f2DPJSIiIiIiIiIiKhkzl4iIiIiIiIiIqGQMLukkhBgUQjwhhDglhDgphPhtdXmbEOKHQojz6n9b1eW7hBA/FULEhBC/m+X1jEKIV4QQ38nznu9TX/e8EOJ96jKHEOIRIcQZdTs+kef51wshjgshLggh/q8QQix77DeXvcb/Ws/vZjOqo/3BKYR4ddnXvBDikzme/30hxFF1ez8lhDDm22bSp5z7ghBiVP2bfVUIcSTPe94rhDir/m1/bNnyj6jLpBCiI8/z/1V9/gkhxOeFEOZC20b61Nn+8ONlx4ZJIcS3cjw/634jhLhdCOFb9hp/tM5fz6ZS5n3BLYT4mlA+t08LIW7J8Z7rPTaMCCGeV9d9SAhhWfbYA8v+Lf+23t/PZlNn+4MQQnxcCHFOff5v5Xj+54Ry3nBMfb9mdblV3T8uqPvLcJl+TZtCjfaFzwshZoUQJ1Yt/0v1uceEEN8UQrhzPD/rekKINwohXhLKZ9VLQog71/8b2jzKtS8IIXaKldcDfiHEf8rxnus9LvCcgXKTUvJLxxeAXgDXqd87AZwDsAfA/wLwMXX5xwD8hfp9F4AbAHwcwO9meb3fAfBvAL6T4/3aAFxS/9uqft8KwAHgDnUdC4AfA3hTjtd4AcDNAASA72nrAbgDwGMArNq21vr322hf9bI/ZFnvJQC35niNFvW/AsDXATyo/px1m/lV/X0BwCiAjgLvZwRwEcBW9RhwFMAe9bFrAQwXeh0Ab1b3AwHg3wF8SM9+yq/G2h9Wrfd1AO/N8RpZ9xsAt+c6JvGr6vvCFwB8QP3eAsBdzL5QxLHhK1j6bPjUsmPDdgCvQP3cAc8bGn1/eD+ALwIw5Pv/CfW8Qf3+r5Zt528A+JT6/YMAHqr177eRvqq9L6iP3QrgOgAnVi2/G4BJ/f4vkOMcMNd66rGlT/1+H4CJWv9+G+mrnPvCstc0ApgGsCXHY+s9LvCcgV85v5i5pJOUckpK+bL6fQDAaQD9AO6HcmCH+t+3q+vMSilfBJBY/VpCiAEA9wH4bJ63vAfAD6WUC1LKRQA/BHCvlDIspXxCfY84gJcBDGR5j14oJwXPSSkllIPF29WHPwTgE1LKmLaten8PpKiX/WHV6+yA8qHz4xzb7Fe/NUH5QNEarmXdZtKnnPuCTjcCuCClvKQeA76svheklK9IKUd1bPN3pQpKEHqgTNu26dXT/qARQrQAuBPAt3Jss679hopTrn1BCOGCcmH4OXW9uJTSm+Ut13VsEEIIKPvJ11ZvG4BfBfD/1M8fnjeUoJ72ByjngX8mpUxr75Vjm/3qewoAdmQ/b/gagLvUdUiHGuwLkFI+DWAhy/IfSCmT6o/PIcs1Rb711GPLpLr8JAC7EMKa799PSyp0znAXgItSyitZHivHcYHnDJQTg0slUNN/rwXwPIBuKeWU+tA0gG4dL/FJAL8HIJ1nnX4AY8t+HleXLd8ON4C3Ang8x/PHczx/B4DXq6nMTwkhbtCxzZRDvewPWLp7mLNLvxDiUQCzAAJYuoAoZZspizLsCxLAD9TU8g/mWEfPvqB3e80A3gPg+6U8n/Kro/3h7QAeXxZgLsYtalnM94QQe0t4PmHd+8IIgDkA/ySU8unPCiGasqy33mNDOwDvsgvI1ecNO4QQzwohnhNC3Jv1FUiXOtgftgF4txDiiPq3vT3Ptv6Tul27APzt6tdW9xcflP2HilSlfUGvX4ZS6VDqej8L4GXt5jUVpwznDJoHoWSlZ1OW40IePGfY5BhcKpJQ6s2/DuA/rT5RVy/qc17Yq89/C4BZKeVL69wOE5QDx/+VUl4q8ukmKOVVNwP4rwC+wjtOpamX/UGV78NE26Z7oKTgWqHcoV79eMFtpuzWuy+oXielvA7AmwB8WAhxa/m3dIW/B/C0lDJrthuVrs72h59DgWNDDi9DSas/COWi8lslvv+mVoZ9wQSlnOUfpJTXAghBKZOoJhOU0rjboexPn8nVm4Xyq5P9wQogKqU8DOAzAD6fa0Up5fsB9EHJqHh3ke9DedTJvqBtyx8CSAL411LWUwMJfwHg10p5/82uTOcMEEqfvLcB+GoJm6H7uJADzxmIwaViqHf5vw7gX6WU31AXz6glaFopWqFU8dcCeJsQYhRKKuKdQogvCSFuWtYA7W0AJgAMLnvegLpM82kA56WUn1Tf27js+X+mrjuQ4/njAL4hFS9AyZjJ2eCTsqun/UEIcRBKLfxL6s+r94cMKWUUwLexlAZb7DbTKmXaFyClnFD/OwvgmwBuFEqzR+3/5a+j8LEh2/Y9qj7/s8uW/TGATij9vqiM6ml/EEqzzRsBPLJs2Zr9Icf7+6WUQfX77wIwizzNoGmtMu0L4wDGpZTPqz9/DcB1FTg2eAC41ZtXq58/DuBhKWVCSnkZSl+QUu5qb2p1tD+MA9De/5sADqjvn/XYIKVMQTlH+Vl1Uea11f3FBWX/IZ2qvC8U2pZfAvAWAL+gZb8LIf5Jff53862nLh+Ash+9V0p5sdD70UrlOmdQvQlK9tiM+tyKHRdW4zkDAUrEm3RQM3s+B+C0lPKvlj30MID3AfiE+t9v53sdKeXvA/h99TVvh9KM7RfVhw8te782AP9DLE3uunvZ8/4cygf5B5a9bmr589X1/EKIm6GkV74XS+nM34LS1PsJofTpsQCYz/sLoBXqaX9QrchMWL0/qHdEnFLKKfVE8D4s9WYqaptppXLtC0JJZTdIKQPq93dDqX0fw8r/lyYA24UQI1BOCB4E8PP5XlvNWFv+Xh+A0sfrLq22nsqjDveHd0JpsBnVFqzeH/JsQw+AGSmlFELcCOWGFC8gdSrj58S0EGJMCLFTSnkWSj+NUxU6NjwBZZ/58qpt+xaUz5l/Ui8WdkAZLEE61dn+8C0o54GXAdwGJVi4Yn9Qt3eblPKC+v3bAJxZtc0/hbK//ChfST6tVO19ocC23AulNcNtUsrwstd+v571hJLB+AiU5tPP6nlPWlKufWGZ1dcDZT0uFPi38JyBOC1O7xeA10FJSTwG4FX1681QaswfB3AeygS2NnX9HigRYD8Ar/p9y6rXvB15uupDqWm+oH69X102oG7H6WXb8YEczz8M4ASUqQB/B0Coyy0AvqQ+9jKAO2v9+220r3rZH5Y9dgnArjzP7Qbworq9J6AEGrWpH1m3mV/V3RegTO44qn6dBPCHed7zzVA+9C8uXw/Ab6mvlwQwCeCzOZ6fVJ+rbe8f6d1P+dU4+4P62JNQhkHk2+as+w2Aj6jvfRRKA9fX1Pr320hf5doX1McOATiivta3kGVaaL59oYhjw1YoTf4vQCmr0KbKCijTwk4BOA51ohy/GnZ/cEMJCByHEiA6mOW5BgDPquucgFIGpb2/Td0/Lqj7y9Za/34b6atG+8K/A5iC0gh6HMCvqMsvQOnBo23Hp3I8P+t6AP4/KOV4ry774jTJ2uwLTVCCOa4C71nycUFdj+cM/Mr5pQUbiIiIiIiIiIiIisaeS0REREREREREVDIGl4iIiIiIiIiIqGQMLhERERERERERUckYXCIiIiIiIiIiopIxuERERERERERERCVjcImIiIiojIQQKSHEq0KIk0KIo0KI/yKEyHvOJYQYFkL8fLW2kYiIiKicGFwiIiIiKq+IlPKQlHIvgDcCeBOAPy7wnGEADC4RERFRQxJSylpvAxEREdGGIYQISimbl/28FcCLADoAbAHwLwCa1Ic/IqX8iRDiOQC7AVwG8AUA/xfAJwDcDsAK4P9JKf+xav8IIiIioiIwuERERERURquDS+oyL4CdAAIA0lLKqBBiO4B/l1IeFkLcDuB3pZRvUdf/IIAuKeWfCyGsAJ4F8C4p5eUq/lOIiIiIdDHVegOIiIiINhEzgL8TQhwCkAKwI8d6dwM4IIR4p/qzC8B2KJlNRERERHWFwSUiIiKiClLL4lIAZqH0XpoBcBBK78torqcB+E0p5aNV2UgiIiKidWBDbyIiIqIKEUJ0AvgUgL+TSi8CF4ApKWUawHsAGNVVAwCcy576KIAPCSHM6uvsEEI0gYiIiKgOMXOJiIiIqLzsQohXoZTAJaE08P4r9bG/B/B1IcR7AXwfQEhdfgxASghxFMA/A/gbKBPkXhZCCABzAN5enc0nIiIiKg4behMRERERERERUclYFkdERERERERERCVjcImIiIiIiIiIiErG4BIREREREREREZWMwSUiIiIiIiIiIioZg0tERERERERERFQyBpeIiIiIiIiIiKhkDC4REREREREREVHJGFwiIiIiIiIiIqKS/f8/Enb36K3t8AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sales_per_week = data.groupby('Date').agg({'Sales': 'sum'}).reset_index()\n",
    "sales_per_week.plot(x=\"Date\", y=\"Sales\", figsize=(20,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see clear seasonality, sales are rising when the summer approaches. Moreover, data is Non-Stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_per_week = sales_per_week.set_index('Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a casual split - 80% of the dataset for training purposes and 20% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(sales_per_week)*0.8)\n",
    "train_data = sales_per_week.iloc[:train_size]\n",
    "test_data = sales_per_week.iloc[train_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the dataset (to get rid of non-stationarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler().fit(train_data)\n",
    "train_scaled = scaler.transform(train_data)\n",
    "test_scaled = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(data, window=10):\n",
    "    X, y = [], []\n",
    "    \n",
    "    for i in range (len(data)-window):\n",
    "        X.append(data[i:i+window])\n",
    "        y.append(data[i+window])\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW = 16 \n",
    "\n",
    "X_train, y_train = create_datasets(train_scaled, WINDOW)\n",
    "X_test, y_test = create_datasets(test_scaled, WINDOW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried many windows sizes, but 16 looks optimal here. In case we hava a bigger dataset - it is better to use a bigger window."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create GRU model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a model and finding best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_parameters(X_train, y_train, X_test, y_test):\n",
    "    model_result = []\n",
    "    \n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        min_delta = 0.001,\n",
    "        patience = 30,\n",
    "        restore_best_weights = True)\n",
    "    \n",
    "    for i in range(2, 225, 2):\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.GRU(2*i, activation='tanh', return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "            tf.keras.layers.GRU(i, activation='tanh', dropout=0.2),\n",
    "            tf.keras.layers.Dense(1)\n",
    "        ])\n",
    "        \n",
    "        model.compile(optimizer='adam', loss='mse')\n",
    "        \n",
    "        history = model.fit(X_train, y_train, batch_size=4, validation_split=0.3, callbacks=[early_stopping], epochs=200, verbose=1)\n",
    "        \n",
    "        prediction = model.predict(X_test)\n",
    "        \n",
    "        Accuracy = []\n",
    "        for j in range(prediction.shape[0]):\n",
    "            error = abs(prediction[j] - y_test[j])\n",
    "            Accuracy.append(float(1 - error))\n",
    "        \n",
    "        model_result.append({\"units\": i,\n",
    "                           \"Accuracy\": sum(Accuracy)/len(Accuracy)})\n",
    "    return model_result\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For evaluation of my model I will use the next error and accuracy: Error = 100% * abs(predicted_values - y_test) -> Accuracy = 100% - Error\n",
    "\n",
    "I don't recomend running the block below as it would probably take up to 25 mins to run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 35ms/step - loss: 0.2894 - val_loss: 0.3151\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.1554 - val_loss: 0.1989\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.1076 - val_loss: 0.1212\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0650 - val_loss: 0.0768\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0446 - val_loss: 0.0597\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0381 - val_loss: 0.0525\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0444 - val_loss: 0.0534\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0364 - val_loss: 0.0553\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0520 - val_loss: 0.0529\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0423 - val_loss: 0.0531\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0386 - val_loss: 0.0511\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0345 - val_loss: 0.0501\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0419 - val_loss: 0.0487\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0475 - val_loss: 0.0500\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0429 - val_loss: 0.0499\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0351 - val_loss: 0.0477\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0394 - val_loss: 0.0487\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0367 - val_loss: 0.0461\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0374 - val_loss: 0.0476\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0373 - val_loss: 0.0461\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0323 - val_loss: 0.0444\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0362 - val_loss: 0.0464\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0354 - val_loss: 0.0453\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0396 - val_loss: 0.0436\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0297 - val_loss: 0.0445\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0279 - val_loss: 0.0425\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 0.0333 - val_loss: 0.0424\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0360 - val_loss: 0.0438\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0337 - val_loss: 0.0430\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0335 - val_loss: 0.0422\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0359 - val_loss: 0.0407\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0347 - val_loss: 0.0404\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0358 - val_loss: 0.0408\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0388 - val_loss: 0.0394\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0416 - val_loss: 0.0386\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0283 - val_loss: 0.0403\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0267 - val_loss: 0.0388\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0348 - val_loss: 0.0374\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0283 - val_loss: 0.0385\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0304 - val_loss: 0.0369\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0291 - val_loss: 0.0372\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0317 - val_loss: 0.0357\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0309 - val_loss: 0.0361\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0299 - val_loss: 0.0357\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0310 - val_loss: 0.0345\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0395 - val_loss: 0.0348\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0371 - val_loss: 0.0347\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0255 - val_loss: 0.0348\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0326 - val_loss: 0.0333\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0321 - val_loss: 0.0336\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0272 - val_loss: 0.0327\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0267 - val_loss: 0.0323\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0256 - val_loss: 0.0330\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0344 - val_loss: 0.0312\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0314 - val_loss: 0.0316\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0347 - val_loss: 0.0312\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0274 - val_loss: 0.0312\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0294 - val_loss: 0.0318\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0222 - val_loss: 0.0313\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0359 - val_loss: 0.0298\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0304 - val_loss: 0.0304\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0335 - val_loss: 0.0306\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0379 - val_loss: 0.0298\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0248 - val_loss: 0.0314\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0260 - val_loss: 0.0298\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0242 - val_loss: 0.0290\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0322 - val_loss: 0.0290\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0236 - val_loss: 0.0293\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0258 - val_loss: 0.0288\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0323 - val_loss: 0.0294\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0269 - val_loss: 0.0286\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0245 - val_loss: 0.0285\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0267 - val_loss: 0.0283\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0240 - val_loss: 0.0283\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0252 - val_loss: 0.0281\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0277 - val_loss: 0.0284\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0302 - val_loss: 0.0280\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0232 - val_loss: 0.0277\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0256 - val_loss: 0.0272\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0297 - val_loss: 0.0270\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0287 - val_loss: 0.0277\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0243 - val_loss: 0.0275\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0259 - val_loss: 0.0270\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0247 - val_loss: 0.0272\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0258 - val_loss: 0.0271\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0251 - val_loss: 0.0275\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0287 - val_loss: 0.0266\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0269 - val_loss: 0.0271\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0272 - val_loss: 0.0269\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0247 - val_loss: 0.0274\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0266\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0233 - val_loss: 0.0266\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0243 - val_loss: 0.0265\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0236 - val_loss: 0.0264\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0325 - val_loss: 0.0272\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0203 - val_loss: 0.0269\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0155 - val_loss: 0.0261\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0207 - val_loss: 0.0260\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0257 - val_loss: 0.0264\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0277 - val_loss: 0.0266\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0271 - val_loss: 0.0270\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0254 - val_loss: 0.0261\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0233 - val_loss: 0.0256\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0273 - val_loss: 0.0263\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0282 - val_loss: 0.0259\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0326 - val_loss: 0.0257\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0243 - val_loss: 0.0254\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0255 - val_loss: 0.0269\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0189 - val_loss: 0.0257\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 0.0195 - val_loss: 0.0255\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0239 - val_loss: 0.0254\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0291 - val_loss: 0.0260\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0184 - val_loss: 0.0259\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0282 - val_loss: 0.0256\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0245 - val_loss: 0.0253\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0243 - val_loss: 0.0261\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0247 - val_loss: 0.0263\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0249 - val_loss: 0.0251\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0269 - val_loss: 0.0256\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0207 - val_loss: 0.0252\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0214 - val_loss: 0.0249\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0273 - val_loss: 0.0251\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0272 - val_loss: 0.0253\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0228 - val_loss: 0.0251\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0204 - val_loss: 0.0250\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0222 - val_loss: 0.0248\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0233 - val_loss: 0.0250\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0209 - val_loss: 0.0251\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0240 - val_loss: 0.0248\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0265 - val_loss: 0.0250\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0318 - val_loss: 0.0253\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0209 - val_loss: 0.0253\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0194 - val_loss: 0.0252\n",
      "WARNING:tensorflow:9 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A8847D9DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 34ms/step - loss: 0.2069 - val_loss: 0.0703\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0453 - val_loss: 0.0369\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0279 - val_loss: 0.0382\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0463 - val_loss: 0.0383\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0332 - val_loss: 0.0368\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0307 - val_loss: 0.0367\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0339 - val_loss: 0.0366\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0349 - val_loss: 0.0358\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0474 - val_loss: 0.0360\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0270 - val_loss: 0.0341\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0297 - val_loss: 0.0339\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0278 - val_loss: 0.0336\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0270 - val_loss: 0.0321\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0272 - val_loss: 0.0328\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0299 - val_loss: 0.0329\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0245 - val_loss: 0.0318\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0377 - val_loss: 0.0322\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0253 - val_loss: 0.0314\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0351 - val_loss: 0.0297\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0322 - val_loss: 0.0322\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0242 - val_loss: 0.0292\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0265 - val_loss: 0.0300\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0395 - val_loss: 0.0302\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0273 - val_loss: 0.0288\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0374 - val_loss: 0.0284\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0278 - val_loss: 0.0295\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0341 - val_loss: 0.0287\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0282 - val_loss: 0.0300\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0291 - val_loss: 0.0292\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0434 - val_loss: 0.0292\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0262 - val_loss: 0.0281\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0263 - val_loss: 0.0284\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0308 - val_loss: 0.0286\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0250 - val_loss: 0.0287\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0320 - val_loss: 0.0283\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 1s 28ms/step - loss: 0.0249 - val_loss: 0.0287\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0305 - val_loss: 0.0273\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0302 - val_loss: 0.0289\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0289 - val_loss: 0.0281\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0259 - val_loss: 0.0277\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0353 - val_loss: 0.0276\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0187 - val_loss: 0.0278\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0265 - val_loss: 0.0270\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0292 - val_loss: 0.0283\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0215 - val_loss: 0.0276\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0237 - val_loss: 0.0269\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0353 - val_loss: 0.0279\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0336 - val_loss: 0.0279\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0308 - val_loss: 0.0271\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0307 - val_loss: 0.0269\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0271 - val_loss: 0.0263\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0270 - val_loss: 0.0269\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0274 - val_loss: 0.0277\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0420 - val_loss: 0.0268\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0272 - val_loss: 0.0263\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0189 - val_loss: 0.0263\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0254 - val_loss: 0.0258\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0203 - val_loss: 0.0267\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0232 - val_loss: 0.0256\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0244 - val_loss: 0.0268\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0264 - val_loss: 0.0253\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0203 - val_loss: 0.0254\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0255 - val_loss: 0.0263\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0171 - val_loss: 0.0252\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0241 - val_loss: 0.0254\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0231 - val_loss: 0.0248\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0242 - val_loss: 0.0249\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0224 - val_loss: 0.0256\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0195 - val_loss: 0.0244\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0230 - val_loss: 0.0251\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0234 - val_loss: 0.0245\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0220 - val_loss: 0.0248\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0223 - val_loss: 0.0247\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0175 - val_loss: 0.0244\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0249\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0232 - val_loss: 0.0244\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0234 - val_loss: 0.0236\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0225 - val_loss: 0.0241\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0236\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0226 - val_loss: 0.0237\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0208 - val_loss: 0.0240\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0175 - val_loss: 0.0236\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0190 - val_loss: 0.0235\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0221 - val_loss: 0.0238\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0228 - val_loss: 0.0241\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0192 - val_loss: 0.0232\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0178 - val_loss: 0.0235\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0174 - val_loss: 0.0231\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0226 - val_loss: 0.0237\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0190 - val_loss: 0.0228\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0234\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0274 - val_loss: 0.0231\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0169 - val_loss: 0.0235\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0226 - val_loss: 0.0228\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0199 - val_loss: 0.0234\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0205 - val_loss: 0.0227\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0251 - val_loss: 0.0232\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0273 - val_loss: 0.0227\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0189 - val_loss: 0.0233\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0231 - val_loss: 0.0227\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0206 - val_loss: 0.0230\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0189 - val_loss: 0.0231\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0190 - val_loss: 0.0230\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0192 - val_loss: 0.0226\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0176 - val_loss: 0.0231\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0256 - val_loss: 0.0235\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0205 - val_loss: 0.0229\n",
      "WARNING:tensorflow:9 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A887E855E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 35ms/step - loss: 0.2697 - val_loss: 0.1285\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0523 - val_loss: 0.0446\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0387 - val_loss: 0.0428\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0373 - val_loss: 0.0461\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0367 - val_loss: 0.0405\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0330 - val_loss: 0.0416\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0314 - val_loss: 0.0397\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0328 - val_loss: 0.0379\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0326 - val_loss: 0.0377\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0341 - val_loss: 0.0354\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0341 - val_loss: 0.0367\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0303 - val_loss: 0.0339\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0364 - val_loss: 0.0330\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0344 - val_loss: 0.0347\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0332 - val_loss: 0.0318\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0306 - val_loss: 0.0316\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0262 - val_loss: 0.0317\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0293 - val_loss: 0.0310\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.0264 - val_loss: 0.0306\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0302 - val_loss: 0.0313\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0257 - val_loss: 0.0287\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0227 - val_loss: 0.0275\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0272 - val_loss: 0.0284\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0259 - val_loss: 0.0284\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0240 - val_loss: 0.0278\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0258 - val_loss: 0.0272\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0275 - val_loss: 0.0283\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0209 - val_loss: 0.0269\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0223 - val_loss: 0.0267\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0231 - val_loss: 0.0269\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0307 - val_loss: 0.0264\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0264 - val_loss: 0.0278\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0205 - val_loss: 0.0261\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0256 - val_loss: 0.0276\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0295 - val_loss: 0.0264\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0221 - val_loss: 0.0257\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0298 - val_loss: 0.0264\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0351 - val_loss: 0.0259\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0204 - val_loss: 0.0261\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0308 - val_loss: 0.0254\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0213 - val_loss: 0.0267\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0206 - val_loss: 0.0253\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0332 - val_loss: 0.0259\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0265 - val_loss: 0.0257\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0247 - val_loss: 0.0250\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0280 - val_loss: 0.0256\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0262 - val_loss: 0.0258\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0208 - val_loss: 0.0262\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0212 - val_loss: 0.0251\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0238 - val_loss: 0.0253\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0214 - val_loss: 0.0248\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0241 - val_loss: 0.0250\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0202 - val_loss: 0.0246\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0218 - val_loss: 0.0250\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0222 - val_loss: 0.0247\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0235 - val_loss: 0.0243\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0235 - val_loss: 0.0248\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0249 - val_loss: 0.0263\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0210 - val_loss: 0.0247\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0276 - val_loss: 0.0252\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0280 - val_loss: 0.0250\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0325 - val_loss: 0.0242\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0293 - val_loss: 0.0252\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0235 - val_loss: 0.0241\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0202 - val_loss: 0.0242\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0188 - val_loss: 0.0240\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0236 - val_loss: 0.0243\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0210 - val_loss: 0.0240\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0192 - val_loss: 0.0239\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0282 - val_loss: 0.0268\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0283 - val_loss: 0.0247\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0217 - val_loss: 0.0246\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0230 - val_loss: 0.0239\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0203 - val_loss: 0.0250\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0205 - val_loss: 0.0238\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0294 - val_loss: 0.0242\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0198 - val_loss: 0.0243\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0187 - val_loss: 0.0244\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0216 - val_loss: 0.0250\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0196 - val_loss: 0.0239\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0221 - val_loss: 0.0243\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0190 - val_loss: 0.0241\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0201 - val_loss: 0.0239\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0276 - val_loss: 0.0234\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0224 - val_loss: 0.0242\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0218 - val_loss: 0.0234\n",
      "WARNING:tensorflow:9 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A871395AF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 35ms/step - loss: 0.1480 - val_loss: 0.0414\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0394 - val_loss: 0.0391\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.0287 - val_loss: 0.0377\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0305 - val_loss: 0.0383\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0288 - val_loss: 0.0346\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0440 - val_loss: 0.0342\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0342 - val_loss: 0.0332\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0312 - val_loss: 0.0340\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0337 - val_loss: 0.0326\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0317 - val_loss: 0.0313\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0270 - val_loss: 0.0322\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0344 - val_loss: 0.0308\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0322 - val_loss: 0.0318\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0320 - val_loss: 0.0306\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0292 - val_loss: 0.0285\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0301 - val_loss: 0.0313\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0237 - val_loss: 0.0280\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0255 - val_loss: 0.0291\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0187 - val_loss: 0.0274\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0311 - val_loss: 0.0283\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0189 - val_loss: 0.0277\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0215 - val_loss: 0.0277\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0340 - val_loss: 0.0298\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0247 - val_loss: 0.0282\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0282 - val_loss: 0.0265\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0274 - val_loss: 0.0284\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0243 - val_loss: 0.0269\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0230 - val_loss: 0.0261\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0214 - val_loss: 0.0268\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0265 - val_loss: 0.0274\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0285 - val_loss: 0.0268\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0334 - val_loss: 0.0259\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0245 - val_loss: 0.0276\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0311 - val_loss: 0.0255\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0273 - val_loss: 0.0255\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0290 - val_loss: 0.0272\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0231 - val_loss: 0.0260\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0214 - val_loss: 0.0274\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0305 - val_loss: 0.0263\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0218 - val_loss: 0.0251\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0220 - val_loss: 0.0250\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0224 - val_loss: 0.0265\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0257 - val_loss: 0.0252\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0195 - val_loss: 0.0248\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0233 - val_loss: 0.0255\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0249 - val_loss: 0.0248\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0187 - val_loss: 0.0247\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0238 - val_loss: 0.0263\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0210 - val_loss: 0.0245\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0238 - val_loss: 0.0270\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0273 - val_loss: 0.0245\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0228 - val_loss: 0.0262\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0221 - val_loss: 0.0244\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0224 - val_loss: 0.0245\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0187 - val_loss: 0.0241\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0308 - val_loss: 0.0264\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0270 - val_loss: 0.0243\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0194 - val_loss: 0.0239\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0234 - val_loss: 0.0241\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0359 - val_loss: 0.0263\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0245 - val_loss: 0.0238\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0205 - val_loss: 0.0240\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0239 - val_loss: 0.0239\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0218 - val_loss: 0.0238\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0262 - val_loss: 0.0245\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0189 - val_loss: 0.0237\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0288 - val_loss: 0.0241\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0303 - val_loss: 0.0251\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0190 - val_loss: 0.0237\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0226 - val_loss: 0.0250\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0232 - val_loss: 0.0236\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0253 - val_loss: 0.0241\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0185 - val_loss: 0.0237\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0226 - val_loss: 0.0238\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0246 - val_loss: 0.0237\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0195 - val_loss: 0.0245\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0297 - val_loss: 0.0244\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0239 - val_loss: 0.0248\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0237 - val_loss: 0.0234\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0199 - val_loss: 0.0249\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0201 - val_loss: 0.0238\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0211 - val_loss: 0.0233\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0270 - val_loss: 0.0244\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0291 - val_loss: 0.0238\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0214 - val_loss: 0.0239\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0274 - val_loss: 0.0233\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0202 - val_loss: 0.0232\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0233 - val_loss: 0.0245\n",
      "WARNING:tensorflow:9 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A70CDA8940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 35ms/step - loss: 0.0799 - val_loss: 0.0336\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0309 - val_loss: 0.0318\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0376 - val_loss: 0.0303\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0318 - val_loss: 0.0293\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.0318 - val_loss: 0.0295\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0288 - val_loss: 0.0300\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0392 - val_loss: 0.0282\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0281 - val_loss: 0.0282\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0299 - val_loss: 0.0287\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0229 - val_loss: 0.0276\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0368 - val_loss: 0.0280\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0258 - val_loss: 0.0271\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0272 - val_loss: 0.0314\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0200 - val_loss: 0.0268\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0230 - val_loss: 0.0265\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0225 - val_loss: 0.0274\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0297 - val_loss: 0.0281\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0288 - val_loss: 0.0267\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0230 - val_loss: 0.0291\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0177 - val_loss: 0.0256\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0268 - val_loss: 0.0283\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0306 - val_loss: 0.0257\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0202 - val_loss: 0.0263\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0241 - val_loss: 0.0260\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0214 - val_loss: 0.0253\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0265 - val_loss: 0.0265\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0307 - val_loss: 0.0266\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0331 - val_loss: 0.0254\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0259 - val_loss: 0.0256\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0259 - val_loss: 0.0255\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0241 - val_loss: 0.0248\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0210 - val_loss: 0.0269\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0246 - val_loss: 0.0246\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0239 - val_loss: 0.0258\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0243 - val_loss: 0.0248\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0210 - val_loss: 0.0248\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0225 - val_loss: 0.0245\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0210 - val_loss: 0.0242\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0225 - val_loss: 0.0265\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0360 - val_loss: 0.0251\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0169 - val_loss: 0.0243\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0252 - val_loss: 0.0246\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0209 - val_loss: 0.0240\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0253 - val_loss: 0.0245\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0274 - val_loss: 0.0258\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0232 - val_loss: 0.0248\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0233 - val_loss: 0.0241\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0228 - val_loss: 0.0245\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0193 - val_loss: 0.0241\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0203 - val_loss: 0.0253\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0351 - val_loss: 0.0237\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0208 - val_loss: 0.0252\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0271 - val_loss: 0.0236\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0197 - val_loss: 0.0235\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0281 - val_loss: 0.0256\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0241 - val_loss: 0.0234\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0223 - val_loss: 0.0244\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0238 - val_loss: 0.0236\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0218 - val_loss: 0.0240\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0247 - val_loss: 0.0247\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0309 - val_loss: 0.0234\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0232 - val_loss: 0.0235\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0230 - val_loss: 0.0232\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0251 - val_loss: 0.0240\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0212 - val_loss: 0.0233\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0197 - val_loss: 0.0237\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0214 - val_loss: 0.0240\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0202 - val_loss: 0.0231\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0216 - val_loss: 0.0249\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0172 - val_loss: 0.0232\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0215 - val_loss: 0.0241\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0179 - val_loss: 0.0231\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0305 - val_loss: 0.0234\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0209 - val_loss: 0.0235\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0218 - val_loss: 0.0234\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0241 - val_loss: 0.0236\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0178 - val_loss: 0.0235\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0195 - val_loss: 0.0230\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0195 - val_loss: 0.0239\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0199 - val_loss: 0.0228\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0276 - val_loss: 0.0230\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0226 - val_loss: 0.0226\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0160 - val_loss: 0.0230\n",
      "WARNING:tensorflow:10 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A8880AB8B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 56ms/step - loss: 0.1066 - val_loss: 0.0344\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0350 - val_loss: 0.0343\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0381 - val_loss: 0.0315\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0352 - val_loss: 0.0310\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0296 - val_loss: 0.0288\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0234 - val_loss: 0.0329\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0309 - val_loss: 0.0287\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0483 - val_loss: 0.0289\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0245 - val_loss: 0.0330\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0284 - val_loss: 0.0269\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0266 - val_loss: 0.0291\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0318 - val_loss: 0.0267\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0228 - val_loss: 0.0280\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0263 - val_loss: 0.0263\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0250 - val_loss: 0.0279\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0220 - val_loss: 0.0260\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0315 - val_loss: 0.0279\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0228 - val_loss: 0.0263\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0218 - val_loss: 0.0257\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0245 - val_loss: 0.0261\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0258 - val_loss: 0.0260\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0284 - val_loss: 0.0257\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0269 - val_loss: 0.0280\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0294 - val_loss: 0.0273\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0286 - val_loss: 0.0251\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0293 - val_loss: 0.0279\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0195 - val_loss: 0.0249\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0223 - val_loss: 0.0248\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0221 - val_loss: 0.0249\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0212 - val_loss: 0.0249\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0241 - val_loss: 0.0250\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0221 - val_loss: 0.0253\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0234 - val_loss: 0.0245\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0192 - val_loss: 0.0244\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0216 - val_loss: 0.0254\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0207 - val_loss: 0.0245\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0211 - val_loss: 0.0264\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0191 - val_loss: 0.0242\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0253 - val_loss: 0.0246\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0240 - val_loss: 0.0244\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0198 - val_loss: 0.0246\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0207 - val_loss: 0.0239\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0263 - val_loss: 0.0241\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0195 - val_loss: 0.0238\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0277 - val_loss: 0.0265\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0216 - val_loss: 0.0239\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0274 - val_loss: 0.0239\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0291 - val_loss: 0.0254\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0231 - val_loss: 0.0236\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0184 - val_loss: 0.0256\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0263 - val_loss: 0.0243\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0243 - val_loss: 0.0246\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0179 - val_loss: 0.0234\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0185 - val_loss: 0.0248\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0187 - val_loss: 0.0233\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0250 - val_loss: 0.0272\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0202 - val_loss: 0.0232\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0237 - val_loss: 0.0232\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0193 - val_loss: 0.0231\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0219 - val_loss: 0.0247\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0194 - val_loss: 0.0231\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0220 - val_loss: 0.0240\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0244 - val_loss: 0.0232\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0287 - val_loss: 0.0247\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0255 - val_loss: 0.0229\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0225 - val_loss: 0.0233\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0195 - val_loss: 0.0227\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0204 - val_loss: 0.0227\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0226 - val_loss: 0.0228\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0237 - val_loss: 0.0234\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0226\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0213 - val_loss: 0.0231\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0202 - val_loss: 0.0226\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0244 - val_loss: 0.0229\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0193 - val_loss: 0.0225\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0205 - val_loss: 0.0227\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0206 - val_loss: 0.0224\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0244 - val_loss: 0.0249\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0222 - val_loss: 0.0226\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0251 - val_loss: 0.0224\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0155 - val_loss: 0.0227\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0169 - val_loss: 0.0233\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0179 - val_loss: 0.0222\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0171 - val_loss: 0.0234\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0192 - val_loss: 0.0223\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0174 - val_loss: 0.0225\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0221 - val_loss: 0.0220\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0217 - val_loss: 0.0239\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0217\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0206 - val_loss: 0.0219\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.0196 - val_loss: 0.0230\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0193 - val_loss: 0.0221\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0205 - val_loss: 0.0221\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0222 - val_loss: 0.0236\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0222 - val_loss: 0.0219\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0188 - val_loss: 0.0230\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0234 - val_loss: 0.0221\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.0213\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0177 - val_loss: 0.0211\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0195 - val_loss: 0.0214\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0202 - val_loss: 0.0218\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0218 - val_loss: 0.0213\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.0216\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0215 - val_loss: 0.0214\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0209 - val_loss: 0.0208\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0149 - val_loss: 0.0209\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0178 - val_loss: 0.0218\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0229 - val_loss: 0.0226\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0203\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0235 - val_loss: 0.0202\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0199 - val_loss: 0.0251\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0253 - val_loss: 0.0219\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0208\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0228 - val_loss: 0.0237\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0169 - val_loss: 0.0202\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0270 - val_loss: 0.0207\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.0198\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0140 - val_loss: 0.0199\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0227 - val_loss: 0.0209\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0195\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0211\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0210\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0164 - val_loss: 0.0222\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0161 - val_loss: 0.0210\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0193 - val_loss: 0.0236\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0194 - val_loss: 0.0195\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0179 - val_loss: 0.0196\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0224\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0201 - val_loss: 0.0211\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0192\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0256 - val_loss: 0.0194\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0149 - val_loss: 0.0194\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.0194\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0167 - val_loss: 0.0189\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0160 - val_loss: 0.0187\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0197 - val_loss: 0.0187\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0198\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0182 - val_loss: 0.0194\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0143 - val_loss: 0.0192\n",
      "Epoch 140/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0184\n",
      "Epoch 141/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0186\n",
      "Epoch 142/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0150 - val_loss: 0.0189\n",
      "Epoch 143/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0165 - val_loss: 0.0184\n",
      "Epoch 144/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0189\n",
      "Epoch 145/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0184\n",
      "Epoch 146/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0181\n",
      "Epoch 147/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0181\n",
      "Epoch 148/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0147 - val_loss: 0.0194\n",
      "Epoch 149/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0142 - val_loss: 0.0188\n",
      "Epoch 150/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.0184\n",
      "Epoch 151/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0179\n",
      "Epoch 152/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0160 - val_loss: 0.0181\n",
      "Epoch 153/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0193\n",
      "Epoch 154/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0200 - val_loss: 0.0178\n",
      "Epoch 155/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0179\n",
      "Epoch 156/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0156 - val_loss: 0.0181\n",
      "Epoch 157/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0185\n",
      "Epoch 158/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0214 - val_loss: 0.0188\n",
      "Epoch 159/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0173 - val_loss: 0.0182\n",
      "Epoch 160/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0146 - val_loss: 0.0179\n",
      "Epoch 161/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0173 - val_loss: 0.0182\n",
      "Epoch 162/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0206 - val_loss: 0.0181\n",
      "Epoch 163/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0183\n",
      "Epoch 164/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0169 - val_loss: 0.0185\n",
      "Epoch 165/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0107 - val_loss: 0.0187\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A85F90B1F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 57ms/step - loss: 0.1340 - val_loss: 0.0378\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0418 - val_loss: 0.0351\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0324 - val_loss: 0.0344\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0240 - val_loss: 0.0322\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0350 - val_loss: 0.0337\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0254 - val_loss: 0.0306\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0258 - val_loss: 0.0327\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0222 - val_loss: 0.0289\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0261 - val_loss: 0.0288\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0251 - val_loss: 0.0276\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0260 - val_loss: 0.0290\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0296 - val_loss: 0.0296\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0191 - val_loss: 0.0278\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0280 - val_loss: 0.0276\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0225 - val_loss: 0.0265\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0194 - val_loss: 0.0263\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0272 - val_loss: 0.0283\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0186 - val_loss: 0.0260\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0282 - val_loss: 0.0280\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0219 - val_loss: 0.0256\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0266 - val_loss: 0.0258\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0197 - val_loss: 0.0253\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0275 - val_loss: 0.0252\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0235 - val_loss: 0.0253\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0191 - val_loss: 0.0252\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0273 - val_loss: 0.0282\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0236 - val_loss: 0.0261\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0198 - val_loss: 0.0249\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0225 - val_loss: 0.0260\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0310 - val_loss: 0.0253\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0212 - val_loss: 0.0256\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.0244\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0206 - val_loss: 0.0259\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0188 - val_loss: 0.0249\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0230 - val_loss: 0.0258\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0213 - val_loss: 0.0242\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0377 - val_loss: 0.0278\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0227 - val_loss: 0.0240\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0258 - val_loss: 0.0255\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0181 - val_loss: 0.0240\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0251 - val_loss: 0.0245\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0216 - val_loss: 0.0255\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0238\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0270 - val_loss: 0.0237\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0244 - val_loss: 0.0255\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0189 - val_loss: 0.0249\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0224 - val_loss: 0.0241\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0293 - val_loss: 0.0272\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0250 - val_loss: 0.0238\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0249 - val_loss: 0.0259\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0243 - val_loss: 0.0234\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0184 - val_loss: 0.0252\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0282 - val_loss: 0.0234\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0211 - val_loss: 0.0240\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0261 - val_loss: 0.0233\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0227 - val_loss: 0.0264\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0185 - val_loss: 0.0234\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0214 - val_loss: 0.0241\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0268 - val_loss: 0.0235\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0184 - val_loss: 0.0234\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0219 - val_loss: 0.0239\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0273 - val_loss: 0.0233\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0190 - val_loss: 0.0270\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0261 - val_loss: 0.0245\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0202 - val_loss: 0.0235\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0167 - val_loss: 0.0236\n",
      "WARNING:tensorflow:11 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A884816D30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 35ms/step - loss: 0.1229 - val_loss: 0.0332\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0311 - val_loss: 0.0353\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.0280 - val_loss: 0.0303\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0270 - val_loss: 0.0318\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0264 - val_loss: 0.0294\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0305 - val_loss: 0.0291\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0333 - val_loss: 0.0322\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0212 - val_loss: 0.0295\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0254 - val_loss: 0.0287\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0269 - val_loss: 0.0327\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0202 - val_loss: 0.0273\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0332 - val_loss: 0.0282\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0305 - val_loss: 0.0297\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0263 - val_loss: 0.0270\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0248 - val_loss: 0.0264\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0244 - val_loss: 0.0264\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0190 - val_loss: 0.0260\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0259 - val_loss: 0.0285\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0191 - val_loss: 0.0267\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0218 - val_loss: 0.0313\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0221 - val_loss: 0.0277\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0256 - val_loss: 0.0255\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0223 - val_loss: 0.0268\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0199 - val_loss: 0.0256\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0215 - val_loss: 0.0265\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0256 - val_loss: 0.0250\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0308 - val_loss: 0.0264\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0221 - val_loss: 0.0249\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0227 - val_loss: 0.0247\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0240 - val_loss: 0.0269\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0202 - val_loss: 0.0246\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0221 - val_loss: 0.0247\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0239 - val_loss: 0.0251\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0315 - val_loss: 0.0291\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0203 - val_loss: 0.0245\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0232 - val_loss: 0.0252\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0261 - val_loss: 0.0255\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0210 - val_loss: 0.0241\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0281 - val_loss: 0.0253\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0177 - val_loss: 0.0240\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0246 - val_loss: 0.0242\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0190 - val_loss: 0.0240\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0226 - val_loss: 0.0251\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0255 - val_loss: 0.0238\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0257 - val_loss: 0.0252\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0218 - val_loss: 0.0238\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0196 - val_loss: 0.0250\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0269 - val_loss: 0.0240\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0181 - val_loss: 0.0238\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0248 - val_loss: 0.0247\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0236\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0328 - val_loss: 0.0238\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0234 - val_loss: 0.0247\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0229 - val_loss: 0.0261\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0230 - val_loss: 0.0238\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0261 - val_loss: 0.0236\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0256 - val_loss: 0.0232\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0202 - val_loss: 0.0232\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0224 - val_loss: 0.0246\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0233 - val_loss: 0.0239\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0289 - val_loss: 0.0248\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0196 - val_loss: 0.0236\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0258 - val_loss: 0.0235\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0238 - val_loss: 0.0235\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0224 - val_loss: 0.0240\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0200 - val_loss: 0.0232\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0203 - val_loss: 0.0254\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0207 - val_loss: 0.0233\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0275 - val_loss: 0.0235\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0202 - val_loss: 0.0227\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0177 - val_loss: 0.0233\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0203 - val_loss: 0.0227\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0234 - val_loss: 0.0232\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0225\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0256 - val_loss: 0.0224\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0185 - val_loss: 0.0249\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0217 - val_loss: 0.0234\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0257 - val_loss: 0.0225\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0197 - val_loss: 0.0224\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0208 - val_loss: 0.0226\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0247 - val_loss: 0.0242\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0219 - val_loss: 0.0224\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0292 - val_loss: 0.0233\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0235 - val_loss: 0.0227\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0250 - val_loss: 0.0230\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0228 - val_loss: 0.0226\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0233 - val_loss: 0.0225\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0205 - val_loss: 0.0222\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0221\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0221 - val_loss: 0.0242\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0162 - val_loss: 0.0236\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0192 - val_loss: 0.0249\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0183 - val_loss: 0.0219\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0207 - val_loss: 0.0241\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0244 - val_loss: 0.0226\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0169 - val_loss: 0.0216\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0225\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.0216\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0228 - val_loss: 0.0216\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0210 - val_loss: 0.0212\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0222 - val_loss: 0.0227\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0201 - val_loss: 0.0208\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0189 - val_loss: 0.0210\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.0207\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0172 - val_loss: 0.0207\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.0182 - val_loss: 0.0210\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0180 - val_loss: 0.0216\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0241 - val_loss: 0.0213\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0188 - val_loss: 0.0201\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0151 - val_loss: 0.0200\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0197 - val_loss: 0.0211\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0186 - val_loss: 0.0229\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0194 - val_loss: 0.0207\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.0195\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0216 - val_loss: 0.0199\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0174 - val_loss: 0.0231\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0140 - val_loss: 0.0196\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0288 - val_loss: 0.0224\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0136 - val_loss: 0.0191\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0196\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0140 - val_loss: 0.0198\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0173 - val_loss: 0.0209\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0199 - val_loss: 0.0191\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0187 - val_loss: 0.0195\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0179 - val_loss: 0.0196\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0157 - val_loss: 0.0202\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0248 - val_loss: 0.0187\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0169 - val_loss: 0.0195\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0141 - val_loss: 0.0196\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0160 - val_loss: 0.0188\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0206\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0184\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0162 - val_loss: 0.0184\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0149 - val_loss: 0.0184\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0183\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0125 - val_loss: 0.0183\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0136 - val_loss: 0.0185\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0181\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0185 - val_loss: 0.0192\n",
      "Epoch 140/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0125 - val_loss: 0.0180\n",
      "Epoch 141/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0143 - val_loss: 0.0181\n",
      "Epoch 142/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0211 - val_loss: 0.0178\n",
      "Epoch 143/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0141 - val_loss: 0.0186\n",
      "Epoch 144/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0120 - val_loss: 0.0176\n",
      "Epoch 145/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0201 - val_loss: 0.0182\n",
      "Epoch 146/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0179\n",
      "Epoch 147/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0143 - val_loss: 0.0205\n",
      "Epoch 148/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0178\n",
      "Epoch 149/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0178 - val_loss: 0.0186\n",
      "Epoch 150/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0215 - val_loss: 0.0181\n",
      "Epoch 151/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0156 - val_loss: 0.0179\n",
      "Epoch 152/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0141 - val_loss: 0.0179\n",
      "Epoch 153/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0172\n",
      "Epoch 154/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0201 - val_loss: 0.0185\n",
      "Epoch 155/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.0183\n",
      "Epoch 156/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.0178\n",
      "Epoch 157/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0180\n",
      "Epoch 158/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0194 - val_loss: 0.0178\n",
      "Epoch 159/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0187\n",
      "Epoch 160/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.0178\n",
      "Epoch 161/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0160 - val_loss: 0.0177\n",
      "Epoch 162/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0179\n",
      "Epoch 163/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.0175\n",
      "Epoch 164/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0187\n",
      "Epoch 165/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0196 - val_loss: 0.0172\n",
      "Epoch 166/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0177 - val_loss: 0.0176\n",
      "Epoch 167/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.0173\n",
      "Epoch 168/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0174\n",
      "Epoch 169/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0173\n",
      "Epoch 170/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0174\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A86005ACA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 36ms/step - loss: 0.0622 - val_loss: 0.0313\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0366 - val_loss: 0.0309\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0286 - val_loss: 0.0307\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0281 - val_loss: 0.0345\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0299 - val_loss: 0.0304\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0302 - val_loss: 0.0297\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0298 - val_loss: 0.0289\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0224 - val_loss: 0.0279\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.0324 - val_loss: 0.0313\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0274 - val_loss: 0.0311\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0332 - val_loss: 0.0272\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0263 - val_loss: 0.0271\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0295 - val_loss: 0.0271\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0262 - val_loss: 0.0301\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0363 - val_loss: 0.0264\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0234 - val_loss: 0.0288\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0277 - val_loss: 0.0342\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0233 - val_loss: 0.0325\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0266 - val_loss: 0.0297\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0215 - val_loss: 0.0264\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0213 - val_loss: 0.0255\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0261 - val_loss: 0.0262\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0240 - val_loss: 0.0274\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0225 - val_loss: 0.0251\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0303 - val_loss: 0.0280\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0186 - val_loss: 0.0249\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0226 - val_loss: 0.0250\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0257 - val_loss: 0.0265\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0259 - val_loss: 0.0282\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0313 - val_loss: 0.0248\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0191 - val_loss: 0.0245\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0200 - val_loss: 0.0261\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0282 - val_loss: 0.0248\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0164 - val_loss: 0.0249\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0202 - val_loss: 0.0254\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0288 - val_loss: 0.0275\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0244 - val_loss: 0.0240\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0333 - val_loss: 0.0258\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0191 - val_loss: 0.0248\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0204 - val_loss: 0.0243\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0216 - val_loss: 0.0246\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0208 - val_loss: 0.0240\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0233 - val_loss: 0.0247\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0288 - val_loss: 0.0245\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0314 - val_loss: 0.0240\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0266\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0182 - val_loss: 0.0237\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0213 - val_loss: 0.0256\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0204 - val_loss: 0.0240\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0218 - val_loss: 0.0249\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0302 - val_loss: 0.0271\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0208 - val_loss: 0.0236\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0206 - val_loss: 0.0243\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0221 - val_loss: 0.0235\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0251 - val_loss: 0.0245\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0246 - val_loss: 0.0234\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0162 - val_loss: 0.0234\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0195 - val_loss: 0.0233\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0194 - val_loss: 0.0239\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0205 - val_loss: 0.0232\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0213 - val_loss: 0.0263\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0236 - val_loss: 0.0236\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0217 - val_loss: 0.0233\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0210 - val_loss: 0.0246\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0192 - val_loss: 0.0233\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0187 - val_loss: 0.0230\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0197 - val_loss: 0.0232\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0263 - val_loss: 0.0234\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0212 - val_loss: 0.0230\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0183 - val_loss: 0.0236\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0256 - val_loss: 0.0229\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0204 - val_loss: 0.0236\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0182 - val_loss: 0.0229\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0156 - val_loss: 0.0239\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0202 - val_loss: 0.0228\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0163 - val_loss: 0.0228\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0224 - val_loss: 0.0281\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0211 - val_loss: 0.0228\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0244 - val_loss: 0.0236\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0267 - val_loss: 0.0226\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0245 - val_loss: 0.0245\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0182 - val_loss: 0.0226\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0212 - val_loss: 0.0235\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0191 - val_loss: 0.0258\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0310 - val_loss: 0.0235\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0231 - val_loss: 0.0238\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0166 - val_loss: 0.0229\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0216 - val_loss: 0.0255\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0260 - val_loss: 0.0238\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0218 - val_loss: 0.0229\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0172 - val_loss: 0.0221\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0244 - val_loss: 0.0239\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0193 - val_loss: 0.0220\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0210 - val_loss: 0.0259\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0163 - val_loss: 0.0218\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0211 - val_loss: 0.0219\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0293 - val_loss: 0.0228\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0199 - val_loss: 0.0226\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0156 - val_loss: 0.0218\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0235 - val_loss: 0.0247\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0139 - val_loss: 0.0222\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0166 - val_loss: 0.0217\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0171 - val_loss: 0.0229\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0177 - val_loss: 0.0222\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0165 - val_loss: 0.0240\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0192 - val_loss: 0.0216\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0226 - val_loss: 0.0224\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0182 - val_loss: 0.0216\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0146 - val_loss: 0.0225\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0170 - val_loss: 0.0216\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0242 - val_loss: 0.0214\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.0146 - val_loss: 0.0216\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.0207\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0150 - val_loss: 0.0228\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0155 - val_loss: 0.0219\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0216 - val_loss: 0.0208\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0163 - val_loss: 0.0211\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0217 - val_loss: 0.0220\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0240 - val_loss: 0.0219\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0201 - val_loss: 0.0211\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0184 - val_loss: 0.0206\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0163 - val_loss: 0.0202\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0192 - val_loss: 0.0215\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0220 - val_loss: 0.0215\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0158 - val_loss: 0.0203\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0213 - val_loss: 0.0201\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0146 - val_loss: 0.0209\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0209 - val_loss: 0.0221\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0139 - val_loss: 0.0199\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0188 - val_loss: 0.0247\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0203 - val_loss: 0.0200\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0163 - val_loss: 0.0200\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0229\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0148 - val_loss: 0.0202\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0198\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0213 - val_loss: 0.0193\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0219 - val_loss: 0.0200\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0128 - val_loss: 0.0209\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0212\n",
      "Epoch 140/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0198 - val_loss: 0.0194\n",
      "Epoch 141/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0207 - val_loss: 0.0193\n",
      "Epoch 142/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0155 - val_loss: 0.0192\n",
      "Epoch 143/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0191 - val_loss: 0.0194\n",
      "Epoch 144/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0146 - val_loss: 0.0194\n",
      "Epoch 145/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0190\n",
      "Epoch 146/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0195 - val_loss: 0.0204\n",
      "Epoch 147/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0176 - val_loss: 0.0190\n",
      "Epoch 148/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0196\n",
      "Epoch 149/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.0191\n",
      "Epoch 150/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0190\n",
      "Epoch 151/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0136 - val_loss: 0.0199\n",
      "Epoch 152/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0139 - val_loss: 0.0194\n",
      "Epoch 153/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0148 - val_loss: 0.0187\n",
      "Epoch 154/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.0183\n",
      "Epoch 155/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0164 - val_loss: 0.0183\n",
      "Epoch 156/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0192\n",
      "Epoch 157/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0204 - val_loss: 0.0192\n",
      "Epoch 158/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0143 - val_loss: 0.0195\n",
      "Epoch 159/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0179 - val_loss: 0.0188\n",
      "Epoch 160/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0193 - val_loss: 0.0185\n",
      "Epoch 161/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0134 - val_loss: 0.0187\n",
      "Epoch 162/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0145 - val_loss: 0.0180\n",
      "Epoch 163/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0155 - val_loss: 0.0197\n",
      "Epoch 164/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0179\n",
      "Epoch 165/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0172 - val_loss: 0.0180\n",
      "Epoch 166/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0167 - val_loss: 0.0185\n",
      "Epoch 167/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0186 - val_loss: 0.0177\n",
      "Epoch 168/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0150 - val_loss: 0.0187\n",
      "Epoch 169/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0154 - val_loss: 0.0182\n",
      "Epoch 170/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0117 - val_loss: 0.0171\n",
      "Epoch 171/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0142 - val_loss: 0.0178\n",
      "Epoch 172/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0149 - val_loss: 0.0199\n",
      "Epoch 173/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0172 - val_loss: 0.0185\n",
      "Epoch 174/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0129 - val_loss: 0.0174\n",
      "Epoch 175/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0202 - val_loss: 0.0188\n",
      "Epoch 176/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0140 - val_loss: 0.0182\n",
      "Epoch 177/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0126 - val_loss: 0.0174\n",
      "Epoch 178/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0078 - val_loss: 0.0184\n",
      "Epoch 179/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0146 - val_loss: 0.0218\n",
      "Epoch 180/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0175\n",
      "Epoch 181/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0129 - val_loss: 0.0169\n",
      "Epoch 182/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0151 - val_loss: 0.0186\n",
      "Epoch 183/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0180 - val_loss: 0.0167\n",
      "Epoch 184/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0167\n",
      "Epoch 185/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0179\n",
      "Epoch 186/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0129 - val_loss: 0.0174\n",
      "Epoch 187/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0100 - val_loss: 0.0164\n",
      "Epoch 188/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0188\n",
      "Epoch 189/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0178 - val_loss: 0.0171\n",
      "Epoch 190/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0112 - val_loss: 0.0164\n",
      "Epoch 191/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0085 - val_loss: 0.0162\n",
      "Epoch 192/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0163 - val_loss: 0.0166\n",
      "Epoch 193/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0162\n",
      "Epoch 194/200\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.0125 - val_loss: 0.0156\n",
      "Epoch 195/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0100 - val_loss: 0.0146\n",
      "Epoch 196/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0119 - val_loss: 0.0152\n",
      "Epoch 197/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0103 - val_loss: 0.0162\n",
      "Epoch 198/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0112 - val_loss: 0.0148\n",
      "Epoch 199/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0146\n",
      "Epoch 200/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0157\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A87536A040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 65ms/step - loss: 0.0893 - val_loss: 0.0317\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0346 - val_loss: 0.0299\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0271 - val_loss: 0.0315\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0427 - val_loss: 0.0372\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0315 - val_loss: 0.0286\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0233 - val_loss: 0.0286\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0257 - val_loss: 0.0292\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0276 - val_loss: 0.0278\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0279 - val_loss: 0.0314\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0277 - val_loss: 0.0294\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0286 - val_loss: 0.0281\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0235 - val_loss: 0.0267\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0274 - val_loss: 0.0264\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0299 - val_loss: 0.0269\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0214 - val_loss: 0.0260\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0261 - val_loss: 0.0311\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0260 - val_loss: 0.0257\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0257 - val_loss: 0.0262\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0249 - val_loss: 0.0260\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0254\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0226 - val_loss: 0.0251\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0330 - val_loss: 0.0268\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0229 - val_loss: 0.0248\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0244 - val_loss: 0.0265\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0185 - val_loss: 0.0247\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0219 - val_loss: 0.0245\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0249 - val_loss: 0.0265\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0339 - val_loss: 0.0245\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0268 - val_loss: 0.0302\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0342 - val_loss: 0.0249\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0225 - val_loss: 0.0245\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0238 - val_loss: 0.0267\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0350 - val_loss: 0.0255\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0206 - val_loss: 0.0242\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0214 - val_loss: 0.0246\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0169 - val_loss: 0.0240\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0203 - val_loss: 0.0239\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0202 - val_loss: 0.0261\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0210 - val_loss: 0.0251\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0221 - val_loss: 0.0237\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0291 - val_loss: 0.0261\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0275 - val_loss: 0.0242\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0210 - val_loss: 0.0240\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0241 - val_loss: 0.0253\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0267 - val_loss: 0.0243\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0201 - val_loss: 0.0275\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0280 - val_loss: 0.0252\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0309 - val_loss: 0.0234\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0269 - val_loss: 0.0248\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0256 - val_loss: 0.0239\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0185 - val_loss: 0.0234\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0182 - val_loss: 0.0240\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0188 - val_loss: 0.0234\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0245 - val_loss: 0.0248\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0223 - val_loss: 0.0246\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0192 - val_loss: 0.0239\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0182 - val_loss: 0.0232\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0210 - val_loss: 0.0246\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0221 - val_loss: 0.0231\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0191 - val_loss: 0.0233\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0235 - val_loss: 0.0235\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0180 - val_loss: 0.0231\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0205 - val_loss: 0.0249\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0194 - val_loss: 0.0230\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0259 - val_loss: 0.0255\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0202 - val_loss: 0.0231\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0171 - val_loss: 0.0235\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0210 - val_loss: 0.0231\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0194 - val_loss: 0.0230\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0203 - val_loss: 0.0236\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0178 - val_loss: 0.0232\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0205 - val_loss: 0.0234\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0227 - val_loss: 0.0228\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0345 - val_loss: 0.0251\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0220 - val_loss: 0.0226\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0191 - val_loss: 0.0229\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0217 - val_loss: 0.0230\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0231 - val_loss: 0.0226\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A88466D820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 57ms/step - loss: 0.1613 - val_loss: 0.0334\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0308 - val_loss: 0.0339\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0340 - val_loss: 0.0327\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0346 - val_loss: 0.0310\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0264 - val_loss: 0.0306\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0317 - val_loss: 0.0322\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0264 - val_loss: 0.0289\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0257 - val_loss: 0.0292\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0285 - val_loss: 0.0320\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0259 - val_loss: 0.0287\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0363 - val_loss: 0.0373\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0274 - val_loss: 0.0281\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0267 - val_loss: 0.0278\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0246 - val_loss: 0.0266\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0246 - val_loss: 0.0293\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0167 - val_loss: 0.0262\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0306 - val_loss: 0.0284\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0303 - val_loss: 0.0266\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0243 - val_loss: 0.0255\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0236 - val_loss: 0.0260\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0280 - val_loss: 0.0291\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0250 - val_loss: 0.0249\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0197 - val_loss: 0.0249\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0237 - val_loss: 0.0246\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0242 - val_loss: 0.0244\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0250 - val_loss: 0.0289\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0158 - val_loss: 0.0260\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0211 - val_loss: 0.0242\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0245 - val_loss: 0.0250\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0224 - val_loss: 0.0273\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0158 - val_loss: 0.0243\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0279 - val_loss: 0.0309\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0328 - val_loss: 0.0246\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0222 - val_loss: 0.0259\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0262 - val_loss: 0.0271\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0223 - val_loss: 0.0245\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0235 - val_loss: 0.0237\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0221 - val_loss: 0.0236\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0270 - val_loss: 0.0239\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0235 - val_loss: 0.0238\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0224 - val_loss: 0.0235\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0210 - val_loss: 0.0248\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0199 - val_loss: 0.0234\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0287 - val_loss: 0.0247\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0221 - val_loss: 0.0240\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0315 - val_loss: 0.0277\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0182 - val_loss: 0.0233\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0211 - val_loss: 0.0239\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0317 - val_loss: 0.0287\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0294 - val_loss: 0.0279\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0188 - val_loss: 0.0231\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0185 - val_loss: 0.0231\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0221 - val_loss: 0.0230\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0227 - val_loss: 0.0249\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0196 - val_loss: 0.0229\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0192 - val_loss: 0.0228\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0214 - val_loss: 0.0236\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0207 - val_loss: 0.0229\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0223 - val_loss: 0.0228\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0174 - val_loss: 0.0226\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0188 - val_loss: 0.0254\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0187 - val_loss: 0.0236\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0245 - val_loss: 0.0228\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0173 - val_loss: 0.0251\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0192 - val_loss: 0.0224\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0224 - val_loss: 0.0240\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0240\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0256 - val_loss: 0.0229\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0313 - val_loss: 0.0241\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0167 - val_loss: 0.0225\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0227 - val_loss: 0.0258\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0229 - val_loss: 0.0225\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0179 - val_loss: 0.0221\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0218\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0234 - val_loss: 0.0232\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0240 - val_loss: 0.0218\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0201 - val_loss: 0.0216\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0177 - val_loss: 0.0215\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0183 - val_loss: 0.0218\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0214 - val_loss: 0.0243\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0185 - val_loss: 0.0219\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0177 - val_loss: 0.0215\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0205 - val_loss: 0.0231\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0188 - val_loss: 0.0213\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0199 - val_loss: 0.0227\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0197 - val_loss: 0.0217\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.0221 - val_loss: 0.0214\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0291 - val_loss: 0.0230\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0182 - val_loss: 0.0220\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0182 - val_loss: 0.0210\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0204 - val_loss: 0.0211\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0231 - val_loss: 0.0202\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0201\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0212\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0150 - val_loss: 0.0210\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0200\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0167 - val_loss: 0.0199\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0221\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0210 - val_loss: 0.0194\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0210 - val_loss: 0.0193\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0208\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0192\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0211 - val_loss: 0.0192\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.0196\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0243\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0180 - val_loss: 0.0219\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0154 - val_loss: 0.0195\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0149 - val_loss: 0.0212\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0198 - val_loss: 0.0186\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0151 - val_loss: 0.0186\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0224 - val_loss: 0.0184\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0190\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0185 - val_loss: 0.0195\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0164 - val_loss: 0.0183\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.0185\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0162 - val_loss: 0.0182\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0127 - val_loss: 0.0180\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.0196\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0186\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0182 - val_loss: 0.0202\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0215\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0216 - val_loss: 0.0184\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0181 - val_loss: 0.0183\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0178\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0143 - val_loss: 0.0200\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0127 - val_loss: 0.0176\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0165 - val_loss: 0.0184\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.0182\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0141 - val_loss: 0.0190\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0173\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0197 - val_loss: 0.0181\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.0185\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0225 - val_loss: 0.0183\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0164 - val_loss: 0.0199\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0155 - val_loss: 0.0175\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0194 - val_loss: 0.0175\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0160 - val_loss: 0.0169\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0187 - val_loss: 0.0174\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0182 - val_loss: 0.0169\n",
      "Epoch 140/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0119 - val_loss: 0.0168\n",
      "Epoch 141/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0157 - val_loss: 0.0168\n",
      "Epoch 142/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0165\n",
      "Epoch 143/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0179\n",
      "Epoch 144/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0175\n",
      "Epoch 145/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0190\n",
      "Epoch 146/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0179\n",
      "Epoch 147/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0190 - val_loss: 0.0172\n",
      "Epoch 148/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0126 - val_loss: 0.0179\n",
      "Epoch 149/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0164\n",
      "Epoch 150/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0179 - val_loss: 0.0157\n",
      "Epoch 151/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0164\n",
      "Epoch 152/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0164 - val_loss: 0.0165\n",
      "Epoch 153/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0149\n",
      "Epoch 154/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0126 - val_loss: 0.0144\n",
      "Epoch 155/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0172\n",
      "Epoch 156/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.0168\n",
      "Epoch 157/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0113 - val_loss: 0.0133\n",
      "Epoch 158/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0147 - val_loss: 0.0173\n",
      "Epoch 159/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0148\n",
      "Epoch 160/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0147\n",
      "Epoch 161/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0155 - val_loss: 0.0128\n",
      "Epoch 162/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0141 - val_loss: 0.0145\n",
      "Epoch 163/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0132\n",
      "Epoch 164/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0131 - val_loss: 0.0133\n",
      "Epoch 165/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0129\n",
      "Epoch 166/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0137\n",
      "Epoch 167/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0114 - val_loss: 0.0144\n",
      "Epoch 168/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0129\n",
      "Epoch 169/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0136\n",
      "Epoch 170/200\n",
      "25/25 [==============================] - 1s 28ms/step - loss: 0.0114 - val_loss: 0.0188\n",
      "Epoch 171/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0128 - val_loss: 0.0145\n",
      "Epoch 172/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0114 - val_loss: 0.0163\n",
      "Epoch 173/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0137 - val_loss: 0.0135\n",
      "Epoch 174/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0079 - val_loss: 0.0133\n",
      "Epoch 175/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0107 - val_loss: 0.0129\n",
      "Epoch 176/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0130 - val_loss: 0.0150\n",
      "Epoch 177/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0137\n",
      "Epoch 178/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0149\n",
      "Epoch 179/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0070 - val_loss: 0.0127\n",
      "Epoch 180/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0177\n",
      "Epoch 181/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0127\n",
      "Epoch 182/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0139\n",
      "Epoch 183/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0134\n",
      "Epoch 184/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0086 - val_loss: 0.0140\n",
      "Epoch 185/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0089 - val_loss: 0.0143\n",
      "Epoch 186/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0093 - val_loss: 0.0143\n",
      "Epoch 187/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0122\n",
      "Epoch 188/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0158\n",
      "Epoch 189/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0155\n",
      "Epoch 190/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0127 - val_loss: 0.0122\n",
      "Epoch 191/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0086 - val_loss: 0.0134\n",
      "Epoch 192/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0129\n",
      "Epoch 193/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0084 - val_loss: 0.0119\n",
      "Epoch 194/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0141\n",
      "Epoch 195/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0087 - val_loss: 0.0127\n",
      "Epoch 196/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0078 - val_loss: 0.0115\n",
      "Epoch 197/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0141\n",
      "Epoch 198/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0083 - val_loss: 0.0149\n",
      "Epoch 199/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0077 - val_loss: 0.0133\n",
      "Epoch 200/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0140\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A70D142E50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 34ms/step - loss: 0.0726 - val_loss: 0.0405\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0380 - val_loss: 0.0310\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0311 - val_loss: 0.0294\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0261 - val_loss: 0.0306\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0282 - val_loss: 0.0326\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0253 - val_loss: 0.0302\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0227 - val_loss: 0.0302\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0334 - val_loss: 0.0339\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0264 - val_loss: 0.0299\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0342 - val_loss: 0.0277\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0240 - val_loss: 0.0266\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0268 - val_loss: 0.0304\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0213 - val_loss: 0.0277\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0294 - val_loss: 0.0312\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0266 - val_loss: 0.0260\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0315 - val_loss: 0.0257\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0298 - val_loss: 0.0282\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0251 - val_loss: 0.0276\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0285 - val_loss: 0.0289\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0240 - val_loss: 0.0260\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0343 - val_loss: 0.0315\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0286 - val_loss: 0.0304\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0243 - val_loss: 0.0249\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0243 - val_loss: 0.0255\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0268 - val_loss: 0.0298\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0270 - val_loss: 0.0267\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0236 - val_loss: 0.0245\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0207 - val_loss: 0.0250\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0281 - val_loss: 0.0266\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0179 - val_loss: 0.0247\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0231 - val_loss: 0.0285\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0186 - val_loss: 0.0242\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0256 - val_loss: 0.0240\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0270 - val_loss: 0.0253\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0185 - val_loss: 0.0239\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0218 - val_loss: 0.0237\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0188 - val_loss: 0.0249\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0272 - val_loss: 0.0266\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0242 - val_loss: 0.0251\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0215 - val_loss: 0.0236\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0258 - val_loss: 0.0324\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0203 - val_loss: 0.0239\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0250 - val_loss: 0.0236\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0238 - val_loss: 0.0239\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0212 - val_loss: 0.0235\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0248 - val_loss: 0.0239\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0250 - val_loss: 0.0274\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0277 - val_loss: 0.0257\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0193 - val_loss: 0.0235\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0238 - val_loss: 0.0238\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.0243\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0202 - val_loss: 0.0247\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0224 - val_loss: 0.0237\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0291 - val_loss: 0.0254\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0229 - val_loss: 0.0232\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0160 - val_loss: 0.0237\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0230 - val_loss: 0.0230\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0258 - val_loss: 0.0256\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0210 - val_loss: 0.0233\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0173 - val_loss: 0.0234\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0301 - val_loss: 0.0251\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0219 - val_loss: 0.0231\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0126 - val_loss: 0.0227\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0226 - val_loss: 0.0254\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0206 - val_loss: 0.0234\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0186 - val_loss: 0.0237\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0228 - val_loss: 0.0228\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0187 - val_loss: 0.0245\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0202 - val_loss: 0.0223\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.0286 - val_loss: 0.0223\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0176 - val_loss: 0.0233\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0217 - val_loss: 0.0227\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0171 - val_loss: 0.0221\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0230 - val_loss: 0.0238\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0237 - val_loss: 0.0234\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0215 - val_loss: 0.0220\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0177 - val_loss: 0.0223\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0161 - val_loss: 0.0222\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0193 - val_loss: 0.0217\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0232 - val_loss: 0.0233\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0237 - val_loss: 0.0310\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0258 - val_loss: 0.0215\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0274 - val_loss: 0.0214\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0170 - val_loss: 0.0213\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0210\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0201 - val_loss: 0.0239\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0190 - val_loss: 0.0205\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0239 - val_loss: 0.0207\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0196 - val_loss: 0.0203\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0202 - val_loss: 0.0208\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0140 - val_loss: 0.0203\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0217 - val_loss: 0.0198\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0136 - val_loss: 0.0200\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0192 - val_loss: 0.0213\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0176 - val_loss: 0.0196\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0136 - val_loss: 0.0199\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0149 - val_loss: 0.0207\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0206 - val_loss: 0.0201\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.0200\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0172 - val_loss: 0.0188\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0194 - val_loss: 0.0190\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0144 - val_loss: 0.0231\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0183 - val_loss: 0.0197\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0170 - val_loss: 0.0223\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0202\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0175 - val_loss: 0.0256\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0181 - val_loss: 0.0190\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0167 - val_loss: 0.0189\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.0188\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0164 - val_loss: 0.0198\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0146 - val_loss: 0.0184\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0115 - val_loss: 0.0183\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0198 - val_loss: 0.0184\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0138 - val_loss: 0.0181\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0171 - val_loss: 0.0180\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0217 - val_loss: 0.0200\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0230 - val_loss: 0.0187\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0138 - val_loss: 0.0181\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0184\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0169 - val_loss: 0.0193\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0177\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0200 - val_loss: 0.0180\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0189\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0226 - val_loss: 0.0180\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0207\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0144 - val_loss: 0.0184\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0169 - val_loss: 0.0166\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0192 - val_loss: 0.0176\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0176\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0155 - val_loss: 0.0172\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0151 - val_loss: 0.0181\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0178\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0223 - val_loss: 0.0172\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0159 - val_loss: 0.0173\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0152 - val_loss: 0.0173\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0119 - val_loss: 0.0173\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0130 - val_loss: 0.0175\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0215 - val_loss: 0.0169\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0128 - val_loss: 0.0171\n",
      "Epoch 140/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0170\n",
      "Epoch 141/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0107 - val_loss: 0.0166\n",
      "Epoch 142/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0155 - val_loss: 0.0173\n",
      "Epoch 143/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0143 - val_loss: 0.0166\n",
      "Epoch 144/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0160 - val_loss: 0.0182\n",
      "Epoch 145/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0174\n",
      "Epoch 146/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0198\n",
      "Epoch 147/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0162 - val_loss: 0.0177\n",
      "Epoch 148/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0181\n",
      "Epoch 149/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0189 - val_loss: 0.0174\n",
      "Epoch 150/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0170\n",
      "Epoch 151/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0162\n",
      "Epoch 152/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0158\n",
      "Epoch 153/200\n",
      "25/25 [==============================] - 1s 28ms/step - loss: 0.0134 - val_loss: 0.0161\n",
      "Epoch 154/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0165\n",
      "Epoch 155/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0160\n",
      "Epoch 156/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0165\n",
      "Epoch 157/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0160\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A88CEEFEE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 65ms/step - loss: 0.0853 - val_loss: 0.0316\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0282 - val_loss: 0.0302\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0277 - val_loss: 0.0304\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0227 - val_loss: 0.0286\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0277 - val_loss: 0.0302\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0249 - val_loss: 0.0276\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0258 - val_loss: 0.0279\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0255 - val_loss: 0.0273\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0222 - val_loss: 0.0265\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0262 - val_loss: 0.0264\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0262 - val_loss: 0.0264\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0286 - val_loss: 0.0280\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0283 - val_loss: 0.0260\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0219 - val_loss: 0.0352\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0264 - val_loss: 0.0264\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0223 - val_loss: 0.0262\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0262 - val_loss: 0.0252\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0246 - val_loss: 0.0251\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0268 - val_loss: 0.0357\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0365 - val_loss: 0.0258\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0208 - val_loss: 0.0261\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.0269\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0182 - val_loss: 0.0258\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0238 - val_loss: 0.0253\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0267 - val_loss: 0.0243\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0210 - val_loss: 0.0250\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0229 - val_loss: 0.0242\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0192 - val_loss: 0.0239\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0297 - val_loss: 0.0282\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0275 - val_loss: 0.0268\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0200 - val_loss: 0.0241\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0282 - val_loss: 0.0238\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0181 - val_loss: 0.0236\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0205 - val_loss: 0.0243\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0259 - val_loss: 0.0236\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0270 - val_loss: 0.0236\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0217 - val_loss: 0.0250\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0194 - val_loss: 0.0240\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0235 - val_loss: 0.0235\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0219 - val_loss: 0.0250\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0216 - val_loss: 0.0232\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0211 - val_loss: 0.0232\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0262 - val_loss: 0.0236\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0218 - val_loss: 0.0244\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0251 - val_loss: 0.0234\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0191 - val_loss: 0.0242\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0254 - val_loss: 0.0299\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0298 - val_loss: 0.0233\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0215 - val_loss: 0.0230\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0190 - val_loss: 0.0234\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0193 - val_loss: 0.0285\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0211 - val_loss: 0.0229\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.0228\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0220 - val_loss: 0.0228\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0239 - val_loss: 0.0231\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0172 - val_loss: 0.0239\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0279 - val_loss: 0.0231\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0253 - val_loss: 0.0254\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0198 - val_loss: 0.0245\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0204 - val_loss: 0.0246\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0237 - val_loss: 0.0225\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0262 - val_loss: 0.0233\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0234 - val_loss: 0.0225\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0255 - val_loss: 0.0224\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0178 - val_loss: 0.0233\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0167 - val_loss: 0.0246\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0230 - val_loss: 0.0220\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0330 - val_loss: 0.0285\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.0218\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0179 - val_loss: 0.0220\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0219 - val_loss: 0.0217\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.0241\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.0231\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0200 - val_loss: 0.0238\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0155 - val_loss: 0.0235\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0275 - val_loss: 0.0265\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0179 - val_loss: 0.0213\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0212\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0206 - val_loss: 0.0224\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0185 - val_loss: 0.0234\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0210 - val_loss: 0.0338\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0245 - val_loss: 0.0206\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0141 - val_loss: 0.0211\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0206\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0187 - val_loss: 0.0210\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0203 - val_loss: 0.0230\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.0223\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0259 - val_loss: 0.0215\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0173 - val_loss: 0.0199\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0156 - val_loss: 0.0204\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0145 - val_loss: 0.0195\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0202 - val_loss: 0.0197\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0189 - val_loss: 0.0192\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0179 - val_loss: 0.0210\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0231 - val_loss: 0.0193\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0202 - val_loss: 0.0207\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0181 - val_loss: 0.0192\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0212 - val_loss: 0.0199\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0175 - val_loss: 0.0217\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0273 - val_loss: 0.0208\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0143 - val_loss: 0.0194\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0192\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.0154 - val_loss: 0.0192\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0187\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.0189\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0127 - val_loss: 0.0186\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0221 - val_loss: 0.0194\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.0239\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0197\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0184\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0138 - val_loss: 0.0187\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0127 - val_loss: 0.0199\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0219\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0115 - val_loss: 0.0178\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0169 - val_loss: 0.0187\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0126 - val_loss: 0.0175\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0152 - val_loss: 0.0171\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0159 - val_loss: 0.0258\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0197 - val_loss: 0.0193\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0114 - val_loss: 0.0182\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.0171\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0107 - val_loss: 0.0174\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0176\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0135 - val_loss: 0.0169\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0168\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0148 - val_loss: 0.0169\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0169\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.0182\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0171\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0149 - val_loss: 0.0167\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0195 - val_loss: 0.0165\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0130 - val_loss: 0.0157\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0160 - val_loss: 0.0166\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0160\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0178\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.0152\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0110 - val_loss: 0.0148\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0150\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0157\n",
      "Epoch 140/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0119 - val_loss: 0.0145\n",
      "Epoch 141/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0168\n",
      "Epoch 142/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0130 - val_loss: 0.0153\n",
      "Epoch 143/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0127 - val_loss: 0.0145\n",
      "Epoch 144/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0114 - val_loss: 0.0144\n",
      "Epoch 145/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0149\n",
      "Epoch 146/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0148\n",
      "Epoch 147/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0173\n",
      "Epoch 148/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0110 - val_loss: 0.0137\n",
      "Epoch 149/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0095 - val_loss: 0.0160\n",
      "Epoch 150/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0073 - val_loss: 0.0152\n",
      "Epoch 151/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0150\n",
      "Epoch 152/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0095 - val_loss: 0.0155\n",
      "Epoch 153/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0077 - val_loss: 0.0187\n",
      "Epoch 154/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0148\n",
      "Epoch 155/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0120 - val_loss: 0.0154\n",
      "Epoch 156/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0080 - val_loss: 0.0178\n",
      "Epoch 157/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0082 - val_loss: 0.0160\n",
      "Epoch 158/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0085 - val_loss: 0.0179\n",
      "Epoch 159/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0073 - val_loss: 0.0158\n",
      "Epoch 160/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0069 - val_loss: 0.0146\n",
      "Epoch 161/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0078 - val_loss: 0.0151\n",
      "Epoch 162/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0079 - val_loss: 0.0152\n",
      "Epoch 163/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0093 - val_loss: 0.0147\n",
      "Epoch 164/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0085 - val_loss: 0.0160\n",
      "Epoch 165/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0064 - val_loss: 0.0145\n",
      "Epoch 166/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0084 - val_loss: 0.0165\n",
      "Epoch 167/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0077 - val_loss: 0.0159\n",
      "Epoch 168/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0069 - val_loss: 0.0168\n",
      "Epoch 169/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0088 - val_loss: 0.0148\n",
      "Epoch 170/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0073 - val_loss: 0.0151\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A70D3999D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 35ms/step - loss: 0.1244 - val_loss: 0.0320\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0286 - val_loss: 0.0315\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0267 - val_loss: 0.0307\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.0260 - val_loss: 0.0303\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0295 - val_loss: 0.0317\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0297 - val_loss: 0.0282\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0297 - val_loss: 0.0294\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0221 - val_loss: 0.0290\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0278 - val_loss: 0.0288\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0295 - val_loss: 0.0291\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0235 - val_loss: 0.0275\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0272 - val_loss: 0.0312\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0323 - val_loss: 0.0266\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0255 - val_loss: 0.0277\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0244 - val_loss: 0.0267\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0283 - val_loss: 0.0258\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0239 - val_loss: 0.0253\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0246 - val_loss: 0.0337\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0297 - val_loss: 0.0258\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0292 - val_loss: 0.0267\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0246 - val_loss: 0.0250\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0230 - val_loss: 0.0281\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0266 - val_loss: 0.0255\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0258 - val_loss: 0.0272\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0235 - val_loss: 0.0258\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0188 - val_loss: 0.0241\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0228 - val_loss: 0.0271\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0262 - val_loss: 0.0249\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0163 - val_loss: 0.0258\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0269 - val_loss: 0.0246\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0226 - val_loss: 0.0264\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0220 - val_loss: 0.0247\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0210 - val_loss: 0.0251\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0196 - val_loss: 0.0237\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0229 - val_loss: 0.0237\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0242 - val_loss: 0.0239\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0222 - val_loss: 0.0309\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0282 - val_loss: 0.0246\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0239 - val_loss: 0.0234\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0179 - val_loss: 0.0234\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0277 - val_loss: 0.0283\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0219 - val_loss: 0.0236\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0268 - val_loss: 0.0235\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0250 - val_loss: 0.0256\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0260 - val_loss: 0.0256\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0246 - val_loss: 0.0242\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0219 - val_loss: 0.0232\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0188 - val_loss: 0.0249\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0214 - val_loss: 0.0230\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0248 - val_loss: 0.0236\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0170 - val_loss: 0.0229\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0247 - val_loss: 0.0235\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0217 - val_loss: 0.0229\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0171 - val_loss: 0.0232\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0268 - val_loss: 0.0229\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0173 - val_loss: 0.0227\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0178 - val_loss: 0.0233\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0204 - val_loss: 0.0230\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0186 - val_loss: 0.0244\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0191 - val_loss: 0.0227\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0167 - val_loss: 0.0232\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0245 - val_loss: 0.0262\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0220 - val_loss: 0.0225\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0257 - val_loss: 0.0237\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0228 - val_loss: 0.0223\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0257 - val_loss: 0.0234\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0205 - val_loss: 0.0238\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0199 - val_loss: 0.0222\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0193 - val_loss: 0.0221\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0211 - val_loss: 0.0255\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0216 - val_loss: 0.0246\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0210 - val_loss: 0.0220\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0236 - val_loss: 0.0240\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0145 - val_loss: 0.0215\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0217\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0185 - val_loss: 0.0245\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0151 - val_loss: 0.0220\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0204 - val_loss: 0.0211\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0191 - val_loss: 0.0209\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0162 - val_loss: 0.0209\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0199 - val_loss: 0.0212\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0211 - val_loss: 0.0234\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0260 - val_loss: 0.0211\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0203\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0139 - val_loss: 0.0206\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0203 - val_loss: 0.0213\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0200\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0174 - val_loss: 0.0219\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0238 - val_loss: 0.0198\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0176 - val_loss: 0.0216\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0207\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0157 - val_loss: 0.0236\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0180 - val_loss: 0.0193\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0160 - val_loss: 0.0218\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0166 - val_loss: 0.0189\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0230 - val_loss: 0.0204\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0202 - val_loss: 0.0197\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.0208\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0130 - val_loss: 0.0195\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0162 - val_loss: 0.0192\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0180\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.0184\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0195 - val_loss: 0.0198\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0183\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0184\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0119 - val_loss: 0.0196\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.0172 - val_loss: 0.0180\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0185 - val_loss: 0.0174\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0148 - val_loss: 0.0179\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0180\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0176 - val_loss: 0.0188\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0158 - val_loss: 0.0175\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0176\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0183 - val_loss: 0.0198\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0139 - val_loss: 0.0188\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0130 - val_loss: 0.0174\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0144 - val_loss: 0.0174\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0144 - val_loss: 0.0186\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0154 - val_loss: 0.0172\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0134 - val_loss: 0.0168\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0156 - val_loss: 0.0166\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0177 - val_loss: 0.0166\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0123 - val_loss: 0.0160\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0130 - val_loss: 0.0171\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0112 - val_loss: 0.0167\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0166\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0097 - val_loss: 0.0163\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0110 - val_loss: 0.0159\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0176\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.0157\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0109 - val_loss: 0.0180\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0146 - val_loss: 0.0171\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0093 - val_loss: 0.0159\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0151 - val_loss: 0.0166\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0149 - val_loss: 0.0160\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0151\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0156\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0101 - val_loss: 0.0160\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0146 - val_loss: 0.0172\n",
      "Epoch 140/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0106 - val_loss: 0.0147\n",
      "Epoch 141/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0104 - val_loss: 0.0150\n",
      "Epoch 142/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0108 - val_loss: 0.0155\n",
      "Epoch 143/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 0.0147\n",
      "Epoch 144/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0105 - val_loss: 0.0141\n",
      "Epoch 145/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0086 - val_loss: 0.0151\n",
      "Epoch 146/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0087 - val_loss: 0.0145\n",
      "Epoch 147/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0087 - val_loss: 0.0150\n",
      "Epoch 148/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0081 - val_loss: 0.0152\n",
      "Epoch 149/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.0149\n",
      "Epoch 150/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0170\n",
      "Epoch 151/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0141\n",
      "Epoch 152/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0103 - val_loss: 0.0155\n",
      "Epoch 153/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0159\n",
      "Epoch 154/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0153\n",
      "Epoch 155/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0068 - val_loss: 0.0162\n",
      "Epoch 156/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0068 - val_loss: 0.0157\n",
      "Epoch 157/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0087 - val_loss: 0.0153\n",
      "Epoch 158/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0077 - val_loss: 0.0151\n",
      "Epoch 159/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0161\n",
      "Epoch 160/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0159\n",
      "Epoch 161/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0087 - val_loss: 0.0176\n",
      "Epoch 162/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0084 - val_loss: 0.0182\n",
      "Epoch 163/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0072 - val_loss: 0.0159\n",
      "Epoch 164/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0086 - val_loss: 0.0158\n",
      "Epoch 165/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0140\n",
      "Epoch 166/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0071 - val_loss: 0.0151\n",
      "Epoch 167/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0165\n",
      "Epoch 168/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0080 - val_loss: 0.0150\n",
      "Epoch 169/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0073 - val_loss: 0.0162\n",
      "Epoch 170/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0073 - val_loss: 0.0149\n",
      "Epoch 171/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0085 - val_loss: 0.0177\n",
      "Epoch 172/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0078 - val_loss: 0.0141\n",
      "Epoch 173/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0069 - val_loss: 0.0159\n",
      "Epoch 174/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0063 - val_loss: 0.0142\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A875407310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 34ms/step - loss: 0.0917 - val_loss: 0.0467\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0272 - val_loss: 0.0294\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0288 - val_loss: 0.0289\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0295 - val_loss: 0.0310\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.0297 - val_loss: 0.0279\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0251 - val_loss: 0.0293\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0251 - val_loss: 0.0347\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0327 - val_loss: 0.0395\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0468 - val_loss: 0.0307\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0348 - val_loss: 0.0323\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0252 - val_loss: 0.0268\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0231 - val_loss: 0.0268\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0281 - val_loss: 0.0307\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0265 - val_loss: 0.0258\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0334 - val_loss: 0.0274\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0218 - val_loss: 0.0268\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0205 - val_loss: 0.0266\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0181 - val_loss: 0.0259\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0246 - val_loss: 0.0249\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0286 - val_loss: 0.0256\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0206 - val_loss: 0.0245\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0272 - val_loss: 0.0248\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0247 - val_loss: 0.0259\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0220 - val_loss: 0.0244\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0223 - val_loss: 0.0284\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0357 - val_loss: 0.0329\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0189 - val_loss: 0.0243\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0214 - val_loss: 0.0261\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0284 - val_loss: 0.0329\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0266 - val_loss: 0.0239\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0212 - val_loss: 0.0239\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0223 - val_loss: 0.0247\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0228 - val_loss: 0.0263\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0264 - val_loss: 0.0254\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0225 - val_loss: 0.0252\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0212 - val_loss: 0.0238\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0211 - val_loss: 0.0238\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0230 - val_loss: 0.0263\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0304 - val_loss: 0.0246\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0335 - val_loss: 0.0239\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0255 - val_loss: 0.0288\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0246 - val_loss: 0.0235\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0217 - val_loss: 0.0233\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0256 - val_loss: 0.0241\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0216 - val_loss: 0.0233\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0185 - val_loss: 0.0233\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0203 - val_loss: 0.0232\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0228 - val_loss: 0.0239\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0221 - val_loss: 0.0232\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0280 - val_loss: 0.0283\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0234 - val_loss: 0.0233\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0250 - val_loss: 0.0239\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0206 - val_loss: 0.0229\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0218 - val_loss: 0.0261\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0236 - val_loss: 0.0229\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0225 - val_loss: 0.0244\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0190 - val_loss: 0.0240\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0230 - val_loss: 0.0256\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0173 - val_loss: 0.0234\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0192 - val_loss: 0.0230\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A875407C10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 35ms/step - loss: 0.0910 - val_loss: 0.0446\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0452 - val_loss: 0.0296\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0317 - val_loss: 0.0310\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0284 - val_loss: 0.0299\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0354 - val_loss: 0.0306\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0282 - val_loss: 0.0277\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0353 - val_loss: 0.0448\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0200 - val_loss: 0.0290\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0317 - val_loss: 0.0353\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0292 - val_loss: 0.0278\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0198 - val_loss: 0.0277\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0202 - val_loss: 0.0276\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0280 - val_loss: 0.0258\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0258 - val_loss: 0.0308\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0220 - val_loss: 0.0272\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0200 - val_loss: 0.0272\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0292 - val_loss: 0.0291\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0320 - val_loss: 0.0264\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0262 - val_loss: 0.0247\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0298 - val_loss: 0.0248\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0190 - val_loss: 0.0249\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0206 - val_loss: 0.0244\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0254 - val_loss: 0.0254\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0181 - val_loss: 0.0252\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0250 - val_loss: 0.0255\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0198 - val_loss: 0.0247\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0215 - val_loss: 0.0241\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0268 - val_loss: 0.0242\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0291 - val_loss: 0.0240\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0295 - val_loss: 0.0271\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0215 - val_loss: 0.0236\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0251 - val_loss: 0.0246\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0235 - val_loss: 0.0252\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0242 - val_loss: 0.0250\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0245 - val_loss: 0.0261\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0239 - val_loss: 0.0241\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0347 - val_loss: 0.0269\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0210 - val_loss: 0.0236\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0213 - val_loss: 0.0243\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.0206 - val_loss: 0.0235\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0208 - val_loss: 0.0255\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0195 - val_loss: 0.0234\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0213 - val_loss: 0.0242\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0201 - val_loss: 0.0234\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0221 - val_loss: 0.0322\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0193 - val_loss: 0.0240\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0260 - val_loss: 0.0252\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0243\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0225 - val_loss: 0.0256\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0291 - val_loss: 0.0231\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0189 - val_loss: 0.0231\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0162 - val_loss: 0.0239\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0223 - val_loss: 0.0232\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0194 - val_loss: 0.0237\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0210 - val_loss: 0.0232\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0218 - val_loss: 0.0248\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0196 - val_loss: 0.0255\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0261 - val_loss: 0.0278\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0194 - val_loss: 0.0241\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0226 - val_loss: 0.0262\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0272 - val_loss: 0.0232\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A887A0BAF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 35ms/step - loss: 0.1151 - val_loss: 0.0487\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0307 - val_loss: 0.0322\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0290 - val_loss: 0.0294\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0313 - val_loss: 0.0292\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0248 - val_loss: 0.0322\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0305 - val_loss: 0.0279\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0210 - val_loss: 0.0282\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0217 - val_loss: 0.0282\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0289 - val_loss: 0.0268\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0269 - val_loss: 0.0264\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0293 - val_loss: 0.0361\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0240 - val_loss: 0.0263\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0258 - val_loss: 0.0282\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0214 - val_loss: 0.0306\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0213 - val_loss: 0.0252\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0196 - val_loss: 0.0249\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0208 - val_loss: 0.0247\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0186 - val_loss: 0.0247\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0264 - val_loss: 0.0372\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0222 - val_loss: 0.0244\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0219 - val_loss: 0.0247\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0244 - val_loss: 0.0255\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0192 - val_loss: 0.0249\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0248 - val_loss: 0.0271\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0241 - val_loss: 0.0265\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0243 - val_loss: 0.0242\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0284 - val_loss: 0.0240\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0201 - val_loss: 0.0259\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0235 - val_loss: 0.0244\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0230 - val_loss: 0.0243\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0213 - val_loss: 0.0239\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0212 - val_loss: 0.0275\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0170 - val_loss: 0.0244\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0244 - val_loss: 0.0242\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0284 - val_loss: 0.0280\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0370 - val_loss: 0.0238\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0244 - val_loss: 0.0236\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0188 - val_loss: 0.0245\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0200 - val_loss: 0.0234\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0231 - val_loss: 0.0233\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0253 - val_loss: 0.0261\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0262 - val_loss: 0.0235\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0264 - val_loss: 0.0235\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0209 - val_loss: 0.0232\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0203 - val_loss: 0.0232\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0186 - val_loss: 0.0238\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0224 - val_loss: 0.0231\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0233 - val_loss: 0.0267\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0278 - val_loss: 0.0237\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0197 - val_loss: 0.0244\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0172 - val_loss: 0.0238\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0216 - val_loss: 0.0228\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0288 - val_loss: 0.0241\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0205 - val_loss: 0.0239\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0283 - val_loss: 0.0333\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0193 - val_loss: 0.0243\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0213 - val_loss: 0.0241\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0155 - val_loss: 0.0229\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0194 - val_loss: 0.0242\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.0196 - val_loss: 0.0227\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0222 - val_loss: 0.0233\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0225 - val_loss: 0.0238\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0195 - val_loss: 0.0253\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0210 - val_loss: 0.0224\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0216 - val_loss: 0.0261\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0223\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0172 - val_loss: 0.0225\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0174 - val_loss: 0.0223\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0193 - val_loss: 0.0221\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0171 - val_loss: 0.0219\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0224 - val_loss: 0.0253\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0242 - val_loss: 0.0220\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0186 - val_loss: 0.0248\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0198 - val_loss: 0.0228\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0294 - val_loss: 0.0229\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0182 - val_loss: 0.0214\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0200 - val_loss: 0.0225\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0182 - val_loss: 0.0213\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0182 - val_loss: 0.0214\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0170 - val_loss: 0.0211\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0180 - val_loss: 0.0247\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0213\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0154 - val_loss: 0.0211\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0200 - val_loss: 0.0208\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0215\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0190 - val_loss: 0.0217\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0155 - val_loss: 0.0205\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0173 - val_loss: 0.0262\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0202 - val_loss: 0.0202\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0232 - val_loss: 0.0197\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0179 - val_loss: 0.0237\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0192 - val_loss: 0.0219\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0185 - val_loss: 0.0220\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0176 - val_loss: 0.0199\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0173 - val_loss: 0.0197\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0252 - val_loss: 0.0242\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0243 - val_loss: 0.0212\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0170 - val_loss: 0.0184\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0126 - val_loss: 0.0185\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0201\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0192\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0203 - val_loss: 0.0198\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0135 - val_loss: 0.0183\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0132 - val_loss: 0.0211\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0234 - val_loss: 0.0180\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0168 - val_loss: 0.0197\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.0178\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0167 - val_loss: 0.0184\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0132 - val_loss: 0.0188\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0190 - val_loss: 0.0211\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0187 - val_loss: 0.0179\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0177 - val_loss: 0.0183\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0140 - val_loss: 0.0187\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0192 - val_loss: 0.0179\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0155 - val_loss: 0.0176\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0191 - val_loss: 0.0181\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0185\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0182\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0217 - val_loss: 0.0212\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0151 - val_loss: 0.0170\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0184 - val_loss: 0.0175\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0173 - val_loss: 0.0179\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0182 - val_loss: 0.0181\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0112 - val_loss: 0.0172\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0167 - val_loss: 0.0158\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0201 - val_loss: 0.0209\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0160 - val_loss: 0.0165\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0119 - val_loss: 0.0181\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0109 - val_loss: 0.0169\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0152 - val_loss: 0.0180\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0138 - val_loss: 0.0172\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0144 - val_loss: 0.0175\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0170\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0186 - val_loss: 0.0189\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0150\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0141 - val_loss: 0.0170\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0112 - val_loss: 0.0149\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0148\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0135\n",
      "Epoch 140/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0145\n",
      "Epoch 141/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0131 - val_loss: 0.0183\n",
      "Epoch 142/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0149\n",
      "Epoch 143/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0149 - val_loss: 0.0147\n",
      "Epoch 144/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.0153\n",
      "Epoch 145/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0082 - val_loss: 0.0141\n",
      "Epoch 146/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0089 - val_loss: 0.0161\n",
      "Epoch 147/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0174\n",
      "Epoch 148/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0146\n",
      "Epoch 149/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0109 - val_loss: 0.0139\n",
      "Epoch 150/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0126 - val_loss: 0.0163\n",
      "Epoch 151/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0100 - val_loss: 0.0143\n",
      "Epoch 152/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0100 - val_loss: 0.0157\n",
      "Epoch 153/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0110 - val_loss: 0.0180\n",
      "Epoch 154/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0131 - val_loss: 0.0163\n",
      "Epoch 155/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0150\n",
      "Epoch 156/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0085 - val_loss: 0.0162\n",
      "Epoch 157/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0179\n",
      "Epoch 158/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0088 - val_loss: 0.0144\n",
      "Epoch 159/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0141\n",
      "Epoch 160/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0089 - val_loss: 0.0158\n",
      "Epoch 161/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0110 - val_loss: 0.0147\n",
      "Epoch 162/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0070 - val_loss: 0.0162\n",
      "Epoch 163/200\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.0073 - val_loss: 0.0143\n",
      "Epoch 164/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0153\n",
      "Epoch 165/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0139\n",
      "Epoch 166/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0100 - val_loss: 0.0170\n",
      "Epoch 167/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0078 - val_loss: 0.0165\n",
      "Epoch 168/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0066 - val_loss: 0.0129\n",
      "Epoch 169/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0083 - val_loss: 0.0142\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A8768DDB80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 67ms/step - loss: 0.0767 - val_loss: 0.0340\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0385 - val_loss: 0.0294\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0304 - val_loss: 0.0406\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0361 - val_loss: 0.0285\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0241 - val_loss: 0.0272\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0301 - val_loss: 0.0269\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0263 - val_loss: 0.0264\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0288 - val_loss: 0.0268\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0287 - val_loss: 0.0257\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0223 - val_loss: 0.0318\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0242 - val_loss: 0.0252\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0270 - val_loss: 0.0249\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0240 - val_loss: 0.0271\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0225 - val_loss: 0.0247\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0238 - val_loss: 0.0262\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0288 - val_loss: 0.0242\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0209 - val_loss: 0.0246\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0219 - val_loss: 0.0297\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0268 - val_loss: 0.0251\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0258 - val_loss: 0.0253\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0350 - val_loss: 0.0250\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0281 - val_loss: 0.0302\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0208 - val_loss: 0.0245\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0192 - val_loss: 0.0259\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0196 - val_loss: 0.0243\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0196 - val_loss: 0.0245\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0284 - val_loss: 0.0302\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0246 - val_loss: 0.0282\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0175 - val_loss: 0.0237\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0241 - val_loss: 0.0235\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0262 - val_loss: 0.0238\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0214 - val_loss: 0.0237\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0214 - val_loss: 0.0316\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0232 - val_loss: 0.0240\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0241 - val_loss: 0.0235\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0180 - val_loss: 0.0240\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0210 - val_loss: 0.0236\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0204 - val_loss: 0.0238\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0257 - val_loss: 0.0233\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0245\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0199 - val_loss: 0.0245\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0202 - val_loss: 0.0242\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0216 - val_loss: 0.0233\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0221 - val_loss: 0.0245\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0239 - val_loss: 0.0231\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0233 - val_loss: 0.0231\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0260 - val_loss: 0.0229\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0196 - val_loss: 0.0240\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0189 - val_loss: 0.0233\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0297 - val_loss: 0.0233\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0237 - val_loss: 0.0297\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0169 - val_loss: 0.0226\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0222 - val_loss: 0.0227\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0216 - val_loss: 0.0233\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0261 - val_loss: 0.0231\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0246 - val_loss: 0.0247\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0234\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0241 - val_loss: 0.0258\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0249 - val_loss: 0.0226\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0176 - val_loss: 0.0223\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0194 - val_loss: 0.0227\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0236 - val_loss: 0.0257\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0213 - val_loss: 0.0220\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0173 - val_loss: 0.0217\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0187 - val_loss: 0.0218\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0198 - val_loss: 0.0219\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0227 - val_loss: 0.0242\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0204 - val_loss: 0.0234\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0162 - val_loss: 0.0215\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0169 - val_loss: 0.0209\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0208 - val_loss: 0.0251\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0145 - val_loss: 0.0211\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0244 - val_loss: 0.0237\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.0225\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.0202\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0160 - val_loss: 0.0200\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0190 - val_loss: 0.0228\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0128 - val_loss: 0.0235\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.0166 - val_loss: 0.0202\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0192 - val_loss: 0.0208\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0155 - val_loss: 0.0199\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0139 - val_loss: 0.0203\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0138 - val_loss: 0.0214\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0171 - val_loss: 0.0197\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0141 - val_loss: 0.0215\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0192 - val_loss: 0.0185\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0126 - val_loss: 0.0188\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0171 - val_loss: 0.0197\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0217 - val_loss: 0.0186\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0138 - val_loss: 0.0187\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0183\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0136 - val_loss: 0.0181\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0206 - val_loss: 0.0198\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0183 - val_loss: 0.0213\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0210 - val_loss: 0.0196\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0239 - val_loss: 0.0240\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0183\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0135 - val_loss: 0.0194\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0149 - val_loss: 0.0188\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0175\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0176\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0160 - val_loss: 0.0180\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0233 - val_loss: 0.0176\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0174\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0141 - val_loss: 0.0181\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0129 - val_loss: 0.0168\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0160 - val_loss: 0.0170\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.0241\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0150 - val_loss: 0.0185\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0167 - val_loss: 0.0215\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.0159\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0102 - val_loss: 0.0164\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0177\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.0156\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0141 - val_loss: 0.0157\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0154 - val_loss: 0.0167\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0155\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0143 - val_loss: 0.0154\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0154 - val_loss: 0.0146\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0154\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0107 - val_loss: 0.0153\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0150\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0149\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0106 - val_loss: 0.0232\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0135 - val_loss: 0.0143\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0109 - val_loss: 0.0153\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0125 - val_loss: 0.0152\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0139\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0135\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0148\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0120\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0090 - val_loss: 0.0123\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0083 - val_loss: 0.0138\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.0117\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0141\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0089 - val_loss: 0.0127\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0078 - val_loss: 0.0119\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0063 - val_loss: 0.0126\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0085 - val_loss: 0.0126\n",
      "Epoch 140/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0062 - val_loss: 0.0119\n",
      "Epoch 141/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0115 - val_loss: 0.0139\n",
      "Epoch 142/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0064 - val_loss: 0.0138\n",
      "Epoch 143/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0060 - val_loss: 0.0144\n",
      "Epoch 144/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0055 - val_loss: 0.0130\n",
      "Epoch 145/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0072 - val_loss: 0.0137\n",
      "Epoch 146/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0072 - val_loss: 0.0127\n",
      "Epoch 147/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0117\n",
      "Epoch 148/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0058 - val_loss: 0.0133\n",
      "Epoch 149/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0064 - val_loss: 0.0119\n",
      "Epoch 150/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0046 - val_loss: 0.0112\n",
      "Epoch 151/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0049 - val_loss: 0.0120\n",
      "Epoch 152/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0055 - val_loss: 0.0121\n",
      "Epoch 153/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0056 - val_loss: 0.0120\n",
      "Epoch 154/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0061 - val_loss: 0.0156\n",
      "Epoch 155/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0051 - val_loss: 0.0116\n",
      "Epoch 156/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0046 - val_loss: 0.0119\n",
      "Epoch 157/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0047 - val_loss: 0.0140\n",
      "Epoch 158/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0037 - val_loss: 0.0142\n",
      "Epoch 159/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0047 - val_loss: 0.0115\n",
      "Epoch 160/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0039 - val_loss: 0.0119\n",
      "Epoch 161/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0040 - val_loss: 0.0103\n",
      "Epoch 162/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0056 - val_loss: 0.0117\n",
      "Epoch 163/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0056 - val_loss: 0.0126\n",
      "Epoch 164/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0038 - val_loss: 0.0117\n",
      "Epoch 165/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0042 - val_loss: 0.0142\n",
      "Epoch 166/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0049 - val_loss: 0.0109\n",
      "Epoch 167/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0034 - val_loss: 0.0116\n",
      "Epoch 168/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0040 - val_loss: 0.0107\n",
      "Epoch 169/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0046 - val_loss: 0.0120\n",
      "Epoch 170/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0054 - val_loss: 0.0120\n",
      "Epoch 171/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0058 - val_loss: 0.0104\n",
      "Epoch 172/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0041 - val_loss: 0.0122\n",
      "Epoch 173/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0031 - val_loss: 0.0117\n",
      "Epoch 174/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0037 - val_loss: 0.0115\n",
      "Epoch 175/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0037 - val_loss: 0.0117\n",
      "Epoch 176/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0031 - val_loss: 0.0113\n",
      "Epoch 177/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.0142\n",
      "Epoch 178/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0032 - val_loss: 0.0127\n",
      "Epoch 179/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0030 - val_loss: 0.0108\n",
      "Epoch 180/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0033 - val_loss: 0.0121\n",
      "Epoch 181/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0031 - val_loss: 0.0109\n",
      "Epoch 182/200\n",
      "25/25 [==============================] - 1s 28ms/step - loss: 0.0027 - val_loss: 0.0126\n",
      "Epoch 183/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0029 - val_loss: 0.0148\n",
      "Epoch 184/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0028 - val_loss: 0.0109\n",
      "Epoch 185/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0029 - val_loss: 0.0153\n",
      "Epoch 186/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0031 - val_loss: 0.0102\n",
      "Epoch 187/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0020 - val_loss: 0.0116\n",
      "Epoch 188/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 0.0129\n",
      "Epoch 189/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0019 - val_loss: 0.0109\n",
      "Epoch 190/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0025 - val_loss: 0.0133\n",
      "Epoch 191/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0020 - val_loss: 0.0116\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A8383304C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 65ms/step - loss: 0.1183 - val_loss: 0.0448\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0374 - val_loss: 0.0402\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0341 - val_loss: 0.0298\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0267 - val_loss: 0.0286\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0262 - val_loss: 0.0287\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0248 - val_loss: 0.0278\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0253 - val_loss: 0.0290\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0216 - val_loss: 0.0268\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0238 - val_loss: 0.0265\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0297 - val_loss: 0.0261\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0229 - val_loss: 0.0318\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0215 - val_loss: 0.0266\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0240 - val_loss: 0.0256\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0269 - val_loss: 0.0329\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0216 - val_loss: 0.0251\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0256 - val_loss: 0.0255\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0355 - val_loss: 0.0264\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0212 - val_loss: 0.0247\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0216 - val_loss: 0.0245\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0217 - val_loss: 0.0243\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0225 - val_loss: 0.0259\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0242 - val_loss: 0.0242\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0194 - val_loss: 0.0242\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0201 - val_loss: 0.0249\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0204 - val_loss: 0.0240\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0224 - val_loss: 0.0265\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0211 - val_loss: 0.0252\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0269 - val_loss: 0.0271\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0211 - val_loss: 0.0237\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0186 - val_loss: 0.0256\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0189 - val_loss: 0.0248\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0231 - val_loss: 0.0245\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0203 - val_loss: 0.0239\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0228 - val_loss: 0.0244\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0177 - val_loss: 0.0248\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0192 - val_loss: 0.0235\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0309 - val_loss: 0.0238\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0188 - val_loss: 0.0236\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0227 - val_loss: 0.0242\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0210 - val_loss: 0.0251\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0232 - val_loss: 0.0305\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0248 - val_loss: 0.0240\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0191 - val_loss: 0.0284\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0243\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0237 - val_loss: 0.0232\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0217 - val_loss: 0.0231\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0209 - val_loss: 0.0235\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0261 - val_loss: 0.0294\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0220 - val_loss: 0.0244\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0218 - val_loss: 0.0229\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0228\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0242 - val_loss: 0.0242\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0186 - val_loss: 0.0228\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0246 - val_loss: 0.0268\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0197 - val_loss: 0.0228\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0263 - val_loss: 0.0251\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0208 - val_loss: 0.0228\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0235 - val_loss: 0.0241\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0204 - val_loss: 0.0228\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0236\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0207 - val_loss: 0.0231\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0232 - val_loss: 0.0251\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0191 - val_loss: 0.0235\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0233\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0236\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0287 - val_loss: 0.0253\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A8846DD550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 59ms/step - loss: 0.0799 - val_loss: 0.0387\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0283 - val_loss: 0.0314\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0276 - val_loss: 0.0292\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0288 - val_loss: 0.0287\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0271 - val_loss: 0.0320\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0338 - val_loss: 0.0286\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0268 - val_loss: 0.0288\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0295 - val_loss: 0.0268\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0307 - val_loss: 0.0264\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0321 - val_loss: 0.0264\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0304 - val_loss: 0.0291\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0290 - val_loss: 0.0267\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0217 - val_loss: 0.0270\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0282 - val_loss: 0.0261\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0294 - val_loss: 0.0368\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0219 - val_loss: 0.0257\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0232 - val_loss: 0.0262\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0231 - val_loss: 0.0283\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0223 - val_loss: 0.0245\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0226 - val_loss: 0.0248\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0336 - val_loss: 0.0248\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0238 - val_loss: 0.0242\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0198 - val_loss: 0.0256\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0181 - val_loss: 0.0242\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0259 - val_loss: 0.0242\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0214 - val_loss: 0.0241\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0219 - val_loss: 0.0252\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0207 - val_loss: 0.0247\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0220 - val_loss: 0.0241\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0183 - val_loss: 0.0262\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0171 - val_loss: 0.0241\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0249 - val_loss: 0.0261\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0271\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0285 - val_loss: 0.0255\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0200 - val_loss: 0.0237\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0194 - val_loss: 0.0257\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0233 - val_loss: 0.0240\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0249 - val_loss: 0.0318\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0209 - val_loss: 0.0234\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0254 - val_loss: 0.0239\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0202 - val_loss: 0.0240\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0234 - val_loss: 0.0276\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0197 - val_loss: 0.0242\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0208 - val_loss: 0.0259\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0276 - val_loss: 0.0259\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0202 - val_loss: 0.0233\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0216 - val_loss: 0.0240\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0227 - val_loss: 0.0240\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0203 - val_loss: 0.0230\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0191 - val_loss: 0.0254\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0232 - val_loss: 0.0259\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0227 - val_loss: 0.0246\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0205 - val_loss: 0.0228\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0169 - val_loss: 0.0226\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0219 - val_loss: 0.0249\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0178 - val_loss: 0.0233\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0232\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0194 - val_loss: 0.0270\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0234 - val_loss: 0.0224\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0190 - val_loss: 0.0229\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0209 - val_loss: 0.0248\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0198 - val_loss: 0.0222\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0296 - val_loss: 0.0256\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0234 - val_loss: 0.0244\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0207 - val_loss: 0.0220\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0172 - val_loss: 0.0238\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0230 - val_loss: 0.0218\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0192 - val_loss: 0.0220\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0240 - val_loss: 0.0217\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0178 - val_loss: 0.0215\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0157 - val_loss: 0.0232\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0241 - val_loss: 0.0238\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0292 - val_loss: 0.0231\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0151 - val_loss: 0.0220\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0172 - val_loss: 0.0207\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0194 - val_loss: 0.0235\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0258 - val_loss: 0.0228\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0238\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0230 - val_loss: 0.0205\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.0217 - val_loss: 0.0206\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0250 - val_loss: 0.0196\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0201 - val_loss: 0.0205\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0192\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0194\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0182 - val_loss: 0.0202\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0234 - val_loss: 0.0189\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0187 - val_loss: 0.0187\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0128 - val_loss: 0.0201\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0240 - val_loss: 0.0203\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0193 - val_loss: 0.0229\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0177 - val_loss: 0.0199\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0207 - val_loss: 0.0212\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0171 - val_loss: 0.0189\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0143 - val_loss: 0.0186\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0189\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0176 - val_loss: 0.0203\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.0176\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0180 - val_loss: 0.0180\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0157 - val_loss: 0.0186\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.0188\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0167 - val_loss: 0.0164\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0178\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0186 - val_loss: 0.0191\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0176\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0141 - val_loss: 0.0172\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.0167\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0143 - val_loss: 0.0190\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0176 - val_loss: 0.0168\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0150 - val_loss: 0.0227\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0185 - val_loss: 0.0195\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.0167\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0149 - val_loss: 0.0165\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0162\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0191\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0123 - val_loss: 0.0159\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0139 - val_loss: 0.0160\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0168\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0156 - val_loss: 0.0147\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.0151\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0162\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0149\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0158\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0132 - val_loss: 0.0160\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0144\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0149\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0157\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0156\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0160\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0143\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0140\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0124 - val_loss: 0.0137\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0090 - val_loss: 0.0147\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0125 - val_loss: 0.0140\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0145\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0084 - val_loss: 0.0143\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0100 - val_loss: 0.0153\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0080 - val_loss: 0.0145\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0155\n",
      "Epoch 140/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0166\n",
      "Epoch 141/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0079 - val_loss: 0.0140\n",
      "Epoch 142/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0142\n",
      "Epoch 143/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0060 - val_loss: 0.0147\n",
      "Epoch 144/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0080 - val_loss: 0.0144\n",
      "Epoch 145/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0064 - val_loss: 0.0163\n",
      "Epoch 146/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0077 - val_loss: 0.0151\n",
      "Epoch 147/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0136\n",
      "Epoch 148/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0142\n",
      "Epoch 149/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0075 - val_loss: 0.0140\n",
      "Epoch 150/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0055 - val_loss: 0.0141\n",
      "Epoch 151/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0079 - val_loss: 0.0155\n",
      "Epoch 152/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0144\n",
      "Epoch 153/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0058 - val_loss: 0.0156\n",
      "Epoch 154/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0061 - val_loss: 0.0190\n",
      "Epoch 155/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0080 - val_loss: 0.0143\n",
      "Epoch 156/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0057 - val_loss: 0.0146\n",
      "Epoch 157/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0045 - val_loss: 0.0137\n",
      "Epoch 158/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0078 - val_loss: 0.0172\n",
      "Epoch 159/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0052 - val_loss: 0.0155\n",
      "Epoch 160/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0050 - val_loss: 0.0145\n",
      "Epoch 161/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0067 - val_loss: 0.0171\n",
      "Epoch 162/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0069 - val_loss: 0.0154\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A86C506280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 34ms/step - loss: 0.0851 - val_loss: 0.0418\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0291 - val_loss: 0.0320\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0237 - val_loss: 0.0321\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0285 - val_loss: 0.0283\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0331 - val_loss: 0.0312\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0259 - val_loss: 0.0271\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0288 - val_loss: 0.0311\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0229 - val_loss: 0.0276\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.0260 - val_loss: 0.0261\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0281 - val_loss: 0.0323\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0354 - val_loss: 0.0331\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0225 - val_loss: 0.0254\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0253 - val_loss: 0.0252\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0217 - val_loss: 0.0249\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0278 - val_loss: 0.0331\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0267 - val_loss: 0.0255\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0213 - val_loss: 0.0267\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0281 - val_loss: 0.0249\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0316 - val_loss: 0.0243\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0201 - val_loss: 0.0241\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0226 - val_loss: 0.0248\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0252 - val_loss: 0.0251\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0215 - val_loss: 0.0256\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0246 - val_loss: 0.0253\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0294 - val_loss: 0.0278\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0193 - val_loss: 0.0239\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0271 - val_loss: 0.0267\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0188 - val_loss: 0.0237\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0246 - val_loss: 0.0261\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0314 - val_loss: 0.0249\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0219 - val_loss: 0.0254\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0240 - val_loss: 0.0241\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0225 - val_loss: 0.0256\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0221 - val_loss: 0.0265\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0205 - val_loss: 0.0248\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0232 - val_loss: 0.0239\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0234 - val_loss: 0.0299\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0231 - val_loss: 0.0236\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0218 - val_loss: 0.0249\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0263 - val_loss: 0.0240\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0204 - val_loss: 0.0249\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0225 - val_loss: 0.0234\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0225 - val_loss: 0.0235\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0259 - val_loss: 0.0232\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0200 - val_loss: 0.0257\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0205 - val_loss: 0.0236\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0237 - val_loss: 0.0228\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0195 - val_loss: 0.0231\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0206 - val_loss: 0.0268\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0240 - val_loss: 0.0229\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0193 - val_loss: 0.0271\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0197 - val_loss: 0.0231\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0206 - val_loss: 0.0230\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0205 - val_loss: 0.0284\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0285 - val_loss: 0.0232\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0216 - val_loss: 0.0228\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0180 - val_loss: 0.0226\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0234 - val_loss: 0.0240\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0212 - val_loss: 0.0218\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0149 - val_loss: 0.0263\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0150 - val_loss: 0.0227\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0189 - val_loss: 0.0230\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0260 - val_loss: 0.0239\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0171 - val_loss: 0.0212\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0171 - val_loss: 0.0222\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0237 - val_loss: 0.0221\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0276\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0214 - val_loss: 0.0209\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0151 - val_loss: 0.0226\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0200 - val_loss: 0.0211\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0187 - val_loss: 0.0210\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0197 - val_loss: 0.0216\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0194 - val_loss: 0.0205\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0218 - val_loss: 0.0208\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0187 - val_loss: 0.0199\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0132 - val_loss: 0.0199\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0155 - val_loss: 0.0210\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0188 - val_loss: 0.0202\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0215\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0210 - val_loss: 0.0203\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0188\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0126 - val_loss: 0.0274\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0185 - val_loss: 0.0190\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0172 - val_loss: 0.0202\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0224 - val_loss: 0.0222\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0179 - val_loss: 0.0200\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0135 - val_loss: 0.0186\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0188\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0187 - val_loss: 0.0190\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0147 - val_loss: 0.0185\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0169 - val_loss: 0.0183\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.0187 - val_loss: 0.0184\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0138 - val_loss: 0.0209\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0178 - val_loss: 0.0202\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0114 - val_loss: 0.0202\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0177\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0176 - val_loss: 0.0181\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0204 - val_loss: 0.0200\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0106 - val_loss: 0.0182\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0177 - val_loss: 0.0198\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0141 - val_loss: 0.0182\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0189 - val_loss: 0.0183\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0173 - val_loss: 0.0186\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0174\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0139 - val_loss: 0.0178\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0138 - val_loss: 0.0168\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0130 - val_loss: 0.0176\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0167\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0127 - val_loss: 0.0171\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0146 - val_loss: 0.0169\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0174\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0149 - val_loss: 0.0165\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0164\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0136 - val_loss: 0.0180\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0104 - val_loss: 0.0164\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0135 - val_loss: 0.0164\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0114 - val_loss: 0.0159\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0189\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0125 - val_loss: 0.0178\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0193\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0145\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0153\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0095 - val_loss: 0.0172\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0154\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.0166\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0207\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0107 - val_loss: 0.0165\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0157\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0136\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.0145\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0081 - val_loss: 0.0164\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.0143\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0136\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0089 - val_loss: 0.0150\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0071 - val_loss: 0.0128\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0066 - val_loss: 0.0134\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0079 - val_loss: 0.0138\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0185\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0126\n",
      "Epoch 140/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0145\n",
      "Epoch 141/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0132\n",
      "Epoch 142/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0076 - val_loss: 0.0144\n",
      "Epoch 143/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0068 - val_loss: 0.0126\n",
      "Epoch 144/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0102 - val_loss: 0.0151\n",
      "Epoch 145/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0057 - val_loss: 0.0146\n",
      "Epoch 146/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0050 - val_loss: 0.0186\n",
      "Epoch 147/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0066 - val_loss: 0.0155\n",
      "Epoch 148/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0068 - val_loss: 0.0151\n",
      "Epoch 149/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0079 - val_loss: 0.0142\n",
      "Epoch 150/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0048 - val_loss: 0.0161\n",
      "Epoch 151/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0063 - val_loss: 0.0151\n",
      "Epoch 152/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.0173\n",
      "Epoch 153/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0054 - val_loss: 0.0159\n",
      "Epoch 154/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0062 - val_loss: 0.0134\n",
      "Epoch 155/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0056 - val_loss: 0.0171\n",
      "Epoch 156/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0046 - val_loss: 0.0149\n",
      "Epoch 157/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0072 - val_loss: 0.0117\n",
      "Epoch 158/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0059 - val_loss: 0.0148\n",
      "Epoch 159/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0050 - val_loss: 0.0135\n",
      "Epoch 160/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0048 - val_loss: 0.0141\n",
      "Epoch 161/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0051 - val_loss: 0.0171\n",
      "Epoch 162/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0042 - val_loss: 0.0126\n",
      "Epoch 163/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0039 - val_loss: 0.0131\n",
      "Epoch 164/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0046 - val_loss: 0.0175\n",
      "Epoch 165/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0040 - val_loss: 0.0156\n",
      "Epoch 166/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0048 - val_loss: 0.0199\n",
      "Epoch 167/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0034 - val_loss: 0.0147\n",
      "Epoch 168/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0102 - val_loss: 0.0208\n",
      "Epoch 169/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0055 - val_loss: 0.0154\n",
      "Epoch 170/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0029 - val_loss: 0.0163\n",
      "Epoch 171/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0155\n",
      "Epoch 172/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0027 - val_loss: 0.0163\n",
      "Epoch 173/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0029 - val_loss: 0.0148\n",
      "Epoch 174/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0034 - val_loss: 0.0144\n",
      "Epoch 175/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0031 - val_loss: 0.0158\n",
      "Epoch 176/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0030 - val_loss: 0.0153\n",
      "Epoch 177/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0030 - val_loss: 0.0159\n",
      "Epoch 178/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0031 - val_loss: 0.0169\n",
      "Epoch 179/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0024 - val_loss: 0.0139\n",
      "Epoch 180/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0044 - val_loss: 0.0135\n",
      "Epoch 181/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0031 - val_loss: 0.0174\n",
      "Epoch 182/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0026 - val_loss: 0.0153\n",
      "Epoch 183/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0043 - val_loss: 0.0163\n",
      "Epoch 184/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0026 - val_loss: 0.0174\n",
      "Epoch 185/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0019 - val_loss: 0.0173\n",
      "Epoch 186/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0032 - val_loss: 0.0136\n",
      "Epoch 187/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0032 - val_loss: 0.0168\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A88484D3A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 56ms/step - loss: 0.1216 - val_loss: 0.0386\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0335 - val_loss: 0.0336\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0274 - val_loss: 0.0303\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0296 - val_loss: 0.0291\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0287 - val_loss: 0.0309\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0250 - val_loss: 0.0289\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0323 - val_loss: 0.0369\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0282 - val_loss: 0.0272\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0294 - val_loss: 0.0293\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0358 - val_loss: 0.0324\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0239 - val_loss: 0.0259\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0224 - val_loss: 0.0273\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0234 - val_loss: 0.0275\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0211 - val_loss: 0.0287\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0310 - val_loss: 0.0261\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0231 - val_loss: 0.0251\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0210 - val_loss: 0.0319\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0234 - val_loss: 0.0244\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0344 - val_loss: 0.0244\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0212 - val_loss: 0.0244\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0200 - val_loss: 0.0250\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0269 - val_loss: 0.0250\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0252\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0280 - val_loss: 0.0261\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0211 - val_loss: 0.0242\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0300 - val_loss: 0.0241\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0251 - val_loss: 0.0241\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0214 - val_loss: 0.0239\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0233 - val_loss: 0.0258\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0221 - val_loss: 0.0245\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0194 - val_loss: 0.0238\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0214 - val_loss: 0.0245\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0189 - val_loss: 0.0239\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0192 - val_loss: 0.0343\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0205 - val_loss: 0.0251\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0249 - val_loss: 0.0255\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0198 - val_loss: 0.0261\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0242 - val_loss: 0.0277\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0233 - val_loss: 0.0247\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0199 - val_loss: 0.0237\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0216 - val_loss: 0.0238\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0262 - val_loss: 0.0239\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0220 - val_loss: 0.0233\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0215 - val_loss: 0.0244\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0204 - val_loss: 0.0236\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0187 - val_loss: 0.0329\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0226 - val_loss: 0.0233\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0204 - val_loss: 0.0233\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0213 - val_loss: 0.0238\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0189 - val_loss: 0.0253\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0218 - val_loss: 0.0231\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0204 - val_loss: 0.0230\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0168 - val_loss: 0.0227\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0228 - val_loss: 0.0272\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0213 - val_loss: 0.0228\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0174 - val_loss: 0.0231\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0205 - val_loss: 0.0228\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0205 - val_loss: 0.0224\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0225 - val_loss: 0.0225\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0289 - val_loss: 0.0236\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0151 - val_loss: 0.0222\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0325 - val_loss: 0.0221\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0191 - val_loss: 0.0242\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0195 - val_loss: 0.0238\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0270 - val_loss: 0.0220\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0181 - val_loss: 0.0222\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0267 - val_loss: 0.0274\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0162 - val_loss: 0.0221\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0195 - val_loss: 0.0226\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0204 - val_loss: 0.0228\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0219 - val_loss: 0.0216\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0213\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0222 - val_loss: 0.0214\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0183 - val_loss: 0.0226\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0190 - val_loss: 0.0210\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0208\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0179 - val_loss: 0.0213\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0260 - val_loss: 0.0215\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0188 - val_loss: 0.0246\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0187 - val_loss: 0.0210\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0205 - val_loss: 0.0202\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0191 - val_loss: 0.0200\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0199\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.0197\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0208 - val_loss: 0.0193\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0174 - val_loss: 0.0198\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0195\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0215 - val_loss: 0.0207\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0209\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0155 - val_loss: 0.0183\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.0182\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0212\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0177\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0135 - val_loss: 0.0201\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0140 - val_loss: 0.0192\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.0172 - val_loss: 0.0197\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0239 - val_loss: 0.0179\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0132 - val_loss: 0.0191\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0182 - val_loss: 0.0172\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0154 - val_loss: 0.0174\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0203 - val_loss: 0.0167\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.0158\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0172 - val_loss: 0.0153\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0124 - val_loss: 0.0164\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0143 - val_loss: 0.0158\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0187\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0190\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0125 - val_loss: 0.0176\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.0147\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0168\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0107 - val_loss: 0.0136\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0205\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0126 - val_loss: 0.0140\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0089 - val_loss: 0.0161\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0132\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0158\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0195\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0147\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0148\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0084 - val_loss: 0.0155\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0085 - val_loss: 0.0123\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0083 - val_loss: 0.0140\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0064 - val_loss: 0.0139\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0072 - val_loss: 0.0155\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0146\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0072 - val_loss: 0.0131\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0059 - val_loss: 0.0154\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0081 - val_loss: 0.0144\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0066 - val_loss: 0.0112\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0073 - val_loss: 0.0128\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0055 - val_loss: 0.0120\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0070 - val_loss: 0.0127\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0065 - val_loss: 0.0140\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0052 - val_loss: 0.0146\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0107\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0075 - val_loss: 0.0121\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0059 - val_loss: 0.0113\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0056 - val_loss: 0.0121\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0058 - val_loss: 0.0126\n",
      "Epoch 140/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0062 - val_loss: 0.0133\n",
      "Epoch 141/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0051 - val_loss: 0.0151\n",
      "Epoch 142/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0077 - val_loss: 0.0137\n",
      "Epoch 143/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0062 - val_loss: 0.0147\n",
      "Epoch 144/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0053 - val_loss: 0.0117\n",
      "Epoch 145/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0044 - val_loss: 0.0115\n",
      "Epoch 146/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0049 - val_loss: 0.0130\n",
      "Epoch 147/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0053 - val_loss: 0.0129\n",
      "Epoch 148/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0045 - val_loss: 0.0134\n",
      "Epoch 149/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0064 - val_loss: 0.0159\n",
      "Epoch 150/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0040 - val_loss: 0.0155\n",
      "Epoch 151/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0064 - val_loss: 0.0130\n",
      "Epoch 152/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0062 - val_loss: 0.0141\n",
      "Epoch 153/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0036 - val_loss: 0.0126\n",
      "Epoch 154/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0046 - val_loss: 0.0124\n",
      "Epoch 155/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0054 - val_loss: 0.0115\n",
      "Epoch 156/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0060 - val_loss: 0.0126\n",
      "Epoch 157/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.0133\n",
      "Epoch 158/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0039 - val_loss: 0.0116\n",
      "Epoch 159/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0048 - val_loss: 0.0134\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A887E85CA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 35ms/step - loss: 0.0634 - val_loss: 0.0453\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0474 - val_loss: 0.0345\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0310 - val_loss: 0.0318\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0362 - val_loss: 0.0275\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0275 - val_loss: 0.0271\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0229 - val_loss: 0.0280\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0226 - val_loss: 0.0271\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0221 - val_loss: 0.0263\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.0319 - val_loss: 0.0258\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0236 - val_loss: 0.0260\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0198 - val_loss: 0.0299\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0225 - val_loss: 0.0250\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0243 - val_loss: 0.0250\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0212 - val_loss: 0.0278\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0241 - val_loss: 0.0269\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0193 - val_loss: 0.0268\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0178 - val_loss: 0.0248\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0176 - val_loss: 0.0246\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0237 - val_loss: 0.0256\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0289 - val_loss: 0.0265\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0199 - val_loss: 0.0243\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0258 - val_loss: 0.0241\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0287 - val_loss: 0.0254\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0215 - val_loss: 0.0264\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0218 - val_loss: 0.0240\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0233 - val_loss: 0.0245\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0248 - val_loss: 0.0275\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0181 - val_loss: 0.0266\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0255 - val_loss: 0.0238\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0211 - val_loss: 0.0253\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0228 - val_loss: 0.0237\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0232 - val_loss: 0.0242\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0216 - val_loss: 0.0235\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0246 - val_loss: 0.0257\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0203 - val_loss: 0.0258\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0247 - val_loss: 0.0242\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0306 - val_loss: 0.0250\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0211 - val_loss: 0.0237\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0261 - val_loss: 0.0322\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0225 - val_loss: 0.0240\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0244 - val_loss: 0.0239\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0191 - val_loss: 0.0232\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0210 - val_loss: 0.0267\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0224 - val_loss: 0.0236\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0169 - val_loss: 0.0230\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0230 - val_loss: 0.0253\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0247 - val_loss: 0.0229\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0280 - val_loss: 0.0256\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0225 - val_loss: 0.0321\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0213 - val_loss: 0.0226\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0216 - val_loss: 0.0231\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0209 - val_loss: 0.0236\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0184 - val_loss: 0.0250\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0291 - val_loss: 0.0242\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0209 - val_loss: 0.0232\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0205 - val_loss: 0.0239\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0224 - val_loss: 0.0289\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0190 - val_loss: 0.0232\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0182 - val_loss: 0.0222\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0192 - val_loss: 0.0220\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0218\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0208 - val_loss: 0.0236\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0163 - val_loss: 0.0231\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0172 - val_loss: 0.0251\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0230 - val_loss: 0.0240\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0160 - val_loss: 0.0219\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0201 - val_loss: 0.0219\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0186 - val_loss: 0.0225\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0226 - val_loss: 0.0211\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0252 - val_loss: 0.0216\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0156 - val_loss: 0.0213\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0223 - val_loss: 0.0214\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0206\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0239 - val_loss: 0.0204\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0204 - val_loss: 0.0203\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0187 - val_loss: 0.0207\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0212 - val_loss: 0.0214\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0210\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0182 - val_loss: 0.0203\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0192 - val_loss: 0.0201\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0206\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0193\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.0189\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0164 - val_loss: 0.0190\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0153 - val_loss: 0.0187\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0176 - val_loss: 0.0219\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0212 - val_loss: 0.0220\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0168 - val_loss: 0.0202\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0183 - val_loss: 0.0188\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0126 - val_loss: 0.0207\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0179 - val_loss: 0.0215\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0174 - val_loss: 0.0186\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0115 - val_loss: 0.0186\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0133 - val_loss: 0.0187\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0131 - val_loss: 0.0186\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.0169\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0211\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0192\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0160 - val_loss: 0.0166\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.0171\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.0187\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0221 - val_loss: 0.0175\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0156\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0145 - val_loss: 0.0180\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0167\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0154\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0104 - val_loss: 0.0151\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0159\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0141 - val_loss: 0.0155\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0086 - val_loss: 0.0159\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.0160\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.0113 - val_loss: 0.0146\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0148\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0120 - val_loss: 0.0143\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0160\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0168\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0100 - val_loss: 0.0158\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0096 - val_loss: 0.0163\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0172\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0164\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0144 - val_loss: 0.0159\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0089 - val_loss: 0.0153\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0064 - val_loss: 0.0149\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0064 - val_loss: 0.0171\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0151\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0064 - val_loss: 0.0150\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0081 - val_loss: 0.0152\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0170\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0069 - val_loss: 0.0174\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0062 - val_loss: 0.0185\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0067 - val_loss: 0.0153\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0061 - val_loss: 0.0167\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0040 - val_loss: 0.0189\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0063 - val_loss: 0.0202\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0075 - val_loss: 0.0201\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0062 - val_loss: 0.0163\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0057 - val_loss: 0.0211\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0054 - val_loss: 0.0158\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0061 - val_loss: 0.0185\n",
      "Epoch 140/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0040 - val_loss: 0.0191\n",
      "Epoch 141/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0065 - val_loss: 0.0196\n",
      "Epoch 142/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0072 - val_loss: 0.0146\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A8380C70D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 35ms/step - loss: 0.0491 - val_loss: 0.0317\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0267 - val_loss: 0.0285\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0359 - val_loss: 0.0346\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0297 - val_loss: 0.0327\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0256 - val_loss: 0.0269\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0345 - val_loss: 0.0294\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0236 - val_loss: 0.0297\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0299 - val_loss: 0.0261\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0276 - val_loss: 0.0260\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0247 - val_loss: 0.0262\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0210 - val_loss: 0.0253\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0238 - val_loss: 0.0265\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0325 - val_loss: 0.0263\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0279 - val_loss: 0.0284\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0180 - val_loss: 0.0246\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0236 - val_loss: 0.0246\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0235 - val_loss: 0.0278\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0230 - val_loss: 0.0243\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0203 - val_loss: 0.0244\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0204 - val_loss: 0.0243\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0208 - val_loss: 0.0247\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0225 - val_loss: 0.0296\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0223 - val_loss: 0.0287\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0292 - val_loss: 0.0245\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0223 - val_loss: 0.0244\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0296 - val_loss: 0.0239\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0191 - val_loss: 0.0243\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0225 - val_loss: 0.0240\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0201 - val_loss: 0.0247\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0265 - val_loss: 0.0237\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0250 - val_loss: 0.0247\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0230 - val_loss: 0.0296\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0328 - val_loss: 0.0254\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0219 - val_loss: 0.0236\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0231 - val_loss: 0.0242\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0214 - val_loss: 0.0234\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0224 - val_loss: 0.0243\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0353 - val_loss: 0.0236\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0241 - val_loss: 0.0245\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0180 - val_loss: 0.0234\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0216 - val_loss: 0.0235\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0183 - val_loss: 0.0252\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0244 - val_loss: 0.0243\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0220 - val_loss: 0.0230\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0157 - val_loss: 0.0233\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0191 - val_loss: 0.0253\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0220 - val_loss: 0.0229\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0218 - val_loss: 0.0247\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 1s 28ms/step - loss: 0.0318 - val_loss: 0.0230\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0207 - val_loss: 0.0244\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0236\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0182 - val_loss: 0.0235\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0195 - val_loss: 0.0233\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0229 - val_loss: 0.0222\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0275 - val_loss: 0.0222\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0181 - val_loss: 0.0225\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0200 - val_loss: 0.0226\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0267 - val_loss: 0.0291\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0179 - val_loss: 0.0222\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0245 - val_loss: 0.0217\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0246 - val_loss: 0.0216\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0199 - val_loss: 0.0217\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0240 - val_loss: 0.0284\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0213 - val_loss: 0.0262\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0182 - val_loss: 0.0225\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0178 - val_loss: 0.0223\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0187 - val_loss: 0.0216\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0180 - val_loss: 0.0218\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0209\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0231 - val_loss: 0.0224\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0157 - val_loss: 0.0206\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0136 - val_loss: 0.0216\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.0206\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0191 - val_loss: 0.0200\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0201\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0187 - val_loss: 0.0233\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0128 - val_loss: 0.0199\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0162 - val_loss: 0.0230\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.0210\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0157 - val_loss: 0.0201\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0177 - val_loss: 0.0193\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0138 - val_loss: 0.0189\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0191 - val_loss: 0.0225\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0178 - val_loss: 0.0186\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0196\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0196 - val_loss: 0.0183\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0167 - val_loss: 0.0182\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0291 - val_loss: 0.0221\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0169 - val_loss: 0.0219\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0187 - val_loss: 0.0188\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0225 - val_loss: 0.0177\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.0207\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0204 - val_loss: 0.0171\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0154 - val_loss: 0.0167\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0190 - val_loss: 0.0186\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0157 - val_loss: 0.0206\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0140 - val_loss: 0.0170\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0201 - val_loss: 0.0162\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.0210\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.0161\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0141 - val_loss: 0.0163\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0107 - val_loss: 0.0172\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0140 - val_loss: 0.0191\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0141 - val_loss: 0.0159\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0156\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0156\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0157\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0173\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0106 - val_loss: 0.0186\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0169\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0166\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0104 - val_loss: 0.0157\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0163\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0175\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0107 - val_loss: 0.0170\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0172\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0179\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0076 - val_loss: 0.0183\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0206\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0164\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0049 - val_loss: 0.0138\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0063 - val_loss: 0.0236\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0075 - val_loss: 0.0147\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0153\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0057 - val_loss: 0.0184\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0081 - val_loss: 0.0193\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0045 - val_loss: 0.0155\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0046 - val_loss: 0.0188\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0050 - val_loss: 0.0173\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0053 - val_loss: 0.0184\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0058 - val_loss: 0.0154\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0043 - val_loss: 0.0204\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0051 - val_loss: 0.0133\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0058 - val_loss: 0.0200\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0051 - val_loss: 0.0232\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0039 - val_loss: 0.0194\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0051 - val_loss: 0.0219\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0043 - val_loss: 0.0205\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0043 - val_loss: 0.0161\n",
      "Epoch 140/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0033 - val_loss: 0.0201\n",
      "Epoch 141/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0052 - val_loss: 0.0200\n",
      "Epoch 142/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.0170\n",
      "Epoch 143/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0038 - val_loss: 0.0213\n",
      "Epoch 144/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0047 - val_loss: 0.0181\n",
      "Epoch 145/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0046 - val_loss: 0.0213\n",
      "Epoch 146/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0037 - val_loss: 0.0225\n",
      "Epoch 147/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0034 - val_loss: 0.0220\n",
      "Epoch 148/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0033 - val_loss: 0.0233\n",
      "Epoch 149/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0040 - val_loss: 0.0222\n",
      "Epoch 150/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0208\n",
      "Epoch 151/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0028 - val_loss: 0.0201\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A871357700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 58ms/step - loss: 0.0999 - val_loss: 0.0326\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0309 - val_loss: 0.0291\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0353 - val_loss: 0.0286\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0290 - val_loss: 0.0316\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0318 - val_loss: 0.0278\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0254 - val_loss: 0.0273\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0278 - val_loss: 0.0269\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0253 - val_loss: 0.0274\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0250 - val_loss: 0.0271\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0268 - val_loss: 0.0268\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0249 - val_loss: 0.0288\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0185 - val_loss: 0.0253\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0266 - val_loss: 0.0298\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0344 - val_loss: 0.0262\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0295\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0297 - val_loss: 0.0278\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0277 - val_loss: 0.0273\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0289 - val_loss: 0.0340\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0260 - val_loss: 0.0271\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0192 - val_loss: 0.0261\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0253 - val_loss: 0.0258\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0220 - val_loss: 0.0265\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0238 - val_loss: 0.0289\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0359 - val_loss: 0.0255\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0211 - val_loss: 0.0251\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0241 - val_loss: 0.0241\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0210 - val_loss: 0.0250\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0218 - val_loss: 0.0248\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0183 - val_loss: 0.0276\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0302 - val_loss: 0.0263\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0210 - val_loss: 0.0238\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0232 - val_loss: 0.0234\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0205 - val_loss: 0.0236\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0248 - val_loss: 0.0387\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0300 - val_loss: 0.0241\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0245 - val_loss: 0.0238\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0215 - val_loss: 0.0235\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0229 - val_loss: 0.0233\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0196 - val_loss: 0.0234\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0212 - val_loss: 0.0252\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0268 - val_loss: 0.0233\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0173 - val_loss: 0.0231\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0275 - val_loss: 0.0231\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0241 - val_loss: 0.0236\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0176 - val_loss: 0.0235\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0207 - val_loss: 0.0238\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0190 - val_loss: 0.0232\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0187 - val_loss: 0.0245\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0226 - val_loss: 0.0335\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0314 - val_loss: 0.0225\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0178 - val_loss: 0.0240\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0181 - val_loss: 0.0247\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0254 - val_loss: 0.0224\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0174 - val_loss: 0.0232\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0256\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0199 - val_loss: 0.0280\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0311 - val_loss: 0.0224\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0243 - val_loss: 0.0223\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0196 - val_loss: 0.0221\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0182 - val_loss: 0.0224\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0186 - val_loss: 0.0262\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0216 - val_loss: 0.0215\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0218 - val_loss: 0.0245\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0222\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0208 - val_loss: 0.0225\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0208 - val_loss: 0.0215\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0172 - val_loss: 0.0264\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0192 - val_loss: 0.0229\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0206 - val_loss: 0.0213\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0258 - val_loss: 0.0227\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0181 - val_loss: 0.0212\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0149 - val_loss: 0.0220\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0172 - val_loss: 0.0202\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0296 - val_loss: 0.0209\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0222 - val_loss: 0.0210\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0189 - val_loss: 0.0227\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0199\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0199 - val_loss: 0.0220\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0185 - val_loss: 0.0200\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0208 - val_loss: 0.0201\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0219 - val_loss: 0.0192\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0208\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0186 - val_loss: 0.0190\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0159 - val_loss: 0.0195\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0173 - val_loss: 0.0191\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.0131 - val_loss: 0.0233\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0181 - val_loss: 0.0194\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0162 - val_loss: 0.0183\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0170 - val_loss: 0.0194\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0196\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0181\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0186\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.0190\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0130 - val_loss: 0.0185\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0159 - val_loss: 0.0197\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0139 - val_loss: 0.0188\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0169\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0178\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0163 - val_loss: 0.0179\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0138 - val_loss: 0.0209\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0140 - val_loss: 0.0170\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0179\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0185\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0156 - val_loss: 0.0167\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0172\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.0163\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0216 - val_loss: 0.0174\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0134 - val_loss: 0.0165\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.0157\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0145 - val_loss: 0.0173\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0149 - val_loss: 0.0145\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0121 - val_loss: 0.0167\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0135 - val_loss: 0.0149\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0132 - val_loss: 0.0202\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0175\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0139 - val_loss: 0.0161\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0164\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0152\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0176\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0140 - val_loss: 0.0145\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0184\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0123 - val_loss: 0.0159\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0174\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0193\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0161\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0132 - val_loss: 0.0202\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0174\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0071 - val_loss: 0.0182\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0166\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0164\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0173\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0087 - val_loss: 0.0153\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0071 - val_loss: 0.0189\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0176\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0191\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0081 - val_loss: 0.0172\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0182\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0114 - val_loss: 0.0142\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0107 - val_loss: 0.0138\n",
      "Epoch 140/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0077 - val_loss: 0.0143\n",
      "Epoch 141/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0075 - val_loss: 0.0152\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A881109F70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 35ms/step - loss: 0.0580 - val_loss: 0.0297\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0378 - val_loss: 0.0312\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0296 - val_loss: 0.0327\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0302 - val_loss: 0.0277\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0275 - val_loss: 0.0271\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0224 - val_loss: 0.0267\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0243 - val_loss: 0.0298\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0325 - val_loss: 0.0290\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0340 - val_loss: 0.0457\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0280 - val_loss: 0.0300\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0296 - val_loss: 0.0254\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0235 - val_loss: 0.0317\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0343 - val_loss: 0.0260\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0271 - val_loss: 0.0427\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0323 - val_loss: 0.0254\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0250 - val_loss: 0.0242\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0244 - val_loss: 0.0245\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 1s 28ms/step - loss: 0.0229 - val_loss: 0.0242\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0249 - val_loss: 0.0250\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0211 - val_loss: 0.0285\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0332 - val_loss: 0.0294\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0197 - val_loss: 0.0239\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0232 - val_loss: 0.0245\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0232 - val_loss: 0.0267\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0202 - val_loss: 0.0241\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0273 - val_loss: 0.0377\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0210 - val_loss: 0.0242\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0169 - val_loss: 0.0239\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0302 - val_loss: 0.0280\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0257 - val_loss: 0.0262\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0237 - val_loss: 0.0251\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0252 - val_loss: 0.0239\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0211 - val_loss: 0.0237\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0248 - val_loss: 0.0249\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0193 - val_loss: 0.0235\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.0279\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0269 - val_loss: 0.0269\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0195 - val_loss: 0.0233\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0199 - val_loss: 0.0235\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0253 - val_loss: 0.0230\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0229 - val_loss: 0.0230\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0220 - val_loss: 0.0239\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0182 - val_loss: 0.0240\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0223 - val_loss: 0.0300\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0200 - val_loss: 0.0235\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0209 - val_loss: 0.0228\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0206 - val_loss: 0.0230\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0289 - val_loss: 0.0228\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0258 - val_loss: 0.0227\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0226\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0227\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.0313\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0214 - val_loss: 0.0225\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0196 - val_loss: 0.0223\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0202 - val_loss: 0.0244\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0275 - val_loss: 0.0227\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0231 - val_loss: 0.0233\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0272 - val_loss: 0.0259\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0216 - val_loss: 0.0218\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0200 - val_loss: 0.0220\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0208 - val_loss: 0.0218\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0211 - val_loss: 0.0222\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0244 - val_loss: 0.0214\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0216 - val_loss: 0.0227\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0239 - val_loss: 0.0214\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0264 - val_loss: 0.0223\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0209 - val_loss: 0.0220\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0187 - val_loss: 0.0214\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0197 - val_loss: 0.0211\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0132 - val_loss: 0.0208\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0218 - val_loss: 0.0218\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0266 - val_loss: 0.0202\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0267 - val_loss: 0.0222\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0199 - val_loss: 0.0232\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0167 - val_loss: 0.0205\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0190 - val_loss: 0.0207\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0151 - val_loss: 0.0201\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0123 - val_loss: 0.0206\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0177 - val_loss: 0.0242\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0207\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0177 - val_loss: 0.0212\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0163 - val_loss: 0.0193\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.0208\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0207\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0187\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0219 - val_loss: 0.0203\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0210 - val_loss: 0.0191\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0177\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0172\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0149 - val_loss: 0.0176\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0173 - val_loss: 0.0158\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0168\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0174\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0190\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0210 - val_loss: 0.0155\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0176 - val_loss: 0.0149\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0178\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0159\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0185\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0164 - val_loss: 0.0159\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0135 - val_loss: 0.0173\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0171\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0150\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0104 - val_loss: 0.0194\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0164\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0123 - val_loss: 0.0176\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0170\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0131 - val_loss: 0.0207\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0170\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0168\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0076 - val_loss: 0.0161\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0138\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0107 - val_loss: 0.0162\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0115\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0069 - val_loss: 0.0129\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0195\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0156\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0084 - val_loss: 0.0199\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0117 - val_loss: 0.0189\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0163\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 1s 28ms/step - loss: 0.0110 - val_loss: 0.0129\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0063 - val_loss: 0.0154\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0061 - val_loss: 0.0154\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0062 - val_loss: 0.0194\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0075 - val_loss: 0.0158\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0064 - val_loss: 0.0149\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0050 - val_loss: 0.0151\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0041 - val_loss: 0.0161\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0078 - val_loss: 0.0173\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0054 - val_loss: 0.0148\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0048 - val_loss: 0.0126\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0059 - val_loss: 0.0192\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0071 - val_loss: 0.0132\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0050 - val_loss: 0.0207\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0081 - val_loss: 0.0198\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0055 - val_loss: 0.0154\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0042 - val_loss: 0.0162\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0041 - val_loss: 0.0181\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0044 - val_loss: 0.0190\n",
      "Epoch 140/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0037 - val_loss: 0.0160\n",
      "Epoch 141/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0059 - val_loss: 0.0227\n",
      "Epoch 142/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0051 - val_loss: 0.0139\n",
      "Epoch 143/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0060 - val_loss: 0.0129\n",
      "Epoch 144/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0055 - val_loss: 0.0153\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A795B171F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 35ms/step - loss: 0.0765 - val_loss: 0.0373\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0377 - val_loss: 0.0366\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0355 - val_loss: 0.0376\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0275 - val_loss: 0.0301\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0296 - val_loss: 0.0273\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0226 - val_loss: 0.0309\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0285 - val_loss: 0.0324\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0297 - val_loss: 0.0362\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0320 - val_loss: 0.0257\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0253\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0237 - val_loss: 0.0285\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0236 - val_loss: 0.0295\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0204 - val_loss: 0.0245\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0242 - val_loss: 0.0246\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0173 - val_loss: 0.0271\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0225 - val_loss: 0.0244\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0202 - val_loss: 0.0243\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0236 - val_loss: 0.0243\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0244 - val_loss: 0.0242\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0258 - val_loss: 0.0260\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0248 - val_loss: 0.0247\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0250 - val_loss: 0.0326\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0248 - val_loss: 0.0248\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0261 - val_loss: 0.0253\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0239 - val_loss: 0.0265\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0292 - val_loss: 0.0238\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0194 - val_loss: 0.0248\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0309 - val_loss: 0.0271\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0234 - val_loss: 0.0278\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0210 - val_loss: 0.0237\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0271 - val_loss: 0.0243\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0195 - val_loss: 0.0259\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0297 - val_loss: 0.0306\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0179 - val_loss: 0.0234\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0202 - val_loss: 0.0231\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0279 - val_loss: 0.0247\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0218 - val_loss: 0.0232\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0244 - val_loss: 0.0233\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0194 - val_loss: 0.0243\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0238 - val_loss: 0.0240\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0230 - val_loss: 0.0228\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0275 - val_loss: 0.0233\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0205 - val_loss: 0.0229\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0213 - val_loss: 0.0243\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0222 - val_loss: 0.0234\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0264 - val_loss: 0.0237\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0171 - val_loss: 0.0228\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0185 - val_loss: 0.0272\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0328 - val_loss: 0.0267\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0154 - val_loss: 0.0257\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0297 - val_loss: 0.0231\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0190 - val_loss: 0.0223\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0222\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0171 - val_loss: 0.0234\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0177 - val_loss: 0.0222\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0209 - val_loss: 0.0260\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0174 - val_loss: 0.0221\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0213 - val_loss: 0.0220\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0217\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0224 - val_loss: 0.0247\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0217 - val_loss: 0.0259\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0286 - val_loss: 0.0212\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0201 - val_loss: 0.0211\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0195 - val_loss: 0.0260\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0195 - val_loss: 0.0223\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0227 - val_loss: 0.0213\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0174 - val_loss: 0.0208\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0162 - val_loss: 0.0218\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0161 - val_loss: 0.0204\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0134 - val_loss: 0.0221\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0182 - val_loss: 0.0200\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0183 - val_loss: 0.0196\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.0167 - val_loss: 0.0207\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0255 - val_loss: 0.0195\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0187 - val_loss: 0.0192\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0191\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0211 - val_loss: 0.0198\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0204\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0199 - val_loss: 0.0193\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0104 - val_loss: 0.0230\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0242 - val_loss: 0.0190\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0158 - val_loss: 0.0194\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0165 - val_loss: 0.0195\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0171 - val_loss: 0.0189\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0188 - val_loss: 0.0184\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0204\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0183\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0192 - val_loss: 0.0183\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0145 - val_loss: 0.0187\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0141 - val_loss: 0.0173\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0151 - val_loss: 0.0194\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0210 - val_loss: 0.0177\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0182\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0169 - val_loss: 0.0164\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0152 - val_loss: 0.0153\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0156 - val_loss: 0.0199\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0172 - val_loss: 0.0159\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0157 - val_loss: 0.0164\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0163\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0143 - val_loss: 0.0159\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0172\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0149 - val_loss: 0.0164\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0151\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0173\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.0164\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0185\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0145\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0123 - val_loss: 0.0133\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0148\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0142\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0127\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0134\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0085 - val_loss: 0.0158\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0083 - val_loss: 0.0138\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0129\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0064 - val_loss: 0.0123\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0074 - val_loss: 0.0133\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0070 - val_loss: 0.0152\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0205\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0132\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0076 - val_loss: 0.0160\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0096 - val_loss: 0.0137\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0079 - val_loss: 0.0183\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0071 - val_loss: 0.0176\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0081 - val_loss: 0.0152\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0164\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0127\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0066 - val_loss: 0.0160\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0065 - val_loss: 0.0144\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0055 - val_loss: 0.0151\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0063 - val_loss: 0.0148\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0047 - val_loss: 0.0174\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0068 - val_loss: 0.0158\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0040 - val_loss: 0.0157\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0044 - val_loss: 0.0173\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0043 - val_loss: 0.0141\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0037 - val_loss: 0.0155\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0065 - val_loss: 0.0143\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A87B02A550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 35ms/step - loss: 0.0736 - val_loss: 0.0303\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0404 - val_loss: 0.0307\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0349 - val_loss: 0.0395\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0315 - val_loss: 0.0296\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0279 - val_loss: 0.0276\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0263 - val_loss: 0.0295\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0210 - val_loss: 0.0317\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.0289 - val_loss: 0.0278\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0263 - val_loss: 0.0288\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0268 - val_loss: 0.0281\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0223 - val_loss: 0.0261\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0207 - val_loss: 0.0249\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0255 - val_loss: 0.0271\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0280 - val_loss: 0.0247\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0241 - val_loss: 0.0246\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0215 - val_loss: 0.0256\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0197 - val_loss: 0.0266\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0421 - val_loss: 0.0259\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0268 - val_loss: 0.0240\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0253 - val_loss: 0.0253\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0215 - val_loss: 0.0288\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0328 - val_loss: 0.0255\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0189 - val_loss: 0.0263\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0216 - val_loss: 0.0237\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0222 - val_loss: 0.0239\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0243 - val_loss: 0.0236\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0246 - val_loss: 0.0242\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0316 - val_loss: 0.0300\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0211 - val_loss: 0.0235\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0224 - val_loss: 0.0286\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0212 - val_loss: 0.0236\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0234 - val_loss: 0.0251\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0396 - val_loss: 0.0317\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0272 - val_loss: 0.0245\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0261 - val_loss: 0.0241\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0210 - val_loss: 0.0250\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0247 - val_loss: 0.0232\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0199 - val_loss: 0.0256\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0275 - val_loss: 0.0230\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0195 - val_loss: 0.0249\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0214 - val_loss: 0.0232\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0178 - val_loss: 0.0229\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0288 - val_loss: 0.0274\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0201 - val_loss: 0.0231\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0277 - val_loss: 0.0227\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0202 - val_loss: 0.0227\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0210 - val_loss: 0.0235\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0182 - val_loss: 0.0226\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0289 - val_loss: 0.0240\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0294 - val_loss: 0.0224\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0205 - val_loss: 0.0233\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.0224\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0226 - val_loss: 0.0222\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0226 - val_loss: 0.0262\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0178 - val_loss: 0.0299\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0179 - val_loss: 0.0220\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0202 - val_loss: 0.0224\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0185 - val_loss: 0.0225\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.0222\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0251 - val_loss: 0.0220\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0219 - val_loss: 0.0227\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0300 - val_loss: 0.0240\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0216\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0231 - val_loss: 0.0233\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0194 - val_loss: 0.0214\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0206 - val_loss: 0.0213\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0227 - val_loss: 0.0232\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0213\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0194 - val_loss: 0.0207\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0220 - val_loss: 0.0205\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0155 - val_loss: 0.0270\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0242 - val_loss: 0.0229\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0209 - val_loss: 0.0228\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0212\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0193 - val_loss: 0.0197\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.0193\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0198 - val_loss: 0.0202\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0203 - val_loss: 0.0202\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0209\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0173 - val_loss: 0.0200\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0204 - val_loss: 0.0205\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0198 - val_loss: 0.0256\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0234 - val_loss: 0.0227\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0170 - val_loss: 0.0187\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0157 - val_loss: 0.0188\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0154 - val_loss: 0.0186\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0123 - val_loss: 0.0193\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0183 - val_loss: 0.0179\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0218 - val_loss: 0.0215\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0196 - val_loss: 0.0187\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0190 - val_loss: 0.0182\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0150 - val_loss: 0.0181\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0141 - val_loss: 0.0185\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0136 - val_loss: 0.0180\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0169 - val_loss: 0.0192\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0163\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0132 - val_loss: 0.0166\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.0163\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0187\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0180 - val_loss: 0.0149\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0145 - val_loss: 0.0198\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0146\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.0155\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0125 - val_loss: 0.0192\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0174\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0114 - val_loss: 0.0182\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0157\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0162\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0155\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.0103 - val_loss: 0.0193\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0154 - val_loss: 0.0156\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0127 - val_loss: 0.0158\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0100 - val_loss: 0.0145\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0149\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0148\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0187\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0176\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0145\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0174\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0132\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0084 - val_loss: 0.0145\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0061 - val_loss: 0.0141\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0075 - val_loss: 0.0146\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0071 - val_loss: 0.0135\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0165\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0075 - val_loss: 0.0157\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0077 - val_loss: 0.0132\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0067 - val_loss: 0.0131\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0055 - val_loss: 0.0127\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0072 - val_loss: 0.0116\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0057 - val_loss: 0.0136\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0060 - val_loss: 0.0114\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0055 - val_loss: 0.0143\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0041 - val_loss: 0.0133\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0043 - val_loss: 0.0133\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0055 - val_loss: 0.0149\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0056 - val_loss: 0.0134\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0042 - val_loss: 0.0163\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0037 - val_loss: 0.0157\n",
      "Epoch 140/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0037 - val_loss: 0.0173\n",
      "Epoch 141/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0038 - val_loss: 0.0145\n",
      "Epoch 142/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0032 - val_loss: 0.0155\n",
      "Epoch 143/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0050 - val_loss: 0.0147\n",
      "Epoch 144/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0134\n",
      "Epoch 145/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0029 - val_loss: 0.0160\n",
      "Epoch 146/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0037 - val_loss: 0.0124\n",
      "Epoch 147/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0025 - val_loss: 0.0145\n",
      "Epoch 148/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0168\n",
      "Epoch 149/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0026 - val_loss: 0.0184\n",
      "Epoch 150/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0041 - val_loss: 0.0154\n",
      "Epoch 151/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0029 - val_loss: 0.0151\n",
      "Epoch 152/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0026 - val_loss: 0.0206\n",
      "Epoch 153/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0032 - val_loss: 0.0141\n",
      "Epoch 154/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0032 - val_loss: 0.0184\n",
      "Epoch 155/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0030 - val_loss: 0.0150\n",
      "Epoch 156/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0049 - val_loss: 0.0183\n",
      "Epoch 157/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0043 - val_loss: 0.0157\n",
      "Epoch 158/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0030 - val_loss: 0.0182\n",
      "Epoch 159/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0033 - val_loss: 0.0145\n",
      "Epoch 160/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0029 - val_loss: 0.0172\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A870B5AC10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 35ms/step - loss: 0.0964 - val_loss: 0.0315\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0249 - val_loss: 0.0301\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0314 - val_loss: 0.0345\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0331 - val_loss: 0.0280\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0296 - val_loss: 0.0342\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0222 - val_loss: 0.0277\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0246 - val_loss: 0.0269\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0314 - val_loss: 0.0263\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0245 - val_loss: 0.0351\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0271 - val_loss: 0.0287\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0238 - val_loss: 0.0264\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0204 - val_loss: 0.0288\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0277 - val_loss: 0.0276\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0261 - val_loss: 0.0247\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0235 - val_loss: 0.0271\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0212 - val_loss: 0.0245\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0257 - val_loss: 0.0281\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0247 - val_loss: 0.0323\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0284 - val_loss: 0.0282\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0227 - val_loss: 0.0243\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0223 - val_loss: 0.0251\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0237 - val_loss: 0.0308\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0195 - val_loss: 0.0242\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0196 - val_loss: 0.0247\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.0243 - val_loss: 0.0285\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0304 - val_loss: 0.0239\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0234 - val_loss: 0.0244\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0181 - val_loss: 0.0258\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0236 - val_loss: 0.0246\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0250 - val_loss: 0.0408\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0221 - val_loss: 0.0246\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0192 - val_loss: 0.0239\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0244 - val_loss: 0.0238\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0200 - val_loss: 0.0255\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0198 - val_loss: 0.0235\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0283 - val_loss: 0.0252\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0178 - val_loss: 0.0234\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0212 - val_loss: 0.0304\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0251 - val_loss: 0.0231\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0270 - val_loss: 0.0263\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0238\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0215 - val_loss: 0.0230\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0285 - val_loss: 0.0253\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0266 - val_loss: 0.0239\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0238 - val_loss: 0.0333\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0193 - val_loss: 0.0227\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0244 - val_loss: 0.0229\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0252 - val_loss: 0.0231\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0212 - val_loss: 0.0224\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0224 - val_loss: 0.0231\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0189 - val_loss: 0.0249\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0221 - val_loss: 0.0254\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0227\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0238 - val_loss: 0.0235\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0283 - val_loss: 0.0322\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0172 - val_loss: 0.0230\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0195 - val_loss: 0.0294\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0239 - val_loss: 0.0223\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0196 - val_loss: 0.0220\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0259 - val_loss: 0.0218\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0194 - val_loss: 0.0221\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0233 - val_loss: 0.0239\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0158 - val_loss: 0.0270\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0176 - val_loss: 0.0254\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0187 - val_loss: 0.0210\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0193 - val_loss: 0.0222\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0210\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0209 - val_loss: 0.0206\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0183 - val_loss: 0.0214\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0204 - val_loss: 0.0275\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0195 - val_loss: 0.0203\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.0207\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0173 - val_loss: 0.0213\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.0205\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0197 - val_loss: 0.0209\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0181 - val_loss: 0.0200\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0181 - val_loss: 0.0211\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0192\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0148 - val_loss: 0.0192\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.0204\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0217 - val_loss: 0.0252\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0245 - val_loss: 0.0253\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0131 - val_loss: 0.0210\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.0199\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0187\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0180 - val_loss: 0.0186\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0180 - val_loss: 0.0206\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0160 - val_loss: 0.0182\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0131 - val_loss: 0.0185\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0212 - val_loss: 0.0200\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0218 - val_loss: 0.0210\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0184\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0164 - val_loss: 0.0197\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0253 - val_loss: 0.0186\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0157 - val_loss: 0.0199\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.0172\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0196\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0183\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0181\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0185\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0194 - val_loss: 0.0167\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0176\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0155 - val_loss: 0.0174\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0165\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0167\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0127 - val_loss: 0.0169\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.0166\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0158\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0126 - val_loss: 0.0146\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0154\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0165\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0119 - val_loss: 0.0159\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0100 - val_loss: 0.0137\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0196\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0148\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0104 - val_loss: 0.0141\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0151\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0151 - val_loss: 0.0132\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0183\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0138\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0100 - val_loss: 0.0145\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0154\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0136\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0154\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0065 - val_loss: 0.0154\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0150\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.0080 - val_loss: 0.0119\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0076 - val_loss: 0.0127\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0069 - val_loss: 0.0131\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0070 - val_loss: 0.0147\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0064 - val_loss: 0.0182\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.0253\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0079 - val_loss: 0.0152\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0065 - val_loss: 0.0176\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0069 - val_loss: 0.0122\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0064 - val_loss: 0.0136\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0068 - val_loss: 0.0179\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0073 - val_loss: 0.0119\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0052 - val_loss: 0.0192\n",
      "Epoch 140/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0051 - val_loss: 0.0164\n",
      "Epoch 141/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0056 - val_loss: 0.0161\n",
      "Epoch 142/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0060 - val_loss: 0.0145\n",
      "Epoch 143/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0044 - val_loss: 0.0136\n",
      "Epoch 144/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0045 - val_loss: 0.0173\n",
      "Epoch 145/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0031 - val_loss: 0.0171\n",
      "Epoch 146/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0039 - val_loss: 0.0209\n",
      "Epoch 147/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0213\n",
      "Epoch 148/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0033 - val_loss: 0.0220\n",
      "Epoch 149/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0056 - val_loss: 0.0185\n",
      "Epoch 150/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0063 - val_loss: 0.0118\n",
      "Epoch 151/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0051 - val_loss: 0.0133\n",
      "Epoch 152/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0038 - val_loss: 0.0146\n",
      "Epoch 153/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0032 - val_loss: 0.0142\n",
      "Epoch 154/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0030 - val_loss: 0.0162\n",
      "Epoch 155/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0029 - val_loss: 0.0120\n",
      "Epoch 156/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0026 - val_loss: 0.0142\n",
      "Epoch 157/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0026 - val_loss: 0.0144\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A8893CB160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 35ms/step - loss: 0.0953 - val_loss: 0.0422\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0332 - val_loss: 0.0332\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0363 - val_loss: 0.0321\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0372 - val_loss: 0.0368\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0281 - val_loss: 0.0273\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0283 - val_loss: 0.0305\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0313 - val_loss: 0.0424\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0261 - val_loss: 0.0290\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0276 - val_loss: 0.0260\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0252 - val_loss: 0.0281\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0206 - val_loss: 0.0253\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0199 - val_loss: 0.0253\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0276 - val_loss: 0.0265\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0243 - val_loss: 0.0247\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0211 - val_loss: 0.0265\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0204 - val_loss: 0.0254\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0201 - val_loss: 0.0246\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0225 - val_loss: 0.0241\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0266 - val_loss: 0.0244\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0230 - val_loss: 0.0263\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0273 - val_loss: 0.0281\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0242 - val_loss: 0.0251\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0279 - val_loss: 0.0255\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0261 - val_loss: 0.0249\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0200 - val_loss: 0.0238\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0191 - val_loss: 0.0239\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0222 - val_loss: 0.0236\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0214 - val_loss: 0.0266\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0168 - val_loss: 0.0245\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0237 - val_loss: 0.0247\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0204 - val_loss: 0.0235\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0219 - val_loss: 0.0234\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0260 - val_loss: 0.0245\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0228 - val_loss: 0.0233\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0236 - val_loss: 0.0266\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0185 - val_loss: 0.0233\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0240 - val_loss: 0.0327\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0221 - val_loss: 0.0231\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0247 - val_loss: 0.0244\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0235 - val_loss: 0.0249\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0229 - val_loss: 0.0234\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0229\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0200 - val_loss: 0.0240\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0193 - val_loss: 0.0254\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0176 - val_loss: 0.0241\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0231 - val_loss: 0.0226\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0203 - val_loss: 0.0255\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0222 - val_loss: 0.0228\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.0198 - val_loss: 0.0226\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0185 - val_loss: 0.0255\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0232\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0176 - val_loss: 0.0257\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0156 - val_loss: 0.0224\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0199 - val_loss: 0.0223\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0216 - val_loss: 0.0289\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0183 - val_loss: 0.0235\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0266 - val_loss: 0.0219\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0160 - val_loss: 0.0221\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0240\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0219 - val_loss: 0.0230\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0179 - val_loss: 0.0234\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0180 - val_loss: 0.0223\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0239 - val_loss: 0.0218\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0232 - val_loss: 0.0239\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.0213\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0196 - val_loss: 0.0220\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0211\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0214\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0156 - val_loss: 0.0229\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0222 - val_loss: 0.0228\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0246 - val_loss: 0.0211\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0173 - val_loss: 0.0216\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0196 - val_loss: 0.0203\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0177 - val_loss: 0.0227\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0226 - val_loss: 0.0230\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0149 - val_loss: 0.0204\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0195\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.0208\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0179 - val_loss: 0.0193\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0189 - val_loss: 0.0204\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0181 - val_loss: 0.0188\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0202\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.0197\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0180 - val_loss: 0.0190\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0180 - val_loss: 0.0186\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.0206\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0170 - val_loss: 0.0186\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0201\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0162 - val_loss: 0.0182\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.0175\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0182\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0215\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0208 - val_loss: 0.0179\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0189 - val_loss: 0.0210\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0201 - val_loss: 0.0191\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0160 - val_loss: 0.0180\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0191 - val_loss: 0.0162\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0141 - val_loss: 0.0172\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0140 - val_loss: 0.0182\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0114 - val_loss: 0.0154\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0138 - val_loss: 0.0156\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0159\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0156 - val_loss: 0.0189\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0130 - val_loss: 0.0169\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0141 - val_loss: 0.0164\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0175\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0181\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.0156\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0149 - val_loss: 0.0167\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0177\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0197\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0177\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0187\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0128 - val_loss: 0.0156\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0180\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0107 - val_loss: 0.0170\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0085 - val_loss: 0.0162\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0197\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0191\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0100 - val_loss: 0.0190\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0171\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0165\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0192\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0141\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0076 - val_loss: 0.0178\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0160\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0067 - val_loss: 0.0171\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0084 - val_loss: 0.0163\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0085 - val_loss: 0.0155\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0179\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0149\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0082 - val_loss: 0.0178\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0063 - val_loss: 0.0157\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0065 - val_loss: 0.0158\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0077 - val_loss: 0.0163\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0082 - val_loss: 0.0202\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0151\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0079 - val_loss: 0.0154\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0077 - val_loss: 0.0170\n",
      "Epoch 140/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0085 - val_loss: 0.0188\n",
      "Epoch 141/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0056 - val_loss: 0.0163\n",
      "Epoch 142/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0073 - val_loss: 0.0147\n",
      "Epoch 143/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0062 - val_loss: 0.0160\n",
      "Epoch 144/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0059 - val_loss: 0.0161\n",
      "Epoch 145/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0076 - val_loss: 0.0174\n",
      "Epoch 146/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0062 - val_loss: 0.0194\n",
      "Epoch 147/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0061 - val_loss: 0.0157\n",
      "Epoch 148/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0051 - val_loss: 0.0180\n",
      "Epoch 149/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0056 - val_loss: 0.0175\n",
      "Epoch 150/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0056 - val_loss: 0.0183\n",
      "Epoch 151/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0051 - val_loss: 0.0132\n",
      "Epoch 152/200\n",
      "25/25 [==============================] - 1s 28ms/step - loss: 0.0064 - val_loss: 0.0152\n",
      "Epoch 153/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0045 - val_loss: 0.0162\n",
      "Epoch 154/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0054 - val_loss: 0.0204\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A887A0BD30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 35ms/step - loss: 0.0792 - val_loss: 0.0367\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 1s 39ms/step - loss: 0.0264 - val_loss: 0.0366\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0362 - val_loss: 0.0278\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0324 - val_loss: 0.0303\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0322 - val_loss: 0.0269\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0313 - val_loss: 0.0269\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0294 - val_loss: 0.0261\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0201 - val_loss: 0.0258\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0272 - val_loss: 0.0267\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0224 - val_loss: 0.0253\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0208 - val_loss: 0.0251\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0259 - val_loss: 0.0256\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0172 - val_loss: 0.0245\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0230 - val_loss: 0.0246\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0261 - val_loss: 0.0245\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0261 - val_loss: 0.0252\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0231 - val_loss: 0.0334\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0206 - val_loss: 0.0240\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0261 - val_loss: 0.0331\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0233 - val_loss: 0.0240\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0218 - val_loss: 0.0243\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0244 - val_loss: 0.0269\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0225 - val_loss: 0.0260\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0281 - val_loss: 0.0290\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0253 - val_loss: 0.0241\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0238 - val_loss: 0.0242\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0211 - val_loss: 0.0260\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0232 - val_loss: 0.0278\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0254 - val_loss: 0.0266\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0252 - val_loss: 0.0266\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0226 - val_loss: 0.0261\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0216 - val_loss: 0.0247\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0215 - val_loss: 0.0238\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0296 - val_loss: 0.0232\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0223 - val_loss: 0.0277\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0214 - val_loss: 0.0235\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0292 - val_loss: 0.0238\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0199 - val_loss: 0.0232\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0212 - val_loss: 0.0240\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0208 - val_loss: 0.0317\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0229 - val_loss: 0.0319\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0338 - val_loss: 0.0249\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0250 - val_loss: 0.0245\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0331 - val_loss: 0.0242\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0220 - val_loss: 0.0262\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0231 - val_loss: 0.0226\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0206 - val_loss: 0.0229\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0185 - val_loss: 0.0240\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0194 - val_loss: 0.0241\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0181 - val_loss: 0.0227\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0224 - val_loss: 0.0244\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0208 - val_loss: 0.0224\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0268 - val_loss: 0.0326\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0281 - val_loss: 0.0242\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0160 - val_loss: 0.0229\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0245 - val_loss: 0.0309\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - ETA: 0s - loss: 0.020 - 0s 8ms/step - loss: 0.0203 - val_loss: 0.0240\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0176 - val_loss: 0.0271\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0251 - val_loss: 0.0216\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0209 - val_loss: 0.0220\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0193 - val_loss: 0.0231\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0194 - val_loss: 0.0230\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0200 - val_loss: 0.0229\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0191 - val_loss: 0.0242\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0232 - val_loss: 0.0219\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0224 - val_loss: 0.0219\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0196 - val_loss: 0.0218\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0221 - val_loss: 0.0246\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0148 - val_loss: 0.0215\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0191 - val_loss: 0.0226\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0198 - val_loss: 0.0207\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0188 - val_loss: 0.0206\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0181 - val_loss: 0.0202\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0246 - val_loss: 0.0201\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0169 - val_loss: 0.0202\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.0216\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0290 - val_loss: 0.0217\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0195 - val_loss: 0.0195\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0170 - val_loss: 0.0191\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0150 - val_loss: 0.0201\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0214\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0179 - val_loss: 0.0191\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0176 - val_loss: 0.0185\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.0226 - val_loss: 0.0182\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0142 - val_loss: 0.0178\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0203 - val_loss: 0.0222\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0175 - val_loss: 0.0173\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0178 - val_loss: 0.0173\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0157 - val_loss: 0.0174\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0189\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0176\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0143 - val_loss: 0.0198\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0151 - val_loss: 0.0188\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0140 - val_loss: 0.0186\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0210\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0167 - val_loss: 0.0205\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0160 - val_loss: 0.0183\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0184\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0181 - val_loss: 0.0167\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0172\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0124 - val_loss: 0.0181\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0179\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0093 - val_loss: 0.0173\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.0159\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0195\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0127 - val_loss: 0.0201\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0190\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0118 - val_loss: 0.0170\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0121 - val_loss: 0.0161\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0163\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0130\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0213\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0164\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0120 - val_loss: 0.0126\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0119\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0133\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0080 - val_loss: 0.0114\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0064 - val_loss: 0.0167\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0151\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0134\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0071 - val_loss: 0.0158\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0077 - val_loss: 0.0165\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0062 - val_loss: 0.0141\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0084 - val_loss: 0.0148\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0067 - val_loss: 0.0138\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0054 - val_loss: 0.0103\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0059 - val_loss: 0.0181\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0061 - val_loss: 0.0161\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0051 - val_loss: 0.0127\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0051 - val_loss: 0.0165\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0066 - val_loss: 0.0144\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0053 - val_loss: 0.0147\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0078 - val_loss: 0.0188\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0044 - val_loss: 0.0194\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0051 - val_loss: 0.0208\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0064 - val_loss: 0.0164\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0078 - val_loss: 0.0143\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0042 - val_loss: 0.0153\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0046 - val_loss: 0.0109\n",
      "Epoch 140/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0062 - val_loss: 0.0139\n",
      "Epoch 141/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0045 - val_loss: 0.0171\n",
      "Epoch 142/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0041 - val_loss: 0.0173\n",
      "Epoch 143/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0050 - val_loss: 0.0133\n",
      "Epoch 144/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0051 - val_loss: 0.0148\n",
      "Epoch 145/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0039 - val_loss: 0.0161\n",
      "Epoch 146/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0037 - val_loss: 0.0226\n",
      "Epoch 147/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0065 - val_loss: 0.0184\n",
      "Epoch 148/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0042 - val_loss: 0.0164\n",
      "Epoch 149/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0042 - val_loss: 0.0152\n",
      "Epoch 150/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0030 - val_loss: 0.0160\n",
      "Epoch 151/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0034 - val_loss: 0.0138\n",
      "Epoch 152/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0055 - val_loss: 0.0174\n",
      "Epoch 153/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.0189\n",
      "Epoch 154/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0041 - val_loss: 0.0165\n",
      "Epoch 155/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0055 - val_loss: 0.0182\n",
      "Epoch 156/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0086 - val_loss: 0.0197\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A70CAB3EE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 34ms/step - loss: 0.0731 - val_loss: 0.0322\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0275 - val_loss: 0.0289\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0371 - val_loss: 0.0298\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0246 - val_loss: 0.0300\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0297 - val_loss: 0.0275\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0285 - val_loss: 0.0266\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0263 - val_loss: 0.0446\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0319 - val_loss: 0.0257\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0254 - val_loss: 0.0273\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0215 - val_loss: 0.0308\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0284 - val_loss: 0.0300\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0276 - val_loss: 0.0251\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0330 - val_loss: 0.0247\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0253 - val_loss: 0.0252\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0189 - val_loss: 0.0273\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0318 - val_loss: 0.0243\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.0195 - val_loss: 0.0249\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0208 - val_loss: 0.0242\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0210 - val_loss: 0.0302\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0296 - val_loss: 0.0262\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0174 - val_loss: 0.0283\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0255 - val_loss: 0.0264\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0215 - val_loss: 0.0247\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0253 - val_loss: 0.0236\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0196 - val_loss: 0.0236\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0245 - val_loss: 0.0244\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0299 - val_loss: 0.0273\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0250 - val_loss: 0.0361\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0233 - val_loss: 0.0284\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0305 - val_loss: 0.0260\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0234 - val_loss: 0.0232\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0218 - val_loss: 0.0250\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0187 - val_loss: 0.0234\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0212 - val_loss: 0.0232\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0238 - val_loss: 0.0233\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0155 - val_loss: 0.0230\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0179 - val_loss: 0.0231\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0180 - val_loss: 0.0242\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0270 - val_loss: 0.0267\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0245 - val_loss: 0.0229\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0226\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0249 - val_loss: 0.0228\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0227\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0259 - val_loss: 0.0244\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0190 - val_loss: 0.0230\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0191 - val_loss: 0.0228\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0253 - val_loss: 0.0283\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0181 - val_loss: 0.0220\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0229 - val_loss: 0.0220\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0219\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0285 - val_loss: 0.0246\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0182 - val_loss: 0.0263\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0176 - val_loss: 0.0223\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0206 - val_loss: 0.0289\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0183 - val_loss: 0.0233\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0255 - val_loss: 0.0238\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0169 - val_loss: 0.0217\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0190 - val_loss: 0.0210\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0157 - val_loss: 0.0214\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0229 - val_loss: 0.0222\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0256 - val_loss: 0.0306\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.0214\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0171 - val_loss: 0.0210\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0193 - val_loss: 0.0227\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0247 - val_loss: 0.0217\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.0200\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0240 - val_loss: 0.0221\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.0199\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0188 - val_loss: 0.0201\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.0229 - val_loss: 0.0197\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0214 - val_loss: 0.0208\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0140 - val_loss: 0.0202\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0204 - val_loss: 0.0194\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.0190\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0192\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0191\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0192\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0150 - val_loss: 0.0183\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0156 - val_loss: 0.0185\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0139 - val_loss: 0.0185\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0196\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0185\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0143 - val_loss: 0.0179\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0135 - val_loss: 0.0189\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0169 - val_loss: 0.0182\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0184\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.0176\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0156 - val_loss: 0.0215\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0171 - val_loss: 0.0193\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.0163\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.0165\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0136 - val_loss: 0.0192\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0132 - val_loss: 0.0168\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.0150\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0190\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0164\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0191\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0135 - val_loss: 0.0189\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0127 - val_loss: 0.0223\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 1s 28ms/step - loss: 0.0119 - val_loss: 0.0154\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0150\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0160\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0145 - val_loss: 0.0159\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0123 - val_loss: 0.0145\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0153\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0153\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0082 - val_loss: 0.0149\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0142\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0090 - val_loss: 0.0152\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0136\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0136 - val_loss: 0.0138\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0143\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0080 - val_loss: 0.0180\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0111\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0145\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0086 - val_loss: 0.0109\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0060 - val_loss: 0.0116\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0058 - val_loss: 0.0112\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0084 - val_loss: 0.0164\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0088\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0057 - val_loss: 0.0112\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0065 - val_loss: 0.0112\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0068 - val_loss: 0.0161\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0138\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0050 - val_loss: 0.0102\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0045 - val_loss: 0.0106\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0052 - val_loss: 0.0140\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0054 - val_loss: 0.0091\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0052 - val_loss: 0.0094\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0056 - val_loss: 0.0107\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0042 - val_loss: 0.0123\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0044 - val_loss: 0.0116\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0046 - val_loss: 0.0124\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0044 - val_loss: 0.0117\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0049 - val_loss: 0.0095\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0046 - val_loss: 0.0111\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.0042 - val_loss: 0.0133\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0042 - val_loss: 0.0104\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0111\n",
      "Epoch 140/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0025 - val_loss: 0.0118\n",
      "Epoch 141/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0038 - val_loss: 0.0129\n",
      "Epoch 142/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0045 - val_loss: 0.0116\n",
      "Epoch 143/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.0133\n",
      "Epoch 144/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0028 - val_loss: 0.0137\n",
      "Epoch 145/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.0134\n",
      "Epoch 146/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0030 - val_loss: 0.0136\n",
      "Epoch 147/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 148/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0026 - val_loss: 0.0112\n",
      "Epoch 149/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0021 - val_loss: 0.0139\n",
      "Epoch 150/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0028 - val_loss: 0.0122\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A70CC38550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 34ms/step - loss: 0.0764 - val_loss: 0.0329\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0218 - val_loss: 0.0292\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0309 - val_loss: 0.0277\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0271 - val_loss: 0.0272\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0395 - val_loss: 0.0329\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0266 - val_loss: 0.0326\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0272\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0240 - val_loss: 0.0299\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0234 - val_loss: 0.0308\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0217 - val_loss: 0.0256\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0215 - val_loss: 0.0363\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0345 - val_loss: 0.0251\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0278 - val_loss: 0.0249\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0284 - val_loss: 0.0250\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0205 - val_loss: 0.0255\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0250 - val_loss: 0.0244\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0211 - val_loss: 0.0243\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0223 - val_loss: 0.0256\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0265 - val_loss: 0.0243\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0194 - val_loss: 0.0339\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0244 - val_loss: 0.0243\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0268 - val_loss: 0.0250\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0236 - val_loss: 0.0241\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0207 - val_loss: 0.0267\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0213 - val_loss: 0.0246\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0244 - val_loss: 0.0253\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0132 - val_loss: 0.0237\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0191 - val_loss: 0.0248\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0266 - val_loss: 0.0296\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0341 - val_loss: 0.0272\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0323 - val_loss: 0.0267\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0228 - val_loss: 0.0235\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0182 - val_loss: 0.0233\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0180 - val_loss: 0.0244\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0201 - val_loss: 0.0238\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0281 - val_loss: 0.0238\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0164 - val_loss: 0.0239\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0179 - val_loss: 0.0239\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0240 - val_loss: 0.0234\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0213 - val_loss: 0.0234\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0201 - val_loss: 0.0274\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0227\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0205 - val_loss: 0.0230\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 1s 28ms/step - loss: 0.0193 - val_loss: 0.0279\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0233 - val_loss: 0.0247\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0200 - val_loss: 0.0230\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0218 - val_loss: 0.0265\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0269 - val_loss: 0.0249\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0247 - val_loss: 0.0224\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0221 - val_loss: 0.0221\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0147 - val_loss: 0.0239\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0215 - val_loss: 0.0225\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0194 - val_loss: 0.0232\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0172 - val_loss: 0.0222\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0190 - val_loss: 0.0263\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0158 - val_loss: 0.0226\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0213\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0187 - val_loss: 0.0234\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0185 - val_loss: 0.0209\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0218 - val_loss: 0.0209\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0243\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0204\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0244 - val_loss: 0.0207\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0228 - val_loss: 0.0250\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0255 - val_loss: 0.0197\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0130 - val_loss: 0.0193\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0201 - val_loss: 0.0214\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0159 - val_loss: 0.0204\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0188\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0187 - val_loss: 0.0188\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0186 - val_loss: 0.0269\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0171 - val_loss: 0.0189\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0149 - val_loss: 0.0181\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0178 - val_loss: 0.0200\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0138 - val_loss: 0.0210\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0187 - val_loss: 0.0187\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0177 - val_loss: 0.0201\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.0188\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0188 - val_loss: 0.0198\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0178 - val_loss: 0.0169\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0177 - val_loss: 0.0180\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0198 - val_loss: 0.0173\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0149 - val_loss: 0.0183\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0150 - val_loss: 0.0167\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0123 - val_loss: 0.0211\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0149 - val_loss: 0.0159\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0155 - val_loss: 0.0202\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.0163\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0163\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0174\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0167 - val_loss: 0.0166\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0145 - val_loss: 0.0164\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0186 - val_loss: 0.0218\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0168 - val_loss: 0.0188\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0169 - val_loss: 0.0162\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0159 - val_loss: 0.0149\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0170\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0177\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0139\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0150\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0187\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.0150\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0113 - val_loss: 0.0149\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0134 - val_loss: 0.0176\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0171\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0096 - val_loss: 0.0180\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0164\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0087 - val_loss: 0.0153\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0088 - val_loss: 0.0150\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0093 - val_loss: 0.0189\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0175\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0143\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0174\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0074 - val_loss: 0.0143\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0069 - val_loss: 0.0162\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0082 - val_loss: 0.0167\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0086 - val_loss: 0.0160\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0085 - val_loss: 0.0168\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0132\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0122 - val_loss: 0.0201\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0100 - val_loss: 0.0192\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0203\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0084 - val_loss: 0.0182\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0063 - val_loss: 0.0163\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0062 - val_loss: 0.0157\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0056 - val_loss: 0.0165\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 1s 28ms/step - loss: 0.0092 - val_loss: 0.0162\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0085 - val_loss: 0.0191\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0064 - val_loss: 0.0147\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A7956B3F70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 35ms/step - loss: 0.0581 - val_loss: 0.0297\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 1s 39ms/step - loss: 0.0358 - val_loss: 0.0280\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0233 - val_loss: 0.0294\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0264 - val_loss: 0.0316\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0329 - val_loss: 0.0348\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0226 - val_loss: 0.0262\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0263 - val_loss: 0.0271\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0342 - val_loss: 0.0363\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0267 - val_loss: 0.0274\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0221 - val_loss: 0.0260\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0249 - val_loss: 0.0278\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0305 - val_loss: 0.0350\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0310 - val_loss: 0.0317\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0208 - val_loss: 0.0244\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0213 - val_loss: 0.0307\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0259 - val_loss: 0.0242\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0333 - val_loss: 0.0314\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0278 - val_loss: 0.0293\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0201 - val_loss: 0.0296\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0233 - val_loss: 0.0242\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0212 - val_loss: 0.0253\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0229 - val_loss: 0.0253\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0208 - val_loss: 0.0261\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0223 - val_loss: 0.0254\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0219 - val_loss: 0.0259\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0229 - val_loss: 0.0243\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0222 - val_loss: 0.0240\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0189 - val_loss: 0.0245\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0312 - val_loss: 0.0261\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0234 - val_loss: 0.0238\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0212 - val_loss: 0.0267\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0195 - val_loss: 0.0231\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0253\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0182 - val_loss: 0.0232\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0224 - val_loss: 0.0234\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0233 - val_loss: 0.0237\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0266 - val_loss: 0.0296\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0171 - val_loss: 0.0240\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0335 - val_loss: 0.0258\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0204 - val_loss: 0.0249\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0261 - val_loss: 0.0246\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0204 - val_loss: 0.0228\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0240 - val_loss: 0.0224\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0194 - val_loss: 0.0232\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0252 - val_loss: 0.0235\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0223 - val_loss: 0.0239\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0204 - val_loss: 0.0231\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0201 - val_loss: 0.0246\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0217 - val_loss: 0.0237\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0143 - val_loss: 0.0218\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0210 - val_loss: 0.0220\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0186 - val_loss: 0.0235\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0194 - val_loss: 0.0217\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0194 - val_loss: 0.0232\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0217 - val_loss: 0.0217\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0177 - val_loss: 0.0219\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0198 - val_loss: 0.0225\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0168 - val_loss: 0.0210\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.0218\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0207 - val_loss: 0.0205\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.0208\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0172 - val_loss: 0.0207\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0157 - val_loss: 0.0227\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0160 - val_loss: 0.0202\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0239 - val_loss: 0.0205\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0197\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0302 - val_loss: 0.0209\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0212 - val_loss: 0.0197\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0173 - val_loss: 0.0198\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0276\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0193 - val_loss: 0.0210\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0201 - val_loss: 0.0201\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0186 - val_loss: 0.0191\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0169 - val_loss: 0.0193\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.0196\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0237\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0207 - val_loss: 0.0183\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0179 - val_loss: 0.0181\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0192\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0141 - val_loss: 0.0176\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0139 - val_loss: 0.0178\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0149 - val_loss: 0.0209\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0174\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.0133 - val_loss: 0.0178\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0196\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0185\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0209\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0175\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0169 - val_loss: 0.0185\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0176 - val_loss: 0.0198\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0160 - val_loss: 0.0166\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0174 - val_loss: 0.0171\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0190\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.0168\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0178 - val_loss: 0.0158\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0119 - val_loss: 0.0173\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0154\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0145\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0096 - val_loss: 0.0170\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0134 - val_loss: 0.0162\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0165\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0194\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0172\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0158\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0127 - val_loss: 0.0191\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0165\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0186\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0181\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.0156\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0083 - val_loss: 0.0188\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0195\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0106 - val_loss: 0.0193\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0172\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0104 - val_loss: 0.0170\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0109 - val_loss: 0.0175\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0145 - val_loss: 0.0131\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.0187\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0131\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0183\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0151 - val_loss: 0.0148\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0135\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0159\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0086 - val_loss: 0.0126\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0058 - val_loss: 0.0154\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0069 - val_loss: 0.0119\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0061 - val_loss: 0.0127\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0053 - val_loss: 0.0132\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0069 - val_loss: 0.0174\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0069 - val_loss: 0.0142\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0069 - val_loss: 0.0138\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0056 - val_loss: 0.0151\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0068 - val_loss: 0.0139\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0047 - val_loss: 0.0145\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0052 - val_loss: 0.0122\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0043 - val_loss: 0.0152\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0051 - val_loss: 0.0134\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0048 - val_loss: 0.0143\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0139\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0042 - val_loss: 0.0160\n",
      "Epoch 140/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0045 - val_loss: 0.0137\n",
      "Epoch 141/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0037 - val_loss: 0.0168\n",
      "Epoch 142/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0050 - val_loss: 0.0137\n",
      "Epoch 143/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0063 - val_loss: 0.0155\n",
      "Epoch 144/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0039 - val_loss: 0.0116\n",
      "Epoch 145/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0030 - val_loss: 0.0124\n",
      "Epoch 146/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0032 - val_loss: 0.0122\n",
      "Epoch 147/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0032 - val_loss: 0.0163\n",
      "Epoch 148/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0043 - val_loss: 0.0105\n",
      "Epoch 149/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0070 - val_loss: 0.0172\n",
      "Epoch 150/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0055 - val_loss: 0.0143\n",
      "Epoch 151/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0056 - val_loss: 0.0110\n",
      "Epoch 152/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0040 - val_loss: 0.0195\n",
      "Epoch 153/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0049 - val_loss: 0.0128\n",
      "Epoch 154/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0033 - val_loss: 0.0181\n",
      "Epoch 155/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0028 - val_loss: 0.0155\n",
      "Epoch 156/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0029 - val_loss: 0.0184\n",
      "Epoch 157/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0030 - val_loss: 0.0158\n",
      "Epoch 158/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0047 - val_loss: 0.0155\n",
      "Epoch 159/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0040 - val_loss: 0.0177\n",
      "Epoch 160/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0166\n",
      "Epoch 161/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0025 - val_loss: 0.0202\n",
      "Epoch 162/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0025 - val_loss: 0.0147\n",
      "Epoch 163/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0022 - val_loss: 0.0170\n",
      "Epoch 164/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0043 - val_loss: 0.0201\n",
      "Epoch 165/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0026 - val_loss: 0.0156\n",
      "Epoch 166/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0023 - val_loss: 0.0161\n",
      "Epoch 167/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0188\n",
      "Epoch 168/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0025 - val_loss: 0.0161\n",
      "Epoch 169/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 0.0225\n",
      "Epoch 170/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0024 - val_loss: 0.0186\n",
      "Epoch 171/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0021 - val_loss: 0.0214\n",
      "Epoch 172/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0023 - val_loss: 0.0186\n",
      "Epoch 173/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0024 - val_loss: 0.0199\n",
      "Epoch 174/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0024 - val_loss: 0.0202\n",
      "Epoch 175/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0021 - val_loss: 0.0201\n",
      "Epoch 176/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0024 - val_loss: 0.0192\n",
      "Epoch 177/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0020 - val_loss: 0.0183\n",
      "Epoch 178/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 0.0223\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A70D2091F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 56ms/step - loss: 0.0963 - val_loss: 0.0294\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0245 - val_loss: 0.0288\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0344 - val_loss: 0.0312\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0266 - val_loss: 0.0307\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0215 - val_loss: 0.0395\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0349 - val_loss: 0.0382\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0274 - val_loss: 0.0281\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0259 - val_loss: 0.0260\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0194 - val_loss: 0.0272\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0258 - val_loss: 0.0271\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0213 - val_loss: 0.0256\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0248 - val_loss: 0.0303\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0287 - val_loss: 0.0293\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0226 - val_loss: 0.0338\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0171 - val_loss: 0.0253\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0261 - val_loss: 0.0262\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0192 - val_loss: 0.0270\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0218 - val_loss: 0.0250\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0295 - val_loss: 0.0322\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0263\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0244 - val_loss: 0.0269\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0251 - val_loss: 0.0263\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0279 - val_loss: 0.0243\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0256 - val_loss: 0.0243\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0238\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0210 - val_loss: 0.0288\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0300 - val_loss: 0.0248\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0229 - val_loss: 0.0257\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0244 - val_loss: 0.0238\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0292 - val_loss: 0.0285\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0210 - val_loss: 0.0261\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0194 - val_loss: 0.0239\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0245 - val_loss: 0.0238\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0259 - val_loss: 0.0322\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0237 - val_loss: 0.0233\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0236\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0228 - val_loss: 0.0239\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0266 - val_loss: 0.0271\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0243 - val_loss: 0.0249\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0188 - val_loss: 0.0229\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0226 - val_loss: 0.0228\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0207 - val_loss: 0.0276\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0229\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0192 - val_loss: 0.0229\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0255 - val_loss: 0.0230\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0194 - val_loss: 0.0233\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0231 - val_loss: 0.0313\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0264 - val_loss: 0.0225\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0264 - val_loss: 0.0258\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0214 - val_loss: 0.0266\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0208 - val_loss: 0.0233\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0167 - val_loss: 0.0278\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0247 - val_loss: 0.0289\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0204 - val_loss: 0.0220\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.0219\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.0218\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0268\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0178 - val_loss: 0.0215\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0194 - val_loss: 0.0215\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0200 - val_loss: 0.0213\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0231\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0172 - val_loss: 0.0243\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0186 - val_loss: 0.0226\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0221\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0184 - val_loss: 0.0207\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0143 - val_loss: 0.0212\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0222 - val_loss: 0.0202\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0177 - val_loss: 0.0205\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0221 - val_loss: 0.0203\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0160 - val_loss: 0.0199\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0195\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0155 - val_loss: 0.0195\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0171 - val_loss: 0.0213\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0179 - val_loss: 0.0190\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0127 - val_loss: 0.0198\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0188 - val_loss: 0.0194\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0147 - val_loss: 0.0186\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0216 - val_loss: 0.0200\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0130 - val_loss: 0.0207\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0209 - val_loss: 0.0188\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0167 - val_loss: 0.0200\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0242 - val_loss: 0.0185\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0185 - val_loss: 0.0220\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0198 - val_loss: 0.0197\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0193\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0243 - val_loss: 0.0187\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0144 - val_loss: 0.0177\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0135 - val_loss: 0.0179\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0194\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0177\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0178 - val_loss: 0.0190\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0172\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0139 - val_loss: 0.0168\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0162\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0135 - val_loss: 0.0166\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 1s 28ms/step - loss: 0.0108 - val_loss: 0.0190\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0100 - val_loss: 0.0181\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0181 - val_loss: 0.0168\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0160\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0117 - val_loss: 0.0187\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0164 - val_loss: 0.0163\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0110 - val_loss: 0.0170\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0161\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0089 - val_loss: 0.0227\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0151\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0123 - val_loss: 0.0214\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0235\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0202\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0148\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0090 - val_loss: 0.0160\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0076 - val_loss: 0.0162\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0176\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0129\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0093 - val_loss: 0.0218\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0128\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0139\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0079 - val_loss: 0.0223\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0172\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0113 - val_loss: 0.0177\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0066 - val_loss: 0.0140\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0069 - val_loss: 0.0147\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0046 - val_loss: 0.0182\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0153\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0087 - val_loss: 0.0169\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0069 - val_loss: 0.0144\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0064 - val_loss: 0.0129\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0056 - val_loss: 0.0135\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0173\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0065 - val_loss: 0.0212\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0081 - val_loss: 0.0172\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0049 - val_loss: 0.0133\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0172\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0063 - val_loss: 0.0150\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0046 - val_loss: 0.0123\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0050 - val_loss: 0.0129\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0050 - val_loss: 0.0129\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0052 - val_loss: 0.0127\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0040 - val_loss: 0.0121\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0044 - val_loss: 0.0130\n",
      "Epoch 140/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0056 - val_loss: 0.0168\n",
      "Epoch 141/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0055 - val_loss: 0.0137\n",
      "Epoch 142/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0159\n",
      "Epoch 143/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0060 - val_loss: 0.0146\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A887A0B3A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 34ms/step - loss: 0.0450 - val_loss: 0.0318\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0358 - val_loss: 0.0301\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0279 - val_loss: 0.0292\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0306 - val_loss: 0.0351\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0246 - val_loss: 0.0342\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0303 - val_loss: 0.0475\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0303 - val_loss: 0.0328\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0305 - val_loss: 0.0268\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0233 - val_loss: 0.0255\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0242 - val_loss: 0.0251\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0193 - val_loss: 0.0329\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0323 - val_loss: 0.0270\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0257 - val_loss: 0.0272\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0199 - val_loss: 0.0263\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0197 - val_loss: 0.0265\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0237 - val_loss: 0.0257\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0202 - val_loss: 0.0266\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0206 - val_loss: 0.0242\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0228 - val_loss: 0.0250\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0230 - val_loss: 0.0258\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0202 - val_loss: 0.0241\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0300 - val_loss: 0.0314\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0197 - val_loss: 0.0244\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0212 - val_loss: 0.0284\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0232 - val_loss: 0.0256\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0257 - val_loss: 0.0239\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0181 - val_loss: 0.0242\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 1s 28ms/step - loss: 0.0192 - val_loss: 0.0238\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0209 - val_loss: 0.0287\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0179 - val_loss: 0.0242\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0299 - val_loss: 0.0390\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0280 - val_loss: 0.0266\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0262 - val_loss: 0.0247\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0205 - val_loss: 0.0234\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0244 - val_loss: 0.0321\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0294 - val_loss: 0.0342\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0236 - val_loss: 0.0234\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0237 - val_loss: 0.0246\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0230 - val_loss: 0.0232\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0212 - val_loss: 0.0232\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0196 - val_loss: 0.0234\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0210 - val_loss: 0.0234\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0212 - val_loss: 0.0243\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0260 - val_loss: 0.0258\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0238 - val_loss: 0.0226\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0205 - val_loss: 0.0252\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0194 - val_loss: 0.0239\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0272 - val_loss: 0.0228\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0256 - val_loss: 0.0332\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0188 - val_loss: 0.0226\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0232 - val_loss: 0.0223\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0223 - val_loss: 0.0228\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0224\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0196 - val_loss: 0.0272\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0271 - val_loss: 0.0222\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0223 - val_loss: 0.0218\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0215 - val_loss: 0.0305\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.0222\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0236\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0230 - val_loss: 0.0231\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0185 - val_loss: 0.0214\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0191 - val_loss: 0.0213\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0125 - val_loss: 0.0213\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0231\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0271 - val_loss: 0.0229\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0178 - val_loss: 0.0213\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0192 - val_loss: 0.0213\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0221\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0203 - val_loss: 0.0205\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0151 - val_loss: 0.0201\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0211\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0157 - val_loss: 0.0205\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0188 - val_loss: 0.0213\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0174 - val_loss: 0.0190\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0178 - val_loss: 0.0204\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0201\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0212 - val_loss: 0.0196\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0197\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0233 - val_loss: 0.0185\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0244 - val_loss: 0.0206\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0181\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.0187\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.0183\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0192 - val_loss: 0.0188\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0172 - val_loss: 0.0177\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0174 - val_loss: 0.0189\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0188\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0183 - val_loss: 0.0181\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0168\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0155 - val_loss: 0.0167\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0186 - val_loss: 0.0200\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0213 - val_loss: 0.0173\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0188 - val_loss: 0.0171\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0149 - val_loss: 0.0168\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0160 - val_loss: 0.0170\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0179 - val_loss: 0.0165\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0198 - val_loss: 0.0184\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0173\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0184\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0154 - val_loss: 0.0192\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0158\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0221\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0122 - val_loss: 0.0182\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0149 - val_loss: 0.0174\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0172\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0174\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0222\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0182\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0106 - val_loss: 0.0190\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0203\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0147\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0082 - val_loss: 0.0227\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0125 - val_loss: 0.0137\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0178\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.0158\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0195\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0076 - val_loss: 0.0135\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0114 - val_loss: 0.0242\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.0130 - val_loss: 0.0232\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0134\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0078 - val_loss: 0.0135\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0066 - val_loss: 0.0128\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0079 - val_loss: 0.0135\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0053 - val_loss: 0.0164\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0077 - val_loss: 0.0156\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0075 - val_loss: 0.0138\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0075 - val_loss: 0.0123\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0063 - val_loss: 0.0151\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0064 - val_loss: 0.0126\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.0047 - val_loss: 0.0113\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0041 - val_loss: 0.0108\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0041 - val_loss: 0.0157\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0053 - val_loss: 0.0164\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0054 - val_loss: 0.0168\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0163\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.0161\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0040 - val_loss: 0.0184\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0037 - val_loss: 0.0134\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0079 - val_loss: 0.0154\n",
      "Epoch 140/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0049 - val_loss: 0.0145\n",
      "Epoch 141/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0046 - val_loss: 0.0135\n",
      "Epoch 142/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0045 - val_loss: 0.0151\n",
      "Epoch 143/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0064 - val_loss: 0.0232\n",
      "Epoch 144/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0049 - val_loss: 0.0175\n",
      "Epoch 145/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0051 - val_loss: 0.0185\n",
      "Epoch 146/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0039 - val_loss: 0.0222\n",
      "Epoch 147/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0040 - val_loss: 0.0170\n",
      "Epoch 148/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0033 - val_loss: 0.0178\n",
      "Epoch 149/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0032 - val_loss: 0.0197\n",
      "Epoch 150/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0027 - val_loss: 0.0171\n",
      "Epoch 151/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0029 - val_loss: 0.0193\n",
      "Epoch 152/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0028 - val_loss: 0.0177\n",
      "Epoch 153/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0024 - val_loss: 0.0200\n",
      "Epoch 154/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0028 - val_loss: 0.0203\n",
      "Epoch 155/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0031 - val_loss: 0.0214\n",
      "Epoch 156/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0026 - val_loss: 0.0176\n",
      "Epoch 157/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0024 - val_loss: 0.0177\n",
      "Epoch 158/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0029 - val_loss: 0.0203\n",
      "Epoch 159/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0022 - val_loss: 0.0185\n",
      "Epoch 160/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0023 - val_loss: 0.0186\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A70CDFB310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 5s 36ms/step - loss: 0.0847 - val_loss: 0.0292\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0243 - val_loss: 0.0282\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0326 - val_loss: 0.0394\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0296 - val_loss: 0.0328\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0366 - val_loss: 0.0285\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0250 - val_loss: 0.0265\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0216 - val_loss: 0.0275\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0336 - val_loss: 0.0259\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0191 - val_loss: 0.0250\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0198 - val_loss: 0.0345\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0280 - val_loss: 0.0253\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0232 - val_loss: 0.0253\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0240 - val_loss: 0.0246\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0278 - val_loss: 0.0282\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0250 - val_loss: 0.0270\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0327 - val_loss: 0.0245\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0199 - val_loss: 0.0246\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0317 - val_loss: 0.0282\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0276 - val_loss: 0.0251\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0211 - val_loss: 0.0255\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0240 - val_loss: 0.0255\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0199 - val_loss: 0.0260\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0249 - val_loss: 0.0262\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0210 - val_loss: 0.0246\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0180 - val_loss: 0.0238\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0219 - val_loss: 0.0243\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0223 - val_loss: 0.0245\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0257 - val_loss: 0.0261\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0201 - val_loss: 0.0248\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0275 - val_loss: 0.0237\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0222 - val_loss: 0.0235\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0233 - val_loss: 0.0236\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0207 - val_loss: 0.0357\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0237 - val_loss: 0.0244\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0205 - val_loss: 0.0235\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0249 - val_loss: 0.0238\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0253 - val_loss: 0.0241\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0179 - val_loss: 0.0254\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0310 - val_loss: 0.0260\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0227 - val_loss: 0.0229\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0232 - val_loss: 0.0236\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0265 - val_loss: 0.0228\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0230 - val_loss: 0.0312\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0236 - val_loss: 0.0229\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0192 - val_loss: 0.0271\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0298 - val_loss: 0.0224\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0182 - val_loss: 0.0224\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.0287\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0266 - val_loss: 0.0226\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0273 - val_loss: 0.0222\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0209 - val_loss: 0.0223\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0296 - val_loss: 0.0241\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0222 - val_loss: 0.0259\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0220 - val_loss: 0.0217\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0227 - val_loss: 0.0221\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0189 - val_loss: 0.0227\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0212\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.0238\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0233 - val_loss: 0.0210\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.0220\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0189 - val_loss: 0.0212\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0181 - val_loss: 0.0206\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 1s 28ms/step - loss: 0.0157 - val_loss: 0.0218\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.0207\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0152 - val_loss: 0.0204\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0167 - val_loss: 0.0225\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0170 - val_loss: 0.0213\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0202 - val_loss: 0.0222\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0281 - val_loss: 0.0207\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0171 - val_loss: 0.0211\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0174 - val_loss: 0.0199\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0208\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0212\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0197 - val_loss: 0.0201\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.0215\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0189 - val_loss: 0.0186\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0179 - val_loss: 0.0180\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0211 - val_loss: 0.0176\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.0203\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0168 - val_loss: 0.0203\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.0171\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0207 - val_loss: 0.0180\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0138 - val_loss: 0.0204\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0160 - val_loss: 0.0176\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0172 - val_loss: 0.0150\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0136 - val_loss: 0.0167\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0194\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0136 - val_loss: 0.0196\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0136 - val_loss: 0.0141\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0151 - val_loss: 0.0175\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.0156\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0100 - val_loss: 0.0166\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0089 - val_loss: 0.0155\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.0185\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0156\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0194\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0135 - val_loss: 0.0152\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0130\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0104 - val_loss: 0.0152\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0143\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0157\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0139\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0096 - val_loss: 0.0140\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0175\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0150 - val_loss: 0.0182\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0129\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0104 - val_loss: 0.0229\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0114 - val_loss: 0.0158\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0083 - val_loss: 0.0159\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0135 - val_loss: 0.0190\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0120\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0076 - val_loss: 0.0124\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0147\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0132\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0143\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0081 - val_loss: 0.0151\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0068 - val_loss: 0.0119\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0067 - val_loss: 0.0121\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0049 - val_loss: 0.0136\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0064 - val_loss: 0.0123\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0080 - val_loss: 0.0142\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0163\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0112\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0062 - val_loss: 0.0128\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0066 - val_loss: 0.0117\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0056 - val_loss: 0.0129\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0066 - val_loss: 0.0137\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0059 - val_loss: 0.0123\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0061 - val_loss: 0.0127\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0074 - val_loss: 0.0154\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0072 - val_loss: 0.0152\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0064 - val_loss: 0.0118\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0060 - val_loss: 0.0128\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0057 - val_loss: 0.0127\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0055 - val_loss: 0.0138\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0056 - val_loss: 0.0135\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0044 - val_loss: 0.0130\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0057 - val_loss: 0.0143\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0072 - val_loss: 0.0131\n",
      "Epoch 140/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0052 - val_loss: 0.0130\n",
      "Epoch 141/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0050 - val_loss: 0.0118\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A87ACA7940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 58ms/step - loss: 0.1125 - val_loss: 0.0322\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0248 - val_loss: 0.0280\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0269 - val_loss: 0.0332\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0326 - val_loss: 0.0348\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0260 - val_loss: 0.0274\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0215 - val_loss: 0.0293\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0245 - val_loss: 0.0256\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0290 - val_loss: 0.0260\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0239 - val_loss: 0.0250\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0207 - val_loss: 0.0277\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0280 - val_loss: 0.0251\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0300 - val_loss: 0.0250\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0277 - val_loss: 0.0270\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0199 - val_loss: 0.0248\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0235 - val_loss: 0.0259\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0246 - val_loss: 0.0244\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0244 - val_loss: 0.0254\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0213 - val_loss: 0.0267\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.0262\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0202 - val_loss: 0.0253\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0251 - val_loss: 0.0245\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0255 - val_loss: 0.0240\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0238 - val_loss: 0.0246\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0237 - val_loss: 0.0239\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0229 - val_loss: 0.0236\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0287 - val_loss: 0.0249\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0239 - val_loss: 0.0236\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0221 - val_loss: 0.0260\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0255 - val_loss: 0.0238\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0247 - val_loss: 0.0238\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0250 - val_loss: 0.0240\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0241 - val_loss: 0.0237\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0237 - val_loss: 0.0266\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0189 - val_loss: 0.0263\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0233 - val_loss: 0.0233\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0190 - val_loss: 0.0234\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0241 - val_loss: 0.0249\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0199 - val_loss: 0.0233\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0202 - val_loss: 0.0359\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0244 - val_loss: 0.0234\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0273 - val_loss: 0.0261\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0285 - val_loss: 0.0230\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0221 - val_loss: 0.0227\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0205 - val_loss: 0.0255\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0198 - val_loss: 0.0230\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0204 - val_loss: 0.0282\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0302 - val_loss: 0.0256\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0176 - val_loss: 0.0225\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0220\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0188 - val_loss: 0.0221\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0264 - val_loss: 0.0251\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0219 - val_loss: 0.0216\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0213 - val_loss: 0.0236\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0209 - val_loss: 0.0239\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0200 - val_loss: 0.0219\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0195 - val_loss: 0.0232\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0223 - val_loss: 0.0249\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0206 - val_loss: 0.0211\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0237\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0188 - val_loss: 0.0206\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0214 - val_loss: 0.0205\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0218\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0191 - val_loss: 0.0201\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0212 - val_loss: 0.0199\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0158 - val_loss: 0.0205\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0207\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0199\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0195 - val_loss: 0.0205\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.0192 - val_loss: 0.0208\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0157 - val_loss: 0.0190\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0181 - val_loss: 0.0192\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0171 - val_loss: 0.0190\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0191\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0157 - val_loss: 0.0186\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0212 - val_loss: 0.0180\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0125 - val_loss: 0.0194\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0172 - val_loss: 0.0227\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0167 - val_loss: 0.0182\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0155 - val_loss: 0.0201\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0188\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0202 - val_loss: 0.0167\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0154 - val_loss: 0.0250\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0185 - val_loss: 0.0169\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0190 - val_loss: 0.0189\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0199\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0162 - val_loss: 0.0175\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0128 - val_loss: 0.0191\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0152\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0154 - val_loss: 0.0156\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0157\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0200 - val_loss: 0.0159\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0186\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0145 - val_loss: 0.0194\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0119 - val_loss: 0.0169\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0165\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0184\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0109 - val_loss: 0.0154\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.0175\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0084 - val_loss: 0.0196\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0137\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0190\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0151\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0078 - val_loss: 0.0166\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0079 - val_loss: 0.0160\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0089 - val_loss: 0.0125\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0081 - val_loss: 0.0163\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0120\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0071 - val_loss: 0.0111\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0079 - val_loss: 0.0107\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0056 - val_loss: 0.0105\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0059 - val_loss: 0.0129\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0074 - val_loss: 0.0149\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0072 - val_loss: 0.0113\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0078 - val_loss: 0.0163\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0103\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0058 - val_loss: 0.0168\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0078 - val_loss: 0.0125\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0111\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0047 - val_loss: 0.0134\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.0188\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0187\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0153\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0068 - val_loss: 0.0173\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0068 - val_loss: 0.0127\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0051 - val_loss: 0.0166\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0061 - val_loss: 0.0104\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0050 - val_loss: 0.0130\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0058 - val_loss: 0.0124\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0191\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0057 - val_loss: 0.0154\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0037 - val_loss: 0.0148\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0046 - val_loss: 0.0145\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0031 - val_loss: 0.0128\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0039 - val_loss: 0.0145\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0038 - val_loss: 0.0142\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0038 - val_loss: 0.0136\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0171\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0048 - val_loss: 0.0129\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A86F2FE3A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 35ms/step - loss: 0.0812 - val_loss: 0.0367\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0369 - val_loss: 0.0310\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0261 - val_loss: 0.0290\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0287 - val_loss: 0.0268\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0252 - val_loss: 0.0263\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0268 - val_loss: 0.0311\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0301 - val_loss: 0.0255\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0235 - val_loss: 0.0314\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0245 - val_loss: 0.0254\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0266 - val_loss: 0.0247\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0249 - val_loss: 0.0256\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0308 - val_loss: 0.0250\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0272 - val_loss: 0.0269\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0242 - val_loss: 0.0243\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0307 - val_loss: 0.0300\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0269 - val_loss: 0.0266\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0222 - val_loss: 0.0238\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0240 - val_loss: 0.0240\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0207 - val_loss: 0.0319\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0222 - val_loss: 0.0239\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0208 - val_loss: 0.0246\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0236 - val_loss: 0.0240\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.0180 - val_loss: 0.0247\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0232 - val_loss: 0.0235\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0242 - val_loss: 0.0236\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0234\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0246 - val_loss: 0.0242\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0187 - val_loss: 0.0242\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0219 - val_loss: 0.0244\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0195 - val_loss: 0.0231\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0188 - val_loss: 0.0232\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0208 - val_loss: 0.0251\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0270 - val_loss: 0.0275\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0217 - val_loss: 0.0265\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0223 - val_loss: 0.0228\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0226 - val_loss: 0.0232\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0200 - val_loss: 0.0228\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0319 - val_loss: 0.0230\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0185 - val_loss: 0.0231\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0285 - val_loss: 0.0252\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0268 - val_loss: 0.0231\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0178 - val_loss: 0.0224\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0233 - val_loss: 0.0241\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0211 - val_loss: 0.0222\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0224 - val_loss: 0.0227\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0198 - val_loss: 0.0240\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0205 - val_loss: 0.0219\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0226\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0218\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.0228\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0203 - val_loss: 0.0229\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0197 - val_loss: 0.0224\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0189 - val_loss: 0.0228\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0211 - val_loss: 0.0240\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0180 - val_loss: 0.0210\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0223\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0250 - val_loss: 0.0209\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0194 - val_loss: 0.0214\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0257 - val_loss: 0.0222\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0258 - val_loss: 0.0207\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0213 - val_loss: 0.0238\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0180 - val_loss: 0.0228\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0240 - val_loss: 0.0217\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0151 - val_loss: 0.0204\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0216 - val_loss: 0.0217\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0191 - val_loss: 0.0215\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0222 - val_loss: 0.0244\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0167 - val_loss: 0.0201\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0182 - val_loss: 0.0191\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0201 - val_loss: 0.0203\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0186 - val_loss: 0.0206\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0160 - val_loss: 0.0190\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0178 - val_loss: 0.0194\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0200\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0141 - val_loss: 0.0205\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0176 - val_loss: 0.0187\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0227\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0180 - val_loss: 0.0192\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0160 - val_loss: 0.0198\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0226 - val_loss: 0.0183\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.0194\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0151 - val_loss: 0.0163\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0174 - val_loss: 0.0189\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0141 - val_loss: 0.0208\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.0206\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0175\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0186\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0151 - val_loss: 0.0211\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0125 - val_loss: 0.0175\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0174\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0080 - val_loss: 0.0186\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0201\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0150\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0108 - val_loss: 0.0190\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0191\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0081 - val_loss: 0.0179\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0155\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0075 - val_loss: 0.0206\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0083 - val_loss: 0.0173\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0131 - val_loss: 0.0218\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0192\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0138\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0183\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0081 - val_loss: 0.0151\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0075 - val_loss: 0.0190\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 1s 28ms/step - loss: 0.0084 - val_loss: 0.0149\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0080 - val_loss: 0.0184\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0096 - val_loss: 0.0162\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0069 - val_loss: 0.0135\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0060 - val_loss: 0.0164\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0052 - val_loss: 0.0156\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0076 - val_loss: 0.0173\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0063 - val_loss: 0.0201\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0060 - val_loss: 0.0165\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0063 - val_loss: 0.0139\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0063 - val_loss: 0.0173\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0064 - val_loss: 0.0152\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0058 - val_loss: 0.0144\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0052 - val_loss: 0.0168\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0049 - val_loss: 0.0133\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0056 - val_loss: 0.0167\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0047 - val_loss: 0.0147\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0049 - val_loss: 0.0208\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0060 - val_loss: 0.0146\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0046 - val_loss: 0.0114\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0069 - val_loss: 0.0178\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0050 - val_loss: 0.0173\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0043 - val_loss: 0.0109\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0046 - val_loss: 0.0131\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0049 - val_loss: 0.0238\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0103 - val_loss: 0.0124\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0046 - val_loss: 0.0151\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0045 - val_loss: 0.0149\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0030 - val_loss: 0.0183\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0045 - val_loss: 0.0163\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0050 - val_loss: 0.0170\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0044 - val_loss: 0.0162\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0029 - val_loss: 0.0133\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0030 - val_loss: 0.0175\n",
      "Epoch 140/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0023 - val_loss: 0.0193\n",
      "Epoch 141/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0052 - val_loss: 0.0165\n",
      "Epoch 142/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0032 - val_loss: 0.0145\n",
      "Epoch 143/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0034 - val_loss: 0.0186\n",
      "Epoch 144/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0030 - val_loss: 0.0180\n",
      "Epoch 145/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0026 - val_loss: 0.0134\n",
      "Epoch 146/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0219\n",
      "Epoch 147/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0040 - val_loss: 0.0177\n",
      "Epoch 148/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0028 - val_loss: 0.0174\n",
      "Epoch 149/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0030 - val_loss: 0.0177\n",
      "Epoch 150/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0028 - val_loss: 0.0187\n",
      "Epoch 151/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0039 - val_loss: 0.0168\n",
      "Epoch 152/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0028 - val_loss: 0.0159\n",
      "Epoch 153/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0026 - val_loss: 0.0182\n",
      "Epoch 154/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0022 - val_loss: 0.0155\n",
      "Epoch 155/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0021 - val_loss: 0.0227\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A796B83310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 35ms/step - loss: 0.0986 - val_loss: 0.0333\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0333 - val_loss: 0.0361\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0276 - val_loss: 0.0277\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0344 - val_loss: 0.0299\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0279 - val_loss: 0.0269\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0213 - val_loss: 0.0263\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0293 - val_loss: 0.0258\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0322 - val_loss: 0.0299\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0261 - val_loss: 0.0254\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0262 - val_loss: 0.0330\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0260 - val_loss: 0.0365\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0212 - val_loss: 0.0277\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0250 - val_loss: 0.0248\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0218 - val_loss: 0.0243\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0206 - val_loss: 0.0280\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0288 - val_loss: 0.0278\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0200 - val_loss: 0.0239\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0261 - val_loss: 0.0240\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0197 - val_loss: 0.0281\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0247 - val_loss: 0.0253\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0226 - val_loss: 0.0270\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0300 - val_loss: 0.0303\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0194 - val_loss: 0.0255\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0235 - val_loss: 0.0235\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0267 - val_loss: 0.0248\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0239 - val_loss: 0.0268\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0269 - val_loss: 0.0290\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0254 - val_loss: 0.0238\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0231 - val_loss: 0.0249\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0219 - val_loss: 0.0235\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0169 - val_loss: 0.0235\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0234 - val_loss: 0.0248\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0187 - val_loss: 0.0232\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0316 - val_loss: 0.0252\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0232 - val_loss: 0.0236\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0188 - val_loss: 0.0227\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0233 - val_loss: 0.0225\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0233 - val_loss: 0.0230\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0278 - val_loss: 0.0246\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0240 - val_loss: 0.0234\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0267 - val_loss: 0.0272\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0195 - val_loss: 0.0237\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0178 - val_loss: 0.0225\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0169 - val_loss: 0.0226\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0227 - val_loss: 0.0233\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0179 - val_loss: 0.0303\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0216 - val_loss: 0.0229\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 1s 28ms/step - loss: 0.0238 - val_loss: 0.0237\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0223\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0248 - val_loss: 0.0221\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0216\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0208 - val_loss: 0.0222\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0173 - val_loss: 0.0236\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0202 - val_loss: 0.0213\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0246\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0182 - val_loss: 0.0208\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0209 - val_loss: 0.0208\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0202\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0200 - val_loss: 0.0217\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0290 - val_loss: 0.0236\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0139 - val_loss: 0.0209\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0249 - val_loss: 0.0234\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0185 - val_loss: 0.0229\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0201 - val_loss: 0.0203\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0180 - val_loss: 0.0206\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0204\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.0190\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0187 - val_loss: 0.0201\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0183\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0178 - val_loss: 0.0199\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0145 - val_loss: 0.0195\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0225 - val_loss: 0.0263\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0138 - val_loss: 0.0186\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0162 - val_loss: 0.0180\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0173\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0203 - val_loss: 0.0182\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0155 - val_loss: 0.0159\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0114 - val_loss: 0.0190\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0130 - val_loss: 0.0188\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0145\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0155 - val_loss: 0.0198\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.0172\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0140\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0181\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0145\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.0170\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0141 - val_loss: 0.0157\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0108 - val_loss: 0.0284\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0146 - val_loss: 0.0129\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0169\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0081 - val_loss: 0.0192\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0165\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0154\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0079 - val_loss: 0.0157\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0080 - val_loss: 0.0127\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0074 - val_loss: 0.0148\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0078 - val_loss: 0.0165\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0104 - val_loss: 0.0135\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0072 - val_loss: 0.0139\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0069 - val_loss: 0.0161\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0065 - val_loss: 0.0123\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0076 - val_loss: 0.0127\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0062 - val_loss: 0.0122\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0074 - val_loss: 0.0143\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0059 - val_loss: 0.0154\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0068 - val_loss: 0.0125\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0069 - val_loss: 0.0197\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0106 - val_loss: 0.0118\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0085 - val_loss: 0.0164\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0064 - val_loss: 0.0121\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0055 - val_loss: 0.0129\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0051 - val_loss: 0.0126\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0040 - val_loss: 0.0158\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0038 - val_loss: 0.0162\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0052 - val_loss: 0.0142\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0063 - val_loss: 0.0187\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0061 - val_loss: 0.0172\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0066 - val_loss: 0.0128\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0045 - val_loss: 0.0151\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0041 - val_loss: 0.0144\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0041 - val_loss: 0.0141\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0134\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0042 - val_loss: 0.0183\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0033 - val_loss: 0.0138\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0055 - val_loss: 0.0147\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0048 - val_loss: 0.0260\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0061 - val_loss: 0.0150\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0029 - val_loss: 0.0182\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0042 - val_loss: 0.0143\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 1s 28ms/step - loss: 0.0031 - val_loss: 0.0147\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0203\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0023 - val_loss: 0.0160\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0028 - val_loss: 0.0162\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0029 - val_loss: 0.0173\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0032 - val_loss: 0.0195\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0019 - val_loss: 0.0244\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0023 - val_loss: 0.0229\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0021 - val_loss: 0.0191\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A878363E50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 64ms/step - loss: 0.0913 - val_loss: 0.0297\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0251 - val_loss: 0.0311\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0272 - val_loss: 0.0274\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0227 - val_loss: 0.0270\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0250 - val_loss: 0.0276\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0240 - val_loss: 0.0269\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0207 - val_loss: 0.0256\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0216 - val_loss: 0.0278\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0263 - val_loss: 0.0332\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0333 - val_loss: 0.0258\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0236 - val_loss: 0.0245\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0242 - val_loss: 0.0246\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0250 - val_loss: 0.0292\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0306 - val_loss: 0.0261\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0257 - val_loss: 0.0287\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0193 - val_loss: 0.0260\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0223 - val_loss: 0.0257\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0245 - val_loss: 0.0242\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0247 - val_loss: 0.0247\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0206 - val_loss: 0.0270\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0285 - val_loss: 0.0273\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0180 - val_loss: 0.0239\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0313 - val_loss: 0.0318\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0220 - val_loss: 0.0238\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0208 - val_loss: 0.0237\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0266 - val_loss: 0.0293\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0220 - val_loss: 0.0272\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0208 - val_loss: 0.0233\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0229 - val_loss: 0.0234\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0271 - val_loss: 0.0275\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0185 - val_loss: 0.0256\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0217 - val_loss: 0.0238\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0243 - val_loss: 0.0233\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0206 - val_loss: 0.0234\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0241 - val_loss: 0.0238\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0267 - val_loss: 0.0240\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0259 - val_loss: 0.0231\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0197 - val_loss: 0.0230\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0305 - val_loss: 0.0250\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0216 - val_loss: 0.0224\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0211 - val_loss: 0.0238\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0189 - val_loss: 0.0226\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0262 - val_loss: 0.0223\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0212 - val_loss: 0.0226\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0201 - val_loss: 0.0235\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0185 - val_loss: 0.0218\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0278 - val_loss: 0.0228\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0245\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0187 - val_loss: 0.0220\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0151 - val_loss: 0.0216\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0262 - val_loss: 0.0223\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0201 - val_loss: 0.0216\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0278 - val_loss: 0.0244\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0216 - val_loss: 0.0225\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0160 - val_loss: 0.0211\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0162 - val_loss: 0.0223\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0177 - val_loss: 0.0209\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0189 - val_loss: 0.0214\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0174 - val_loss: 0.0207\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0171 - val_loss: 0.0206\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0202 - val_loss: 0.0204\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0213 - val_loss: 0.0275\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0301 - val_loss: 0.0216\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0191 - val_loss: 0.0200\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0186 - val_loss: 0.0211\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0169 - val_loss: 0.0193\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0206 - val_loss: 0.0194\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0169 - val_loss: 0.0193\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0168 - val_loss: 0.0188\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0189\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0186\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0190 - val_loss: 0.0186\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0195 - val_loss: 0.0190\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0229 - val_loss: 0.0177\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0264 - val_loss: 0.0222\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0253 - val_loss: 0.0180\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0196\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0225 - val_loss: 0.0182\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0141 - val_loss: 0.0178\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0178\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0167\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.0202\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0158 - val_loss: 0.0232\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.0165\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0113 - val_loss: 0.0184\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0143\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0168\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0213 - val_loss: 0.0233\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0190\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0162 - val_loss: 0.0165\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0186\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0130 - val_loss: 0.0166\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0135 - val_loss: 0.0191\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0134 - val_loss: 0.0178\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0135 - val_loss: 0.0187\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0172\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0215\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 1s 28ms/step - loss: 0.0106 - val_loss: 0.0168\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0199\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0163\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0183\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0203\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0104 - val_loss: 0.0176\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0084 - val_loss: 0.0170\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0096 - val_loss: 0.0177\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0068 - val_loss: 0.0156\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0186\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0085 - val_loss: 0.0163\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0070 - val_loss: 0.0194\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0076 - val_loss: 0.0152\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0073 - val_loss: 0.0181\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0154\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0070 - val_loss: 0.0193\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0073 - val_loss: 0.0129\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0049 - val_loss: 0.0214\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0044 - val_loss: 0.0158\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0050 - val_loss: 0.0169\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0059 - val_loss: 0.0175\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0050 - val_loss: 0.0198\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0038 - val_loss: 0.0154\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0054 - val_loss: 0.0214\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0031 - val_loss: 0.0167\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0029 - val_loss: 0.0136\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0041 - val_loss: 0.0254\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0038 - val_loss: 0.0237\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0148\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0054 - val_loss: 0.0138\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0048 - val_loss: 0.0148\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.0183\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0037 - val_loss: 0.0197\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0030 - val_loss: 0.0169\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0042 - val_loss: 0.0180\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0024 - val_loss: 0.0179\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0039 - val_loss: 0.0183\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 0.0131\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.0201\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0025 - val_loss: 0.0256\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0031 - val_loss: 0.0224\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0033 - val_loss: 0.0248\n",
      "Epoch 140/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 0.0194\n",
      "Epoch 141/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 0.0247\n",
      "Epoch 142/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0028 - val_loss: 0.0258\n",
      "Epoch 143/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0033 - val_loss: 0.0224\n",
      "Epoch 144/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0037 - val_loss: 0.0151\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A70DAF9CA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 34ms/step - loss: 0.0806 - val_loss: 0.0298\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0275 - val_loss: 0.0287\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0209 - val_loss: 0.0282\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0262 - val_loss: 0.0274\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0235 - val_loss: 0.0269\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0294 - val_loss: 0.0393\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0271 - val_loss: 0.0324\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0309 - val_loss: 0.0302\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0234 - val_loss: 0.0254\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0244 - val_loss: 0.0247\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0249 - val_loss: 0.0250\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0243 - val_loss: 0.0246\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0240 - val_loss: 0.0256\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0264 - val_loss: 0.0246\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0278 - val_loss: 0.0242\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0262 - val_loss: 0.0326\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0295 - val_loss: 0.0344\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0275 - val_loss: 0.0266\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0242 - val_loss: 0.0241\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0317 - val_loss: 0.0279\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0239 - val_loss: 0.0256\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0183 - val_loss: 0.0239\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0208 - val_loss: 0.0244\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0205 - val_loss: 0.0249\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0280 - val_loss: 0.0293\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.0237\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0225 - val_loss: 0.0265\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0213 - val_loss: 0.0239\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 1s 28ms/step - loss: 0.0265 - val_loss: 0.0241\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0208 - val_loss: 0.0248\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0195 - val_loss: 0.0232\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0194 - val_loss: 0.0251\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0217 - val_loss: 0.0233\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0204 - val_loss: 0.0233\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0227 - val_loss: 0.0230\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0200 - val_loss: 0.0237\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0333 - val_loss: 0.0231\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0180 - val_loss: 0.0234\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0215 - val_loss: 0.0227\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0189 - val_loss: 0.0227\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0184 - val_loss: 0.0225\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0177 - val_loss: 0.0276\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0345 - val_loss: 0.0225\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0150 - val_loss: 0.0222\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0206 - val_loss: 0.0232\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0185 - val_loss: 0.0232\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0215 - val_loss: 0.0249\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0182 - val_loss: 0.0218\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0284 - val_loss: 0.0249\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0136 - val_loss: 0.0266\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0220 - val_loss: 0.0241\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0226 - val_loss: 0.0217\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0210 - val_loss: 0.0220\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0229 - val_loss: 0.0210\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0236 - val_loss: 0.0208\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0277 - val_loss: 0.0215\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0195 - val_loss: 0.0206\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0172 - val_loss: 0.0240\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0228 - val_loss: 0.0214\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0225 - val_loss: 0.0225\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0211\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0202 - val_loss: 0.0218\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0280 - val_loss: 0.0217\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0202 - val_loss: 0.0198\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.0195\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.0197\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0198 - val_loss: 0.0199\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0151 - val_loss: 0.0234\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0193\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0198\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0182 - val_loss: 0.0200\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0156 - val_loss: 0.0183\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0138 - val_loss: 0.0187\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0154 - val_loss: 0.0183\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.0178\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0180\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0155 - val_loss: 0.0179\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0174 - val_loss: 0.0181\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0136 - val_loss: 0.0180\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0180 - val_loss: 0.0175\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0173 - val_loss: 0.0173\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0172 - val_loss: 0.0217\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0199 - val_loss: 0.0160\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0174 - val_loss: 0.0174\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.0182\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0138 - val_loss: 0.0219\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0161\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0184\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0169 - val_loss: 0.0217\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0153 - val_loss: 0.0219\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0114 - val_loss: 0.0178\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0155\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0155\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0200\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0165\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0211\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0162\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0262\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - ETA: 0s - loss: 0.017 - 0s 8ms/step - loss: 0.0172 - val_loss: 0.0141\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0104 - val_loss: 0.0155\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0206\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0181\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0155\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0107 - val_loss: 0.0195\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0202\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0166\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0212\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0181\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0096 - val_loss: 0.0148\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0067 - val_loss: 0.0150\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0075 - val_loss: 0.0164\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0073 - val_loss: 0.0132\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0067 - val_loss: 0.0155\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0061 - val_loss: 0.0158\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0085 - val_loss: 0.0242\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0133\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0147\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0074 - val_loss: 0.0120\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0058 - val_loss: 0.0175\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0065 - val_loss: 0.0135\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0070 - val_loss: 0.0155\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0068 - val_loss: 0.0147\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0042 - val_loss: 0.0134\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0047 - val_loss: 0.0180\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0063 - val_loss: 0.0115\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0059 - val_loss: 0.0133\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0075 - val_loss: 0.0128\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0053 - val_loss: 0.0128\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0041 - val_loss: 0.0133\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0046 - val_loss: 0.0183\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0039 - val_loss: 0.0162\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.0049 - val_loss: 0.0151\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0026 - val_loss: 0.0148\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0024 - val_loss: 0.0147\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.0149\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0032 - val_loss: 0.0165\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0032 - val_loss: 0.0170\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0025 - val_loss: 0.0162\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0037 - val_loss: 0.0155\n",
      "Epoch 140/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0029 - val_loss: 0.0138\n",
      "Epoch 141/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0040 - val_loss: 0.0152\n",
      "Epoch 142/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0132\n",
      "Epoch 143/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0029 - val_loss: 0.0141\n",
      "Epoch 144/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0030 - val_loss: 0.0185\n",
      "Epoch 145/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0041 - val_loss: 0.0178\n",
      "Epoch 146/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0037 - val_loss: 0.0184\n",
      "Epoch 147/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0036 - val_loss: 0.0165\n",
      "Epoch 148/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0027 - val_loss: 0.0172\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A85F90B5E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 34ms/step - loss: 0.0557 - val_loss: 0.0284\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0395 - val_loss: 0.0499\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0352 - val_loss: 0.0270\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0259 - val_loss: 0.0265\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0257 - val_loss: 0.0387\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0269 - val_loss: 0.0274\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0268 - val_loss: 0.0281\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0250 - val_loss: 0.0258\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0241 - val_loss: 0.0255\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0248 - val_loss: 0.0275\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0244\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0210 - val_loss: 0.0242\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0204 - val_loss: 0.0253\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0264 - val_loss: 0.0291\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0207 - val_loss: 0.0253\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0222 - val_loss: 0.0242\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0206 - val_loss: 0.0239\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0220 - val_loss: 0.0294\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0243 - val_loss: 0.0269\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0207 - val_loss: 0.0252\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0301 - val_loss: 0.0240\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0239 - val_loss: 0.0238\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0221 - val_loss: 0.0261\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0247 - val_loss: 0.0261\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0210 - val_loss: 0.0297\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0204 - val_loss: 0.0253\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0214 - val_loss: 0.0234\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0187 - val_loss: 0.0256\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0265 - val_loss: 0.0289\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0214 - val_loss: 0.0247\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0210 - val_loss: 0.0237\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0186 - val_loss: 0.0235\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0232\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0275 - val_loss: 0.0308\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0194 - val_loss: 0.0298\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0258 - val_loss: 0.0230\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0218 - val_loss: 0.0322\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0263 - val_loss: 0.0381\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0222 - val_loss: 0.0279\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0210 - val_loss: 0.0231\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0255 - val_loss: 0.0282\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0246 - val_loss: 0.0280\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0162 - val_loss: 0.0225\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0185 - val_loss: 0.0227\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0185 - val_loss: 0.0238\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0209 - val_loss: 0.0238\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0206 - val_loss: 0.0312\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0248 - val_loss: 0.0222\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0218 - val_loss: 0.0220\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0225\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0194 - val_loss: 0.0229\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0235 - val_loss: 0.0316\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0258 - val_loss: 0.0222\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0202 - val_loss: 0.0241\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0185 - val_loss: 0.0210\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.0235\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0201 - val_loss: 0.0225\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0208 - val_loss: 0.0213\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0201 - val_loss: 0.0220\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0229 - val_loss: 0.0236\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0182 - val_loss: 0.0219\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0213\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0200\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0171 - val_loss: 0.0221\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0198 - val_loss: 0.0243\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0172 - val_loss: 0.0192\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.0159 - val_loss: 0.0208\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0203 - val_loss: 0.0195\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 20ms/step - loss: 0.0192 - val_loss: 0.0189\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0193 - val_loss: 0.0218\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0202 - val_loss: 0.0215\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.0212\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0216 - val_loss: 0.0192\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0181\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0159 - val_loss: 0.0197\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.0175\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0213\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.0181\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0188\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0162 - val_loss: 0.0184\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0189\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0139 - val_loss: 0.0173\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0206 - val_loss: 0.0229\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0190 - val_loss: 0.0236\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0257 - val_loss: 0.0244\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0268 - val_loss: 0.0189\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0173 - val_loss: 0.0177\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0208 - val_loss: 0.0173\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0165\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0136 - val_loss: 0.0158\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0173\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0184\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0159 - val_loss: 0.0168\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0138 - val_loss: 0.0183\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0114 - val_loss: 0.0190\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0186\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0122 - val_loss: 0.0195\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0100 - val_loss: 0.0185\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0080 - val_loss: 0.0231\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0128 - val_loss: 0.0143\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0166\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0115 - val_loss: 0.0179\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0112 - val_loss: 0.0148\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0113 - val_loss: 0.0171\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0199\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0076 - val_loss: 0.0151\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0118 - val_loss: 0.0169\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0058 - val_loss: 0.0146\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0105 - val_loss: 0.0173\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0087 - val_loss: 0.0199\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0088 - val_loss: 0.0162\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0073 - val_loss: 0.0149\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0057 - val_loss: 0.0166\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0067 - val_loss: 0.0120\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0083 - val_loss: 0.0135\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0065 - val_loss: 0.0180\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0059 - val_loss: 0.0124\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0068 - val_loss: 0.0145\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0061 - val_loss: 0.0121\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0048 - val_loss: 0.0091\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0054 - val_loss: 0.0124\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0035 - val_loss: 0.0133\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0073 - val_loss: 0.0126\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0056 - val_loss: 0.0138\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0054 - val_loss: 0.0115\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0046 - val_loss: 0.0143\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0040 - val_loss: 0.0187\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0051 - val_loss: 0.0142\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0033 - val_loss: 0.0131\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0039 - val_loss: 0.0204\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0042 - val_loss: 0.0157\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0049 - val_loss: 0.0156\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0055 - val_loss: 0.0151\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0049 - val_loss: 0.0183\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0031 - val_loss: 0.0174\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0028 - val_loss: 0.0135\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0035 - val_loss: 0.0230\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0030 - val_loss: 0.0177\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0033 - val_loss: 0.0202\n",
      "Epoch 140/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0031 - val_loss: 0.0187\n",
      "Epoch 141/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0253\n",
      "Epoch 142/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0045 - val_loss: 0.0229\n",
      "Epoch 143/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0039 - val_loss: 0.0229\n",
      "Epoch 144/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.0192\n",
      "Epoch 145/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0035 - val_loss: 0.0242\n",
      "Epoch 146/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0035 - val_loss: 0.0151\n",
      "Epoch 147/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0023 - val_loss: 0.0206\n",
      "Epoch 148/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0025 - val_loss: 0.0173\n",
      "Epoch 149/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 0.0187\n",
      "Epoch 150/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0023 - val_loss: 0.0215\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A839598C10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 35ms/step - loss: 0.0862 - val_loss: 0.0290\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0372 - val_loss: 0.0292\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0286 - val_loss: 0.0387\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0335 - val_loss: 0.0347\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0280 - val_loss: 0.0287\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.0207 - val_loss: 0.0270\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0190 - val_loss: 0.0264\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0267 - val_loss: 0.0277\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0285 - val_loss: 0.0265\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0189 - val_loss: 0.0248\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0272 - val_loss: 0.0248\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0188 - val_loss: 0.0283\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0186 - val_loss: 0.0343\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0207 - val_loss: 0.0254\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0344 - val_loss: 0.0272\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0218 - val_loss: 0.0310\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0287 - val_loss: 0.0242\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0185 - val_loss: 0.0261\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0216 - val_loss: 0.0308\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0335 - val_loss: 0.0244\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0179 - val_loss: 0.0249\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0220 - val_loss: 0.0250\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0192 - val_loss: 0.0238\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0271 - val_loss: 0.0267\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0279 - val_loss: 0.0263\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0160 - val_loss: 0.0241\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0217 - val_loss: 0.0234\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0249 - val_loss: 0.0262\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0225 - val_loss: 0.0274\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0193 - val_loss: 0.0233\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0210 - val_loss: 0.0233\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0194 - val_loss: 0.0277\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0310 - val_loss: 0.0232\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0183 - val_loss: 0.0232\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0270 - val_loss: 0.0230\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0266 - val_loss: 0.0243\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0202 - val_loss: 0.0244\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0238 - val_loss: 0.0290\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0230 - val_loss: 0.0262\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0194 - val_loss: 0.0227\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0160 - val_loss: 0.0226\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0199 - val_loss: 0.0236\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0202 - val_loss: 0.0270\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0252 - val_loss: 0.0261\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0245 - val_loss: 0.0343\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0239 - val_loss: 0.0250\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0233 - val_loss: 0.0218\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0215 - val_loss: 0.0257\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0205 - val_loss: 0.0217\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0200 - val_loss: 0.0266\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0191 - val_loss: 0.0230\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0199 - val_loss: 0.0219\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0226\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0229 - val_loss: 0.0326\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0200 - val_loss: 0.0224\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0217\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0199 - val_loss: 0.0207\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0186 - val_loss: 0.0205\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0157 - val_loss: 0.0209\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0226 - val_loss: 0.0217\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0169 - val_loss: 0.0209\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0190 - val_loss: 0.0210\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0220 - val_loss: 0.0210\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0194 - val_loss: 0.0194\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0209 - val_loss: 0.0208\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0197 - val_loss: 0.0204\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0198 - val_loss: 0.0225\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0190\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0219 - val_loss: 0.0194\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0194\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0201\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.0195\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0138 - val_loss: 0.0194\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0146 - val_loss: 0.0223\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0196 - val_loss: 0.0186\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.0250\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0182\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0164 - val_loss: 0.0195\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0224 - val_loss: 0.0177\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0183 - val_loss: 0.0170\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0125 - val_loss: 0.0185\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0157\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0126 - val_loss: 0.0190\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0222\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0189 - val_loss: 0.0166\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0133 - val_loss: 0.0165\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0124 - val_loss: 0.0167\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0183 - val_loss: 0.0155\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0228\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0155 - val_loss: 0.0258\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0156 - val_loss: 0.0185\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0139 - val_loss: 0.0173\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0240\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0195\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0149 - val_loss: 0.0132\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0119 - val_loss: 0.0169\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0123 - val_loss: 0.0200\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0156\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0137\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0136 - val_loss: 0.0179\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0115 - val_loss: 0.0108\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0107 - val_loss: 0.0134\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0081 - val_loss: 0.0174\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0149\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0135\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0198\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0208\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0107 - val_loss: 0.0119\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.0068 - val_loss: 0.0138\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0081 - val_loss: 0.0137\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0062 - val_loss: 0.0152\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0072 - val_loss: 0.0134\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0075 - val_loss: 0.0141\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0115\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0075 - val_loss: 0.0150\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0070 - val_loss: 0.0142\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0075 - val_loss: 0.0156\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0076 - val_loss: 0.0183\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0090 - val_loss: 0.0151\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0073 - val_loss: 0.0157\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0145\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0104\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0134\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0066 - val_loss: 0.0106\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0067 - val_loss: 0.0099\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0063 - val_loss: 0.0116\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0038 - val_loss: 0.0102\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0044 - val_loss: 0.0123\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0049 - val_loss: 0.0104\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0054 - val_loss: 0.0109\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0042 - val_loss: 0.0117\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A8399850D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 36ms/step - loss: 0.0603 - val_loss: 0.0298\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0337 - val_loss: 0.0275\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0240 - val_loss: 0.0280\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0259 - val_loss: 0.0263\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0256 - val_loss: 0.0265\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0226 - val_loss: 0.0286\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0378 - val_loss: 0.0256\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0262 - val_loss: 0.0253\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0271 - val_loss: 0.0255\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0290 - val_loss: 0.0281\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0185 - val_loss: 0.0244\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0265 - val_loss: 0.0333\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0332 - val_loss: 0.0258\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0275\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0226 - val_loss: 0.0246\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0269 - val_loss: 0.0242\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0186 - val_loss: 0.0247\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0262 - val_loss: 0.0246\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0222 - val_loss: 0.0254\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0305 - val_loss: 0.0271\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0190 - val_loss: 0.0261\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0147 - val_loss: 0.0247\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0343 - val_loss: 0.0245\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0337 - val_loss: 0.0236\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0229 - val_loss: 0.0243\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0272 - val_loss: 0.0247\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0185 - val_loss: 0.0299\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0211 - val_loss: 0.0237\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0185 - val_loss: 0.0278\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0263 - val_loss: 0.0245\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0319 - val_loss: 0.0234\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.0234\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0262 - val_loss: 0.0232\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0227 - val_loss: 0.0259\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0281 - val_loss: 0.0234\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0206 - val_loss: 0.0271\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0199 - val_loss: 0.0245\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0240 - val_loss: 0.0288\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0201 - val_loss: 0.0229\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0304 - val_loss: 0.0286\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.0231\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0235 - val_loss: 0.0264\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0228\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0198 - val_loss: 0.0234\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0239 - val_loss: 0.0231\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0217\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0195 - val_loss: 0.0221\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0221 - val_loss: 0.0238\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0226 - val_loss: 0.0253\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0196 - val_loss: 0.0214\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0212\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0223 - val_loss: 0.0250\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0167 - val_loss: 0.0207\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0221\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0174 - val_loss: 0.0206\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0242 - val_loss: 0.0264\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0202 - val_loss: 0.0234\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 1s 28ms/step - loss: 0.0173 - val_loss: 0.0305\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0233 - val_loss: 0.0199\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0207 - val_loss: 0.0198\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0193\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0160 - val_loss: 0.0255\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0143 - val_loss: 0.0215\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0198\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0225 - val_loss: 0.0205\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0217 - val_loss: 0.0185\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.0211\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0195 - val_loss: 0.0193\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0178 - val_loss: 0.0207\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0178 - val_loss: 0.0211\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0183 - val_loss: 0.0178\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0119 - val_loss: 0.0172\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0156 - val_loss: 0.0181\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0208\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0149 - val_loss: 0.0222\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0160 - val_loss: 0.0220\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0223\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0171 - val_loss: 0.0184\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0184 - val_loss: 0.0175\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0152 - val_loss: 0.0178\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0145 - val_loss: 0.0152\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0169 - val_loss: 0.0174\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0149 - val_loss: 0.0157\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0169\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0174\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0136 - val_loss: 0.0197\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0128 - val_loss: 0.0162\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0134 - val_loss: 0.0219\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0167\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0176\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0125 - val_loss: 0.0183\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0167\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0119 - val_loss: 0.0173\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0179\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0160\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0209\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0076 - val_loss: 0.0135\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0158\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0078 - val_loss: 0.0292\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0160\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0187\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0084 - val_loss: 0.0195\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0194\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0064 - val_loss: 0.0140\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0069 - val_loss: 0.0213\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0082 - val_loss: 0.0123\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0051 - val_loss: 0.0163\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0062 - val_loss: 0.0141\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0054 - val_loss: 0.0132\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0077 - val_loss: 0.0228\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0071 - val_loss: 0.0146\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0052 - val_loss: 0.0186\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0057 - val_loss: 0.0164\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0073 - val_loss: 0.0186\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0089 - val_loss: 0.0187\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0067 - val_loss: 0.0185\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0041 - val_loss: 0.0165\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0065 - val_loss: 0.0167\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0064 - val_loss: 0.0145\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0037 - val_loss: 0.0152\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0047 - val_loss: 0.0147\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0043 - val_loss: 0.0170\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0058 - val_loss: 0.0222\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0054 - val_loss: 0.0175\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0039 - val_loss: 0.0208\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0037 - val_loss: 0.0167\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0045 - val_loss: 0.0174\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0044 - val_loss: 0.0199\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0037 - val_loss: 0.0171\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0033 - val_loss: 0.0187\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0032 - val_loss: 0.0218\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0028 - val_loss: 0.0179\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0027 - val_loss: 0.0183\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0028 - val_loss: 0.0194\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0037 - val_loss: 0.0204\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0036 - val_loss: 0.0167\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A70C8DA5E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 36ms/step - loss: 0.0537 - val_loss: 0.0334\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0339 - val_loss: 0.0277\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0234 - val_loss: 0.0270\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0301 - val_loss: 0.0264\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0302 - val_loss: 0.0362\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0206 - val_loss: 0.0260\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0297 - val_loss: 0.0317\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0192 - val_loss: 0.0255\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0206 - val_loss: 0.0259\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0238 - val_loss: 0.0246\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0186 - val_loss: 0.0303\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0262 - val_loss: 0.0256\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0228 - val_loss: 0.0245\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0322 - val_loss: 0.0242\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.0218 - val_loss: 0.0242\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0204 - val_loss: 0.0320\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0267 - val_loss: 0.0254\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0198 - val_loss: 0.0242\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0272 - val_loss: 0.0295\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0234 - val_loss: 0.0279\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0225 - val_loss: 0.0241\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0223 - val_loss: 0.0238\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0247 - val_loss: 0.0241\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0256 - val_loss: 0.0238\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0226 - val_loss: 0.0238\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0204 - val_loss: 0.0265\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0233 - val_loss: 0.0240\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0266 - val_loss: 0.0249\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0250 - val_loss: 0.0244\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0227 - val_loss: 0.0234\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0209 - val_loss: 0.0232\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0285 - val_loss: 0.0232\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0221 - val_loss: 0.0250\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0203 - val_loss: 0.0264\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0261 - val_loss: 0.0234\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0176 - val_loss: 0.0226\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0218 - val_loss: 0.0229\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0205 - val_loss: 0.0225\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0178 - val_loss: 0.0243\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0235 - val_loss: 0.0261\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0235 - val_loss: 0.0256\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0208 - val_loss: 0.0222\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0231 - val_loss: 0.0223\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0227 - val_loss: 0.0225\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0205 - val_loss: 0.0223\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0238 - val_loss: 0.0332\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0327 - val_loss: 0.0227\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0197 - val_loss: 0.0277\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0259 - val_loss: 0.0218\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0243 - val_loss: 0.0254\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0228\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0212\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0207 - val_loss: 0.0210\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0181 - val_loss: 0.0309\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0242 - val_loss: 0.0215\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0211 - val_loss: 0.0242\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0210 - val_loss: 0.0210\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0173 - val_loss: 0.0204\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0153 - val_loss: 0.0208\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0230 - val_loss: 0.0213\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0189 - val_loss: 0.0206\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0149 - val_loss: 0.0211\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0172 - val_loss: 0.0202\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0194\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0142 - val_loss: 0.0192\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0159 - val_loss: 0.0198\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0162 - val_loss: 0.0201\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0186 - val_loss: 0.0206\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0203 - val_loss: 0.0222\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0149 - val_loss: 0.0200\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0154 - val_loss: 0.0202\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0177 - val_loss: 0.0182\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0407\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0301 - val_loss: 0.0177\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0193\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0179 - val_loss: 0.0184\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0136 - val_loss: 0.0260\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0188 - val_loss: 0.0178\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0123 - val_loss: 0.0204\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0167\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0160 - val_loss: 0.0221\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0157\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0138 - val_loss: 0.0167\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.0158\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0173\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0187\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0143 - val_loss: 0.0154\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0150\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0197\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0205 - val_loss: 0.0193\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0128 - val_loss: 0.0181\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0153\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0119 - val_loss: 0.0188\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0175\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0178\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0107 - val_loss: 0.0137\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.0109 - val_loss: 0.0136\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.0167\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0134\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0127\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0158\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0083 - val_loss: 0.0194\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0138\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0108\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0064 - val_loss: 0.0100\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0058 - val_loss: 0.0120\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0057 - val_loss: 0.0123\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0070 - val_loss: 0.0173\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0060 - val_loss: 0.0159\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0080 - val_loss: 0.0139\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0065 - val_loss: 0.0116\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0112\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0077 - val_loss: 0.0132\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0063 - val_loss: 0.0107\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0062 - val_loss: 0.0129\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0037 - val_loss: 0.0107\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0051 - val_loss: 0.0106\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0046 - val_loss: 0.0135\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0054 - val_loss: 0.0134\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0045 - val_loss: 0.0107\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0037 - val_loss: 0.0115\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0121\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0041 - val_loss: 0.0119\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0031 - val_loss: 0.0148\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0022 - val_loss: 0.0142\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0047 - val_loss: 0.0137\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0037 - val_loss: 0.0120\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0025 - val_loss: 0.0155\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0056 - val_loss: 0.0131\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0030 - val_loss: 0.0120\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0034 - val_loss: 0.0149\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0028 - val_loss: 0.0149\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0022 - val_loss: 0.0154\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0030 - val_loss: 0.0120\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A70DC8CB80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 36ms/step - loss: 0.0550 - val_loss: 0.0339\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0336 - val_loss: 0.0428\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0287 - val_loss: 0.0336\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0354 - val_loss: 0.0348\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0155 - val_loss: 0.0329\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0353 - val_loss: 0.0274\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0316 - val_loss: 0.0261\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0242 - val_loss: 0.0256\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0228 - val_loss: 0.0258\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0232 - val_loss: 0.0247\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0298 - val_loss: 0.0280\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0283 - val_loss: 0.0302\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0223 - val_loss: 0.0246\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0172 - val_loss: 0.0272\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0276 - val_loss: 0.0246\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0211 - val_loss: 0.0258\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0237 - val_loss: 0.0260\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0218 - val_loss: 0.0245\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0241 - val_loss: 0.0246\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0247 - val_loss: 0.0339\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0200 - val_loss: 0.0273\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0250 - val_loss: 0.0248\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0219 - val_loss: 0.0261\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0309 - val_loss: 0.0247\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0197 - val_loss: 0.0249\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0202 - val_loss: 0.0237\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0199 - val_loss: 0.0264\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0254 - val_loss: 0.0253\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0311 - val_loss: 0.0263\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0176 - val_loss: 0.0237\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0223 - val_loss: 0.0265\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0174 - val_loss: 0.0251\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0198 - val_loss: 0.0231\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0224 - val_loss: 0.0287\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.0241\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0238 - val_loss: 0.0227\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0223 - val_loss: 0.0241\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0245 - val_loss: 0.0229\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0241 - val_loss: 0.0227\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0194 - val_loss: 0.0223\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0213 - val_loss: 0.0231\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0224 - val_loss: 0.0242\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0277 - val_loss: 0.0302\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0165 - val_loss: 0.0220\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0181 - val_loss: 0.0216\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0199 - val_loss: 0.0227\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0191 - val_loss: 0.0236\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0183 - val_loss: 0.0219\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0169 - val_loss: 0.0274\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0262 - val_loss: 0.0216\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0196 - val_loss: 0.0227\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.0206\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0208\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0214 - val_loss: 0.0210\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0158 - val_loss: 0.0223\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0189 - val_loss: 0.0202\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0162 - val_loss: 0.0220\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0198\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0186 - val_loss: 0.0202\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0185 - val_loss: 0.0205\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0176 - val_loss: 0.0190\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.0191 - val_loss: 0.0188\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0176 - val_loss: 0.0234\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0172 - val_loss: 0.0185\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0268 - val_loss: 0.0215\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0202 - val_loss: 0.0190\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0181 - val_loss: 0.0193\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0171 - val_loss: 0.0181\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0142 - val_loss: 0.0189\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0196 - val_loss: 0.0222\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0231 - val_loss: 0.0218\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0265 - val_loss: 0.0220\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0205 - val_loss: 0.0182\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0171 - val_loss: 0.0191\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0167 - val_loss: 0.0171\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0153 - val_loss: 0.0169\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0154 - val_loss: 0.0181\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0181 - val_loss: 0.0193\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0134 - val_loss: 0.0165\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0166 - val_loss: 0.0175\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0115 - val_loss: 0.0164\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0177\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0203\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0136 - val_loss: 0.0177\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0123 - val_loss: 0.0199\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0144 - val_loss: 0.0158\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0155\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0158 - val_loss: 0.0191\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0128 - val_loss: 0.0151\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0118 - val_loss: 0.0149\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0113 - val_loss: 0.0178\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0156\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0074 - val_loss: 0.0174\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0133\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0079 - val_loss: 0.0148\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0156\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0114 - val_loss: 0.0167\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0118 - val_loss: 0.0165\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0165\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0124 - val_loss: 0.0145\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0108 - val_loss: 0.0114\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0100 - val_loss: 0.0143\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0077 - val_loss: 0.0116\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0078 - val_loss: 0.0118\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0067 - val_loss: 0.0136\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0074 - val_loss: 0.0137\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0090 - val_loss: 0.0121\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0071 - val_loss: 0.0120\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0066 - val_loss: 0.0120\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0070 - val_loss: 0.0130\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0075 - val_loss: 0.0121\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0044 - val_loss: 0.0126\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0259\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0131 - val_loss: 0.0173\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0163 - val_loss: 0.0174\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0122 - val_loss: 0.0172\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0121 - val_loss: 0.0184\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0079 - val_loss: 0.0166\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0149\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0075 - val_loss: 0.0171\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0080 - val_loss: 0.0147\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0044 - val_loss: 0.0206\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0089 - val_loss: 0.0148\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0066 - val_loss: 0.0152\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0063 - val_loss: 0.0134\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0051 - val_loss: 0.0118\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0046 - val_loss: 0.0155\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0038 - val_loss: 0.0134\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0054 - val_loss: 0.0141\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0045 - val_loss: 0.0171\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0046 - val_loss: 0.0129\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A8876C3040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 36ms/step - loss: 0.0679 - val_loss: 0.0463\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0419 - val_loss: 0.0290\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.0278 - val_loss: 0.0286\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0328 - val_loss: 0.0277\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0210 - val_loss: 0.0292\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0339 - val_loss: 0.0262\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0258 - val_loss: 0.0259\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0270 - val_loss: 0.0293\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0228 - val_loss: 0.0265\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0263 - val_loss: 0.0320\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0220 - val_loss: 0.0246\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0264 - val_loss: 0.0250\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0202 - val_loss: 0.0275\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0192 - val_loss: 0.0367\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0214 - val_loss: 0.0250\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0250 - val_loss: 0.0269\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0247 - val_loss: 0.0315\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0200 - val_loss: 0.0300\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0198 - val_loss: 0.0257\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0217 - val_loss: 0.0256\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0206 - val_loss: 0.0247\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0178 - val_loss: 0.0269\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0250 - val_loss: 0.0250\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0251 - val_loss: 0.0242\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0252 - val_loss: 0.0238\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0269 - val_loss: 0.0236\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0230 - val_loss: 0.0309\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0395 - val_loss: 0.0252\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0225 - val_loss: 0.0261\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0235 - val_loss: 0.0253\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0183 - val_loss: 0.0244\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0185 - val_loss: 0.0232\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0207 - val_loss: 0.0261\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0214 - val_loss: 0.0249\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0251 - val_loss: 0.0234\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0227 - val_loss: 0.0252\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0280 - val_loss: 0.0247\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0258 - val_loss: 0.0252\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0173 - val_loss: 0.0226\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0263 - val_loss: 0.0254\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0190 - val_loss: 0.0257\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0191 - val_loss: 0.0235\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0198 - val_loss: 0.0265\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0225 - val_loss: 0.0252\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0230 - val_loss: 0.0228\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0183 - val_loss: 0.0253\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0193 - val_loss: 0.0233\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0176 - val_loss: 0.0234\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0244 - val_loss: 0.0222\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0218 - val_loss: 0.0224\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0250 - val_loss: 0.0219\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.0212\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0205 - val_loss: 0.0214\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0148 - val_loss: 0.0213\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0189 - val_loss: 0.0219\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0227 - val_loss: 0.0219\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0194 - val_loss: 0.0228\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0211 - val_loss: 0.0203\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0201 - val_loss: 0.0212\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0155 - val_loss: 0.0207\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0204\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0140 - val_loss: 0.0206\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0176 - val_loss: 0.0204\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0207 - val_loss: 0.0206\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.0241\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0162 - val_loss: 0.0214\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0155 - val_loss: 0.0199\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0201\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0187 - val_loss: 0.0196\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0173 - val_loss: 0.0201\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0190 - val_loss: 0.0220\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0169 - val_loss: 0.0184\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0198 - val_loss: 0.0188\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0150 - val_loss: 0.0176\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0160 - val_loss: 0.0199\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0251 - val_loss: 0.0199\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.0171\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0136 - val_loss: 0.0176\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0164\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0187 - val_loss: 0.0150\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.0192\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.0156\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0150 - val_loss: 0.0170\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0119 - val_loss: 0.0180\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0173 - val_loss: 0.0209\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0156 - val_loss: 0.0197\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0128 - val_loss: 0.0169\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0171\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0083 - val_loss: 0.0181\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0132 - val_loss: 0.0183\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0107 - val_loss: 0.0203\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0167\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0135 - val_loss: 0.0186\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0157 - val_loss: 0.0144\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0151\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0171\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0128 - val_loss: 0.0156\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.0218\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0145\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0063 - val_loss: 0.0172\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0119 - val_loss: 0.0164\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0139 - val_loss: 0.0134\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0084 - val_loss: 0.0191\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0132\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.0070 - val_loss: 0.0173\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0124\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0062 - val_loss: 0.0170\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0078 - val_loss: 0.0221\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0139 - val_loss: 0.0138\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0051 - val_loss: 0.0158\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0074 - val_loss: 0.0157\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0058 - val_loss: 0.0128\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0059 - val_loss: 0.0154\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0141\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0078 - val_loss: 0.0175\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0073 - val_loss: 0.0159\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0075 - val_loss: 0.0159\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0204\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0071 - val_loss: 0.0192\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0080 - val_loss: 0.0168\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0061 - val_loss: 0.0144\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0062 - val_loss: 0.0219\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0059 - val_loss: 0.0183\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0074 - val_loss: 0.0192\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0128\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0058 - val_loss: 0.0201\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0065 - val_loss: 0.0183\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0041 - val_loss: 0.0154\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0033 - val_loss: 0.0182\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0043 - val_loss: 0.0160\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0170\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0030 - val_loss: 0.0203\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0055 - val_loss: 0.0162\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0039 - val_loss: 0.0159\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0040 - val_loss: 0.0201\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0038 - val_loss: 0.0179\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A8876C3B80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 35ms/step - loss: 0.0275 - val_loss: 0.0317\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0252 - val_loss: 0.0281\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0335 - val_loss: 0.0287\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0303 - val_loss: 0.0289\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0276 - val_loss: 0.0258\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0260 - val_loss: 0.0268\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0319 - val_loss: 0.0249\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0228 - val_loss: 0.0355\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0199 - val_loss: 0.0254\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0331 - val_loss: 0.0269\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0245 - val_loss: 0.0276\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0222 - val_loss: 0.0286\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0302 - val_loss: 0.0325\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0245 - val_loss: 0.0288\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0311 - val_loss: 0.0241\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0244 - val_loss: 0.0243\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0323 - val_loss: 0.0269\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0235 - val_loss: 0.0263\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0230 - val_loss: 0.0251\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0262 - val_loss: 0.0400\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0259 - val_loss: 0.0244\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0211 - val_loss: 0.0305\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0233 - val_loss: 0.0242\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0211 - val_loss: 0.0298\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0187 - val_loss: 0.0237\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0268 - val_loss: 0.0237\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0290 - val_loss: 0.0256\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0216 - val_loss: 0.0238\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0251 - val_loss: 0.0246\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0221 - val_loss: 0.0240\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0220 - val_loss: 0.0236\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0187 - val_loss: 0.0236\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0269 - val_loss: 0.0258\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0214 - val_loss: 0.0230\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0189 - val_loss: 0.0246\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0279 - val_loss: 0.0238\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0267 - val_loss: 0.0239\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0162 - val_loss: 0.0330\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0244 - val_loss: 0.0228\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0184 - val_loss: 0.0264\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0241 - val_loss: 0.0257\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0231 - val_loss: 0.0239\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0221 - val_loss: 0.0228\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0201 - val_loss: 0.0242\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0164 - val_loss: 0.0219\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.0163 - val_loss: 0.0224\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0219\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0173 - val_loss: 0.0221\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0224 - val_loss: 0.0246\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0256 - val_loss: 0.0231\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0181 - val_loss: 0.0217\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0177 - val_loss: 0.0218\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0196 - val_loss: 0.0229\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0189 - val_loss: 0.0217\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0195 - val_loss: 0.0206\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0232 - val_loss: 0.0202\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0201 - val_loss: 0.0235\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0152 - val_loss: 0.0200\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0183 - val_loss: 0.0266\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0178 - val_loss: 0.0230\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0285 - val_loss: 0.0213\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0206 - val_loss: 0.0223\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0159 - val_loss: 0.0194\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.0197\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0178 - val_loss: 0.0206\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0204 - val_loss: 0.0187\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0189\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0192 - val_loss: 0.0208\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0174 - val_loss: 0.0183\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0156 - val_loss: 0.0318\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0224 - val_loss: 0.0245\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0203 - val_loss: 0.0200\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0210 - val_loss: 0.0183\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0173 - val_loss: 0.0176\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0178 - val_loss: 0.0178\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0193 - val_loss: 0.0188\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0128 - val_loss: 0.0198\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0106 - val_loss: 0.0268\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0159 - val_loss: 0.0174\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0148 - val_loss: 0.0171\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0163\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0115 - val_loss: 0.0162\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0142 - val_loss: 0.0170\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0123 - val_loss: 0.0172\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0129 - val_loss: 0.0166\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0102 - val_loss: 0.0166\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0132 - val_loss: 0.0206\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0122 - val_loss: 0.0177\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0148 - val_loss: 0.0185\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0193\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0157 - val_loss: 0.0191\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0147 - val_loss: 0.0224\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.0200\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.0192\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0166 - val_loss: 0.0190\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.0169\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0114 - val_loss: 0.0154\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0194\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0089 - val_loss: 0.0201\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0134 - val_loss: 0.0220\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0186\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0088 - val_loss: 0.0233\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0086 - val_loss: 0.0187\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0076 - val_loss: 0.0170\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0083 - val_loss: 0.0232\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0118 - val_loss: 0.0182\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0149\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0086 - val_loss: 0.0144\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0070 - val_loss: 0.0177\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0076 - val_loss: 0.0185\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0078 - val_loss: 0.0155\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0063 - val_loss: 0.0192\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0066 - val_loss: 0.0186\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0067 - val_loss: 0.0196\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0088 - val_loss: 0.0169\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0071 - val_loss: 0.0138\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0058 - val_loss: 0.0185\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0063 - val_loss: 0.0164\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0041 - val_loss: 0.0213\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0061 - val_loss: 0.0201\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0067 - val_loss: 0.0221\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0047 - val_loss: 0.0192\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0041 - val_loss: 0.0255\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0068 - val_loss: 0.0147\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0041 - val_loss: 0.0239\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0040 - val_loss: 0.0157\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0034 - val_loss: 0.0195\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0062 - val_loss: 0.0209\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0046 - val_loss: 0.0215\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0033 - val_loss: 0.0218\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0053 - val_loss: 0.0219\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0048 - val_loss: 0.0205\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0043 - val_loss: 0.0199\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0030 - val_loss: 0.0144\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0048 - val_loss: 0.0196\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.0197\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 0.0145\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0025 - val_loss: 0.0220\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0024 - val_loss: 0.0216\n",
      "Epoch 140/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0028 - val_loss: 0.0224\n",
      "Epoch 141/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0029 - val_loss: 0.0209\n",
      "Epoch 142/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0035 - val_loss: 0.0230\n",
      "Epoch 143/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0023 - val_loss: 0.0210\n",
      "Epoch 144/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0024 - val_loss: 0.0179\n",
      "Epoch 145/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0022 - val_loss: 0.0245\n",
      "Epoch 146/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0020 - val_loss: 0.0155\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A7887B6C10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 56ms/step - loss: 0.0619 - val_loss: 0.0285\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0440 - val_loss: 0.0287\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0325 - val_loss: 0.0325\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0277 - val_loss: 0.0267\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0244 - val_loss: 0.0269\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0273 - val_loss: 0.0323\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0278 - val_loss: 0.0377\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0278 - val_loss: 0.0311\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0394 - val_loss: 0.0296\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0295 - val_loss: 0.0247\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0298 - val_loss: 0.0270\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0281 - val_loss: 0.0243\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0249 - val_loss: 0.0380\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0331 - val_loss: 0.0245\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0224 - val_loss: 0.0244\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0231 - val_loss: 0.0252\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0192 - val_loss: 0.0271\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0262 - val_loss: 0.0242\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0223 - val_loss: 0.0242\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0295 - val_loss: 0.0242\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0246 - val_loss: 0.0245\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0294 - val_loss: 0.0377\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0267 - val_loss: 0.0322\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0260 - val_loss: 0.0240\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0185 - val_loss: 0.0254\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0246 - val_loss: 0.0244\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0327 - val_loss: 0.0235\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0294 - val_loss: 0.0243\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0207 - val_loss: 0.0234\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0217 - val_loss: 0.0265\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0217 - val_loss: 0.0274\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0201 - val_loss: 0.0238\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0257 - val_loss: 0.0234\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0219 - val_loss: 0.0230\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0173 - val_loss: 0.0278\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0226 - val_loss: 0.0260\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0200 - val_loss: 0.0247\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0243 - val_loss: 0.0243\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0229 - val_loss: 0.0236\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0228 - val_loss: 0.0225\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0194 - val_loss: 0.0231\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0181 - val_loss: 0.0231\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0255 - val_loss: 0.0230\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0182 - val_loss: 0.0224\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0197 - val_loss: 0.0246\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0266 - val_loss: 0.0229\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0232 - val_loss: 0.0223\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0201 - val_loss: 0.0219\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0200 - val_loss: 0.0254\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0209 - val_loss: 0.0220\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0207 - val_loss: 0.0250\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0188 - val_loss: 0.0239\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0213 - val_loss: 0.0218\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0223 - val_loss: 0.0247\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0239 - val_loss: 0.0215\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0190 - val_loss: 0.0208\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0195 - val_loss: 0.0209\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0172 - val_loss: 0.0204\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0173 - val_loss: 0.0209\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0208 - val_loss: 0.0265\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0217 - val_loss: 0.0202\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0186 - val_loss: 0.0203\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0184 - val_loss: 0.0211\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0204 - val_loss: 0.0204\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0176 - val_loss: 0.0204\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.0217\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0156 - val_loss: 0.0210\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0162 - val_loss: 0.0188\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0160 - val_loss: 0.0192\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.0152 - val_loss: 0.0180\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0186 - val_loss: 0.0185\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0177\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0174 - val_loss: 0.0197\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0176\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0177 - val_loss: 0.0220\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0149 - val_loss: 0.0183\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0214\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0236 - val_loss: 0.0169\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0236\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0178 - val_loss: 0.0171\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.0172\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0161\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0139 - val_loss: 0.0165\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0136 - val_loss: 0.0187\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0154\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0171\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0140 - val_loss: 0.0166\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0196 - val_loss: 0.0176\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0204\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.0174\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0181 - val_loss: 0.0189\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0165\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0197\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0171 - val_loss: 0.0247\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0125 - val_loss: 0.0168\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0083 - val_loss: 0.0180\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0096 - val_loss: 0.0197\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0165 - val_loss: 0.0202\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0140 - val_loss: 0.0173\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0076 - val_loss: 0.0173\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0119 - val_loss: 0.0195\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0180\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0129 - val_loss: 0.0157\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0183\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0188\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0100 - val_loss: 0.0212\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0185\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0192\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0080 - val_loss: 0.0227\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0152\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0119 - val_loss: 0.0172\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0073 - val_loss: 0.0163\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A872B29AF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 36ms/step - loss: 0.0674 - val_loss: 0.0321\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0308 - val_loss: 0.0280\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0266 - val_loss: 0.0277\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0253 - val_loss: 0.0276\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0221 - val_loss: 0.0262\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0204 - val_loss: 0.0326\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0278 - val_loss: 0.0259\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0285 - val_loss: 0.0356\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0264 - val_loss: 0.0256\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0262 - val_loss: 0.0249\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0277 - val_loss: 0.0285\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0231 - val_loss: 0.0298\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0222 - val_loss: 0.0259\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0219 - val_loss: 0.0259\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0243 - val_loss: 0.0244\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0188 - val_loss: 0.0243\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0197 - val_loss: 0.0243\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0232 - val_loss: 0.0249\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0234 - val_loss: 0.0249\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0183 - val_loss: 0.0245\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0199 - val_loss: 0.0239\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0278 - val_loss: 0.0271\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0333 - val_loss: 0.0295\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0216 - val_loss: 0.0247\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0199 - val_loss: 0.0250\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0279 - val_loss: 0.0315\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0220 - val_loss: 0.0236\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0242 - val_loss: 0.0333\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0214 - val_loss: 0.0259\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0230 - val_loss: 0.0233\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0328 - val_loss: 0.0276\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0282 - val_loss: 0.0230\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0264 - val_loss: 0.0326\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0235 - val_loss: 0.0239\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0213 - val_loss: 0.0236\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0208 - val_loss: 0.0252\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0213 - val_loss: 0.0241\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0261 - val_loss: 0.0226\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0210 - val_loss: 0.0280\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0188 - val_loss: 0.0225\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0157 - val_loss: 0.0225\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0232\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0140 - val_loss: 0.0233\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0212 - val_loss: 0.0257\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0207 - val_loss: 0.0226\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0181 - val_loss: 0.0224\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0166 - val_loss: 0.0218\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0174 - val_loss: 0.0232\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0299 - val_loss: 0.0217\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0197 - val_loss: 0.0220\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0189 - val_loss: 0.0299\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0192 - val_loss: 0.0211\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0228 - val_loss: 0.0223\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0213 - val_loss: 0.0217\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.0181 - val_loss: 0.0209\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0194 - val_loss: 0.0214\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0188 - val_loss: 0.0202\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0149 - val_loss: 0.0227\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0214 - val_loss: 0.0205\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0163 - val_loss: 0.0208\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0159 - val_loss: 0.0198\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0177 - val_loss: 0.0206\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0200 - val_loss: 0.0224\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0196 - val_loss: 0.0197\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0198 - val_loss: 0.0195\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0177 - val_loss: 0.0192\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0204 - val_loss: 0.0194\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0192 - val_loss: 0.0186\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0159 - val_loss: 0.0212\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0164 - val_loss: 0.0176\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0152 - val_loss: 0.0212\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0181 - val_loss: 0.0184\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0182 - val_loss: 0.0179\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0133 - val_loss: 0.0212\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0251 - val_loss: 0.0177\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0148 - val_loss: 0.0177\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0163\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0133 - val_loss: 0.0271\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0182 - val_loss: 0.0181\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0159 - val_loss: 0.0155\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0162 - val_loss: 0.0164\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0151 - val_loss: 0.0171\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0357\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0205 - val_loss: 0.0182\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0139 - val_loss: 0.0251\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0190\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0135 - val_loss: 0.0250\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0168 - val_loss: 0.0225\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0181\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0172 - val_loss: 0.0165\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0162 - val_loss: 0.0152\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0172\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0122 - val_loss: 0.0249\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0127 - val_loss: 0.0195\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0175\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0198\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0208\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0195 - val_loss: 0.0178\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0089 - val_loss: 0.0248\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0100 - val_loss: 0.0169\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0176\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0085 - val_loss: 0.0141\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0102 - val_loss: 0.0157\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0074 - val_loss: 0.0170\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0177\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0102 - val_loss: 0.0196\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0107 - val_loss: 0.0157\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0102 - val_loss: 0.0159\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0066 - val_loss: 0.0198\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0080 - val_loss: 0.0190\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0168\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0076 - val_loss: 0.0251\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0163\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0053 - val_loss: 0.0170\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0064 - val_loss: 0.0154\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0072 - val_loss: 0.0139\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.0255\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0090 - val_loss: 0.0185\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0145 - val_loss: 0.0172\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0079 - val_loss: 0.0180\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0095 - val_loss: 0.0185\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0074 - val_loss: 0.0196\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0076 - val_loss: 0.0184\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0184\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0195\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0064 - val_loss: 0.0168\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0063 - val_loss: 0.0154\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0057 - val_loss: 0.0200\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0043 - val_loss: 0.0148\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0041 - val_loss: 0.0196\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0043 - val_loss: 0.0179\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0040 - val_loss: 0.0227\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A887E28AF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 56ms/step - loss: 0.0582 - val_loss: 0.0291\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0325 - val_loss: 0.0312\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0289 - val_loss: 0.0319\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0284 - val_loss: 0.0266\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0305 - val_loss: 0.0261\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0215 - val_loss: 0.0256\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0256 - val_loss: 0.0316\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0269 - val_loss: 0.0267\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0207 - val_loss: 0.0247\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0298 - val_loss: 0.0311\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0328 - val_loss: 0.0254\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0238 - val_loss: 0.0247\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0272 - val_loss: 0.0247\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0278 - val_loss: 0.0247\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0265 - val_loss: 0.0255\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0288 - val_loss: 0.0254\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0229 - val_loss: 0.0240\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0222 - val_loss: 0.0248\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0323 - val_loss: 0.0238\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0235 - val_loss: 0.0241\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0222 - val_loss: 0.0253\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0270 - val_loss: 0.0239\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0243 - val_loss: 0.0259\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0283 - val_loss: 0.0252\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0222 - val_loss: 0.0238\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0219 - val_loss: 0.0237\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0230 - val_loss: 0.0299\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0211 - val_loss: 0.0234\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0222 - val_loss: 0.0247\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0243 - val_loss: 0.0233\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0208 - val_loss: 0.0231\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0194 - val_loss: 0.0245\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0185 - val_loss: 0.0230\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0208 - val_loss: 0.0246\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0233 - val_loss: 0.0228\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.0227\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0304 - val_loss: 0.0225\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0277 - val_loss: 0.0265\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0214 - val_loss: 0.0233\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0214 - val_loss: 0.0226\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0237 - val_loss: 0.0222\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0251 - val_loss: 0.0248\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0218\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0201 - val_loss: 0.0259\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0282 - val_loss: 0.0275\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0246 - val_loss: 0.0219\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0266 - val_loss: 0.0246\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0185 - val_loss: 0.0242\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0176 - val_loss: 0.0264\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0180 - val_loss: 0.0220\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0178 - val_loss: 0.0213\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0221\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0227 - val_loss: 0.0213\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0233 - val_loss: 0.0217\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0302 - val_loss: 0.0239\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0251 - val_loss: 0.0223\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0208\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0162 - val_loss: 0.0201\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0264 - val_loss: 0.0216\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0264 - val_loss: 0.0206\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0222 - val_loss: 0.0243\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0256 - val_loss: 0.0272\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0224 - val_loss: 0.0213\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0246 - val_loss: 0.0215\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0192 - val_loss: 0.0224\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0233 - val_loss: 0.0247\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0160 - val_loss: 0.0201\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0197 - val_loss: 0.0210\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0166 - val_loss: 0.0190\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0149 - val_loss: 0.0189\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0140 - val_loss: 0.0231\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0165 - val_loss: 0.0195\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0173 - val_loss: 0.0210\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0220\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0279 - val_loss: 0.0192\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0219 - val_loss: 0.0180\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0185\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0139 - val_loss: 0.0188\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.0171\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0139 - val_loss: 0.0186\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0132 - val_loss: 0.0190\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0193 - val_loss: 0.0173\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0145 - val_loss: 0.0177\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0137 - val_loss: 0.0149\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0219\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0141 - val_loss: 0.0151\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.0205\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0237\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0150 - val_loss: 0.0215\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0134 - val_loss: 0.0172\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0145 - val_loss: 0.0164\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0205\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.0118 - val_loss: 0.0177\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0123 - val_loss: 0.0187\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0090 - val_loss: 0.0198\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0106 - val_loss: 0.0252\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0127 - val_loss: 0.0192\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0153\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0157\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.0194\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0174\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0090 - val_loss: 0.0196\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0229\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0138\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0076 - val_loss: 0.0152\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0155 - val_loss: 0.0153\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0169\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0169\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0107 - val_loss: 0.0235\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0089 - val_loss: 0.0147\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0129\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0071 - val_loss: 0.0125\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0062 - val_loss: 0.0139\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0078 - val_loss: 0.0157\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0064 - val_loss: 0.0157\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0081 - val_loss: 0.0145\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0154\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0066 - val_loss: 0.0149\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0082 - val_loss: 0.0140\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0061 - val_loss: 0.0132\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0039 - val_loss: 0.0131\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0056 - val_loss: 0.0193\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0053 - val_loss: 0.0133\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0049 - val_loss: 0.0140\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0043 - val_loss: 0.0164\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0061 - val_loss: 0.0123\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0058 - val_loss: 0.0156\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0046 - val_loss: 0.0139\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0046 - val_loss: 0.0165\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0056 - val_loss: 0.0126\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.0141\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0041 - val_loss: 0.0169\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0043 - val_loss: 0.0131\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0039 - val_loss: 0.0171\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0049 - val_loss: 0.0138\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0050 - val_loss: 0.0174\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0055 - val_loss: 0.0143\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0052 - val_loss: 0.0107\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0052 - val_loss: 0.0163\n",
      "Epoch 140/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0187\n",
      "Epoch 141/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0034 - val_loss: 0.0148\n",
      "Epoch 142/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0021 - val_loss: 0.0137\n",
      "Epoch 143/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0031 - val_loss: 0.0227\n",
      "Epoch 144/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0034 - val_loss: 0.0156\n",
      "Epoch 145/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 0.0201\n",
      "Epoch 146/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0042 - val_loss: 0.0224\n",
      "Epoch 147/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0020 - val_loss: 0.0204\n",
      "Epoch 148/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0021 - val_loss: 0.0168\n",
      "Epoch 149/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0030 - val_loss: 0.0211\n",
      "Epoch 150/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0040 - val_loss: 0.0215\n",
      "Epoch 151/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0024 - val_loss: 0.0169\n",
      "Epoch 152/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0026 - val_loss: 0.0161\n",
      "Epoch 153/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0023 - val_loss: 0.0195\n",
      "Epoch 154/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0021 - val_loss: 0.0201\n",
      "Epoch 155/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0023 - val_loss: 0.0243\n",
      "Epoch 156/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0038 - val_loss: 0.0160\n",
      "Epoch 157/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0028 - val_loss: 0.0176\n",
      "Epoch 158/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0026 - val_loss: 0.0213\n",
      "Epoch 159/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 0.0206\n",
      "Epoch 160/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0022 - val_loss: 0.0222\n",
      "Epoch 161/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0033 - val_loss: 0.0210\n",
      "Epoch 162/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0019 - val_loss: 0.0244\n",
      "Epoch 163/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 0.0221\n",
      "Epoch 164/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 0.0244\n",
      "Epoch 165/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 0.0225\n",
      "Epoch 166/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 0.0205\n",
      "Epoch 167/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 0.0239\n",
      "Epoch 168/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 0.0221\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A88956C9D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 58ms/step - loss: 0.0727 - val_loss: 0.0316\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0281 - val_loss: 0.0278\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0245 - val_loss: 0.0278\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0306 - val_loss: 0.0283\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0246 - val_loss: 0.0262\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0280 - val_loss: 0.0320\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0363 - val_loss: 0.0308\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0327 - val_loss: 0.0377\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0238 - val_loss: 0.0265\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0316 - val_loss: 0.0259\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0171 - val_loss: 0.0407\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0366 - val_loss: 0.0275\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0250 - val_loss: 0.0248\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0231 - val_loss: 0.0252\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0197 - val_loss: 0.0246\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0228 - val_loss: 0.0253\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0239 - val_loss: 0.0241\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0287 - val_loss: 0.0284\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0232 - val_loss: 0.0240\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0203 - val_loss: 0.0254\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0210 - val_loss: 0.0252\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0320 - val_loss: 0.0238\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0215 - val_loss: 0.0288\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0207 - val_loss: 0.0282\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0261 - val_loss: 0.0327\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0247 - val_loss: 0.0237\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0262 - val_loss: 0.0243\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0293 - val_loss: 0.0314\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0257 - val_loss: 0.0244\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0200 - val_loss: 0.0233\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0207 - val_loss: 0.0244\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0200 - val_loss: 0.0232\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0210 - val_loss: 0.0237\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0292 - val_loss: 0.0282\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0236 - val_loss: 0.0228\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0172 - val_loss: 0.0264\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0239 - val_loss: 0.0247\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0210 - val_loss: 0.0233\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0223\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0205 - val_loss: 0.0230\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0225 - val_loss: 0.0230\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0189 - val_loss: 0.0227\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0205 - val_loss: 0.0221\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0216 - val_loss: 0.0227\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0254 - val_loss: 0.0223\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0206 - val_loss: 0.0228\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0215 - val_loss: 0.0228\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0183 - val_loss: 0.0235\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0250 - val_loss: 0.0214\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0160 - val_loss: 0.0216\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0205 - val_loss: 0.0215\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0209 - val_loss: 0.0220\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0196 - val_loss: 0.0215\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0203 - val_loss: 0.0226\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0207 - val_loss: 0.0211\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0172 - val_loss: 0.0225\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0232 - val_loss: 0.0208\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0190 - val_loss: 0.0247\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0302 - val_loss: 0.0370\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0232 - val_loss: 0.0226\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0178 - val_loss: 0.0255\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0230 - val_loss: 0.0253\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0309 - val_loss: 0.0255\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0176 - val_loss: 0.0210\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0161 - val_loss: 0.0203\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0192 - val_loss: 0.0212\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0234 - val_loss: 0.0191\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0202 - val_loss: 0.0185\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0199 - val_loss: 0.0187\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0162 - val_loss: 0.0185\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0215 - val_loss: 0.0176\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0141 - val_loss: 0.0198\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0222 - val_loss: 0.0193\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0162 - val_loss: 0.0167\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.0178\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0132 - val_loss: 0.0194\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.0160 - val_loss: 0.0151\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0149 - val_loss: 0.0192\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0194\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0127 - val_loss: 0.0215\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0216\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0138 - val_loss: 0.0222\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0125 - val_loss: 0.0173\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.0195\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0124 - val_loss: 0.0145\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0126 - val_loss: 0.0164\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0096 - val_loss: 0.0184\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0158\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0114 - val_loss: 0.0186\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0106 - val_loss: 0.0165\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0158\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0166\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0166\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0079 - val_loss: 0.0195\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0093 - val_loss: 0.0169\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0082 - val_loss: 0.0193\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0063 - val_loss: 0.0180\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0103 - val_loss: 0.0160\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0075 - val_loss: 0.0179\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0068 - val_loss: 0.0159\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0066 - val_loss: 0.0158\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0056 - val_loss: 0.0153\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0073 - val_loss: 0.0203\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0119 - val_loss: 0.0244\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0223 - val_loss: 0.0191\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0103 - val_loss: 0.0152\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0108 - val_loss: 0.0206\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A86F0D9A60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 35ms/step - loss: 0.0574 - val_loss: 0.0407\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0377 - val_loss: 0.0278\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0302 - val_loss: 0.0272\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0299 - val_loss: 0.0283\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0284 - val_loss: 0.0333\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0246 - val_loss: 0.0264\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0256\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0232 - val_loss: 0.0265\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0233 - val_loss: 0.0246\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0258 - val_loss: 0.0248\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0181 - val_loss: 0.0259\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0205 - val_loss: 0.0258\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0218 - val_loss: 0.0248\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0272 - val_loss: 0.0252\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0240 - val_loss: 0.0245\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0228 - val_loss: 0.0392\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0354 - val_loss: 0.0245\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0229 - val_loss: 0.0341\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0228 - val_loss: 0.0239\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0239\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0223 - val_loss: 0.0257\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0265 - val_loss: 0.0250\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0210 - val_loss: 0.0238\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0233 - val_loss: 0.0243\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0247 - val_loss: 0.0245\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0287 - val_loss: 0.0301\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0216 - val_loss: 0.0261\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0230 - val_loss: 0.0238\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0212 - val_loss: 0.0231\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0253 - val_loss: 0.0233\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0183 - val_loss: 0.0244\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0254 - val_loss: 0.0253\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0246 - val_loss: 0.0234\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0187 - val_loss: 0.0228\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0199 - val_loss: 0.0256\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0304 - val_loss: 0.0247\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0226 - val_loss: 0.0284\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0247 - val_loss: 0.0233\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0236 - val_loss: 0.0381\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0252 - val_loss: 0.0234\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0254 - val_loss: 0.0284\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0341 - val_loss: 0.0230\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0191 - val_loss: 0.0225\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0218 - val_loss: 0.0291\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0229 - val_loss: 0.0221\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0156 - val_loss: 0.0224\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0192 - val_loss: 0.0233\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0207 - val_loss: 0.0230\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0173 - val_loss: 0.0214\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0173 - val_loss: 0.0211\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0170 - val_loss: 0.0254\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0238\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0222 - val_loss: 0.0206\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.0235\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0208 - val_loss: 0.0281\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0179 - val_loss: 0.0206\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0193 - val_loss: 0.0197\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0160 - val_loss: 0.0195\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0209 - val_loss: 0.0192\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.0279\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0179 - val_loss: 0.0198\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0195 - val_loss: 0.0187\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0157 - val_loss: 0.0194\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0182 - val_loss: 0.0326\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0221 - val_loss: 0.0228\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.0216\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0162 - val_loss: 0.0182\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0202 - val_loss: 0.0189\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0214 - val_loss: 0.0183\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0248 - val_loss: 0.0198\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0171 - val_loss: 0.0185\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.0124 - val_loss: 0.0178\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0130 - val_loss: 0.0178\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0149 - val_loss: 0.0206\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0185 - val_loss: 0.0177\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0106 - val_loss: 0.0164\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0185\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.0146\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0167 - val_loss: 0.0195\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0141 - val_loss: 0.0170\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0123 - val_loss: 0.0170\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0155 - val_loss: 0.0165\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0160 - val_loss: 0.0153\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0164\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0173\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.0160\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0211\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0137 - val_loss: 0.0190\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0146\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0148\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0077 - val_loss: 0.0137\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0089 - val_loss: 0.0128\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0129\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0077 - val_loss: 0.0155\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0118\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0075 - val_loss: 0.0203\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0181\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0133\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0173\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0090 - val_loss: 0.0148\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0076 - val_loss: 0.0146\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0113\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0077 - val_loss: 0.0131\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0064 - val_loss: 0.0170\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0068 - val_loss: 0.0159\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0078 - val_loss: 0.0117\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0140\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0078 - val_loss: 0.0181\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0061 - val_loss: 0.0142\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0064 - val_loss: 0.0191\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0065 - val_loss: 0.0112\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0045 - val_loss: 0.0125\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0039 - val_loss: 0.0129\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0076 - val_loss: 0.0155\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0077 - val_loss: 0.0096\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0043 - val_loss: 0.0124\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0054 - val_loss: 0.0131\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.0116\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0031 - val_loss: 0.0124\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0030 - val_loss: 0.0150\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0038 - val_loss: 0.0129\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0036 - val_loss: 0.0119\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0043 - val_loss: 0.0163\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0040 - val_loss: 0.0138\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0039 - val_loss: 0.0136\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0029 - val_loss: 0.0154\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0028 - val_loss: 0.0190\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0030 - val_loss: 0.0162\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0038 - val_loss: 0.0114\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0023 - val_loss: 0.0164\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0032 - val_loss: 0.0198\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0027 - val_loss: 0.0141\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 0.0130\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0024 - val_loss: 0.0143\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0024 - val_loss: 0.0115\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0032 - val_loss: 0.0146\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0023 - val_loss: 0.0175\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0035 - val_loss: 0.0151\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0025 - val_loss: 0.0138\n",
      "Epoch 140/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0133\n",
      "Epoch 141/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0029 - val_loss: 0.0146\n",
      "Epoch 142/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 0.0192\n",
      "Epoch 143/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0020 - val_loss: 0.0147\n",
      "Epoch 144/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0023 - val_loss: 0.0159\n",
      "Epoch 145/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0031 - val_loss: 0.0152\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A70DECDD30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 57ms/step - loss: 0.0554 - val_loss: 0.0408\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0343 - val_loss: 0.0283\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0234 - val_loss: 0.0278\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0262 - val_loss: 0.0286\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0248 - val_loss: 0.0267\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0242 - val_loss: 0.0256\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0214 - val_loss: 0.0252\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0267 - val_loss: 0.0291\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0307 - val_loss: 0.0250\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0318 - val_loss: 0.0280\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0248 - val_loss: 0.0247\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0270 - val_loss: 0.0249\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0295 - val_loss: 0.0246\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0272 - val_loss: 0.0243\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0202 - val_loss: 0.0242\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0244 - val_loss: 0.0253\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0246 - val_loss: 0.0282\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0206 - val_loss: 0.0249\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0297 - val_loss: 0.0299\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0325 - val_loss: 0.0285\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0227 - val_loss: 0.0313\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0249 - val_loss: 0.0242\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0202 - val_loss: 0.0276\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0227 - val_loss: 0.0284\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0276 - val_loss: 0.0350\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0190 - val_loss: 0.0273\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0236 - val_loss: 0.0237\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0210 - val_loss: 0.0273\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0198 - val_loss: 0.0244\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0248 - val_loss: 0.0321\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0182 - val_loss: 0.0231\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0247 - val_loss: 0.0235\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0200 - val_loss: 0.0229\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0299 - val_loss: 0.0246\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0174 - val_loss: 0.0273\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0200 - val_loss: 0.0230\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0224 - val_loss: 0.0286\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0246\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0212 - val_loss: 0.0225\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0240 - val_loss: 0.0243\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0274 - val_loss: 0.0276\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0175 - val_loss: 0.0221\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0267 - val_loss: 0.0216\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0169 - val_loss: 0.0217\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0205 - val_loss: 0.0252\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0209 - val_loss: 0.0261\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0216\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0230 - val_loss: 0.0298\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0178 - val_loss: 0.0221\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0197 - val_loss: 0.0207\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0193 - val_loss: 0.0251\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0203 - val_loss: 0.0232\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0178 - val_loss: 0.0235\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0217\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0186 - val_loss: 0.0209\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0198 - val_loss: 0.0197\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0240 - val_loss: 0.0221\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0249 - val_loss: 0.0196\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0185 - val_loss: 0.0203\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0193 - val_loss: 0.0201\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0172 - val_loss: 0.0215\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0265 - val_loss: 0.0199\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0162 - val_loss: 0.0223\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0197 - val_loss: 0.0258\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0224 - val_loss: 0.0193\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0157 - val_loss: 0.0187\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0194\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0193 - val_loss: 0.0190\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0154 - val_loss: 0.0211\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0184\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0155 - val_loss: 0.0206\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0127 - val_loss: 0.0212\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0252 - val_loss: 0.0179\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0143 - val_loss: 0.0174\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.0171\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0188 - val_loss: 0.0174\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0157 - val_loss: 0.0156\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0195 - val_loss: 0.0202\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0162 - val_loss: 0.0182\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0196 - val_loss: 0.0178\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.0184 - val_loss: 0.0185\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0192 - val_loss: 0.0217\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0174 - val_loss: 0.0182\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0166\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0172\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0174 - val_loss: 0.0191\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0130 - val_loss: 0.0217\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0183\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0123 - val_loss: 0.0175\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0149 - val_loss: 0.0168\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0104 - val_loss: 0.0181\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0198\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0121 - val_loss: 0.0181\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0142\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0164\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0122 - val_loss: 0.0189\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0088 - val_loss: 0.0164\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0146\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0065 - val_loss: 0.0144\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0055 - val_loss: 0.0154\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0182\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0072 - val_loss: 0.0173\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0069 - val_loss: 0.0223\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0117 - val_loss: 0.0268\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0109 - val_loss: 0.0157\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0088 - val_loss: 0.0153\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0063 - val_loss: 0.0215\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0084 - val_loss: 0.0187\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0077 - val_loss: 0.0142\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0063 - val_loss: 0.0194\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0082 - val_loss: 0.0202\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0075 - val_loss: 0.0274\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0069 - val_loss: 0.0165\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0056 - val_loss: 0.0139\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0047 - val_loss: 0.0148\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0064 - val_loss: 0.0144\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0063 - val_loss: 0.0190\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0058 - val_loss: 0.0143\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0061 - val_loss: 0.0159\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0042 - val_loss: 0.0202\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0052 - val_loss: 0.0139\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0030 - val_loss: 0.0202\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0030 - val_loss: 0.0196\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0034 - val_loss: 0.0301\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A86F305AF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 35ms/step - loss: 0.0583 - val_loss: 0.0306\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0301 - val_loss: 0.0346\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0275 - val_loss: 0.0286\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0241 - val_loss: 0.0345\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0247 - val_loss: 0.0264\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0237 - val_loss: 0.0270\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0234 - val_loss: 0.0262\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0240 - val_loss: 0.0255\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0285 - val_loss: 0.0295\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0343 - val_loss: 0.0248\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0274 - val_loss: 0.0263\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0292 - val_loss: 0.0377\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0272 - val_loss: 0.0300\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0199 - val_loss: 0.0240\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0259 - val_loss: 0.0245\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0226 - val_loss: 0.0243\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0277 - val_loss: 0.0247\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0323 - val_loss: 0.0239\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0313 - val_loss: 0.0279\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0171 - val_loss: 0.0243\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0239 - val_loss: 0.0252\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0229 - val_loss: 0.0238\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0235 - val_loss: 0.0498\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0201 - val_loss: 0.0238\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0258 - val_loss: 0.0250\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0232 - val_loss: 0.0268\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0244 - val_loss: 0.0261\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0251 - val_loss: 0.0234\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0215 - val_loss: 0.0279\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0190 - val_loss: 0.0240\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0255 - val_loss: 0.0348\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0246 - val_loss: 0.0231\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0199 - val_loss: 0.0233\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0219 - val_loss: 0.0228\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0208 - val_loss: 0.0278\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0298 - val_loss: 0.0269\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0190 - val_loss: 0.0252\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0237 - val_loss: 0.0224\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0198 - val_loss: 0.0232\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0229 - val_loss: 0.0217\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0237 - val_loss: 0.0263\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0215 - val_loss: 0.0225\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0132 - val_loss: 0.0216\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0159 - val_loss: 0.0215\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0223\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0167 - val_loss: 0.0214\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0212 - val_loss: 0.0250\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0161 - val_loss: 0.0205\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0194 - val_loss: 0.0290\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0234 - val_loss: 0.0224\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0166 - val_loss: 0.0210\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0196 - val_loss: 0.0212\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0165 - val_loss: 0.0201\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.0218 - val_loss: 0.0221\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0204 - val_loss: 0.0213\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0167 - val_loss: 0.0214\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0170 - val_loss: 0.0209\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0203 - val_loss: 0.0216\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0242\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0198\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0169 - val_loss: 0.0194\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0179 - val_loss: 0.0187\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.0189\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0194 - val_loss: 0.0192\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0180 - val_loss: 0.0203\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0210 - val_loss: 0.0183\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0171 - val_loss: 0.0181\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0145 - val_loss: 0.0206\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0218 - val_loss: 0.0212\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0176 - val_loss: 0.0261\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.0182\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0176 - val_loss: 0.0184\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0222 - val_loss: 0.0166\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0164\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0141 - val_loss: 0.0163\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0170\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0218\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0214 - val_loss: 0.0193\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.0183\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0179\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0159\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0096 - val_loss: 0.0179\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0204\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0191 - val_loss: 0.0166\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0177\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0150\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0194\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0136 - val_loss: 0.0193\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0189\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0155 - val_loss: 0.0150\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0095 - val_loss: 0.0158\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0110 - val_loss: 0.0147\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0117 - val_loss: 0.0205\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0126 - val_loss: 0.0153\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0154\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.0190\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0142\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0106 - val_loss: 0.0186\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0132\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0103 - val_loss: 0.0164\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0113\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0075 - val_loss: 0.0137\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0077 - val_loss: 0.0172\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0093 - val_loss: 0.0164\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0072 - val_loss: 0.0114\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0071 - val_loss: 0.0119\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0065 - val_loss: 0.0135\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0047 - val_loss: 0.0151\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0065 - val_loss: 0.0118\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0085 - val_loss: 0.0123\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0056 - val_loss: 0.0172\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0076 - val_loss: 0.0095\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0079 - val_loss: 0.0175\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0062 - val_loss: 0.0116\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0047 - val_loss: 0.0158\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0057 - val_loss: 0.0153\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0055 - val_loss: 0.0149\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0059 - val_loss: 0.0144\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0060 - val_loss: 0.0140\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0048 - val_loss: 0.0116\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0040 - val_loss: 0.0114\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0038 - val_loss: 0.0101\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0035 - val_loss: 0.0145\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0074 - val_loss: 0.0162\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0036 - val_loss: 0.0117\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0056 - val_loss: 0.0145\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0045 - val_loss: 0.0163\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0046 - val_loss: 0.0185\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0056 - val_loss: 0.0187\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.0160\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0039 - val_loss: 0.0213\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0041 - val_loss: 0.0194\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0024 - val_loss: 0.0206\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 0.0164\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0027 - val_loss: 0.0253\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0032 - val_loss: 0.0139\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.0028 - val_loss: 0.0155\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0033 - val_loss: 0.0152\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0022 - val_loss: 0.0149\n",
      "Epoch 140/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0023 - val_loss: 0.0119\n",
      "Epoch 141/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0028 - val_loss: 0.0141\n",
      "Epoch 142/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0022 - val_loss: 0.0185\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A876747790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 5s 72ms/step - loss: 0.0693 - val_loss: 0.0306\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0318 - val_loss: 0.0339\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0345 - val_loss: 0.0289\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0209 - val_loss: 0.0322\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0278 - val_loss: 0.0262\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0228 - val_loss: 0.0256\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0176 - val_loss: 0.0299\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0268 - val_loss: 0.0252\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0298 - val_loss: 0.0310\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0290 - val_loss: 0.0368\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0251 - val_loss: 0.0252\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0230 - val_loss: 0.0278\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0279 - val_loss: 0.0327\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0242 - val_loss: 0.0244\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0267 - val_loss: 0.0242\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0243 - val_loss: 0.0281\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0240 - val_loss: 0.0303\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0213 - val_loss: 0.0245\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0261 - val_loss: 0.0265\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0236 - val_loss: 0.0264\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0216 - val_loss: 0.0254\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0202 - val_loss: 0.0255\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0224 - val_loss: 0.0239\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0253 - val_loss: 0.0242\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0256 - val_loss: 0.0274\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0235 - val_loss: 0.0352\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0275 - val_loss: 0.0297\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0231 - val_loss: 0.0235\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0190 - val_loss: 0.0242\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0229 - val_loss: 0.0234\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0251 - val_loss: 0.0261\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0244 - val_loss: 0.0245\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0213 - val_loss: 0.0251\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0218 - val_loss: 0.0237\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0290 - val_loss: 0.0351\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0306 - val_loss: 0.0365\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0207 - val_loss: 0.0237\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0228 - val_loss: 0.0231\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0260 - val_loss: 0.0248\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0204 - val_loss: 0.0231\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0210 - val_loss: 0.0269\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0188 - val_loss: 0.0241\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0207 - val_loss: 0.0231\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0160 - val_loss: 0.0220\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0223 - val_loss: 0.0254\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0238 - val_loss: 0.0220\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0174 - val_loss: 0.0306\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0201 - val_loss: 0.0258\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0222 - val_loss: 0.0259\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0227 - val_loss: 0.0226\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0181 - val_loss: 0.0250\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0227 - val_loss: 0.0210\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0192 - val_loss: 0.0209\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0241 - val_loss: 0.0242\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0203 - val_loss: 0.0222\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0139 - val_loss: 0.0207\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0233 - val_loss: 0.0219\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0186 - val_loss: 0.0198\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0153 - val_loss: 0.0226\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0203 - val_loss: 0.0191\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0230 - val_loss: 0.0200\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0150 - val_loss: 0.0204\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0218 - val_loss: 0.0232\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0157 - val_loss: 0.0192\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0181 - val_loss: 0.0201\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0155 - val_loss: 0.0187\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.0192\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0174 - val_loss: 0.0178\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0157 - val_loss: 0.0194\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0213 - val_loss: 0.0176\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0159 - val_loss: 0.0194\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0202 - val_loss: 0.0226\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0188 - val_loss: 0.0173\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0135 - val_loss: 0.0176\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0189 - val_loss: 0.0177\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0211 - val_loss: 0.0163\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0127 - val_loss: 0.0205\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0199 - val_loss: 0.0194\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0157 - val_loss: 0.0177\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0207\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0157 - val_loss: 0.0186\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0114 - val_loss: 0.0170\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0139 - val_loss: 0.0183\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0123 - val_loss: 0.0163\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0142 - val_loss: 0.0250\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0146 - val_loss: 0.0231\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0118 - val_loss: 0.0143\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0182\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0127 - val_loss: 0.0154\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0095 - val_loss: 0.0281\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0138 - val_loss: 0.0183\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0142 - val_loss: 0.0151\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0164 - val_loss: 0.0195\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0106 - val_loss: 0.0239\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0165\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0072 - val_loss: 0.0191\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0178\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0156\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0139\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0074 - val_loss: 0.0176\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0169\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0132\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.0099 - val_loss: 0.0145\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0073 - val_loss: 0.0153\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0078 - val_loss: 0.0120\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0071 - val_loss: 0.0153\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0056 - val_loss: 0.0128\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0075 - val_loss: 0.0193\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0114\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0076 - val_loss: 0.0159\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0071 - val_loss: 0.0127\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0076 - val_loss: 0.0217\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0143\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0163\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0057 - val_loss: 0.0144\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0048 - val_loss: 0.0135\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0073 - val_loss: 0.0124\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0073 - val_loss: 0.0152\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0059 - val_loss: 0.0118\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0056 - val_loss: 0.0141\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0043 - val_loss: 0.0118\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0045 - val_loss: 0.0118\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0049 - val_loss: 0.0119\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0040 - val_loss: 0.0147\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0059 - val_loss: 0.0171\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0068 - val_loss: 0.0162\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0053 - val_loss: 0.0106\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0034 - val_loss: 0.0122\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0042 - val_loss: 0.0121\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0036 - val_loss: 0.0097\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0044 - val_loss: 0.0134\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0038 - val_loss: 0.0132\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0040 - val_loss: 0.0144\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0037 - val_loss: 0.0130\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0032 - val_loss: 0.0108\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0036 - val_loss: 0.0130\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0039 - val_loss: 0.0118\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0039 - val_loss: 0.0181\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0038 - val_loss: 0.0120\n",
      "Epoch 140/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0029 - val_loss: 0.0107\n",
      "Epoch 141/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0036 - val_loss: 0.0138\n",
      "Epoch 142/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0038 - val_loss: 0.0146\n",
      "Epoch 143/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 0.0186\n",
      "Epoch 144/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0032 - val_loss: 0.0127\n",
      "Epoch 145/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0035 - val_loss: 0.0137\n",
      "Epoch 146/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0026 - val_loss: 0.0143\n",
      "Epoch 147/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0031 - val_loss: 0.0168\n",
      "Epoch 148/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0031 - val_loss: 0.0117\n",
      "Epoch 149/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0023 - val_loss: 0.0118\n",
      "Epoch 150/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 0.0171\n",
      "Epoch 151/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0025 - val_loss: 0.0123\n",
      "Epoch 152/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 0.0146\n",
      "Epoch 153/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0028 - val_loss: 0.0150\n",
      "Epoch 154/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0047 - val_loss: 0.0127\n",
      "Epoch 155/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0025 - val_loss: 0.0134\n",
      "Epoch 156/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 0.0124\n",
      "Epoch 157/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0026 - val_loss: 0.0129\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A873D53940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 37ms/step - loss: 0.0778 - val_loss: 0.0279\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0276 - val_loss: 0.0290\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0325 - val_loss: 0.0370\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0280 - val_loss: 0.0343\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0239 - val_loss: 0.0331\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0313 - val_loss: 0.0294\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0325 - val_loss: 0.0278\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0191 - val_loss: 0.0253\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0210 - val_loss: 0.0280\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0181 - val_loss: 0.0339\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0202 - val_loss: 0.0243\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0266 - val_loss: 0.0270\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0258 - val_loss: 0.0260\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0217 - val_loss: 0.0241\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0236 - val_loss: 0.0388\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0262 - val_loss: 0.0263\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0273 - val_loss: 0.0314\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0266 - val_loss: 0.0243\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.0177 - val_loss: 0.0352\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0214 - val_loss: 0.0259\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0286 - val_loss: 0.0238\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0233 - val_loss: 0.0316\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0182 - val_loss: 0.0266\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0212 - val_loss: 0.0254\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0281 - val_loss: 0.0244\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0235 - val_loss: 0.0239\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0196 - val_loss: 0.0234\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0245 - val_loss: 0.0294\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0242 - val_loss: 0.0231\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0267 - val_loss: 0.0256\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0212 - val_loss: 0.0239\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0213 - val_loss: 0.0278\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0211 - val_loss: 0.0273\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0183 - val_loss: 0.0227\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0270 - val_loss: 0.0250\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0225 - val_loss: 0.0312\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0285 - val_loss: 0.0238\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0275 - val_loss: 0.0250\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0174 - val_loss: 0.0224\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0211 - val_loss: 0.0238\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0223 - val_loss: 0.0232\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0202 - val_loss: 0.0222\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0194 - val_loss: 0.0221\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0168 - val_loss: 0.0219\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0165 - val_loss: 0.0258\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0216 - val_loss: 0.0221\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0229 - val_loss: 0.0284\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0206 - val_loss: 0.0216\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0216 - val_loss: 0.0235\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0174 - val_loss: 0.0210\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0163 - val_loss: 0.0210\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0198 - val_loss: 0.0235\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0216 - val_loss: 0.0214\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0146 - val_loss: 0.0202\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0236 - val_loss: 0.0218\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0178 - val_loss: 0.0201\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0183 - val_loss: 0.0197\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0166 - val_loss: 0.0227\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0205 - val_loss: 0.0202\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0233\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0177 - val_loss: 0.0200\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0168 - val_loss: 0.0200\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0190 - val_loss: 0.0198\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0177 - val_loss: 0.0308\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0236 - val_loss: 0.0277\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0193 - val_loss: 0.0182\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0142 - val_loss: 0.0218\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0217\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0192\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0169 - val_loss: 0.0188\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0149 - val_loss: 0.0187\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0136 - val_loss: 0.0191\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0155 - val_loss: 0.0226\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0163 - val_loss: 0.0176\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0144 - val_loss: 0.0214\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0185\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0208 - val_loss: 0.0173\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0192 - val_loss: 0.0171\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0151 - val_loss: 0.0173\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0181 - val_loss: 0.0209\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0151 - val_loss: 0.0218\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0165 - val_loss: 0.0160\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0174 - val_loss: 0.0242\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0161 - val_loss: 0.0159\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0206\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0121 - val_loss: 0.0165\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0156 - val_loss: 0.0138\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0129 - val_loss: 0.0186\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0169 - val_loss: 0.0172\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0190 - val_loss: 0.0166\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0144\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0161\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0107 - val_loss: 0.0156\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0086 - val_loss: 0.0184\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0086 - val_loss: 0.0199\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0200\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0114 - val_loss: 0.0153\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0135 - val_loss: 0.0158\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.0159\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0147\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0093 - val_loss: 0.0143\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0079 - val_loss: 0.0130\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0082 - val_loss: 0.0153\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.0165\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0163\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0068 - val_loss: 0.0125\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0063 - val_loss: 0.0112\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0053 - val_loss: 0.0208\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0119 - val_loss: 0.0135\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0072 - val_loss: 0.0137\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0089 - val_loss: 0.0161\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0146\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0080 - val_loss: 0.0115\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0056 - val_loss: 0.0129\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0069 - val_loss: 0.0136\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0063 - val_loss: 0.0155\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0062 - val_loss: 0.0150\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0052 - val_loss: 0.0140\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0054 - val_loss: 0.0155\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0046 - val_loss: 0.0123\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0029 - val_loss: 0.0158\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.0047 - val_loss: 0.0118\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0048 - val_loss: 0.0098\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0032 - val_loss: 0.0156\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0051 - val_loss: 0.0225\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0057 - val_loss: 0.0130\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0045 - val_loss: 0.0120\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.0118\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0026 - val_loss: 0.0163\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0121\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0053 - val_loss: 0.0125\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0028 - val_loss: 0.0190\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0026 - val_loss: 0.0145\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0038 - val_loss: 0.0141\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0029 - val_loss: 0.0159\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0029 - val_loss: 0.0154\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 0.0144\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0027 - val_loss: 0.0199\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 0.0158\n",
      "Epoch 140/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0020 - val_loss: 0.0133\n",
      "Epoch 141/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 0.0166\n",
      "Epoch 142/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 0.0176\n",
      "Epoch 143/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 0.0192\n",
      "Epoch 144/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 0.0211\n",
      "Epoch 145/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0022 - val_loss: 0.0190\n",
      "Epoch 146/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0029 - val_loss: 0.0140\n",
      "Epoch 147/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0022 - val_loss: 0.0174\n",
      "Epoch 148/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0031 - val_loss: 0.0166\n",
      "Epoch 149/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0026 - val_loss: 0.0154\n",
      "Epoch 150/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 0.0192\n",
      "Epoch 151/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 0.0164\n",
      "Epoch 152/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0031 - val_loss: 0.0172\n",
      "Epoch 153/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0031 - val_loss: 0.0187\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A70C921B80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 35ms/step - loss: 0.0657 - val_loss: 0.0311\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0296 - val_loss: 0.0291\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0310 - val_loss: 0.0275\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0221 - val_loss: 0.0264\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0217 - val_loss: 0.0265\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0240 - val_loss: 0.0260\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0253 - val_loss: 0.0321\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0261 - val_loss: 0.0249\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0297 - val_loss: 0.0280\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0264 - val_loss: 0.0292\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0230 - val_loss: 0.0360\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0294 - val_loss: 0.0414\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0268 - val_loss: 0.0261\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0204 - val_loss: 0.0242\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0234 - val_loss: 0.0384\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0252 - val_loss: 0.0248\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0202 - val_loss: 0.0247\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0319 - val_loss: 0.0277\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0270 - val_loss: 0.0292\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0222 - val_loss: 0.0237\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0226 - val_loss: 0.0249\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0256 - val_loss: 0.0269\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0197 - val_loss: 0.0235\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0214 - val_loss: 0.0295\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0263 - val_loss: 0.0236\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0261 - val_loss: 0.0232\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0208 - val_loss: 0.0264\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0245 - val_loss: 0.0285\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0179 - val_loss: 0.0286\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0223 - val_loss: 0.0231\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0210 - val_loss: 0.0236\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0224 - val_loss: 0.0275\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0282 - val_loss: 0.0229\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0305 - val_loss: 0.0225\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0219 - val_loss: 0.0227\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0209 - val_loss: 0.0227\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0252 - val_loss: 0.0251\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0246 - val_loss: 0.0225\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0177 - val_loss: 0.0218\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0236 - val_loss: 0.0221\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0169 - val_loss: 0.0262\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0210 - val_loss: 0.0264\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0193 - val_loss: 0.0261\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.0214\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0201 - val_loss: 0.0228\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0170 - val_loss: 0.0229\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0203 - val_loss: 0.0217\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0245 - val_loss: 0.0235\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0216 - val_loss: 0.0215\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0225 - val_loss: 0.0243\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0200 - val_loss: 0.0262\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0234 - val_loss: 0.0217\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0238 - val_loss: 0.0227\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0308\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0177 - val_loss: 0.0220\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0139 - val_loss: 0.0205\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - ETA: 0s - loss: 0.020 - 0s 8ms/step - loss: 0.0202 - val_loss: 0.0211\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0196\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.0195 - val_loss: 0.0202\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0186 - val_loss: 0.0217\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0192\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0183 - val_loss: 0.0190\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0194 - val_loss: 0.0195\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0165 - val_loss: 0.0194\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0146 - val_loss: 0.0192\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0188\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0138 - val_loss: 0.0183\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0198\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0165 - val_loss: 0.0184\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0217\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0186 - val_loss: 0.0182\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0179\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0197\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0141 - val_loss: 0.0202\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0163\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0142 - val_loss: 0.0176\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0186 - val_loss: 0.0246\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0258 - val_loss: 0.0171\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0164 - val_loss: 0.0174\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0104 - val_loss: 0.0145\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.0165\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0136 - val_loss: 0.0281\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0195 - val_loss: 0.0183\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.0160\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0119 - val_loss: 0.0157\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.0185\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0123 - val_loss: 0.0159\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0130 - val_loss: 0.0162\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0246\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0169\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0113 - val_loss: 0.0179\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0138 - val_loss: 0.0131\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0117 - val_loss: 0.0259\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0150 - val_loss: 0.0197\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0119 - val_loss: 0.0160\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0189\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0180\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0075 - val_loss: 0.0174\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0090 - val_loss: 0.0167\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0190\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0086 - val_loss: 0.0155\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0075 - val_loss: 0.0137\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0190\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0104 - val_loss: 0.0153\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0085 - val_loss: 0.0156\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0084 - val_loss: 0.0127\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0081 - val_loss: 0.0195\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0065 - val_loss: 0.0147\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0055 - val_loss: 0.0191\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0074 - val_loss: 0.0209\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0073 - val_loss: 0.0303\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0079 - val_loss: 0.0196\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0057 - val_loss: 0.0243\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0114 - val_loss: 0.0215\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0141\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0060 - val_loss: 0.0164\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0049 - val_loss: 0.0206\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0053 - val_loss: 0.0130\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0040 - val_loss: 0.0197\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0052 - val_loss: 0.0162\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0041 - val_loss: 0.0159\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0165\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A70DE359D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 34ms/step - loss: 0.0466 - val_loss: 0.0337\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0218 - val_loss: 0.0274\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0269 - val_loss: 0.0266\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0242 - val_loss: 0.0261\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0330 - val_loss: 0.0320\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0247 - val_loss: 0.0255\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0241 - val_loss: 0.0249\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.0203 - val_loss: 0.0247\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0282 - val_loss: 0.0275\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0227 - val_loss: 0.0245\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0210 - val_loss: 0.0265\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0240 - val_loss: 0.0242\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0196 - val_loss: 0.0257\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0171 - val_loss: 0.0242\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0205 - val_loss: 0.0256\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0254 - val_loss: 0.0251\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0227 - val_loss: 0.0348\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0256 - val_loss: 0.0243\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0171 - val_loss: 0.0306\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0271 - val_loss: 0.0243\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0199 - val_loss: 0.0240\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0242 - val_loss: 0.0239\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0214 - val_loss: 0.0237\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0193 - val_loss: 0.0248\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0260 - val_loss: 0.0284\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0273 - val_loss: 0.0284\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0235 - val_loss: 0.0296\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0189 - val_loss: 0.0237\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0237 - val_loss: 0.0260\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0260 - val_loss: 0.0236\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0318 - val_loss: 0.0240\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0175 - val_loss: 0.0231\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0187 - val_loss: 0.0232\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0258 - val_loss: 0.0230\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0254 - val_loss: 0.0233\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0279 - val_loss: 0.0236\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0185 - val_loss: 0.0247\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0195 - val_loss: 0.0228\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0219 - val_loss: 0.0247\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0277 - val_loss: 0.0337\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0220 - val_loss: 0.0229\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0210 - val_loss: 0.0237\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0181 - val_loss: 0.0265\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0280 - val_loss: 0.0221\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0177 - val_loss: 0.0219\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0181 - val_loss: 0.0223\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0234 - val_loss: 0.0216\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0169 - val_loss: 0.0227\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0219 - val_loss: 0.0228\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0188 - val_loss: 0.0207\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0199 - val_loss: 0.0215\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0173 - val_loss: 0.0208\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0184 - val_loss: 0.0206\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0160 - val_loss: 0.0213\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0210 - val_loss: 0.0200\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0153 - val_loss: 0.0239\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0223 - val_loss: 0.0196\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0167 - val_loss: 0.0232\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0185 - val_loss: 0.0204\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0197\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0186 - val_loss: 0.0200\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0179 - val_loss: 0.0211\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0187 - val_loss: 0.0202\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.0187\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0176 - val_loss: 0.0198\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0224 - val_loss: 0.0223\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0244 - val_loss: 0.0185\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0184\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0188 - val_loss: 0.0178\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0162 - val_loss: 0.0187\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0168 - val_loss: 0.0176\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0166\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0158 - val_loss: 0.0195\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0187 - val_loss: 0.0226\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0172 - val_loss: 0.0168\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0146 - val_loss: 0.0187\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0173\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0158 - val_loss: 0.0212\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0107 - val_loss: 0.0192\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0174\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0174\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0167\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0172\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0183\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0202\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0150 - val_loss: 0.0163\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0192\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0187 - val_loss: 0.0169\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0119 - val_loss: 0.0151\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0167 - val_loss: 0.0159\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0156\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0164\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0126 - val_loss: 0.0170\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0101 - val_loss: 0.0135\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0079 - val_loss: 0.0147\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0121 - val_loss: 0.0110\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0134\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0116\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0073 - val_loss: 0.0137\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0057 - val_loss: 0.0132\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0143\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0233\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 0.0103\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0190\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0110 - val_loss: 0.0143\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0073 - val_loss: 0.0128\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 0.0139\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0077 - val_loss: 0.0127\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0058 - val_loss: 0.0121\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0056 - val_loss: 0.0116\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.0046 - val_loss: 0.0151\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0076 - val_loss: 0.0143\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0063 - val_loss: 0.0163\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0063 - val_loss: 0.0146\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0129\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0082 - val_loss: 0.0160\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0075 - val_loss: 0.0110\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0050 - val_loss: 0.0138\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0057 - val_loss: 0.0113\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0047 - val_loss: 0.0136\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0047 - val_loss: 0.0135\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0058 - val_loss: 0.0108\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0053 - val_loss: 0.0115\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0056 - val_loss: 0.0122\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0048 - val_loss: 0.0169\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0045 - val_loss: 0.0123\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A87110AA60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 36ms/step - loss: 0.0721 - val_loss: 0.0289\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0349 - val_loss: 0.0314\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0206 - val_loss: 0.0268\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0266 - val_loss: 0.0303\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0232 - val_loss: 0.0272\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0297 - val_loss: 0.0256\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0247 - val_loss: 0.0272\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0223 - val_loss: 0.0247\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0209 - val_loss: 0.0280\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0211 - val_loss: 0.0265\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0228 - val_loss: 0.0299\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0232 - val_loss: 0.0250\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0254 - val_loss: 0.0264\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0210 - val_loss: 0.0255\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0289 - val_loss: 0.0244\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0213 - val_loss: 0.0251\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0220 - val_loss: 0.0239\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0253 - val_loss: 0.0262\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0232 - val_loss: 0.0240\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0265 - val_loss: 0.0285\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0286 - val_loss: 0.0247\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0242 - val_loss: 0.0294\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0212 - val_loss: 0.0236\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0247 - val_loss: 0.0234\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0257 - val_loss: 0.0240\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0263 - val_loss: 0.0268\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0202 - val_loss: 0.0249\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0218 - val_loss: 0.0243\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0301 - val_loss: 0.0229\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0178 - val_loss: 0.0249\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0224 - val_loss: 0.0260\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0279 - val_loss: 0.0233\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0242 - val_loss: 0.0248\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0297 - val_loss: 0.0306\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0268 - val_loss: 0.0231\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0244 - val_loss: 0.0229\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0235 - val_loss: 0.0259\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0300 - val_loss: 0.0230\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0186 - val_loss: 0.0223\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0213 - val_loss: 0.0219\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0182 - val_loss: 0.0219\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0198 - val_loss: 0.0229\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0222 - val_loss: 0.0223\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0171 - val_loss: 0.0225\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0185 - val_loss: 0.0214\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0164 - val_loss: 0.0261\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0248 - val_loss: 0.0226\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0190 - val_loss: 0.0213\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0172 - val_loss: 0.0264\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0154 - val_loss: 0.0213\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.0199\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0149 - val_loss: 0.0219\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.0202\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0190 - val_loss: 0.0211\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0198 - val_loss: 0.0196\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0188 - val_loss: 0.0195\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0202 - val_loss: 0.0231\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0246 - val_loss: 0.0211\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0174 - val_loss: 0.0225\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0194 - val_loss: 0.0192\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0175 - val_loss: 0.0224\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0219 - val_loss: 0.0195\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0167 - val_loss: 0.0192\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0133 - val_loss: 0.0194\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0188\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.0170 - val_loss: 0.0203\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0175 - val_loss: 0.0180\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0202 - val_loss: 0.0183\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0194 - val_loss: 0.0178\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0182 - val_loss: 0.0177\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0205 - val_loss: 0.0256\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0216 - val_loss: 0.0182\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0165 - val_loss: 0.0182\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0155 - val_loss: 0.0185\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0241 - val_loss: 0.0181\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0171 - val_loss: 0.0180\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0203 - val_loss: 0.0241\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0186 - val_loss: 0.0190\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0177 - val_loss: 0.0172\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0236\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0162 - val_loss: 0.0168\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0172 - val_loss: 0.0150\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0122 - val_loss: 0.0175\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0153 - val_loss: 0.0173\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0130 - val_loss: 0.0163\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0170 - val_loss: 0.0157\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0130 - val_loss: 0.0182\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0162 - val_loss: 0.0178\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0163\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0107 - val_loss: 0.0145\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0147\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0130\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0157 - val_loss: 0.0190\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0161\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0125 - val_loss: 0.0165\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0168\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0126 - val_loss: 0.0218\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0170\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0145\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0194\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0148 - val_loss: 0.0255\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0150 - val_loss: 0.0167\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0169\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0207\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0166\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0165\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0190\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0198\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0119 - val_loss: 0.0159\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0178\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0155\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0124 - val_loss: 0.0150\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0100 - val_loss: 0.0155\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0089 - val_loss: 0.0159\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0073 - val_loss: 0.0244\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0138 - val_loss: 0.0173\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0084 - val_loss: 0.0157\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0077 - val_loss: 0.0184\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0073 - val_loss: 0.0134\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0070 - val_loss: 0.0181\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0059 - val_loss: 0.0145\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0079 - val_loss: 0.0221\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A88CEE83A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 35ms/step - loss: 0.0668 - val_loss: 0.0284\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0256 - val_loss: 0.0284\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0342 - val_loss: 0.0270\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0322 - val_loss: 0.0263\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0258 - val_loss: 0.0256\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0277 - val_loss: 0.0254\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0222 - val_loss: 0.0330\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0260 - val_loss: 0.0290\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0227 - val_loss: 0.0351\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0258 - val_loss: 0.0343\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0265 - val_loss: 0.0277\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0189 - val_loss: 0.0264\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0231 - val_loss: 0.0309\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0205 - val_loss: 0.0244\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0235 - val_loss: 0.0249\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0221 - val_loss: 0.0258\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0222 - val_loss: 0.0268\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0226 - val_loss: 0.0334\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0195 - val_loss: 0.0240\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0255 - val_loss: 0.0237\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0218 - val_loss: 0.0259\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0251 - val_loss: 0.0237\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0218 - val_loss: 0.0249\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0286 - val_loss: 0.0366\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0231 - val_loss: 0.0238\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0196 - val_loss: 0.0237\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0312 - val_loss: 0.0276\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0183 - val_loss: 0.0254\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0172 - val_loss: 0.0233\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0209 - val_loss: 0.0250\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0305 - val_loss: 0.0231\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0254 - val_loss: 0.0265\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0235 - val_loss: 0.0245\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0193 - val_loss: 0.0254\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0216 - val_loss: 0.0233\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0252 - val_loss: 0.0225\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0177 - val_loss: 0.0248\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0211 - val_loss: 0.0245\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.0161 - val_loss: 0.0225\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0194 - val_loss: 0.0231\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0207 - val_loss: 0.0225\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0176 - val_loss: 0.0258\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0268 - val_loss: 0.0217\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0187 - val_loss: 0.0243\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0219 - val_loss: 0.0229\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0170 - val_loss: 0.0229\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0225 - val_loss: 0.0209\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0146 - val_loss: 0.0224\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0254 - val_loss: 0.0233\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0185 - val_loss: 0.0203\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0205 - val_loss: 0.0269\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0251\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0221 - val_loss: 0.0204\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0181 - val_loss: 0.0252\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0206 - val_loss: 0.0198\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0214 - val_loss: 0.0191\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0200\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0155 - val_loss: 0.0192\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0161 - val_loss: 0.0202\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0214 - val_loss: 0.0251\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0149 - val_loss: 0.0194\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0226 - val_loss: 0.0208\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0144 - val_loss: 0.0193\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0246 - val_loss: 0.0198\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.0192\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0138 - val_loss: 0.0206\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0270 - val_loss: 0.0187\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0189 - val_loss: 0.0177\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0137 - val_loss: 0.0225\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0188 - val_loss: 0.0222\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.0175\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0185 - val_loss: 0.0197\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0216 - val_loss: 0.0271\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0137 - val_loss: 0.0168\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0190\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0157 - val_loss: 0.0174\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.0251\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0153 - val_loss: 0.0201\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0216 - val_loss: 0.0173\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0154 - val_loss: 0.0172\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0182\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0156 - val_loss: 0.0150\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0114 - val_loss: 0.0157\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0119 - val_loss: 0.0204\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0148 - val_loss: 0.0159\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0188 - val_loss: 0.0170\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0189 - val_loss: 0.0177\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0125 - val_loss: 0.0157\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0141 - val_loss: 0.0207\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0163 - val_loss: 0.0159\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0163\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.0172\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0135 - val_loss: 0.0200\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0144 - val_loss: 0.0159\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0086 - val_loss: 0.0230\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0128 - val_loss: 0.0250\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0138 - val_loss: 0.0128\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0082 - val_loss: 0.0201\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0125 - val_loss: 0.0151\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0084 - val_loss: 0.0179\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0127 - val_loss: 0.0189\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0165\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0083 - val_loss: 0.0155\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0110 - val_loss: 0.0190\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0075 - val_loss: 0.0162\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0072 - val_loss: 0.0224\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0076 - val_loss: 0.0184\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0161\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0077 - val_loss: 0.0239\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0066 - val_loss: 0.0167\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0215\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0106 - val_loss: 0.0156\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0063 - val_loss: 0.0171\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0061 - val_loss: 0.0200\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0051 - val_loss: 0.0214\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0043 - val_loss: 0.0237\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0056 - val_loss: 0.0271\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0082 - val_loss: 0.0135\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0052 - val_loss: 0.0183\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0061 - val_loss: 0.0192\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0042 - val_loss: 0.0249\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.0040 - val_loss: 0.0236\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0042 - val_loss: 0.0213\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0049 - val_loss: 0.0242\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0043 - val_loss: 0.0193\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0034 - val_loss: 0.0224\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0045 - val_loss: 0.0275\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A70CE0AA60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 65ms/step - loss: 0.0610 - val_loss: 0.0327\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0293 - val_loss: 0.0273\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0351 - val_loss: 0.0267\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0285 - val_loss: 0.0323\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0274 - val_loss: 0.0307\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0318 - val_loss: 0.0253\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0280 - val_loss: 0.0288\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0233 - val_loss: 0.0255\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0186 - val_loss: 0.0257\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0209 - val_loss: 0.0245\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0235 - val_loss: 0.0266\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0242 - val_loss: 0.0257\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0316 - val_loss: 0.0259\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0216 - val_loss: 0.0294\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0230 - val_loss: 0.0275\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0247 - val_loss: 0.0254\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0260 - val_loss: 0.0296\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0198 - val_loss: 0.0261\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0271 - val_loss: 0.0294\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0218 - val_loss: 0.0245\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0266 - val_loss: 0.0255\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0225 - val_loss: 0.0240\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0278 - val_loss: 0.0241\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0225 - val_loss: 0.0245\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0280 - val_loss: 0.0263\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0348 - val_loss: 0.0323\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0318 - val_loss: 0.0397\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0174 - val_loss: 0.0234\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0201 - val_loss: 0.0261\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0234 - val_loss: 0.0237\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0168 - val_loss: 0.0248\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0230\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0213 - val_loss: 0.0258\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0292 - val_loss: 0.0228\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0205 - val_loss: 0.0227\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0233 - val_loss: 0.0278\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0160 - val_loss: 0.0249\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0337 - val_loss: 0.0228\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0243 - val_loss: 0.0253\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0231 - val_loss: 0.0235\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0248 - val_loss: 0.0245\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0261 - val_loss: 0.0251\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0216 - val_loss: 0.0230\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0181 - val_loss: 0.0224\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0256 - val_loss: 0.0251\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0164 - val_loss: 0.0220\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0222 - val_loss: 0.0257\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0221 - val_loss: 0.0220\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0193 - val_loss: 0.0252\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0179 - val_loss: 0.0216\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0192 - val_loss: 0.0226\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0225 - val_loss: 0.0214\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0206 - val_loss: 0.0237\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0175 - val_loss: 0.0233\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0240 - val_loss: 0.0203\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0201 - val_loss: 0.0203\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0177 - val_loss: 0.0216\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0194 - val_loss: 0.0203\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0208 - val_loss: 0.0225\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0149 - val_loss: 0.0220\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0195 - val_loss: 0.0198\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0157 - val_loss: 0.0239\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0178 - val_loss: 0.0197\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0179 - val_loss: 0.0201\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0186 - val_loss: 0.0193\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0182 - val_loss: 0.0192\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0190 - val_loss: 0.0194\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0146 - val_loss: 0.0191\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0237 - val_loss: 0.0255\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0157 - val_loss: 0.0202\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0165 - val_loss: 0.0167\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0199\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0203 - val_loss: 0.0177\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0160 - val_loss: 0.0158\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0173 - val_loss: 0.0264\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.0176\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0144 - val_loss: 0.0197\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0125 - val_loss: 0.0183\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0156 - val_loss: 0.0194\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0169 - val_loss: 0.0182\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0153 - val_loss: 0.0214\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.0187\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0184 - val_loss: 0.0159\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0191\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0159\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0122 - val_loss: 0.0141\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0167 - val_loss: 0.0191\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0200\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0271\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0162 - val_loss: 0.0183\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0110 - val_loss: 0.0186\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0161\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0364\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0114 - val_loss: 0.0222\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0110 - val_loss: 0.0154\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0170\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0095 - val_loss: 0.0217\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0183\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0107 - val_loss: 0.0194\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.0165 - val_loss: 0.0167\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0103 - val_loss: 0.0162\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0082 - val_loss: 0.0211\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0114 - val_loss: 0.0143\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0192\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0179 - val_loss: 0.0156\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0191\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0079 - val_loss: 0.0136\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0066 - val_loss: 0.0171\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0070 - val_loss: 0.0150\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0082 - val_loss: 0.0173\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0075 - val_loss: 0.0176\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0060 - val_loss: 0.0154\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0083 - val_loss: 0.0190\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0131 - val_loss: 0.0142\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0140\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0066 - val_loss: 0.0171\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A8895B2310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 35ms/step - loss: 0.0497 - val_loss: 0.0313\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0309 - val_loss: 0.0272\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0383 - val_loss: 0.0331\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0278 - val_loss: 0.0376\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0293 - val_loss: 0.0355\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0222 - val_loss: 0.0256\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0270 - val_loss: 0.0428\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0320 - val_loss: 0.0251\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0220 - val_loss: 0.0246\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0245 - val_loss: 0.0265\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0330 - val_loss: 0.0253\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0265 - val_loss: 0.0246\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0225 - val_loss: 0.0243\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0264 - val_loss: 0.0244\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0271 - val_loss: 0.0332\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0305 - val_loss: 0.0238\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0240 - val_loss: 0.0256\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0301 - val_loss: 0.0281\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0209 - val_loss: 0.0262\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0213 - val_loss: 0.0245\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0222 - val_loss: 0.0322\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0231 - val_loss: 0.0259\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0241 - val_loss: 0.0276\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0246 - val_loss: 0.0246\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0237 - val_loss: 0.0233\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0183 - val_loss: 0.0234\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0250 - val_loss: 0.0248\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0258 - val_loss: 0.0258\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0182 - val_loss: 0.0243\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0228 - val_loss: 0.0267\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0247 - val_loss: 0.0260\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0253 - val_loss: 0.0266\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0276 - val_loss: 0.0225\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0263\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0240 - val_loss: 0.0241\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0221 - val_loss: 0.0243\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0264 - val_loss: 0.0221\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0224 - val_loss: 0.0287\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0228 - val_loss: 0.0229\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0260\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0198 - val_loss: 0.0395\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0314 - val_loss: 0.0218\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0196 - val_loss: 0.0222\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0223 - val_loss: 0.0215\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0260 - val_loss: 0.0216\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0185 - val_loss: 0.0218\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0192 - val_loss: 0.0245\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0203 - val_loss: 0.0214\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0193 - val_loss: 0.0291\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0225 - val_loss: 0.0239\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0201 - val_loss: 0.0234\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0204\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0155 - val_loss: 0.0206\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0227 - val_loss: 0.0243\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0221 - val_loss: 0.0229\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0176 - val_loss: 0.0221\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0200 - val_loss: 0.0218\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0212\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0249 - val_loss: 0.0201\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0207\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0203 - val_loss: 0.0185\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0178 - val_loss: 0.0231\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0234 - val_loss: 0.0213\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0169 - val_loss: 0.0208\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0221 - val_loss: 0.0183\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0182 - val_loss: 0.0217\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0201 - val_loss: 0.0184\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.0207 - val_loss: 0.0192\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0216 - val_loss: 0.0173\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0160 - val_loss: 0.0183\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0195\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0160 - val_loss: 0.0181\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0209 - val_loss: 0.0218\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0172 - val_loss: 0.0202\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0206 - val_loss: 0.0173\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0157 - val_loss: 0.0230\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0225 - val_loss: 0.0177\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0106 - val_loss: 0.0182\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0151 - val_loss: 0.0233\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0180 - val_loss: 0.0187\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0223\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0117 - val_loss: 0.0187\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0157 - val_loss: 0.0286\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.0201\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0147\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0125 - val_loss: 0.0247\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0148 - val_loss: 0.0153\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0134 - val_loss: 0.0166\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0149 - val_loss: 0.0213\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0120 - val_loss: 0.0216\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0134 - val_loss: 0.0153\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0113 - val_loss: 0.0249\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0165\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0216\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0175 - val_loss: 0.0188\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0169 - val_loss: 0.0218\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0128 - val_loss: 0.0153\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0118 - val_loss: 0.0219\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0181\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0155\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0178\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0151 - val_loss: 0.0199\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0173\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0165\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0125 - val_loss: 0.0164\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0067 - val_loss: 0.0169\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0191\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0051 - val_loss: 0.0133\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0080 - val_loss: 0.0167\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0181\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0136 - val_loss: 0.0114\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0066 - val_loss: 0.0163\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0059 - val_loss: 0.0151\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0067 - val_loss: 0.0162\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0060 - val_loss: 0.0157\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0052 - val_loss: 0.0146\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0052 - val_loss: 0.0153\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0062 - val_loss: 0.0150\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0054 - val_loss: 0.0150\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0057 - val_loss: 0.0157\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0052 - val_loss: 0.0140\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0039 - val_loss: 0.0159\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0062 - val_loss: 0.0212\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0079 - val_loss: 0.0168\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0057 - val_loss: 0.0165\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0041 - val_loss: 0.0146\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0045 - val_loss: 0.0160\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0051 - val_loss: 0.0196\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0040 - val_loss: 0.0139\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0043 - val_loss: 0.0187\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0037 - val_loss: 0.0224\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0042 - val_loss: 0.0172\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0040 - val_loss: 0.0177\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0043 - val_loss: 0.0184\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0067 - val_loss: 0.0254\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0040 - val_loss: 0.0139\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0021 - val_loss: 0.0245\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0046 - val_loss: 0.0205\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0025 - val_loss: 0.0161\n",
      "Epoch 140/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0023 - val_loss: 0.0182\n",
      "Epoch 141/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0022 - val_loss: 0.0198\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A70DC36DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 36ms/step - loss: 0.0656 - val_loss: 0.0285\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0310 - val_loss: 0.0361\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0198 - val_loss: 0.0334\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0197 - val_loss: 0.0285\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0308 - val_loss: 0.0325\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0225 - val_loss: 0.0257\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0214 - val_loss: 0.0265\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0302 - val_loss: 0.0306\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0249 - val_loss: 0.0273\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0215 - val_loss: 0.0271\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0185 - val_loss: 0.0244\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0354 - val_loss: 0.0282\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0245 - val_loss: 0.0278\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0284 - val_loss: 0.0242\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0234 - val_loss: 0.0243\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0239 - val_loss: 0.0242\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0228 - val_loss: 0.0239\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.0238 - val_loss: 0.0351\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0231 - val_loss: 0.0245\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0198 - val_loss: 0.0237\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0254 - val_loss: 0.0256\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0245 - val_loss: 0.0245\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0230 - val_loss: 0.0238\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0255 - val_loss: 0.0269\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0262 - val_loss: 0.0233\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0249 - val_loss: 0.0256\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0285 - val_loss: 0.0232\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0193 - val_loss: 0.0273\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0325 - val_loss: 0.0247\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0208 - val_loss: 0.0333\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0219 - val_loss: 0.0269\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0241 - val_loss: 0.0242\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0223 - val_loss: 0.0261\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0268 - val_loss: 0.0240\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0237 - val_loss: 0.0227\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0188 - val_loss: 0.0231\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0240 - val_loss: 0.0323\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0221 - val_loss: 0.0224\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0217 - val_loss: 0.0285\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0201 - val_loss: 0.0272\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0207 - val_loss: 0.0215\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0183 - val_loss: 0.0214\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0176 - val_loss: 0.0226\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0200 - val_loss: 0.0239\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0198 - val_loss: 0.0214\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0221 - val_loss: 0.0211\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0228 - val_loss: 0.0225\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0136 - val_loss: 0.0235\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0216\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0152 - val_loss: 0.0253\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0239 - val_loss: 0.0204\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.0209\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0248 - val_loss: 0.0211\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0154 - val_loss: 0.0197\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0216 - val_loss: 0.0217\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0227 - val_loss: 0.0223\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0157 - val_loss: 0.0197\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0147 - val_loss: 0.0218\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0191 - val_loss: 0.0225\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0208 - val_loss: 0.0195\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0169 - val_loss: 0.0181\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0135 - val_loss: 0.0188\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0141 - val_loss: 0.0172\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0224 - val_loss: 0.0215\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0195 - val_loss: 0.0217\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0189 - val_loss: 0.0194\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0208\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0187 - val_loss: 0.0191\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0151 - val_loss: 0.0187\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0185 - val_loss: 0.0188\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0245 - val_loss: 0.0171\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0204 - val_loss: 0.0235\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0182 - val_loss: 0.0160\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0212 - val_loss: 0.0165\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0143 - val_loss: 0.0211\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0164\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0162 - val_loss: 0.0148\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0218\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0156\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0120 - val_loss: 0.0168\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0150\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0139 - val_loss: 0.0242\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.0190\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0140 - val_loss: 0.0179\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0139 - val_loss: 0.0209\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0133 - val_loss: 0.0155\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0163 - val_loss: 0.0212\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0186\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0110 - val_loss: 0.0182\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0102 - val_loss: 0.0184\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0095 - val_loss: 0.0189\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0128 - val_loss: 0.0161\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0124 - val_loss: 0.0137\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0086 - val_loss: 0.0147\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0126 - val_loss: 0.0150\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0066 - val_loss: 0.0156\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0106 - val_loss: 0.0175\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0087 - val_loss: 0.0138\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0138 - val_loss: 0.0165\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0084 - val_loss: 0.0135\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.0098 - val_loss: 0.0221\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0160 - val_loss: 0.0161\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0075 - val_loss: 0.0148\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0073 - val_loss: 0.0142\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0064 - val_loss: 0.0174\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0130 - val_loss: 0.0220\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0071 - val_loss: 0.0209\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0078 - val_loss: 0.0156\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0060 - val_loss: 0.0172\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0046 - val_loss: 0.0180\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0061 - val_loss: 0.0179\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0054 - val_loss: 0.0142\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0051 - val_loss: 0.0217\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0065 - val_loss: 0.0188\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0056 - val_loss: 0.0174\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0044 - val_loss: 0.0145\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0063 - val_loss: 0.0140\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0046 - val_loss: 0.0189\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0036 - val_loss: 0.0206\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0047 - val_loss: 0.0192\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0045 - val_loss: 0.0179\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0047 - val_loss: 0.0223\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0047 - val_loss: 0.0217\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A70CA9E3A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 36ms/step - loss: 0.0581 - val_loss: 0.0308\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0290 - val_loss: 0.0277\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0357 - val_loss: 0.0277\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0337 - val_loss: 0.0278\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0215 - val_loss: 0.0256\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0253 - val_loss: 0.0307\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0290 - val_loss: 0.0252\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0261 - val_loss: 0.0261\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0287 - val_loss: 0.0286\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0300 - val_loss: 0.0245\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0235 - val_loss: 0.0256\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0276 - val_loss: 0.0245\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0254 - val_loss: 0.0243\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0234 - val_loss: 0.0243\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0255 - val_loss: 0.0253\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0226 - val_loss: 0.0243\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0231 - val_loss: 0.0314\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0226 - val_loss: 0.0306\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0182 - val_loss: 0.0239\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0271 - val_loss: 0.0304\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0238 - val_loss: 0.0239\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0218 - val_loss: 0.0236\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0273 - val_loss: 0.0241\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0230 - val_loss: 0.0236\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0203 - val_loss: 0.0232\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0161 - val_loss: 0.0232\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0241 - val_loss: 0.0253\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0199 - val_loss: 0.0229\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0200 - val_loss: 0.0254\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0297 - val_loss: 0.0240\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0225\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0240 - val_loss: 0.0232\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0237 - val_loss: 0.0237\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0212 - val_loss: 0.0285\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0240 - val_loss: 0.0303\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0224 - val_loss: 0.0373\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0221 - val_loss: 0.0228\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0208 - val_loss: 0.0235\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0227 - val_loss: 0.0296\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0211 - val_loss: 0.0269\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0254 - val_loss: 0.0312\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0213 - val_loss: 0.0235\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0225 - val_loss: 0.0225\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0197 - val_loss: 0.0273\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0211 - val_loss: 0.0310\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0217 - val_loss: 0.0250\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0258 - val_loss: 0.0208\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0208 - val_loss: 0.0209\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0190 - val_loss: 0.0210\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0205 - val_loss: 0.0229\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0185 - val_loss: 0.0238\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0254 - val_loss: 0.0204\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0149 - val_loss: 0.0222\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0176 - val_loss: 0.0200\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0169 - val_loss: 0.0217\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0185 - val_loss: 0.0211\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.0199\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0199 - val_loss: 0.0211\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0204 - val_loss: 0.0194\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0156 - val_loss: 0.0192\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0190\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.0198\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.0184\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0181\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0207 - val_loss: 0.0180\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0151 - val_loss: 0.0202\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0189 - val_loss: 0.0198\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0202\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0146 - val_loss: 0.0192\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0138 - val_loss: 0.0258\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0210 - val_loss: 0.0208\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0169\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.0169\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0132 - val_loss: 0.0167\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0174 - val_loss: 0.0171\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0161 - val_loss: 0.0203\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0182 - val_loss: 0.0159\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0156 - val_loss: 0.0208\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0122 - val_loss: 0.0178\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0127 - val_loss: 0.0157\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0119 - val_loss: 0.0182\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.0115 - val_loss: 0.0184\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0151 - val_loss: 0.0252\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0165 - val_loss: 0.0202\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0148 - val_loss: 0.0177\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0112 - val_loss: 0.0194\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0137 - val_loss: 0.0183\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0112 - val_loss: 0.0202\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0223\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0172 - val_loss: 0.0197\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.0256\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0120 - val_loss: 0.0153\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0174\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0127 - val_loss: 0.0210\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0096 - val_loss: 0.0175\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0203\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0102 - val_loss: 0.0197\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0102 - val_loss: 0.0179\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0093 - val_loss: 0.0204\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0190\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0191\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0119 - val_loss: 0.0213\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0077 - val_loss: 0.0191\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.0201\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0161\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0223\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0066 - val_loss: 0.0206\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0048 - val_loss: 0.0208\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0052 - val_loss: 0.0189\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0049 - val_loss: 0.0221\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A881A5B5E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 5s 37ms/step - loss: 0.0872 - val_loss: 0.0293\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0316 - val_loss: 0.0295\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0271 - val_loss: 0.0283\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0285 - val_loss: 0.0285\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0305 - val_loss: 0.0271\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0224 - val_loss: 0.0268\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0312 - val_loss: 0.0251\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0246 - val_loss: 0.0354\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0267 - val_loss: 0.0373\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0373 - val_loss: 0.0332\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0214 - val_loss: 0.0382\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0246 - val_loss: 0.0250\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0209 - val_loss: 0.0244\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0225 - val_loss: 0.0245\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0184 - val_loss: 0.0249\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0304 - val_loss: 0.0246\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0210 - val_loss: 0.0248\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0189 - val_loss: 0.0249\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0234 - val_loss: 0.0268\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0162 - val_loss: 0.0283\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0427 - val_loss: 0.0269\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0286 - val_loss: 0.0308\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0245 - val_loss: 0.0273\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0227 - val_loss: 0.0236\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0207 - val_loss: 0.0302\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0236 - val_loss: 0.0268\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0236 - val_loss: 0.0234\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0219 - val_loss: 0.0277\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0184 - val_loss: 0.0241\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0151 - val_loss: 0.0228\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0229 - val_loss: 0.0230\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0209 - val_loss: 0.0242\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0247 - val_loss: 0.0335\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0226 - val_loss: 0.0258\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0185 - val_loss: 0.0281\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0227 - val_loss: 0.0365\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0246 - val_loss: 0.0224\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0224 - val_loss: 0.0223\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0228 - val_loss: 0.0225\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0149 - val_loss: 0.0218\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0222 - val_loss: 0.0217\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.0247\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0213 - val_loss: 0.0266\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0212 - val_loss: 0.0243\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0232\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0210 - val_loss: 0.0238\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0234 - val_loss: 0.0213\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0172 - val_loss: 0.0228\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0200 - val_loss: 0.0207\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0176 - val_loss: 0.0215\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0159 - val_loss: 0.0205\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0207\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.0180 - val_loss: 0.0201\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0281 - val_loss: 0.0229\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0141 - val_loss: 0.0221\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0199 - val_loss: 0.0268\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0233\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0199 - val_loss: 0.0210\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0211 - val_loss: 0.0205\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0181 - val_loss: 0.0194\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0167 - val_loss: 0.0208\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0179 - val_loss: 0.0186\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0185 - val_loss: 0.0180\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0181 - val_loss: 0.0182\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0175\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0183 - val_loss: 0.0171\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0130 - val_loss: 0.0170\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0187 - val_loss: 0.0181\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.0176\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0179 - val_loss: 0.0195\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0191\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0143 - val_loss: 0.0224\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0162 - val_loss: 0.0191\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0159 - val_loss: 0.0225\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0135 - val_loss: 0.0250\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0168 - val_loss: 0.0171\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0143 - val_loss: 0.0187\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0150 - val_loss: 0.0197\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0135 - val_loss: 0.0170\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0134 - val_loss: 0.0193\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0122 - val_loss: 0.0169\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0120 - val_loss: 0.0149\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0250\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0120 - val_loss: 0.0226\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.0151\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0189\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0157 - val_loss: 0.0179\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0190 - val_loss: 0.0193\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0172\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0140 - val_loss: 0.0152\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0076 - val_loss: 0.0179\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0194\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0106 - val_loss: 0.0183\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0090 - val_loss: 0.0157\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0077 - val_loss: 0.0176\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0195\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0070 - val_loss: 0.0206\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0131\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0077 - val_loss: 0.0218\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0089 - val_loss: 0.0143\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0175\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0106 - val_loss: 0.0191\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0118\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0071 - val_loss: 0.0195\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0052 - val_loss: 0.0124\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0069 - val_loss: 0.0117\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0088 - val_loss: 0.0175\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0063 - val_loss: 0.0146\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0062 - val_loss: 0.0167\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0047 - val_loss: 0.0199\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0044 - val_loss: 0.0206\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0050 - val_loss: 0.0163\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0085 - val_loss: 0.0148\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0050 - val_loss: 0.0143\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0055 - val_loss: 0.0173\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0065 - val_loss: 0.0169\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0067 - val_loss: 0.0121\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0053 - val_loss: 0.0162\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0045 - val_loss: 0.0184\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0042 - val_loss: 0.0191\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0052 - val_loss: 0.0219\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0045 - val_loss: 0.0186\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0034 - val_loss: 0.0216\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0044 - val_loss: 0.0302\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0046 - val_loss: 0.0175\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0048 - val_loss: 0.0318\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0031 - val_loss: 0.0244\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0033 - val_loss: 0.0181\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0034 - val_loss: 0.0278\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0044 - val_loss: 0.0218\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0033 - val_loss: 0.0244\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0032 - val_loss: 0.0231\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0039 - val_loss: 0.0188\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A8877BDD30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 35ms/step - loss: 0.0496 - val_loss: 0.0461\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0393 - val_loss: 0.0281\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0230 - val_loss: 0.0267\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0235 - val_loss: 0.0298\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0288 - val_loss: 0.0353\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0232 - val_loss: 0.0362\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0300 - val_loss: 0.0251\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0243 - val_loss: 0.0258\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0316 - val_loss: 0.0271\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0236 - val_loss: 0.0247\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0252 - val_loss: 0.0396\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.0212 - val_loss: 0.0258\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0209 - val_loss: 0.0281\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0313 - val_loss: 0.0241\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0249 - val_loss: 0.0244\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0252 - val_loss: 0.0240\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0215 - val_loss: 0.0249\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0266 - val_loss: 0.0241\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0202 - val_loss: 0.0244\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0191 - val_loss: 0.0251\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0185 - val_loss: 0.0242\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0227 - val_loss: 0.0253\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0200 - val_loss: 0.0263\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0217 - val_loss: 0.0266\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0215 - val_loss: 0.0297\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0223 - val_loss: 0.0243\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0311 - val_loss: 0.0288\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0258 - val_loss: 0.0244\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0216 - val_loss: 0.0230\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0190 - val_loss: 0.0266\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0214 - val_loss: 0.0313\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0335 - val_loss: 0.0244\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0177 - val_loss: 0.0298\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0234 - val_loss: 0.0233\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0233 - val_loss: 0.0232\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0194 - val_loss: 0.0225\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0222 - val_loss: 0.0220\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0235 - val_loss: 0.0224\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0261 - val_loss: 0.0218\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0207 - val_loss: 0.0312\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0332 - val_loss: 0.0249\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0204 - val_loss: 0.0219\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0214 - val_loss: 0.0239\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0179 - val_loss: 0.0215\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0177 - val_loss: 0.0209\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0182 - val_loss: 0.0240\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.0213\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0195 - val_loss: 0.0220\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0241 - val_loss: 0.0323\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0171 - val_loss: 0.0219\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0177 - val_loss: 0.0218\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0225 - val_loss: 0.0204\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0201 - val_loss: 0.0200\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0183 - val_loss: 0.0280\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0201\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0181 - val_loss: 0.0209\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0228\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0173 - val_loss: 0.0199\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0218 - val_loss: 0.0207\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0169 - val_loss: 0.0190\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0219\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0193\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.0195\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0196\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0132 - val_loss: 0.0188\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0243 - val_loss: 0.0200\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0224 - val_loss: 0.0206\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0167 - val_loss: 0.0197\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0180 - val_loss: 0.0178\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0147 - val_loss: 0.0202\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0178 - val_loss: 0.0168\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.0161\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0136 - val_loss: 0.0161\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0179\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0206 - val_loss: 0.0239\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0178 - val_loss: 0.0155\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0217 - val_loss: 0.0202\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0157 - val_loss: 0.0155\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0112 - val_loss: 0.0165\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0128 - val_loss: 0.0194\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0130 - val_loss: 0.0175\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0145 - val_loss: 0.0199\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0166 - val_loss: 0.0166\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0182\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0123 - val_loss: 0.0205\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0168\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0206\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0107 - val_loss: 0.0156\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.0181\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0154\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.0220\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0169\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0300\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 1s 28ms/step - loss: 0.0127 - val_loss: 0.0176\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0140 - val_loss: 0.0179\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0159\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0197\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.0297\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0190\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0073 - val_loss: 0.0177\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0212\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0151\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0089 - val_loss: 0.0172\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0230\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0161\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0058 - val_loss: 0.0186\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A8754F40D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 5s 68ms/step - loss: 0.0523 - val_loss: 0.0283\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0257 - val_loss: 0.0308\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0267 - val_loss: 0.0282\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0264 - val_loss: 0.0338\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0349 - val_loss: 0.0290\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0371 - val_loss: 0.0304\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0343 - val_loss: 0.0248\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0187 - val_loss: 0.0249\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0296 - val_loss: 0.0266\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0249 - val_loss: 0.0293\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0205 - val_loss: 0.0269\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0216 - val_loss: 0.0241\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0210 - val_loss: 0.0240\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0215 - val_loss: 0.0295\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0192 - val_loss: 0.0255\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0278 - val_loss: 0.0259\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0256 - val_loss: 0.0248\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0245 - val_loss: 0.0262\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0290 - val_loss: 0.0293\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0189 - val_loss: 0.0252\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0304 - val_loss: 0.0399\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0299 - val_loss: 0.0241\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0263 - val_loss: 0.0291\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0269 - val_loss: 0.0259\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0284 - val_loss: 0.0236\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0195 - val_loss: 0.0258\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0250 - val_loss: 0.0236\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0241 - val_loss: 0.0309\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0251 - val_loss: 0.0230\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0201 - val_loss: 0.0321\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0222 - val_loss: 0.0237\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0205 - val_loss: 0.0257\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0249 - val_loss: 0.0243\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0232 - val_loss: 0.0231\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0259 - val_loss: 0.0221\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0231\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0237 - val_loss: 0.0225\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0215 - val_loss: 0.0218\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0182 - val_loss: 0.0231\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0192 - val_loss: 0.0224\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.0215\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0283 - val_loss: 0.0230\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0199 - val_loss: 0.0229\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0287 - val_loss: 0.0279\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0237 - val_loss: 0.0266\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0287 - val_loss: 0.0308\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0178 - val_loss: 0.0224\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0198 - val_loss: 0.0214\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0187 - val_loss: 0.0209\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0215\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0275 - val_loss: 0.0204\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0176 - val_loss: 0.0207\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0209 - val_loss: 0.0211\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0243 - val_loss: 0.0229\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0245 - val_loss: 0.0237\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0167 - val_loss: 0.0207\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0151 - val_loss: 0.0195\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.0356\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0200 - val_loss: 0.0198\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0226 - val_loss: 0.0189\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0226\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0191 - val_loss: 0.0191\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0195 - val_loss: 0.0179\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0138 - val_loss: 0.0231\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.0216\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0138 - val_loss: 0.0184\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0174\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0192 - val_loss: 0.0205\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0162 - val_loss: 0.0172\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0204\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0192 - val_loss: 0.0207\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0248\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0186 - val_loss: 0.0190\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0186 - val_loss: 0.0177\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0266 - val_loss: 0.0183\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0167 - val_loss: 0.0159\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0224 - val_loss: 0.0168\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0200\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0164\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0159\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0134 - val_loss: 0.0199\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0134 - val_loss: 0.0173\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0200\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0117 - val_loss: 0.0182\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0176 - val_loss: 0.0212\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0128 - val_loss: 0.0157\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0155 - val_loss: 0.0169\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0168 - val_loss: 0.0172\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0120 - val_loss: 0.0162\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0146 - val_loss: 0.0146\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0095 - val_loss: 0.0186\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.0115 - val_loss: 0.0146\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0199\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0106 - val_loss: 0.0151\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0174\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0171\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0077 - val_loss: 0.0136\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0084 - val_loss: 0.0262\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0155 - val_loss: 0.0198\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0087 - val_loss: 0.0131\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0168\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0123 - val_loss: 0.0263\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0179 - val_loss: 0.0243\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0114\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0074 - val_loss: 0.0169\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0071 - val_loss: 0.0228\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0184\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0067 - val_loss: 0.0137\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0051 - val_loss: 0.0233\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0070 - val_loss: 0.0249\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0074 - val_loss: 0.0171\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0156\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0058 - val_loss: 0.0146\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0046 - val_loss: 0.0191\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0063 - val_loss: 0.0185\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0050 - val_loss: 0.0172\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0033 - val_loss: 0.0182\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0044 - val_loss: 0.0184\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0043 - val_loss: 0.0239\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0076 - val_loss: 0.0169\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0121 - val_loss: 0.0159\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0063 - val_loss: 0.0127\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0044 - val_loss: 0.0149\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0053 - val_loss: 0.0166\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0039 - val_loss: 0.0210\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0052 - val_loss: 0.0156\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0041 - val_loss: 0.0183\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0028 - val_loss: 0.0224\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0042 - val_loss: 0.0190\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0025 - val_loss: 0.0147\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0032 - val_loss: 0.0198\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0033 - val_loss: 0.0174\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0026 - val_loss: 0.0189\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0031 - val_loss: 0.0209\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A70CC35940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 5s 39ms/step - loss: 0.0597 - val_loss: 0.0312\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0272 - val_loss: 0.0371\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0271 - val_loss: 0.0553\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0322 - val_loss: 0.0294\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0220 - val_loss: 0.0266\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0263 - val_loss: 0.0311\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0275 - val_loss: 0.0253\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0170 - val_loss: 0.0275\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0245 - val_loss: 0.0250\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0212 - val_loss: 0.0245\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0278 - val_loss: 0.0325\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0382 - val_loss: 0.0246\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0212 - val_loss: 0.0394\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0344 - val_loss: 0.0254\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0210 - val_loss: 0.0324\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0223 - val_loss: 0.0259\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0256 - val_loss: 0.0238\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0216 - val_loss: 0.0302\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0191 - val_loss: 0.0235\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0233 - val_loss: 0.0363\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0225 - val_loss: 0.0233\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0223 - val_loss: 0.0240\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0266 - val_loss: 0.0307\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0267 - val_loss: 0.0319\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0231 - val_loss: 0.0243\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0297 - val_loss: 0.0240\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0227 - val_loss: 0.0339\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0150 - val_loss: 0.0237\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0216 - val_loss: 0.0234\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0278 - val_loss: 0.0236\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0279 - val_loss: 0.0266\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0235 - val_loss: 0.0417\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0257 - val_loss: 0.0331\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.0246 - val_loss: 0.0223\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0199 - val_loss: 0.0224\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0203 - val_loss: 0.0249\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0266 - val_loss: 0.0223\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0271 - val_loss: 0.0219\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0266 - val_loss: 0.0272\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0203 - val_loss: 0.0319\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0238 - val_loss: 0.0258\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0164 - val_loss: 0.0218\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0208 - val_loss: 0.0213\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0214 - val_loss: 0.0221\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0193 - val_loss: 0.0228\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0229 - val_loss: 0.0212\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0172 - val_loss: 0.0217\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0159 - val_loss: 0.0212\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0156 - val_loss: 0.0216\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0210 - val_loss: 0.0202\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0202\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0154 - val_loss: 0.0244\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0282 - val_loss: 0.0244\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0224 - val_loss: 0.0197\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0172 - val_loss: 0.0195\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0142 - val_loss: 0.0188\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0174 - val_loss: 0.0208\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0174 - val_loss: 0.0222\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0190 - val_loss: 0.0222\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0190 - val_loss: 0.0228\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0201\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0198 - val_loss: 0.0189\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0257 - val_loss: 0.0215\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.0223\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0157 - val_loss: 0.0191\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0163 - val_loss: 0.0177\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0139 - val_loss: 0.0173\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0148 - val_loss: 0.0171\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0168 - val_loss: 0.0199\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0193 - val_loss: 0.0184\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0165 - val_loss: 0.0177\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0226 - val_loss: 0.0178\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0164 - val_loss: 0.0225\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0169 - val_loss: 0.0213\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0211 - val_loss: 0.0181\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0149 - val_loss: 0.0180\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0135 - val_loss: 0.0183\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0123 - val_loss: 0.0201\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0173 - val_loss: 0.0181\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.0172\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0128 - val_loss: 0.0204\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0149 - val_loss: 0.0188\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0152 - val_loss: 0.0178\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0106 - val_loss: 0.0267\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0147 - val_loss: 0.0174\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0136 - val_loss: 0.0194\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0127 - val_loss: 0.0161\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0207\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0117 - val_loss: 0.0149\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0125 - val_loss: 0.0259\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0168\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0122 - val_loss: 0.0159\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0185\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0102 - val_loss: 0.0163\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0086 - val_loss: 0.0233\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0147\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0149\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0182\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0167 - val_loss: 0.0242\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0208 - val_loss: 0.0163\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0132 - val_loss: 0.0157\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0066 - val_loss: 0.0134\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0085 - val_loss: 0.0181\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0159\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0077 - val_loss: 0.0156\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0100 - val_loss: 0.0134\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0071 - val_loss: 0.0151\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0071 - val_loss: 0.0179\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0110 - val_loss: 0.0217\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0171\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0104 - val_loss: 0.0201\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0184\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0059 - val_loss: 0.0158\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0056 - val_loss: 0.0139\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0067 - val_loss: 0.0142\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0061 - val_loss: 0.0135\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0044 - val_loss: 0.0222\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0077 - val_loss: 0.0155\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0052 - val_loss: 0.0158\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0050 - val_loss: 0.0168\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0041 - val_loss: 0.0161\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0045 - val_loss: 0.0176\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0044 - val_loss: 0.0220\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0039 - val_loss: 0.0227\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0039 - val_loss: 0.0216\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0046 - val_loss: 0.0187\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0038 - val_loss: 0.0183\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0030 - val_loss: 0.0162\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0037 - val_loss: 0.0217\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0044 - val_loss: 0.0204\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0035 - val_loss: 0.0223\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0044 - val_loss: 0.0197\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A70DC8C4C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 57ms/step - loss: 0.0878 - val_loss: 0.0308\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0326 - val_loss: 0.0273\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0259 - val_loss: 0.0271\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0277 - val_loss: 0.0283\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0239 - val_loss: 0.0286\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0255 - val_loss: 0.0277\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0245 - val_loss: 0.0255\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0240 - val_loss: 0.0255\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0279 - val_loss: 0.0271\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0246 - val_loss: 0.0362\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0334 - val_loss: 0.0354\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0254 - val_loss: 0.0246\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0182 - val_loss: 0.0242\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0295 - val_loss: 0.0244\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0229 - val_loss: 0.0278\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0323 - val_loss: 0.0248\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0211 - val_loss: 0.0241\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0243 - val_loss: 0.0243\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0253 - val_loss: 0.0366\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0284 - val_loss: 0.0243\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0215 - val_loss: 0.0283\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0248 - val_loss: 0.0292\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0279 - val_loss: 0.0267\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0203 - val_loss: 0.0260\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0210 - val_loss: 0.0237\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0206 - val_loss: 0.0235\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0205 - val_loss: 0.0241\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0200 - val_loss: 0.0233\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0247 - val_loss: 0.0232\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0257 - val_loss: 0.0243\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0282 - val_loss: 0.0253\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0261 - val_loss: 0.0299\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0218 - val_loss: 0.0241\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0234 - val_loss: 0.0280\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0246 - val_loss: 0.0225\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0274 - val_loss: 0.0233\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0179 - val_loss: 0.0220\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0202 - val_loss: 0.0220\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0228 - val_loss: 0.0245\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0197 - val_loss: 0.0218\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0251 - val_loss: 0.0217\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0286 - val_loss: 0.0227\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0250 - val_loss: 0.0264\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0198 - val_loss: 0.0234\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.0209\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0208 - val_loss: 0.0292\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0160 - val_loss: 0.0207\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0253 - val_loss: 0.0218\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0162 - val_loss: 0.0209\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0167 - val_loss: 0.0203\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0181 - val_loss: 0.0204\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0244 - val_loss: 0.0237\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0172 - val_loss: 0.0211\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0205 - val_loss: 0.0234\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0213 - val_loss: 0.0213\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0178 - val_loss: 0.0200\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0172 - val_loss: 0.0445\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0227 - val_loss: 0.0257\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0138 - val_loss: 0.0197\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0182 - val_loss: 0.0204\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0182 - val_loss: 0.0200\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0198 - val_loss: 0.0202\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0174 - val_loss: 0.0191\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0139 - val_loss: 0.0182\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0176 - val_loss: 0.0205\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0180 - val_loss: 0.0184\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0179\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0204 - val_loss: 0.0181\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0158 - val_loss: 0.0209\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0184 - val_loss: 0.0177\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0170\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0200 - val_loss: 0.0198\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0185 - val_loss: 0.0176\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.0179 - val_loss: 0.0165\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0184\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0159 - val_loss: 0.0218\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.0170\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0150 - val_loss: 0.0179\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0108 - val_loss: 0.0222\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0149 - val_loss: 0.0162\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0123 - val_loss: 0.0252\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0194 - val_loss: 0.0195\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0185 - val_loss: 0.0228\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0201 - val_loss: 0.0178\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0216\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0190 - val_loss: 0.0233\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0168\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0129 - val_loss: 0.0253\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0130 - val_loss: 0.0189\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0137 - val_loss: 0.0214\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0189 - val_loss: 0.0183\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0145 - val_loss: 0.0213\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0137 - val_loss: 0.0158\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0173\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0262\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0157 - val_loss: 0.0160\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0084 - val_loss: 0.0156\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0085 - val_loss: 0.0179\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0102 - val_loss: 0.0219\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0191 - val_loss: 0.0175\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0106 - val_loss: 0.0163\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0109 - val_loss: 0.0156\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0071 - val_loss: 0.0175\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0064 - val_loss: 0.0162\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0076 - val_loss: 0.0201\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0080 - val_loss: 0.0151\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0066 - val_loss: 0.0192\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0073 - val_loss: 0.0172\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0087 - val_loss: 0.0199\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0160\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0064 - val_loss: 0.0201\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0048 - val_loss: 0.0192\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0059 - val_loss: 0.0179\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0179\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0058 - val_loss: 0.0160\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0056 - val_loss: 0.0179\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0059 - val_loss: 0.0191\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0039 - val_loss: 0.0188\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0039 - val_loss: 0.0163\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0049 - val_loss: 0.0175\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0032 - val_loss: 0.0171\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0028 - val_loss: 0.0169\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0034 - val_loss: 0.0183\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A70D8B1B80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 35ms/step - loss: 0.0527 - val_loss: 0.0373\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0326 - val_loss: 0.0624\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0379 - val_loss: 0.0319\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0227 - val_loss: 0.0261\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0252 - val_loss: 0.0339\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0388 - val_loss: 0.0254\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0276 - val_loss: 0.0254\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0268 - val_loss: 0.0264\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0208 - val_loss: 0.0246\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0231 - val_loss: 0.0299\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0294 - val_loss: 0.0298\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0222 - val_loss: 0.0245\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0240 - val_loss: 0.0272\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0284 - val_loss: 0.0409\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0351 - val_loss: 0.0264\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0188 - val_loss: 0.0293\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0362 - val_loss: 0.0261\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0263 - val_loss: 0.0242\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0275 - val_loss: 0.0246\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0297 - val_loss: 0.0290\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0304 - val_loss: 0.0255\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0208 - val_loss: 0.0238\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0275 - val_loss: 0.0311\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0265 - val_loss: 0.0237\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0207 - val_loss: 0.0253\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0206 - val_loss: 0.0275\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0258 - val_loss: 0.0276\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0258 - val_loss: 0.0276\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0230 - val_loss: 0.0269\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0176 - val_loss: 0.0229\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0227 - val_loss: 0.0261\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0269 - val_loss: 0.0229\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0246 - val_loss: 0.0290\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0246 - val_loss: 0.0330\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0193 - val_loss: 0.0265\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0253 - val_loss: 0.0373\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0230 - val_loss: 0.0227\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0212 - val_loss: 0.0229\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.0228 - val_loss: 0.0287\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0206 - val_loss: 0.0242\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0209 - val_loss: 0.0219\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0177 - val_loss: 0.0231\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0199 - val_loss: 0.0214\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0186 - val_loss: 0.0235\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0249 - val_loss: 0.0213\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0176 - val_loss: 0.0212\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0215 - val_loss: 0.0224\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0169 - val_loss: 0.0235\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0212 - val_loss: 0.0210\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0165 - val_loss: 0.0205\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0173 - val_loss: 0.0203\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0191 - val_loss: 0.0214\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0185 - val_loss: 0.0201\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.0220\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0197 - val_loss: 0.0227\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0185 - val_loss: 0.0194\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0193 - val_loss: 0.0278\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0269 - val_loss: 0.0201\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0196 - val_loss: 0.0217\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0167 - val_loss: 0.0197\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0212 - val_loss: 0.0204\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0169 - val_loss: 0.0198\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0194\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.0200\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0242 - val_loss: 0.0241\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0224 - val_loss: 0.0180\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0247 - val_loss: 0.0183\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0174 - val_loss: 0.0178\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0163 - val_loss: 0.0190\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0173 - val_loss: 0.0176\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0131 - val_loss: 0.0162\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0133 - val_loss: 0.0168\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0154 - val_loss: 0.0176\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0173\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0132 - val_loss: 0.0179\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0179\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0165 - val_loss: 0.0180\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0137 - val_loss: 0.0199\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0116 - val_loss: 0.0198\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0164 - val_loss: 0.0184\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0164 - val_loss: 0.0183\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0151 - val_loss: 0.0215\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0117 - val_loss: 0.0220\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0168 - val_loss: 0.0178\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0111 - val_loss: 0.0202\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0122 - val_loss: 0.0179\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0186\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0153 - val_loss: 0.0186\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0123 - val_loss: 0.0118\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0178\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0161 - val_loss: 0.0181\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0150 - val_loss: 0.0170\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0190\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0110 - val_loss: 0.0289\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0151 - val_loss: 0.0195\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0110 - val_loss: 0.0126\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0146\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0093 - val_loss: 0.0142\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0066 - val_loss: 0.0132\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0064 - val_loss: 0.0171\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0114\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0081 - val_loss: 0.0127\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0075 - val_loss: 0.0128\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0064 - val_loss: 0.0127\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0047 - val_loss: 0.0191\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0077 - val_loss: 0.0164\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0136\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0128\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0151\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0139\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0074 - val_loss: 0.0120\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0058 - val_loss: 0.0147\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0143 - val_loss: 0.0226\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.0179\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0121 - val_loss: 0.0141\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0051 - val_loss: 0.0147\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0068 - val_loss: 0.0154\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0048 - val_loss: 0.0171\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0051 - val_loss: 0.0213\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A884816550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 38ms/step - loss: 0.1097 - val_loss: 0.0303\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0272 - val_loss: 0.0355\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0249 - val_loss: 0.0280\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0238 - val_loss: 0.0286\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0275 - val_loss: 0.0264\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0240 - val_loss: 0.0322\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0267 - val_loss: 0.0296\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0240 - val_loss: 0.0255\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0274 - val_loss: 0.0266\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.0269 - val_loss: 0.0267\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0227 - val_loss: 0.0251\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0254 - val_loss: 0.0259\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0295 - val_loss: 0.0259\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0268 - val_loss: 0.0409\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0207 - val_loss: 0.0321\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0206 - val_loss: 0.0243\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0253 - val_loss: 0.0279\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0296 - val_loss: 0.0252\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0256 - val_loss: 0.0241\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0275 - val_loss: 0.0241\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0243 - val_loss: 0.0309\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0213 - val_loss: 0.0271\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0256 - val_loss: 0.0239\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0242 - val_loss: 0.0364\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0306 - val_loss: 0.0281\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0235 - val_loss: 0.0271\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0191 - val_loss: 0.0236\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0229 - val_loss: 0.0243\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0266 - val_loss: 0.0242\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0176 - val_loss: 0.0230\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0200 - val_loss: 0.0266\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0295 - val_loss: 0.0341\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0252 - val_loss: 0.0279\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0161 - val_loss: 0.0228\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0248 - val_loss: 0.0230\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0262 - val_loss: 0.0228\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0199 - val_loss: 0.0225\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0231 - val_loss: 0.0230\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0224 - val_loss: 0.0223\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0230 - val_loss: 0.0231\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0224 - val_loss: 0.0243\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0213 - val_loss: 0.0238\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0165 - val_loss: 0.0229\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0168 - val_loss: 0.0234\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0200 - val_loss: 0.0216\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0181 - val_loss: 0.0216\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0173 - val_loss: 0.0252\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0162 - val_loss: 0.0218\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0214 - val_loss: 0.0213\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0230 - val_loss: 0.0228\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0192 - val_loss: 0.0212\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0198 - val_loss: 0.0223\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0148 - val_loss: 0.0208\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0185 - val_loss: 0.0239\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0179 - val_loss: 0.0221\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0193 - val_loss: 0.0233\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0198\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0205 - val_loss: 0.0223\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0182 - val_loss: 0.0226\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0147 - val_loss: 0.0220\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0166 - val_loss: 0.0200\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0191 - val_loss: 0.0207\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0199 - val_loss: 0.0188\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0188 - val_loss: 0.0184\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0149 - val_loss: 0.0182\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0199\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0183 - val_loss: 0.0183\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0136 - val_loss: 0.0237\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0183 - val_loss: 0.0230\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0187 - val_loss: 0.0176\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0191 - val_loss: 0.0191\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0186 - val_loss: 0.0204\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0193 - val_loss: 0.0211\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0192\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0207 - val_loss: 0.0173\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.0223\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0174 - val_loss: 0.0191\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0188 - val_loss: 0.0179\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0162\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0149 - val_loss: 0.0172\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.0249\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0172 - val_loss: 0.0224\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0177 - val_loss: 0.0224\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0130 - val_loss: 0.0182\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0138 - val_loss: 0.0245\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0151 - val_loss: 0.0220\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0219\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0160 - val_loss: 0.0186\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0203\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0135 - val_loss: 0.0179\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0194\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0193\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.0122 - val_loss: 0.0236\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0171\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0151 - val_loss: 0.0189\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0199\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0195\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0119 - val_loss: 0.0175\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0200\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0162 - val_loss: 0.0166\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0169 - val_loss: 0.0200\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0147 - val_loss: 0.0167\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0163 - val_loss: 0.0178\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.0150\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0110 - val_loss: 0.0155\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0102 - val_loss: 0.0175\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0167\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0065 - val_loss: 0.0194\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0072 - val_loss: 0.0245\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0081 - val_loss: 0.0172\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0161\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0165\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0054 - val_loss: 0.0140\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0070 - val_loss: 0.0137\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0068 - val_loss: 0.0173\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0046 - val_loss: 0.0147\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0063 - val_loss: 0.0118\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0062 - val_loss: 0.0149\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0077 - val_loss: 0.0217\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0053 - val_loss: 0.0152\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0044 - val_loss: 0.0163\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0054 - val_loss: 0.0210\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0062 - val_loss: 0.0166\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0044 - val_loss: 0.0166\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0047 - val_loss: 0.0225\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0045 - val_loss: 0.0234\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0042 - val_loss: 0.0225\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0034 - val_loss: 0.0231\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0034 - val_loss: 0.0224\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0053 - val_loss: 0.0264\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0042 - val_loss: 0.0305\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0058 - val_loss: 0.0161\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0054 - val_loss: 0.0146\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0030 - val_loss: 0.0144\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0027 - val_loss: 0.0192\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0026 - val_loss: 0.0151\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0030 - val_loss: 0.0202\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0033 - val_loss: 0.0181\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0025 - val_loss: 0.0195\n",
      "Epoch 140/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0024 - val_loss: 0.0181\n",
      "Epoch 141/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0026 - val_loss: 0.0199\n",
      "Epoch 142/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0023 - val_loss: 0.0191\n",
      "Epoch 143/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0049 - val_loss: 0.0245\n",
      "Epoch 144/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0077 - val_loss: 0.0258\n",
      "Epoch 145/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0065 - val_loss: 0.0197\n",
      "Epoch 146/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0043 - val_loss: 0.0207\n",
      "Epoch 147/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0031 - val_loss: 0.0170\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A70D41C430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 35ms/step - loss: 0.0747 - val_loss: 0.0282\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0294 - val_loss: 0.0284\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0304 - val_loss: 0.0281\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0287 - val_loss: 0.0325\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0240 - val_loss: 0.0271\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0248 - val_loss: 0.0250\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0237 - val_loss: 0.0323\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0242 - val_loss: 0.0246\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0262 - val_loss: 0.0257\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0345 - val_loss: 0.0273\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0254 - val_loss: 0.0245\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0247 - val_loss: 0.0251\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0222 - val_loss: 0.0265\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0219 - val_loss: 0.0242\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0317 - val_loss: 0.0241\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0224 - val_loss: 0.0317\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0256 - val_loss: 0.0301\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0177 - val_loss: 0.0240\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0224 - val_loss: 0.0313\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0280 - val_loss: 0.0241\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0224 - val_loss: 0.0237\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0360 - val_loss: 0.0237\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0246 - val_loss: 0.0303\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0280\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0208 - val_loss: 0.0237\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0249 - val_loss: 0.0251\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0372 - val_loss: 0.0276\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0209 - val_loss: 0.0255\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.0261 - val_loss: 0.0252\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0198 - val_loss: 0.0283\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0225 - val_loss: 0.0241\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0197 - val_loss: 0.0242\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0220 - val_loss: 0.0265\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0303 - val_loss: 0.0226\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0190 - val_loss: 0.0230\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0221 - val_loss: 0.0228\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0224 - val_loss: 0.0330\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0195 - val_loss: 0.0249\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0219 - val_loss: 0.0220\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0247 - val_loss: 0.0260\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0190 - val_loss: 0.0219\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.0229 - val_loss: 0.0243\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0196 - val_loss: 0.0229\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0186 - val_loss: 0.0274\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0195 - val_loss: 0.0223\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0193 - val_loss: 0.0212\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0229 - val_loss: 0.0252\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0192 - val_loss: 0.0223\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0214 - val_loss: 0.0219\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0196 - val_loss: 0.0212\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0225 - val_loss: 0.0263\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0138 - val_loss: 0.0202\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0193 - val_loss: 0.0369\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0199 - val_loss: 0.0198\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0160 - val_loss: 0.0206\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0172 - val_loss: 0.0210\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0201 - val_loss: 0.0205\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0201 - val_loss: 0.0223\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0197 - val_loss: 0.0202\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0197 - val_loss: 0.0196\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0200 - val_loss: 0.0187\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0194 - val_loss: 0.0210\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0160 - val_loss: 0.0216\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0195 - val_loss: 0.0244\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0165 - val_loss: 0.0203\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0179 - val_loss: 0.0207\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0249 - val_loss: 0.0206\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0145 - val_loss: 0.0194\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0187\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0214\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0203 - val_loss: 0.0191\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0159 - val_loss: 0.0197\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0188 - val_loss: 0.0171\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0246\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0203 - val_loss: 0.0168\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0220\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0168\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0172 - val_loss: 0.0175\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0162 - val_loss: 0.0198\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0127 - val_loss: 0.0191\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0122 - val_loss: 0.0159\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0134 - val_loss: 0.0182\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0252\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0185 - val_loss: 0.0181\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.0157\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0167\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0163 - val_loss: 0.0197\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0109 - val_loss: 0.0210\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0104 - val_loss: 0.0132\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0184\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0107 - val_loss: 0.0195\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0130 - val_loss: 0.0206\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0072 - val_loss: 0.0179\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0078 - val_loss: 0.0180\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0166\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0074 - val_loss: 0.0164\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0109 - val_loss: 0.0229\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0109 - val_loss: 0.0150\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0148\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0142 - val_loss: 0.0244\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0077 - val_loss: 0.0177\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0072 - val_loss: 0.0212\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0150\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0059 - val_loss: 0.0171\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0059 - val_loss: 0.0169\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0074 - val_loss: 0.0235\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0078 - val_loss: 0.0224\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0087 - val_loss: 0.0227\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0054 - val_loss: 0.0196\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0045 - val_loss: 0.0144\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0047 - val_loss: 0.0249\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0136 - val_loss: 0.0159\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0204 - val_loss: 0.0160\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0102 - val_loss: 0.0171\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0075 - val_loss: 0.0146\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0047 - val_loss: 0.0161\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0074 - val_loss: 0.0165\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0057 - val_loss: 0.0168\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0050 - val_loss: 0.0160\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A8795A9310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 58ms/step - loss: 0.0668 - val_loss: 0.0312\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0229 - val_loss: 0.0347\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0310 - val_loss: 0.0286\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0292 - val_loss: 0.0335\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0224 - val_loss: 0.0252\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0219 - val_loss: 0.0326\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0273 - val_loss: 0.0248\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0219 - val_loss: 0.0248\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0291 - val_loss: 0.0250\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0272 - val_loss: 0.0250\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0289 - val_loss: 0.0268\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0232 - val_loss: 0.0241\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0256 - val_loss: 0.0249\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0319 - val_loss: 0.0253\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0202 - val_loss: 0.0239\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0226 - val_loss: 0.0246\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0205 - val_loss: 0.0273\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0273 - val_loss: 0.0265\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0263 - val_loss: 0.0244\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0209 - val_loss: 0.0253\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0267 - val_loss: 0.0244\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0316 - val_loss: 0.0296\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0235 - val_loss: 0.0236\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0286 - val_loss: 0.0236\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0220 - val_loss: 0.0262\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0299 - val_loss: 0.0236\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0216 - val_loss: 0.0234\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0218 - val_loss: 0.0234\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0216 - val_loss: 0.0267\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0269 - val_loss: 0.0318\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0358 - val_loss: 0.0395\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0186 - val_loss: 0.0226\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0205 - val_loss: 0.0252\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0351 - val_loss: 0.0228\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0299 - val_loss: 0.0274\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0219 - val_loss: 0.0271\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0193 - val_loss: 0.0248\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0238 - val_loss: 0.0247\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0219 - val_loss: 0.0237\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0209 - val_loss: 0.0254\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0217 - val_loss: 0.0213\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0208 - val_loss: 0.0212\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0258 - val_loss: 0.0217\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0216 - val_loss: 0.0306\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0179 - val_loss: 0.0239\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0208 - val_loss: 0.0213\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0166 - val_loss: 0.0209\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0171 - val_loss: 0.0225\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0194 - val_loss: 0.0226\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0185 - val_loss: 0.0198\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0198 - val_loss: 0.0235\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0166 - val_loss: 0.0218\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0206 - val_loss: 0.0217\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0224 - val_loss: 0.0226\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0192 - val_loss: 0.0206\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0170 - val_loss: 0.0189\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0144 - val_loss: 0.0187\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0160 - val_loss: 0.0237\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0178 - val_loss: 0.0201\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0149 - val_loss: 0.0186\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0237 - val_loss: 0.0207\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0178 - val_loss: 0.0196\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0158 - val_loss: 0.0187\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0184 - val_loss: 0.0202\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0162 - val_loss: 0.0221\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0160 - val_loss: 0.0186\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0161 - val_loss: 0.0208\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0212 - val_loss: 0.0175\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0177\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0174 - val_loss: 0.0179\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0127 - val_loss: 0.0170\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0204 - val_loss: 0.0225\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0204 - val_loss: 0.0219\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0178 - val_loss: 0.0200\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0177 - val_loss: 0.0185\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0143 - val_loss: 0.0188\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.0126 - val_loss: 0.0193\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0183 - val_loss: 0.0184\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0164 - val_loss: 0.0186\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0149 - val_loss: 0.0241\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0181 - val_loss: 0.0173\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0221 - val_loss: 0.0159\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0162 - val_loss: 0.0164\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0134 - val_loss: 0.0186\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0134 - val_loss: 0.0191\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0140 - val_loss: 0.0203\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0137 - val_loss: 0.0190\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0159\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0137 - val_loss: 0.0167\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0114 - val_loss: 0.0147\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0139 - val_loss: 0.0162\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0166\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0081 - val_loss: 0.0137\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0185 - val_loss: 0.0203\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0131 - val_loss: 0.0226\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0166 - val_loss: 0.0155\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0073 - val_loss: 0.0152\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0087 - val_loss: 0.0189\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0086 - val_loss: 0.0176\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0157 - val_loss: 0.0169\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0139 - val_loss: 0.0163\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0157 - val_loss: 0.0250\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0110 - val_loss: 0.0127\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0084 - val_loss: 0.0185\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0163\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0182\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0150\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0188\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0085 - val_loss: 0.0135\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0070 - val_loss: 0.0178\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0066 - val_loss: 0.0207\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0058 - val_loss: 0.0175\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0079 - val_loss: 0.0163\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0103 - val_loss: 0.0176\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0093 - val_loss: 0.0139\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0061 - val_loss: 0.0176\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0044 - val_loss: 0.0231\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0051 - val_loss: 0.0233\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0074 - val_loss: 0.0228\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0068 - val_loss: 0.0224\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0059 - val_loss: 0.0193\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0048 - val_loss: 0.0152\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0051 - val_loss: 0.0256\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A79567BC10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 35ms/step - loss: 0.0778 - val_loss: 0.0285\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0359 - val_loss: 0.0310\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0333 - val_loss: 0.0268\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0302 - val_loss: 0.0268\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0324 - val_loss: 0.0288\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0251 - val_loss: 0.0249\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0233 - val_loss: 0.0283\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0295 - val_loss: 0.0306\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0263 - val_loss: 0.0326\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0254 - val_loss: 0.0312\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0192 - val_loss: 0.0244\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0293 - val_loss: 0.0295\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0214 - val_loss: 0.0239\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0241 - val_loss: 0.0245\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0252 - val_loss: 0.0251\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0213 - val_loss: 0.0250\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0239 - val_loss: 0.0288\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0265 - val_loss: 0.0256\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0251 - val_loss: 0.0257\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0233 - val_loss: 0.0240\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0234 - val_loss: 0.0272\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0227 - val_loss: 0.0298\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0272 - val_loss: 0.0258\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0247 - val_loss: 0.0274\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0241 - val_loss: 0.0270\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0189 - val_loss: 0.0239\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0206 - val_loss: 0.0233\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0194 - val_loss: 0.0283\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0251 - val_loss: 0.0241\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0231 - val_loss: 0.0231\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0238 - val_loss: 0.0232\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0201 - val_loss: 0.0237\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0211 - val_loss: 0.0228\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0194 - val_loss: 0.0229\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0190 - val_loss: 0.0243\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0233 - val_loss: 0.0222\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0217 - val_loss: 0.0221\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0162 - val_loss: 0.0231\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0256 - val_loss: 0.0247\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0209 - val_loss: 0.0214\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0237 - val_loss: 0.0238\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0191 - val_loss: 0.0213\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0187 - val_loss: 0.0216\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0214 - val_loss: 0.0248\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0192 - val_loss: 0.0216\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0146 - val_loss: 0.0218\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0234 - val_loss: 0.0309\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0240 - val_loss: 0.0223\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0166 - val_loss: 0.0260\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0194 - val_loss: 0.0247\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.0281 - val_loss: 0.0204\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0210\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0173 - val_loss: 0.0205\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0212\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0201 - val_loss: 0.0213\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0191\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0176 - val_loss: 0.0217\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0221 - val_loss: 0.0200\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0190\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0149 - val_loss: 0.0204\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0167 - val_loss: 0.0190\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0174 - val_loss: 0.0182\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0234\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0186\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0172 - val_loss: 0.0261\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0321 - val_loss: 0.0184\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0135 - val_loss: 0.0193\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0179\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0177\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.0165\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.0156\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0140 - val_loss: 0.0185\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0192\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0194 - val_loss: 0.0174\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0126 - val_loss: 0.0162\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0187 - val_loss: 0.0167\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0167\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0180 - val_loss: 0.0193\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0149 - val_loss: 0.0154\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0189\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0151 - val_loss: 0.0186\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0156 - val_loss: 0.0243\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0205\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0198 - val_loss: 0.0180\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0141 - val_loss: 0.0223\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0217\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0126 - val_loss: 0.0192\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0250\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0138\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0171\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0130 - val_loss: 0.0239\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.0298\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0142 - val_loss: 0.0150\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0191\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0149 - val_loss: 0.0176\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0081 - val_loss: 0.0244\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0207\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0128 - val_loss: 0.0148\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0191\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0086 - val_loss: 0.0188\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0127 - val_loss: 0.0203\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0190\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0187 - val_loss: 0.0286\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0157 - val_loss: 0.0179\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.0171\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0201\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0125 - val_loss: 0.0237\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0065 - val_loss: 0.0182\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0206\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0100 - val_loss: 0.0219\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0136\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0074 - val_loss: 0.0193\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0079 - val_loss: 0.0186\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0053 - val_loss: 0.0172\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0071 - val_loss: 0.0143\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0053 - val_loss: 0.0211\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0069 - val_loss: 0.0206\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0187\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0158\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A87536A550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 35ms/step - loss: 0.0934 - val_loss: 0.0290\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.0270 - val_loss: 0.0278\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0269 - val_loss: 0.0290\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0299 - val_loss: 0.0261\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0250 - val_loss: 0.0256\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0340 - val_loss: 0.0299\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0354 - val_loss: 0.0252\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0259 - val_loss: 0.0253\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0326 - val_loss: 0.0317\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0374 - val_loss: 0.0243\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0231 - val_loss: 0.0292\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0206 - val_loss: 0.0279\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0322 - val_loss: 0.0319\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0173 - val_loss: 0.0275\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0239 - val_loss: 0.0327\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0274 - val_loss: 0.0263\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0211 - val_loss: 0.0245\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0257 - val_loss: 0.0292\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0308 - val_loss: 0.0279\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0227 - val_loss: 0.0329\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0276 - val_loss: 0.0242\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0191 - val_loss: 0.0237\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0289 - val_loss: 0.0258\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0197 - val_loss: 0.0239\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0210 - val_loss: 0.0247\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0254 - val_loss: 0.0234\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0189 - val_loss: 0.0238\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0183 - val_loss: 0.0233\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0181 - val_loss: 0.0245\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0236 - val_loss: 0.0231\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0272 - val_loss: 0.0234\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0240 - val_loss: 0.0284\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0256 - val_loss: 0.0234\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0215 - val_loss: 0.0225\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0244 - val_loss: 0.0281\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0257 - val_loss: 0.0303\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0176 - val_loss: 0.0222\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0219 - val_loss: 0.0222\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0152 - val_loss: 0.0239\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0215 - val_loss: 0.0214\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0177 - val_loss: 0.0209\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0204 - val_loss: 0.0235\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0232 - val_loss: 0.0209\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0189 - val_loss: 0.0213\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0213 - val_loss: 0.0232\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0173 - val_loss: 0.0206\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0210 - val_loss: 0.0209\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0173 - val_loss: 0.0235\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0198 - val_loss: 0.0202\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0213 - val_loss: 0.0263\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0197 - val_loss: 0.0210\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0253 - val_loss: 0.0214\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0195 - val_loss: 0.0258\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0199 - val_loss: 0.0196\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0166 - val_loss: 0.0201\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0182 - val_loss: 0.0210\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0187 - val_loss: 0.0189\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0169 - val_loss: 0.0206\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0172 - val_loss: 0.0185\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0197 - val_loss: 0.0232\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0232\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0166 - val_loss: 0.0194\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0165 - val_loss: 0.0183\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0151 - val_loss: 0.0201\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0188 - val_loss: 0.0174\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0226 - val_loss: 0.0206\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0150 - val_loss: 0.0180\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0192 - val_loss: 0.0207\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0219 - val_loss: 0.0178\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0168 - val_loss: 0.0204\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0184 - val_loss: 0.0203\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0127 - val_loss: 0.0188\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0161 - val_loss: 0.0181\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0189 - val_loss: 0.0217\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0171 - val_loss: 0.0196\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0153 - val_loss: 0.0240\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.0189\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0154 - val_loss: 0.0183\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0213 - val_loss: 0.0196\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0164 - val_loss: 0.0245\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0160 - val_loss: 0.0163\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0153 - val_loss: 0.0198\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0153 - val_loss: 0.0156\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0196\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0154 - val_loss: 0.0157\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0120 - val_loss: 0.0158\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0142 - val_loss: 0.0172\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0188\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0154 - val_loss: 0.0208\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0218 - val_loss: 0.0218\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0164 - val_loss: 0.0152\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0118 - val_loss: 0.0137\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0152\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0116\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0068 - val_loss: 0.0274\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0167\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0137\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0141\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0093 - val_loss: 0.0214\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0087 - val_loss: 0.0228\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0194\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0136 - val_loss: 0.0153\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0151\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.0054 - val_loss: 0.0126\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0157 - val_loss: 0.0178\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0181 - val_loss: 0.0190\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0136 - val_loss: 0.0183\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0148\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0123 - val_loss: 0.0147\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0055 - val_loss: 0.0145\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0067 - val_loss: 0.0160\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0047 - val_loss: 0.0158\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0061 - val_loss: 0.0204\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0075 - val_loss: 0.0175\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0042 - val_loss: 0.0161\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0053 - val_loss: 0.0131\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0044 - val_loss: 0.0151\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0077 - val_loss: 0.0158\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0038 - val_loss: 0.0182\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0026 - val_loss: 0.0197\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0030 - val_loss: 0.0177\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0043 - val_loss: 0.0222\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0029 - val_loss: 0.0182\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0036 - val_loss: 0.0209\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A870B5A700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 35ms/step - loss: 0.0845 - val_loss: 0.0284\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0211 - val_loss: 0.0271\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0250 - val_loss: 0.0267\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0312 - val_loss: 0.0346\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0270 - val_loss: 0.0257\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0239 - val_loss: 0.0259\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0268 - val_loss: 0.0444\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0388 - val_loss: 0.0335\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0230 - val_loss: 0.0361\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0261 - val_loss: 0.0346\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0258 - val_loss: 0.0246\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0274 - val_loss: 0.0243\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0258 - val_loss: 0.0311\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0251 - val_loss: 0.0273\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0239 - val_loss: 0.0261\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0265 - val_loss: 0.0253\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0273 - val_loss: 0.0246\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0194 - val_loss: 0.0246\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0244 - val_loss: 0.0289\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0252 - val_loss: 0.0239\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0283 - val_loss: 0.0273\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0320 - val_loss: 0.0311\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0214 - val_loss: 0.0307\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0213 - val_loss: 0.0233\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0198 - val_loss: 0.0393\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0175 - val_loss: 0.0255\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0241 - val_loss: 0.0238\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0261 - val_loss: 0.0264\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0173 - val_loss: 0.0240\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0226 - val_loss: 0.0252\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0225 - val_loss: 0.0227\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0197 - val_loss: 0.0225\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0206 - val_loss: 0.0224\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0274 - val_loss: 0.0225\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0224 - val_loss: 0.0230\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0241 - val_loss: 0.0276\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0309 - val_loss: 0.0238\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0168 - val_loss: 0.0218\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0218 - val_loss: 0.0237\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0215 - val_loss: 0.0243\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0256 - val_loss: 0.0222\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0233 - val_loss: 0.0243\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0201 - val_loss: 0.0304\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0253 - val_loss: 0.0243\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0187 - val_loss: 0.0206\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0226 - val_loss: 0.0212\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0187 - val_loss: 0.0205\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0244 - val_loss: 0.0206\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0142 - val_loss: 0.0199\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0172 - val_loss: 0.0210\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0171 - val_loss: 0.0208\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0198\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0190 - val_loss: 0.0205\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0155 - val_loss: 0.0196\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0171 - val_loss: 0.0206\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0175 - val_loss: 0.0213\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0192\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0240\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0203\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0165 - val_loss: 0.0190\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.0210\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 1s 28ms/step - loss: 0.0178 - val_loss: 0.0175\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0205 - val_loss: 0.0222\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0175\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0192 - val_loss: 0.0183\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0167 - val_loss: 0.0178\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.0179\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0174 - val_loss: 0.0185\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0198\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0235 - val_loss: 0.0268\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0202\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0188 - val_loss: 0.0201\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0176\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0142 - val_loss: 0.0197\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0178 - val_loss: 0.0162\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0139 - val_loss: 0.0167\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.0183\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0159\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0180 - val_loss: 0.0226\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0185 - val_loss: 0.0185\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0167 - val_loss: 0.0197\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0172\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0162 - val_loss: 0.0186\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0146\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.0199\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0168\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0177\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0100 - val_loss: 0.0203\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0090 - val_loss: 0.0182\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0176\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0211 - val_loss: 0.0220\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0166\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0177\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0081 - val_loss: 0.0127\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0145\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0077 - val_loss: 0.0185\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0073 - val_loss: 0.0162\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0082 - val_loss: 0.0130\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0081 - val_loss: 0.0143\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0065 - val_loss: 0.0179\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0069 - val_loss: 0.0148\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0062 - val_loss: 0.0157\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0058 - val_loss: 0.0209\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0131\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0087 - val_loss: 0.0132\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0050 - val_loss: 0.0162\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0071 - val_loss: 0.0158\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0071 - val_loss: 0.0167\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0071 - val_loss: 0.0115\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0078 - val_loss: 0.0202\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0065 - val_loss: 0.0216\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0048 - val_loss: 0.0138\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0074 - val_loss: 0.0209\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0044 - val_loss: 0.0178\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0049 - val_loss: 0.0130\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0058 - val_loss: 0.0166\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0042 - val_loss: 0.0226\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0043 - val_loss: 0.0170\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0039 - val_loss: 0.0197\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0045 - val_loss: 0.0103\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0284\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0086 - val_loss: 0.0134\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0064 - val_loss: 0.0169\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0072 - val_loss: 0.0184\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0113\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.0143\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0033 - val_loss: 0.0152\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0052 - val_loss: 0.0135\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0046 - val_loss: 0.0236\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0034 - val_loss: 0.0166\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0032 - val_loss: 0.0162\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0024 - val_loss: 0.0181\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0037 - val_loss: 0.0144\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0066 - val_loss: 0.0195\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0042 - val_loss: 0.0176\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 0.0196\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 0.0188\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0022 - val_loss: 0.0223\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0020 - val_loss: 0.0208\n",
      "Epoch 140/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 0.0218\n",
      "Epoch 141/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 0.0207\n",
      "Epoch 142/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0024 - val_loss: 0.0220\n",
      "Epoch 143/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0031 - val_loss: 0.0209\n",
      "Epoch 144/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 0.0191\n",
      "Epoch 145/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0019 - val_loss: 0.0200\n",
      "Epoch 146/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0019 - val_loss: 0.0215\n",
      "Epoch 147/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 0.0202\n",
      "Epoch 148/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0023 - val_loss: 0.0187\n",
      "Epoch 149/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 0.0245\n",
      "Epoch 150/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 0.0201\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A887E859D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 35ms/step - loss: 0.0856 - val_loss: 0.0278\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0311 - val_loss: 0.0368\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.0344 - val_loss: 0.0272\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0269 - val_loss: 0.0294\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0286 - val_loss: 0.0280\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0206 - val_loss: 0.0284\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0250 - val_loss: 0.0249\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0251 - val_loss: 0.0259\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0257 - val_loss: 0.0297\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0281 - val_loss: 0.0272\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0170 - val_loss: 0.0244\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0271 - val_loss: 0.0244\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0354 - val_loss: 0.0242\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0225 - val_loss: 0.0246\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0263 - val_loss: 0.0240\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0241 - val_loss: 0.0242\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0305 - val_loss: 0.0258\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0268 - val_loss: 0.0327\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0274 - val_loss: 0.0248\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0197 - val_loss: 0.0257\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0185 - val_loss: 0.0241\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0242 - val_loss: 0.0237\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0322 - val_loss: 0.0235\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0190 - val_loss: 0.0254\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0197 - val_loss: 0.0301\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0195 - val_loss: 0.0247\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0172 - val_loss: 0.0236\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0242 - val_loss: 0.0231\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0176 - val_loss: 0.0230\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0259 - val_loss: 0.0280\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0230 - val_loss: 0.0240\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0263 - val_loss: 0.0316\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0246 - val_loss: 0.0240\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0247 - val_loss: 0.0270\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0223 - val_loss: 0.0223\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0226 - val_loss: 0.0313\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0187 - val_loss: 0.0227\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0178 - val_loss: 0.0242\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0202 - val_loss: 0.0248\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0199 - val_loss: 0.0250\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0278 - val_loss: 0.0217\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0163 - val_loss: 0.0216\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0172 - val_loss: 0.0232\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0163 - val_loss: 0.0228\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0235 - val_loss: 0.0215\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0202 - val_loss: 0.0269\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0221 - val_loss: 0.0209\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0182 - val_loss: 0.0206\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0149 - val_loss: 0.0213\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0200 - val_loss: 0.0209\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0158 - val_loss: 0.0204\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0171 - val_loss: 0.0224\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0166 - val_loss: 0.0197\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0185 - val_loss: 0.0214\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0171 - val_loss: 0.0226\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0217 - val_loss: 0.0198\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0181 - val_loss: 0.0193\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0287\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0235 - val_loss: 0.0192\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0173 - val_loss: 0.0202\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0125 - val_loss: 0.0206\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0212 - val_loss: 0.0218\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0169 - val_loss: 0.0198\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0189 - val_loss: 0.0186\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0152 - val_loss: 0.0233\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0181 - val_loss: 0.0182\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0170 - val_loss: 0.0217\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0191 - val_loss: 0.0187\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0158 - val_loss: 0.0222\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0200 - val_loss: 0.0250\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0287 - val_loss: 0.0316\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0131 - val_loss: 0.0184\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0130 - val_loss: 0.0168\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0192 - val_loss: 0.0243\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0192 - val_loss: 0.0171\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0139 - val_loss: 0.0178\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0156 - val_loss: 0.0229\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0165 - val_loss: 0.0155\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0127 - val_loss: 0.0169\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0162\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0193\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0151 - val_loss: 0.0185\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0114 - val_loss: 0.0215\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0106 - val_loss: 0.0278\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.0124 - val_loss: 0.0177\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0159 - val_loss: 0.0152\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0106 - val_loss: 0.0185\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0110 - val_loss: 0.0177\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0109 - val_loss: 0.0210\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0146 - val_loss: 0.0202\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0126 - val_loss: 0.0168\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0215\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.0091 - val_loss: 0.0173\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.0095 - val_loss: 0.0141\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0162\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0141 - val_loss: 0.0175\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0122 - val_loss: 0.0159\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0167\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0072 - val_loss: 0.0181\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0080 - val_loss: 0.0179\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0070 - val_loss: 0.0244\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0125 - val_loss: 0.0200\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0138 - val_loss: 0.0152\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.0154\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0109 - val_loss: 0.0157\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0089 - val_loss: 0.0203\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0067 - val_loss: 0.0179\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0058 - val_loss: 0.0158\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0057 - val_loss: 0.0159\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0048 - val_loss: 0.0133\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0065 - val_loss: 0.0216\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0071 - val_loss: 0.0112\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0081 - val_loss: 0.0166\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0072 - val_loss: 0.0135\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0060 - val_loss: 0.0160\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0083 - val_loss: 0.0136\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0085 - val_loss: 0.0169\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0075 - val_loss: 0.0133\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0051 - val_loss: 0.0139\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0056 - val_loss: 0.0195\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0053 - val_loss: 0.0174\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0071 - val_loss: 0.0164\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0211\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0080 - val_loss: 0.0132\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0051 - val_loss: 0.0166\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0053 - val_loss: 0.0201\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0070 - val_loss: 0.0121\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0056 - val_loss: 0.0212\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0074 - val_loss: 0.0186\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0057 - val_loss: 0.0180\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0053 - val_loss: 0.0149\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0037 - val_loss: 0.0168\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0038 - val_loss: 0.0196\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0040 - val_loss: 0.0176\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0031 - val_loss: 0.0193\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0035 - val_loss: 0.0189\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0038 - val_loss: 0.0176\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0036 - val_loss: 0.0235\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0039 - val_loss: 0.0165\n",
      "Epoch 140/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0042 - val_loss: 0.0153\n",
      "Epoch 141/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0031 - val_loss: 0.0193\n",
      "Epoch 142/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0036 - val_loss: 0.0224\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A7AE1479D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 5s 38ms/step - loss: 0.0642 - val_loss: 0.0448\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0279 - val_loss: 0.0298\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0274 - val_loss: 0.0264\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0310 - val_loss: 0.0386\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0254 - val_loss: 0.0329\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0290 - val_loss: 0.0346\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0311\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0356 - val_loss: 0.0256\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0244 - val_loss: 0.0439\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0367 - val_loss: 0.0253\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0326 - val_loss: 0.0316\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0259 - val_loss: 0.0336\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0235 - val_loss: 0.0330\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0319 - val_loss: 0.0335\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0302 - val_loss: 0.0315\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0236 - val_loss: 0.0245\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0193 - val_loss: 0.0259\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0264 - val_loss: 0.0438\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0337 - val_loss: 0.0243\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0300 - val_loss: 0.0247\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0245 - val_loss: 0.0268\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0256 - val_loss: 0.0240\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0198 - val_loss: 0.0242\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0227 - val_loss: 0.0250\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0213 - val_loss: 0.0237\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0226 - val_loss: 0.0236\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0200 - val_loss: 0.0234\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0209 - val_loss: 0.0234\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0223 - val_loss: 0.0255\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0179 - val_loss: 0.0256\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0223 - val_loss: 0.0241\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0226 - val_loss: 0.0235\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0239 - val_loss: 0.0265\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0345 - val_loss: 0.0270\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0226\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.0202 - val_loss: 0.0246\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0189 - val_loss: 0.0348\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0334 - val_loss: 0.0365\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0297 - val_loss: 0.0264\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0205 - val_loss: 0.0232\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0268 - val_loss: 0.0231\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0275 - val_loss: 0.0226\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0201 - val_loss: 0.0218\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.0215\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0205 - val_loss: 0.0250\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0234 - val_loss: 0.0202\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0235 - val_loss: 0.0226\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0212 - val_loss: 0.0196\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0132 - val_loss: 0.0204\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.0229\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0202 - val_loss: 0.0228\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0181 - val_loss: 0.0202\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0206 - val_loss: 0.0229\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.0213\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0179 - val_loss: 0.0241\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0178 - val_loss: 0.0192\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0141 - val_loss: 0.0195\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0174 - val_loss: 0.0204\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.0213\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0206 - val_loss: 0.0184\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0272 - val_loss: 0.0188\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.0194\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0141 - val_loss: 0.0194\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0188 - val_loss: 0.0183\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0192\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0183 - val_loss: 0.0188\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.0196\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0212 - val_loss: 0.0192\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0187\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0201 - val_loss: 0.0180\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0206 - val_loss: 0.0195\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0176 - val_loss: 0.0225\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0176 - val_loss: 0.0186\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0136 - val_loss: 0.0183\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0141 - val_loss: 0.0179\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0160\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0161\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0202\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0171 - val_loss: 0.0176\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0192\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0148\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0151 - val_loss: 0.0191\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0240\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0222 - val_loss: 0.0150\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0181\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0159\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0148\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0189\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0150 - val_loss: 0.0195\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.0165\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0149\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0133\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0090 - val_loss: 0.0167\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0149\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0076 - val_loss: 0.0108\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0132\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0107 - val_loss: 0.0137\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0127 - val_loss: 0.0167\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0121\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0125\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0075 - val_loss: 0.0196\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0160\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0205\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0171\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0162\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0078 - val_loss: 0.0171\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0201\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0078 - val_loss: 0.0166\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0090 - val_loss: 0.0196\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0039 - val_loss: 0.0154\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0077 - val_loss: 0.0167\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0049 - val_loss: 0.0149\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0058 - val_loss: 0.0152\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0029 - val_loss: 0.0112\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0039 - val_loss: 0.0146\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0039 - val_loss: 0.0172\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0079 - val_loss: 0.0133\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.0072 - val_loss: 0.0162\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0057 - val_loss: 0.0131\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0060 - val_loss: 0.0120\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0040 - val_loss: 0.0171\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0049 - val_loss: 0.0113\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0033 - val_loss: 0.0186\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0024 - val_loss: 0.0116\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0022 - val_loss: 0.0190\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A70DE398B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 5s 70ms/step - loss: 0.0697 - val_loss: 0.0399\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0262 - val_loss: 0.0270\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.0213 - val_loss: 0.0277\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0259 - val_loss: 0.0284\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0302 - val_loss: 0.0292\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0223 - val_loss: 0.0281\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0298 - val_loss: 0.0248\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0214 - val_loss: 0.0288\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0237 - val_loss: 0.0251\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0235 - val_loss: 0.0285\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0200 - val_loss: 0.0280\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0307 - val_loss: 0.0248\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0268 - val_loss: 0.0295\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0258 - val_loss: 0.0320\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0314 - val_loss: 0.0296\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0247 - val_loss: 0.0245\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0303 - val_loss: 0.0250\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0209 - val_loss: 0.0250\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0212 - val_loss: 0.0240\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0249 - val_loss: 0.0291\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0229 - val_loss: 0.0237\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0243 - val_loss: 0.0240\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0313 - val_loss: 0.0256\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0271 - val_loss: 0.0242\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0304 - val_loss: 0.0232\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0253 - val_loss: 0.0238\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0271 - val_loss: 0.0231\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0275 - val_loss: 0.0237\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0322 - val_loss: 0.0271\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0200 - val_loss: 0.0229\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0235 - val_loss: 0.0268\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0267 - val_loss: 0.0240\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0280 - val_loss: 0.0223\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0199 - val_loss: 0.0226\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0239 - val_loss: 0.0262\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0214 - val_loss: 0.0245\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0189 - val_loss: 0.0264\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0240 - val_loss: 0.0240\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0170 - val_loss: 0.0233\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0224 - val_loss: 0.0233\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0231 - val_loss: 0.0207\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0209 - val_loss: 0.0225\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0176 - val_loss: 0.0228\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0186 - val_loss: 0.0220\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0170 - val_loss: 0.0222\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0209 - val_loss: 0.0202\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0198 - val_loss: 0.0214\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0198 - val_loss: 0.0216\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0184 - val_loss: 0.0209\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0196 - val_loss: 0.0215\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0244 - val_loss: 0.0206\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0171 - val_loss: 0.0195\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0218 - val_loss: 0.0183\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0235 - val_loss: 0.0187\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0174 - val_loss: 0.0182\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0125 - val_loss: 0.0187\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0166 - val_loss: 0.0194\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.0202\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0210 - val_loss: 0.0185\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0179 - val_loss: 0.0221\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0152 - val_loss: 0.0284\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0176 - val_loss: 0.0181\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0153 - val_loss: 0.0181\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0158 - val_loss: 0.0177\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0156 - val_loss: 0.0185\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0138 - val_loss: 0.0216\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0208 - val_loss: 0.0193\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0135 - val_loss: 0.0184\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.0141 - val_loss: 0.0205\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0166 - val_loss: 0.0189\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0180\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 14ms/step - loss: 0.0148 - val_loss: 0.0226\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 14ms/step - loss: 0.0132 - val_loss: 0.0239\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.0128 - val_loss: 0.0171\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0126 - val_loss: 0.0196\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0145 - val_loss: 0.0209\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0204 - val_loss: 0.0304\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0202 - val_loss: 0.0155\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0158 - val_loss: 0.0185\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0151\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0110 - val_loss: 0.0178\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.0090 - val_loss: 0.0282\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0185 - val_loss: 0.0160\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0165 - val_loss: 0.0197\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0132 - val_loss: 0.0169\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0068 - val_loss: 0.0190\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0076 - val_loss: 0.0168\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0068 - val_loss: 0.0229\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0107 - val_loss: 0.0216\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0107 - val_loss: 0.0181\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0191\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0064 - val_loss: 0.0197\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0081 - val_loss: 0.0140\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0062 - val_loss: 0.0263\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0086 - val_loss: 0.0210\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0141 - val_loss: 0.0154\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0072 - val_loss: 0.0169\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0048 - val_loss: 0.0191\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0055 - val_loss: 0.0177\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0077 - val_loss: 0.0162\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.0074 - val_loss: 0.0208\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0042 - val_loss: 0.0171\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0059 - val_loss: 0.0164\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0171\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0124 - val_loss: 0.0162\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0064 - val_loss: 0.0168\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0061 - val_loss: 0.0174\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0080 - val_loss: 0.0234\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0055 - val_loss: 0.0225\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0042 - val_loss: 0.0206\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0052 - val_loss: 0.0188\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0041 - val_loss: 0.0262\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0066 - val_loss: 0.0287\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0075 - val_loss: 0.0238\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0048 - val_loss: 0.0181\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0067 - val_loss: 0.0192\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0030 - val_loss: 0.0186\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0042 - val_loss: 0.0223\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0031 - val_loss: 0.0238\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0025 - val_loss: 0.0234\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0043 - val_loss: 0.0243\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0031 - val_loss: 0.0283\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0054 - val_loss: 0.0146\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A8769C9430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 5s 35ms/step - loss: 0.0582 - val_loss: 0.0297\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0285 - val_loss: 0.0274\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0281 - val_loss: 0.0470\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0317 - val_loss: 0.0262\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0241 - val_loss: 0.0262\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0216 - val_loss: 0.0248\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0220 - val_loss: 0.0288\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0248 - val_loss: 0.0275\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0276 - val_loss: 0.0248\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0253 - val_loss: 0.0279\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0284 - val_loss: 0.0363\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0221 - val_loss: 0.0286\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0215 - val_loss: 0.0242\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.0290\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0325 - val_loss: 0.0327\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0314 - val_loss: 0.0384\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0191 - val_loss: 0.0305\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0204 - val_loss: 0.0358\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0272 - val_loss: 0.0256\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0248 - val_loss: 0.0308\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0249 - val_loss: 0.0262\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0206 - val_loss: 0.0343\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0329 - val_loss: 0.0305\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0263 - val_loss: 0.0313\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0244 - val_loss: 0.0325\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0284 - val_loss: 0.0237\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0233 - val_loss: 0.0273\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0275 - val_loss: 0.0333\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0278 - val_loss: 0.0231\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0232 - val_loss: 0.0260\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0249 - val_loss: 0.0291\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0204 - val_loss: 0.0252\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0186 - val_loss: 0.0227\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0252\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0211 - val_loss: 0.0223\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0196 - val_loss: 0.0253\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0269 - val_loss: 0.0221\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0203 - val_loss: 0.0249\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0266 - val_loss: 0.0254\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0245 - val_loss: 0.0216\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0177 - val_loss: 0.0213\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0175 - val_loss: 0.0214\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0181 - val_loss: 0.0235\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0231 - val_loss: 0.0230\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0212 - val_loss: 0.0204\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0242 - val_loss: 0.0207\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0249 - val_loss: 0.0376\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0265 - val_loss: 0.0219\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0190 - val_loss: 0.0246\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0205 - val_loss: 0.0203\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0155 - val_loss: 0.0218\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0201 - val_loss: 0.0237\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0194 - val_loss: 0.0213\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0227 - val_loss: 0.0198\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0192 - val_loss: 0.0201\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0173 - val_loss: 0.0197\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0182 - val_loss: 0.0195\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0173 - val_loss: 0.0189\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.0172 - val_loss: 0.0188\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0259 - val_loss: 0.0180\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0202 - val_loss: 0.0218\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0209 - val_loss: 0.0188\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0161 - val_loss: 0.0203\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0211\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0155 - val_loss: 0.0252\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0220 - val_loss: 0.0243\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0195\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0142 - val_loss: 0.0177\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0147 - val_loss: 0.0177\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0171 - val_loss: 0.0170\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0151 - val_loss: 0.0175\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0218 - val_loss: 0.0232\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0250 - val_loss: 0.0201\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0169 - val_loss: 0.0203\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0179 - val_loss: 0.0191\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0205 - val_loss: 0.0180\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0169 - val_loss: 0.0173\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0165 - val_loss: 0.0151\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0191 - val_loss: 0.0186\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0135 - val_loss: 0.0171\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0209\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0146\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0207\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0123 - val_loss: 0.0214\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0198\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0208 - val_loss: 0.0187\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0191 - val_loss: 0.0200\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0156 - val_loss: 0.0159\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0214\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0162 - val_loss: 0.0183\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0150\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0113 - val_loss: 0.0248\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0115 - val_loss: 0.0186\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0205\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0138 - val_loss: 0.0121\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0077 - val_loss: 0.0183\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0144\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0152 - val_loss: 0.0149\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0149\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0077 - val_loss: 0.0120\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0109 - val_loss: 0.0192\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0081 - val_loss: 0.0199\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0078 - val_loss: 0.0130\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0060 - val_loss: 0.0137\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0050 - val_loss: 0.0145\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0070 - val_loss: 0.0209\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0055 - val_loss: 0.0150\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0060 - val_loss: 0.0185\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0125 - val_loss: 0.0154\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0067 - val_loss: 0.0137\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0055 - val_loss: 0.0186\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0056 - val_loss: 0.0131\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0068 - val_loss: 0.0155\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0047 - val_loss: 0.0188\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0033 - val_loss: 0.0223\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0042 - val_loss: 0.0115\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0043 - val_loss: 0.0207\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0040 - val_loss: 0.0160\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0036 - val_loss: 0.0130\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0050 - val_loss: 0.0207\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0054 - val_loss: 0.0198\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0039 - val_loss: 0.0226\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0052 - val_loss: 0.0173\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0075 - val_loss: 0.0130\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0045 - val_loss: 0.0120\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A8769C9670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 35ms/step - loss: 0.0779 - val_loss: 0.0274\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0290 - val_loss: 0.0275\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0248 - val_loss: 0.0261\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0208 - val_loss: 0.0255\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0210 - val_loss: 0.0257\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0261 - val_loss: 0.0281\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0325 - val_loss: 0.0247\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0238 - val_loss: 0.0308\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0244 - val_loss: 0.0246\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0343 - val_loss: 0.0330\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0179 - val_loss: 0.0291\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0225 - val_loss: 0.0258\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0289 - val_loss: 0.0328\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0247 - val_loss: 0.0249\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0297 - val_loss: 0.0326\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0260 - val_loss: 0.0379\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0316 - val_loss: 0.0365\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0330 - val_loss: 0.0479\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0376 - val_loss: 0.0271\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0238 - val_loss: 0.0252\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0224 - val_loss: 0.0248\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0224 - val_loss: 0.0238\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0243 - val_loss: 0.0247\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0198 - val_loss: 0.0247\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.0245 - val_loss: 0.0255\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0203 - val_loss: 0.0232\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0299 - val_loss: 0.0229\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0257 - val_loss: 0.0237\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0193 - val_loss: 0.0294\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0214 - val_loss: 0.0308\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0239 - val_loss: 0.0298\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0258 - val_loss: 0.0269\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0284 - val_loss: 0.0222\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0193 - val_loss: 0.0237\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0158 - val_loss: 0.0227\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0242 - val_loss: 0.0223\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0201 - val_loss: 0.0219\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0190 - val_loss: 0.0215\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0184 - val_loss: 0.0278\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0204 - val_loss: 0.0255\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0172 - val_loss: 0.0213\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0199 - val_loss: 0.0230\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0190 - val_loss: 0.0218\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0169 - val_loss: 0.0247\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0233 - val_loss: 0.0220\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0199 - val_loss: 0.0201\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0171 - val_loss: 0.0203\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0234 - val_loss: 0.0203\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0234 - val_loss: 0.0195\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0191 - val_loss: 0.0200\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0162 - val_loss: 0.0227\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0224 - val_loss: 0.0209\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0197\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0201 - val_loss: 0.0196\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0209 - val_loss: 0.0195\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0187 - val_loss: 0.0197\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0203 - val_loss: 0.0192\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0182 - val_loss: 0.0241\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0190 - val_loss: 0.0226\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0178 - val_loss: 0.0184\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0207 - val_loss: 0.0182\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0163 - val_loss: 0.0210\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0218 - val_loss: 0.0224\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.0167\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0188\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0153 - val_loss: 0.0183\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0188 - val_loss: 0.0187\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0182 - val_loss: 0.0218\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0156 - val_loss: 0.0178\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0166 - val_loss: 0.0175\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0174 - val_loss: 0.0160\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0136 - val_loss: 0.0162\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0105 - val_loss: 0.0195\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0167 - val_loss: 0.0161\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0138 - val_loss: 0.0168\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0169 - val_loss: 0.0201\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0123 - val_loss: 0.0152\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0118 - val_loss: 0.0205\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0144 - val_loss: 0.0154\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0114 - val_loss: 0.0176\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0117 - val_loss: 0.0152\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0306\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0210 - val_loss: 0.0249\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0150 - val_loss: 0.0217\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0161 - val_loss: 0.0160\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0103 - val_loss: 0.0161\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0122 - val_loss: 0.0188\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0120 - val_loss: 0.0138\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0082 - val_loss: 0.0138\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0108 - val_loss: 0.0215\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0131 - val_loss: 0.0180\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0113 - val_loss: 0.0150\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0135 - val_loss: 0.0179\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 0.0150\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0084 - val_loss: 0.0182\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0066 - val_loss: 0.0151\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0088 - val_loss: 0.0149\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0069 - val_loss: 0.0125\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0061 - val_loss: 0.0161\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0062 - val_loss: 0.0139\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0078 - val_loss: 0.0216\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0068 - val_loss: 0.0161\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0061 - val_loss: 0.0189\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0061 - val_loss: 0.0193\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0072 - val_loss: 0.0155\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.0064 - val_loss: 0.0133\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0044 - val_loss: 0.0148\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0049 - val_loss: 0.0153\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0057 - val_loss: 0.0172\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0064 - val_loss: 0.0167\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0060 - val_loss: 0.0216\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0069 - val_loss: 0.0156\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0084 - val_loss: 0.0173\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0061 - val_loss: 0.0232\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0062 - val_loss: 0.0162\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0056 - val_loss: 0.0228\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0057 - val_loss: 0.0194\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0063 - val_loss: 0.0142\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0053 - val_loss: 0.0239\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0056 - val_loss: 0.0206\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0050 - val_loss: 0.0127\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0073 - val_loss: 0.0130\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0057 - val_loss: 0.0157\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0083 - val_loss: 0.0147\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0034 - val_loss: 0.0137\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0034 - val_loss: 0.0165\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0024 - val_loss: 0.0190\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0037 - val_loss: 0.0143\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A86C7B1790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 35ms/step - loss: 0.0745 - val_loss: 0.0334\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0400 - val_loss: 0.0326\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0244 - val_loss: 0.0273\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0293 - val_loss: 0.0263\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0229 - val_loss: 0.0258\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0237 - val_loss: 0.0281\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0284 - val_loss: 0.0278\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0188 - val_loss: 0.0259\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0239 - val_loss: 0.0536\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0262 - val_loss: 0.0285\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0265 - val_loss: 0.0246\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0233 - val_loss: 0.0244\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0228 - val_loss: 0.0321\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0245 - val_loss: 0.0409\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0300 - val_loss: 0.0249\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0230 - val_loss: 0.0242\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0218 - val_loss: 0.0245\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0245 - val_loss: 0.0358\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0339 - val_loss: 0.0282\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0333 - val_loss: 0.0240\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0254 - val_loss: 0.0240\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0266 - val_loss: 0.0243\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0241 - val_loss: 0.0285\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0327 - val_loss: 0.0244\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0199 - val_loss: 0.0272\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0225 - val_loss: 0.0236\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0198 - val_loss: 0.0268\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0297 - val_loss: 0.0299\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0283 - val_loss: 0.0244\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0309 - val_loss: 0.0239\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0296 - val_loss: 0.0248\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0239 - val_loss: 0.0258\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0284 - val_loss: 0.0262\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0232 - val_loss: 0.0252\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0155 - val_loss: 0.0219\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0253 - val_loss: 0.0243\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0191 - val_loss: 0.0239\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0212 - val_loss: 0.0236\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0208 - val_loss: 0.0252\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0202 - val_loss: 0.0233\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0212 - val_loss: 0.0301\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0218 - val_loss: 0.0254\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0291 - val_loss: 0.0305\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0230 - val_loss: 0.0247\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0252 - val_loss: 0.0218\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0155 - val_loss: 0.0215\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0140 - val_loss: 0.0225\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0193 - val_loss: 0.0256\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0177 - val_loss: 0.0199\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0200\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0182 - val_loss: 0.0200\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0189 - val_loss: 0.0194\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0177 - val_loss: 0.0230\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0264 - val_loss: 0.0212\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0174 - val_loss: 0.0237\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0196 - val_loss: 0.0215\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0210 - val_loss: 0.0185\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0243\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0288 - val_loss: 0.0217\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0200 - val_loss: 0.0199\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0139 - val_loss: 0.0309\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0275 - val_loss: 0.0253\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0237 - val_loss: 0.0202\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0193\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0185\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0114 - val_loss: 0.0172\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0160 - val_loss: 0.0249\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0199 - val_loss: 0.0178\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0189 - val_loss: 0.0214\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0217 - val_loss: 0.0192\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0126 - val_loss: 0.0187\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0154 - val_loss: 0.0197\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0143 - val_loss: 0.0175\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0211\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0183\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0139 - val_loss: 0.0186\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0210\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0162 - val_loss: 0.0186\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0132 - val_loss: 0.0180\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 1s 28ms/step - loss: 0.0113 - val_loss: 0.0181\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0139 - val_loss: 0.0224\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0104 - val_loss: 0.0308\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0204\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0213\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0182\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0139 - val_loss: 0.0237\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0253\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0118 - val_loss: 0.0235\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.0229\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0197\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0241\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0125 - val_loss: 0.0136\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0198\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0176\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0158\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0164\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0076 - val_loss: 0.0182\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0195\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0090 - val_loss: 0.0171\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0070 - val_loss: 0.0187\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0085 - val_loss: 0.0165\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0067 - val_loss: 0.0147\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0229\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0113\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.0279\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0173 - val_loss: 0.0240\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0083 - val_loss: 0.0183\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0240\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0104 - val_loss: 0.0180\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0064 - val_loss: 0.0188\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0065 - val_loss: 0.0218\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0057 - val_loss: 0.0156\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0046 - val_loss: 0.0184\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0051 - val_loss: 0.0189\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0052 - val_loss: 0.0159\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0065 - val_loss: 0.0192\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0050 - val_loss: 0.0153\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0040 - val_loss: 0.0194\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0041 - val_loss: 0.0216\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0041 - val_loss: 0.0162\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0037 - val_loss: 0.0181\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0037 - val_loss: 0.0242\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0067 - val_loss: 0.0146\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0042 - val_loss: 0.0205\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0042 - val_loss: 0.0196\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0050 - val_loss: 0.0196\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0045 - val_loss: 0.0172\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0044 - val_loss: 0.0197\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0044 - val_loss: 0.0160\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0037 - val_loss: 0.0166\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0037 - val_loss: 0.0162\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0036 - val_loss: 0.0184\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0076 - val_loss: 0.0207\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0048 - val_loss: 0.0185\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A85F9B9040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 35ms/step - loss: 0.0590 - val_loss: 0.0347\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0242 - val_loss: 0.0277\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0209 - val_loss: 0.0292\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0253 - val_loss: 0.0285\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0239 - val_loss: 0.0258\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0224 - val_loss: 0.0248\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0263 - val_loss: 0.0266\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0297 - val_loss: 0.0259\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0202 - val_loss: 0.0246\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0239 - val_loss: 0.0345\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0360 - val_loss: 0.0252\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0275 - val_loss: 0.0258\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0225 - val_loss: 0.0248\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0221 - val_loss: 0.0251\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0189 - val_loss: 0.0254\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0249 - val_loss: 0.0242\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0230 - val_loss: 0.0364\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0264 - val_loss: 0.0241\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0231 - val_loss: 0.0276\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.0219 - val_loss: 0.0253\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0230 - val_loss: 0.0244\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0220 - val_loss: 0.0250\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0317 - val_loss: 0.0236\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0235\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0213 - val_loss: 0.0262\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0257 - val_loss: 0.0231\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0283 - val_loss: 0.0249\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0298 - val_loss: 0.0228\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0222 - val_loss: 0.0252\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0263 - val_loss: 0.0228\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0164 - val_loss: 0.0342\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0270 - val_loss: 0.0358\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0233 - val_loss: 0.0225\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0191 - val_loss: 0.0220\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0184 - val_loss: 0.0303\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0221 - val_loss: 0.0223\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0182 - val_loss: 0.0219\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0221 - val_loss: 0.0215\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - ETA: 0s - loss: 0.021 - 0s 10ms/step - loss: 0.0212 - val_loss: 0.0245\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0161 - val_loss: 0.0244\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0201 - val_loss: 0.0223\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0155 - val_loss: 0.0207\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0197 - val_loss: 0.0249\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0159 - val_loss: 0.0234\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0217 - val_loss: 0.0300\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0197 - val_loss: 0.0214\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0188 - val_loss: 0.0201\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0226 - val_loss: 0.0215\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0132 - val_loss: 0.0195\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0205 - val_loss: 0.0197\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0211 - val_loss: 0.0192\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0208 - val_loss: 0.0204\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0162 - val_loss: 0.0208\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0166 - val_loss: 0.0191\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0166 - val_loss: 0.0175\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0176 - val_loss: 0.0178\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0170 - val_loss: 0.0209\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0158 - val_loss: 0.0185\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0214 - val_loss: 0.0220\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0235 - val_loss: 0.0266\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0171 - val_loss: 0.0173\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0211 - val_loss: 0.0193\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0192 - val_loss: 0.0223\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0174 - val_loss: 0.0175\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0135 - val_loss: 0.0265\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0189 - val_loss: 0.0169\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0150 - val_loss: 0.0189\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0191 - val_loss: 0.0185\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0122 - val_loss: 0.0197\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0195 - val_loss: 0.0183\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0200 - val_loss: 0.0213\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0142 - val_loss: 0.0154\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0239\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0151 - val_loss: 0.0160\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0131 - val_loss: 0.0241\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0151 - val_loss: 0.0172\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0219\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0134 - val_loss: 0.0226\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0162 - val_loss: 0.0216\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0132 - val_loss: 0.0209\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0163 - val_loss: 0.0150\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0095 - val_loss: 0.0152\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0081 - val_loss: 0.0151\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0167\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0251\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0120 - val_loss: 0.0229\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0121 - val_loss: 0.0191\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0159\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0125 - val_loss: 0.0136\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0074 - val_loss: 0.0169\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0077 - val_loss: 0.0170\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0074 - val_loss: 0.0163\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0081 - val_loss: 0.0174\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0064 - val_loss: 0.0171\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0087 - val_loss: 0.0188\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0075 - val_loss: 0.0128\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0050 - val_loss: 0.0203\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0069 - val_loss: 0.0157\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0078 - val_loss: 0.0151\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0054 - val_loss: 0.0225\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0060 - val_loss: 0.0181\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0058 - val_loss: 0.0203\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0048 - val_loss: 0.0128\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0056 - val_loss: 0.0192\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0061 - val_loss: 0.0221\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0065 - val_loss: 0.0160\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0051 - val_loss: 0.0165\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0042 - val_loss: 0.0135\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0061 - val_loss: 0.0117\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0040 - val_loss: 0.0204\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0046 - val_loss: 0.0148\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0054 - val_loss: 0.0208\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0036 - val_loss: 0.0200\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0029 - val_loss: 0.0178\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0026 - val_loss: 0.0208\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0035 - val_loss: 0.0159\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0043 - val_loss: 0.0208\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0039 - val_loss: 0.0211\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0026 - val_loss: 0.0169\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0031 - val_loss: 0.0188\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 0.0197\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0191\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.0032 - val_loss: 0.0238\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0045 - val_loss: 0.0205\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0052 - val_loss: 0.0156\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0045 - val_loss: 0.0220\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0029 - val_loss: 0.0247\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0039 - val_loss: 0.0221\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0046 - val_loss: 0.0172\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0037 - val_loss: 0.0187\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0045 - val_loss: 0.0211\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0043 - val_loss: 0.0220\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0027 - val_loss: 0.0171\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0024 - val_loss: 0.0242\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0039 - val_loss: 0.0237\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0047 - val_loss: 0.0203\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0031 - val_loss: 0.0187\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0024 - val_loss: 0.0202\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 0.0183\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A85FC43160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 5s 39ms/step - loss: 0.0513 - val_loss: 0.0320\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0349 - val_loss: 0.0283\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0385 - val_loss: 0.0354\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0282 - val_loss: 0.0357\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0312 - val_loss: 0.0255\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0188 - val_loss: 0.0275\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0301 - val_loss: 0.0283\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0290 - val_loss: 0.0247\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0249 - val_loss: 0.0248\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0307 - val_loss: 0.0270\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0219 - val_loss: 0.0253\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0260 - val_loss: 0.0240\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0261 - val_loss: 0.0300\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0301 - val_loss: 0.0243\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0233 - val_loss: 0.0301\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0242 - val_loss: 0.0260\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0296 - val_loss: 0.0241\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0204 - val_loss: 0.0267\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0248 - val_loss: 0.0277\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0238 - val_loss: 0.0240\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0220 - val_loss: 0.0241\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0216 - val_loss: 0.0266\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0226 - val_loss: 0.0234\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0258 - val_loss: 0.0271\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0279 - val_loss: 0.0328\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0236 - val_loss: 0.0253\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0195 - val_loss: 0.0274\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0202 - val_loss: 0.0335\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0309 - val_loss: 0.0241\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0287 - val_loss: 0.0226\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0205 - val_loss: 0.0235\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0248 - val_loss: 0.0343\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0199 - val_loss: 0.0317\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0230 - val_loss: 0.0292\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0215 - val_loss: 0.0247\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0181 - val_loss: 0.0232\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0234 - val_loss: 0.0222\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0269 - val_loss: 0.0228\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0215 - val_loss: 0.0226\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0172 - val_loss: 0.0231\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0198 - val_loss: 0.0209\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0272 - val_loss: 0.0216\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0191 - val_loss: 0.0206\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0194 - val_loss: 0.0214\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0149 - val_loss: 0.0247\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0175 - val_loss: 0.0201\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0162 - val_loss: 0.0197\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0299\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0241 - val_loss: 0.0225\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0176 - val_loss: 0.0213\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0193 - val_loss: 0.0289\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0243 - val_loss: 0.0215\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0206 - val_loss: 0.0203\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0180 - val_loss: 0.0194\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0169 - val_loss: 0.0192\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0168 - val_loss: 0.0190\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0187 - val_loss: 0.0184\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0245 - val_loss: 0.0203\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0171 - val_loss: 0.0196\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0191\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0140 - val_loss: 0.0201\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.0181\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0172 - val_loss: 0.0199\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0190 - val_loss: 0.0180\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0139 - val_loss: 0.0202\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0159 - val_loss: 0.0174\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0183 - val_loss: 0.0185\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0210 - val_loss: 0.0179\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0160 - val_loss: 0.0170\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0172\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0153 - val_loss: 0.0174\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0134 - val_loss: 0.0166\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0169 - val_loss: 0.0201\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.0193\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0156 - val_loss: 0.0220\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0233 - val_loss: 0.0182\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0170 - val_loss: 0.0228\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0138 - val_loss: 0.0176\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0144 - val_loss: 0.0152\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0205 - val_loss: 0.0186\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0129 - val_loss: 0.0164\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0152 - val_loss: 0.0170\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0216\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0169 - val_loss: 0.0220\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.0206 - val_loss: 0.0163\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0138 - val_loss: 0.0191\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0109 - val_loss: 0.0196\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0165 - val_loss: 0.0157\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0173\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0130 - val_loss: 0.0187\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0109 - val_loss: 0.0192\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0119 - val_loss: 0.0148\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0070 - val_loss: 0.0192\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0084 - val_loss: 0.0274\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0166\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0171\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0075 - val_loss: 0.0178\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0083 - val_loss: 0.0195\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0080 - val_loss: 0.0170\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0065 - val_loss: 0.0124\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0180\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0159\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0106 - val_loss: 0.0175\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0061 - val_loss: 0.0121\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0082 - val_loss: 0.0139\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0078 - val_loss: 0.0125\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0061 - val_loss: 0.0139\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0063 - val_loss: 0.0200\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0062 - val_loss: 0.0151\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0039 - val_loss: 0.0160\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0066 - val_loss: 0.0240\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0109 - val_loss: 0.0140\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0046 - val_loss: 0.0145\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0068 - val_loss: 0.0176\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0049 - val_loss: 0.0132\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0055 - val_loss: 0.0156\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0032 - val_loss: 0.0145\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0034 - val_loss: 0.0221\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0036 - val_loss: 0.0186\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0106 - val_loss: 0.0187\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0090 - val_loss: 0.0159\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0082 - val_loss: 0.0250\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0052 - val_loss: 0.0163\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0062 - val_loss: 0.0126\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0082 - val_loss: 0.0203\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0054 - val_loss: 0.0189\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0031 - val_loss: 0.0120\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0037 - val_loss: 0.0166\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0037 - val_loss: 0.0149\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0032 - val_loss: 0.0173\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A86DC96310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 36ms/step - loss: 0.1130 - val_loss: 0.0276\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0284 - val_loss: 0.0276\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0242 - val_loss: 0.0270\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0299 - val_loss: 0.0352\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0274 - val_loss: 0.0277\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0229 - val_loss: 0.0265\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0247 - val_loss: 0.0272\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0248 - val_loss: 0.0306\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0264 - val_loss: 0.0273\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0279 - val_loss: 0.0253\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0272 - val_loss: 0.0278\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0227 - val_loss: 0.0250\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0197 - val_loss: 0.0242\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0276 - val_loss: 0.0244\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0216 - val_loss: 0.0245\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0279 - val_loss: 0.0240\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0228 - val_loss: 0.0320\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0315 - val_loss: 0.0297\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0265 - val_loss: 0.0241\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0214 - val_loss: 0.0247\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0240 - val_loss: 0.0334\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0207 - val_loss: 0.0237\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0220 - val_loss: 0.0279\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0309 - val_loss: 0.0252\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0214 - val_loss: 0.0241\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0253 - val_loss: 0.0232\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0229 - val_loss: 0.0245\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0341 - val_loss: 0.0270\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0196 - val_loss: 0.0356\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0170 - val_loss: 0.0236\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0242 - val_loss: 0.0259\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.0286 - val_loss: 0.0227\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0192 - val_loss: 0.0235\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0181 - val_loss: 0.0301\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0287 - val_loss: 0.0247\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0225 - val_loss: 0.0225\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0183 - val_loss: 0.0224\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0237 - val_loss: 0.0221\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0200 - val_loss: 0.0221\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0193 - val_loss: 0.0215\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0222 - val_loss: 0.0214\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0254 - val_loss: 0.0226\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0242 - val_loss: 0.0220\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0176 - val_loss: 0.0265\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0246 - val_loss: 0.0241\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0238 - val_loss: 0.0205\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0170 - val_loss: 0.0208\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0188 - val_loss: 0.0214\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0189 - val_loss: 0.0351\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0247 - val_loss: 0.0298\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0199 - val_loss: 0.0227\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0189 - val_loss: 0.0209\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0209 - val_loss: 0.0210\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0173 - val_loss: 0.0197\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0256 - val_loss: 0.0198\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0152 - val_loss: 0.0192\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0157 - val_loss: 0.0243\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0207 - val_loss: 0.0237\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0225 - val_loss: 0.0198\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0173 - val_loss: 0.0190\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0149 - val_loss: 0.0191\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0181 - val_loss: 0.0187\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0191 - val_loss: 0.0203\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0156 - val_loss: 0.0181\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0146 - val_loss: 0.0181\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0154 - val_loss: 0.0198\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0175 - val_loss: 0.0175\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0169 - val_loss: 0.0191\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0200 - val_loss: 0.0164\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0141 - val_loss: 0.0189\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0136 - val_loss: 0.0179\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0128 - val_loss: 0.0206\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0239 - val_loss: 0.0186\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0173 - val_loss: 0.0192\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0171 - val_loss: 0.0182\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.0190\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0198 - val_loss: 0.0178\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.0160\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.0157 - val_loss: 0.0214\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0156 - val_loss: 0.0181\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0155 - val_loss: 0.0207\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0172 - val_loss: 0.0173\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0157 - val_loss: 0.0160\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0146 - val_loss: 0.0187\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0147 - val_loss: 0.0178\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0165 - val_loss: 0.0201\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0170 - val_loss: 0.0190\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0156 - val_loss: 0.0166\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0144\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0123 - val_loss: 0.0210\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0113 - val_loss: 0.0159\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0124 - val_loss: 0.0212\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0165\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0131 - val_loss: 0.0181\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0087 - val_loss: 0.0185\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0150\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0181\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0106 - val_loss: 0.0141\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0070 - val_loss: 0.0115\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0148 - val_loss: 0.0168\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0146\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0117 - val_loss: 0.0137\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0081 - val_loss: 0.0198\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0085 - val_loss: 0.0174\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0221\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0137 - val_loss: 0.0212\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0137 - val_loss: 0.0138\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0081 - val_loss: 0.0153\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0109 - val_loss: 0.0167\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0085 - val_loss: 0.0163\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0063 - val_loss: 0.0133\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0055 - val_loss: 0.0244\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0166\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0130\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0080 - val_loss: 0.0160\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0064 - val_loss: 0.0145\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0064 - val_loss: 0.0191\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 0.0159\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0071 - val_loss: 0.0133\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0068 - val_loss: 0.0263\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0081 - val_loss: 0.0257\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0080 - val_loss: 0.0163\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0040 - val_loss: 0.0143\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0120 - val_loss: 0.0272\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0147 - val_loss: 0.0136\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0067 - val_loss: 0.0212\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0051 - val_loss: 0.0151\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0042 - val_loss: 0.0172\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0038 - val_loss: 0.0152\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A8847D9AF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 60ms/step - loss: 0.0999 - val_loss: 0.0285\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0291 - val_loss: 0.0273\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0316 - val_loss: 0.0270\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0268 - val_loss: 0.0259\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0293 - val_loss: 0.0334\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0262 - val_loss: 0.0296\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0251 - val_loss: 0.0247\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0238 - val_loss: 0.0249\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0250 - val_loss: 0.0248\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0179 - val_loss: 0.0260\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0239 - val_loss: 0.0273\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0353 - val_loss: 0.0248\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0230 - val_loss: 0.0263\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0260 - val_loss: 0.0245\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0224 - val_loss: 0.0293\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0268 - val_loss: 0.0242\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0209 - val_loss: 0.0316\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0172 - val_loss: 0.0240\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0218 - val_loss: 0.0238\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0203 - val_loss: 0.0240\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0237 - val_loss: 0.0242\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0211 - val_loss: 0.0260\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0247 - val_loss: 0.0286\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0193 - val_loss: 0.0241\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0188 - val_loss: 0.0242\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0286 - val_loss: 0.0244\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0229 - val_loss: 0.0245\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0189 - val_loss: 0.0232\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0252 - val_loss: 0.0240\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0279 - val_loss: 0.0286\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0200 - val_loss: 0.0236\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0176 - val_loss: 0.0268\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0236 - val_loss: 0.0266\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0238 - val_loss: 0.0223\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0170 - val_loss: 0.0227\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0230 - val_loss: 0.0224\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0224 - val_loss: 0.0247\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0212 - val_loss: 0.0218\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0170 - val_loss: 0.0226\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0247 - val_loss: 0.0230\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0196 - val_loss: 0.0217\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0223 - val_loss: 0.0273\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0242 - val_loss: 0.0229\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0172 - val_loss: 0.0219\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0174 - val_loss: 0.0218\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0214 - val_loss: 0.0204\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0219 - val_loss: 0.0286\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0245 - val_loss: 0.0202\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0179 - val_loss: 0.0203\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0232\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0171 - val_loss: 0.0207\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0193 - val_loss: 0.0216\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0163 - val_loss: 0.0211\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0195 - val_loss: 0.0193\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0195 - val_loss: 0.0190\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0193 - val_loss: 0.0188\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0246 - val_loss: 0.0248\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0214 - val_loss: 0.0221\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0220 - val_loss: 0.0189\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0142 - val_loss: 0.0221\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0194 - val_loss: 0.0202\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0186\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0212 - val_loss: 0.0217\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0174 - val_loss: 0.0207\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0192 - val_loss: 0.0190\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0191\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0230\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0213 - val_loss: 0.0202\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0238 - val_loss: 0.0192\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0149 - val_loss: 0.0205\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0155 - val_loss: 0.0174\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.0168 - val_loss: 0.0195\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0154 - val_loss: 0.0181\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0188 - val_loss: 0.0174\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0193\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0167 - val_loss: 0.0152\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0131 - val_loss: 0.0182\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0130 - val_loss: 0.0213\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0106 - val_loss: 0.0214\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0149 - val_loss: 0.0185\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0248\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0142 - val_loss: 0.0146\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0177 - val_loss: 0.0202\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0155 - val_loss: 0.0168\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0155 - val_loss: 0.0212\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0258\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0149 - val_loss: 0.0215\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0209\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0126 - val_loss: 0.0215\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.0149\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0189\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0242\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0114 - val_loss: 0.0170\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0075 - val_loss: 0.0142\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0117 - val_loss: 0.0175\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0141 - val_loss: 0.0164\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0081 - val_loss: 0.0233\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0155\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0079 - val_loss: 0.0148\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0078 - val_loss: 0.0119\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0162\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0132 - val_loss: 0.0178\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0079 - val_loss: 0.0160\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0120\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0054 - val_loss: 0.0188\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0074 - val_loss: 0.0141\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0115 - val_loss: 0.0189\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0155\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0067 - val_loss: 0.0146\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0074 - val_loss: 0.0166\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0083 - val_loss: 0.0134\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0081 - val_loss: 0.0168\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0061 - val_loss: 0.0216\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0064 - val_loss: 0.0215\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0070 - val_loss: 0.0180\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0052 - val_loss: 0.0203\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0043 - val_loss: 0.0204\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0058 - val_loss: 0.0219\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0046 - val_loss: 0.0217\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0040 - val_loss: 0.0179\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0030 - val_loss: 0.0213\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0045 - val_loss: 0.0198\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0054 - val_loss: 0.0199\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0044 - val_loss: 0.0189\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0034 - val_loss: 0.0167\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0035 - val_loss: 0.0215\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0054 - val_loss: 0.0261\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0046 - val_loss: 0.0169\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0031 - val_loss: 0.0272\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0055 - val_loss: 0.0194\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A70CDEFC10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 5s 37ms/step - loss: 0.0713 - val_loss: 0.0272\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0248 - val_loss: 0.0281\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0283 - val_loss: 0.0318\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0253 - val_loss: 0.0264\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0247 - val_loss: 0.0253\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0238 - val_loss: 0.0261\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0236 - val_loss: 0.0273\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0255 - val_loss: 0.0318\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0247 - val_loss: 0.0295\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0188 - val_loss: 0.0245\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0236 - val_loss: 0.0246\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0228 - val_loss: 0.0263\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 0.0278 - val_loss: 0.0244\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0247 - val_loss: 0.0247\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0244 - val_loss: 0.0249\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0237 - val_loss: 0.0243\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0234 - val_loss: 0.0249\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0254 - val_loss: 0.0245\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0239 - val_loss: 0.0267\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0296 - val_loss: 0.0269\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0281 - val_loss: 0.0292\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0240 - val_loss: 0.0294\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0263 - val_loss: 0.0375\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0255 - val_loss: 0.0273\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0175 - val_loss: 0.0272\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0226 - val_loss: 0.0292\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0206 - val_loss: 0.0232\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0192 - val_loss: 0.0230\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0217 - val_loss: 0.0230\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0169 - val_loss: 0.0242\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0231 - val_loss: 0.0228\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0252 - val_loss: 0.0232\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0176 - val_loss: 0.0224\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0217 - val_loss: 0.0266\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0250 - val_loss: 0.0241\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.0238 - val_loss: 0.0227\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0193 - val_loss: 0.0246\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0235 - val_loss: 0.0305\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0238 - val_loss: 0.0239\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0173 - val_loss: 0.0224\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0272 - val_loss: 0.0212\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0160 - val_loss: 0.0212\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0173 - val_loss: 0.0214\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0221 - val_loss: 0.0230\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0172 - val_loss: 0.0209\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0232 - val_loss: 0.0212\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0206 - val_loss: 0.0205\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0261 - val_loss: 0.0230\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0147 - val_loss: 0.0206\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0230 - val_loss: 0.0199\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0192 - val_loss: 0.0201\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0207 - val_loss: 0.0237\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0170 - val_loss: 0.0212\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0177 - val_loss: 0.0199\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.0244 - val_loss: 0.0190\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0159 - val_loss: 0.0253\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0195 - val_loss: 0.0198\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0200 - val_loss: 0.0265\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0234 - val_loss: 0.0218\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0211 - val_loss: 0.0196\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0288 - val_loss: 0.0224\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0202 - val_loss: 0.0190\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0186 - val_loss: 0.0196\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0183 - val_loss: 0.0215\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0212 - val_loss: 0.0191\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0194 - val_loss: 0.0236\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0164 - val_loss: 0.0244\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0219 - val_loss: 0.0191\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0183 - val_loss: 0.0266\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0191 - val_loss: 0.0175\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0147 - val_loss: 0.0195\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0212 - val_loss: 0.0201\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0200 - val_loss: 0.0178\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0155 - val_loss: 0.0173\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0260 - val_loss: 0.0173\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0158 - val_loss: 0.0169\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0127 - val_loss: 0.0156\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0114 - val_loss: 0.0176\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0196 - val_loss: 0.0189\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0119 - val_loss: 0.0210\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0251\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0155 - val_loss: 0.0186\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0209 - val_loss: 0.0172\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0129 - val_loss: 0.0168\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0103 - val_loss: 0.0210\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0121 - val_loss: 0.0148\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0121 - val_loss: 0.0177\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0122 - val_loss: 0.0186\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0154 - val_loss: 0.0188\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0110 - val_loss: 0.0152\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0113 - val_loss: 0.0178\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0109 - val_loss: 0.0256\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0159\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0138 - val_loss: 0.0232\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0173\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0124 - val_loss: 0.0166\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0068 - val_loss: 0.0209\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0175\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0168\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0151 - val_loss: 0.0187\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0179\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0083 - val_loss: 0.0147\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0068 - val_loss: 0.0184\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0052 - val_loss: 0.0164\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0150\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0213\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0087 - val_loss: 0.0111\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0078 - val_loss: 0.0151\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0066 - val_loss: 0.0217\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0110 - val_loss: 0.0157\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0071 - val_loss: 0.0218\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0081 - val_loss: 0.0188\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0047 - val_loss: 0.0200\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0093 - val_loss: 0.0162\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0051 - val_loss: 0.0203\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0051 - val_loss: 0.0206\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0051 - val_loss: 0.0107\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.0047 - val_loss: 0.0177\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0051 - val_loss: 0.0127\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0046 - val_loss: 0.0237\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0079 - val_loss: 0.0175\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0072 - val_loss: 0.0173\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0081 - val_loss: 0.0180\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0036 - val_loss: 0.0151\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0049 - val_loss: 0.0130\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0052 - val_loss: 0.0192\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0032 - val_loss: 0.0171\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0026 - val_loss: 0.0174\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0045 - val_loss: 0.0238\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0057 - val_loss: 0.0160\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0027 - val_loss: 0.0196\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0032 - val_loss: 0.0179\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0024 - val_loss: 0.0128\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0033 - val_loss: 0.0218\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0035 - val_loss: 0.0177\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0023 - val_loss: 0.0185\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 0.0163\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A868B95430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 5s 37ms/step - loss: 0.0820 - val_loss: 0.0330\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0323 - val_loss: 0.0268\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0212 - val_loss: 0.0281\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0296 - val_loss: 0.0265\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0321 - val_loss: 0.0285\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0237 - val_loss: 0.0279\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0212 - val_loss: 0.0250\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0321 - val_loss: 0.0281\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0245 - val_loss: 0.0248\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0235 - val_loss: 0.0293\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0268 - val_loss: 0.0251\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0236 - val_loss: 0.0248\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0183 - val_loss: 0.0243\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0213 - val_loss: 0.0249\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0188 - val_loss: 0.0242\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0200 - val_loss: 0.0307\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0239 - val_loss: 0.0307\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0305 - val_loss: 0.0280\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0212 - val_loss: 0.0264\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0205 - val_loss: 0.0263\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0255 - val_loss: 0.0269\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0258 - val_loss: 0.0279\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0171 - val_loss: 0.0239\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0198 - val_loss: 0.0278\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0319 - val_loss: 0.0244\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0267 - val_loss: 0.0326\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0390 - val_loss: 0.0233\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0228 - val_loss: 0.0238\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0169 - val_loss: 0.0253\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0218 - val_loss: 0.0236\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0209 - val_loss: 0.0243\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0273 - val_loss: 0.0280\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0234 - val_loss: 0.0261\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0296 - val_loss: 0.0225\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0203 - val_loss: 0.0247\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0245 - val_loss: 0.0226\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0212 - val_loss: 0.0227\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0199 - val_loss: 0.0223\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0225 - val_loss: 0.0235\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0260 - val_loss: 0.0218\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0210 - val_loss: 0.0216\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0215\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0190 - val_loss: 0.0213\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0206 - val_loss: 0.0235\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0178 - val_loss: 0.0216\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0192 - val_loss: 0.0231\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0171 - val_loss: 0.0208\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0202\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0267 - val_loss: 0.0216\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0174 - val_loss: 0.0201\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0181 - val_loss: 0.0276\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0199 - val_loss: 0.0197\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0179 - val_loss: 0.0197\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0210\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0187 - val_loss: 0.0234\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0172 - val_loss: 0.0194\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0224 - val_loss: 0.0213\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0149 - val_loss: 0.0193\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0150 - val_loss: 0.0198\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0201\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0188 - val_loss: 0.0214\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0151 - val_loss: 0.0193\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0210\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0167 - val_loss: 0.0173\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0185 - val_loss: 0.0206\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0196 - val_loss: 0.0181\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0298 - val_loss: 0.0184\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.0185 - val_loss: 0.0208\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0205 - val_loss: 0.0169\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0133 - val_loss: 0.0223\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0164 - val_loss: 0.0248\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0203 - val_loss: 0.0157\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0192 - val_loss: 0.0211\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0158 - val_loss: 0.0190\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0118 - val_loss: 0.0165\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0154 - val_loss: 0.0214\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0171\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0142 - val_loss: 0.0238\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0187 - val_loss: 0.0195\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0152 - val_loss: 0.0175\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0194\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0106 - val_loss: 0.0223\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0139 - val_loss: 0.0158\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0114 - val_loss: 0.0168\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0155 - val_loss: 0.0229\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0152 - val_loss: 0.0186\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0198\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0133 - val_loss: 0.0174\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0112 - val_loss: 0.0372\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0229 - val_loss: 0.0218\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0225 - val_loss: 0.0198\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0148 - val_loss: 0.0205\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0181\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0089 - val_loss: 0.0197\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0103 - val_loss: 0.0173\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0068 - val_loss: 0.0186\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0072 - val_loss: 0.0166\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0102 - val_loss: 0.0183\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0117 - val_loss: 0.0156\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0307\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0166 - val_loss: 0.0170\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A888178430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 5s 38ms/step - loss: 0.0717 - val_loss: 0.0302\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0272 - val_loss: 0.0279\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0243 - val_loss: 0.0321\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0268 - val_loss: 0.0295\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0196 - val_loss: 0.0277\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0296 - val_loss: 0.0262\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0223 - val_loss: 0.0249\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0228 - val_loss: 0.0248\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0213 - val_loss: 0.0271\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0255 - val_loss: 0.0348\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0259 - val_loss: 0.0247\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0210 - val_loss: 0.0292\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0199 - val_loss: 0.0243\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0247 - val_loss: 0.0444\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0237 - val_loss: 0.0242\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0242 - val_loss: 0.0256\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0277 - val_loss: 0.0270\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0224 - val_loss: 0.0321\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0252 - val_loss: 0.0239\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0292 - val_loss: 0.0293\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0273 - val_loss: 0.0391\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0171 - val_loss: 0.0235\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0195 - val_loss: 0.0242\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0213 - val_loss: 0.0232\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0259 - val_loss: 0.0259\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0186 - val_loss: 0.0286\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0255 - val_loss: 0.0236\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0266 - val_loss: 0.0231\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0212 - val_loss: 0.0231\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0234 - val_loss: 0.0286\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0221 - val_loss: 0.0312\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0230 - val_loss: 0.0236\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0194 - val_loss: 0.0230\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0215 - val_loss: 0.0260\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0156 - val_loss: 0.0228\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0262 - val_loss: 0.0219\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0203 - val_loss: 0.0223\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0236 - val_loss: 0.0297\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0169 - val_loss: 0.0285\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0308 - val_loss: 0.0271\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0355 - val_loss: 0.0229\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0221 - val_loss: 0.0252\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0208 - val_loss: 0.0239\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0201 - val_loss: 0.0341\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0259 - val_loss: 0.0215\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0257 - val_loss: 0.0232\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0221 - val_loss: 0.0202\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0185 - val_loss: 0.0206\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0182 - val_loss: 0.0196\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0241 - val_loss: 0.0246\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0203 - val_loss: 0.0196\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0192 - val_loss: 0.0205\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0232 - val_loss: 0.0202\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0188 - val_loss: 0.0240\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0226\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0194 - val_loss: 0.0202\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0220 - val_loss: 0.0198\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0261 - val_loss: 0.0208\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0174 - val_loss: 0.0202\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0165 - val_loss: 0.0192\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0183 - val_loss: 0.0206\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0141 - val_loss: 0.0175\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0182 - val_loss: 0.0175\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0157 - val_loss: 0.0195\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0201 - val_loss: 0.0191\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0141 - val_loss: 0.0224\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.0219 - val_loss: 0.0198\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0150 - val_loss: 0.0192\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0175 - val_loss: 0.0180\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0144 - val_loss: 0.0260\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0216 - val_loss: 0.0169\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0159 - val_loss: 0.0184\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0152 - val_loss: 0.0165\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0171 - val_loss: 0.0198\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0112 - val_loss: 0.0215\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0185 - val_loss: 0.0184\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0159 - val_loss: 0.0168\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0152 - val_loss: 0.0139\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0150 - val_loss: 0.0197\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0124 - val_loss: 0.0170\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0156 - val_loss: 0.0173\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0113 - val_loss: 0.0175\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0101 - val_loss: 0.0217\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0172\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0199 - val_loss: 0.0193\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0204 - val_loss: 0.0164\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0144 - val_loss: 0.0152\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0135 - val_loss: 0.0158\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0236\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0113 - val_loss: 0.0162\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0095 - val_loss: 0.0188\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0108 - val_loss: 0.0164\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0119 - val_loss: 0.0184\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0213\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0088 - val_loss: 0.0167\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0118 - val_loss: 0.0281\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0162 - val_loss: 0.0143\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0115 - val_loss: 0.0229\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0121 - val_loss: 0.0127\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0061 - val_loss: 0.0138\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0069 - val_loss: 0.0177\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0062 - val_loss: 0.0154\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0066 - val_loss: 0.0254\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0142 - val_loss: 0.0145\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0078 - val_loss: 0.0136\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0063 - val_loss: 0.0182\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0060 - val_loss: 0.0129\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0048 - val_loss: 0.0176\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0059 - val_loss: 0.0179\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0076 - val_loss: 0.0179\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0055 - val_loss: 0.0123\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0110 - val_loss: 0.0153\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0063 - val_loss: 0.0187\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0055 - val_loss: 0.0194\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0053 - val_loss: 0.0183\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0051 - val_loss: 0.0171\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0080 - val_loss: 0.0146\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0074 - val_loss: 0.0205\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0052 - val_loss: 0.0180\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0057 - val_loss: 0.0158\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0054 - val_loss: 0.0197\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0059 - val_loss: 0.0238\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0050 - val_loss: 0.0153\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0050 - val_loss: 0.0119\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0043 - val_loss: 0.0157\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0051 - val_loss: 0.0226\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0055 - val_loss: 0.0165\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0041 - val_loss: 0.0182\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0039 - val_loss: 0.0192\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A8873D2C10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 35ms/step - loss: 0.0694 - val_loss: 0.0296\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0250 - val_loss: 0.0270\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0293 - val_loss: 0.0297\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0174 - val_loss: 0.0252\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0238 - val_loss: 0.0315\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0248 - val_loss: 0.0248\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0183 - val_loss: 0.0340\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0202 - val_loss: 0.0249\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0343 - val_loss: 0.0266\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0245 - val_loss: 0.0244\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0251 - val_loss: 0.0298\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0221 - val_loss: 0.0249\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.0306 - val_loss: 0.0241\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0231 - val_loss: 0.0256\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0224 - val_loss: 0.0264\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0281 - val_loss: 0.0245\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0292 - val_loss: 0.0294\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0247 - val_loss: 0.0237\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0301 - val_loss: 0.0252\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0255 - val_loss: 0.0243\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0294 - val_loss: 0.0267\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0230 - val_loss: 0.0263\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0201 - val_loss: 0.0238\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0185 - val_loss: 0.0268\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0250 - val_loss: 0.0237\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0220 - val_loss: 0.0258\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0292 - val_loss: 0.0264\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0271 - val_loss: 0.0227\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0332 - val_loss: 0.0245\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0222 - val_loss: 0.0307\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0183 - val_loss: 0.0270\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0251 - val_loss: 0.0245\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0261 - val_loss: 0.0266\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0235 - val_loss: 0.0241\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0176 - val_loss: 0.0240\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0244 - val_loss: 0.0286\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0187 - val_loss: 0.0252\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0247 - val_loss: 0.0361\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0247 - val_loss: 0.0243\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0238 - val_loss: 0.0240\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0273 - val_loss: 0.0214\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0242 - val_loss: 0.0227\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0183 - val_loss: 0.0218\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0301 - val_loss: 0.0226\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0178 - val_loss: 0.0221\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0144 - val_loss: 0.0226\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0169 - val_loss: 0.0257\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0178 - val_loss: 0.0215\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0189 - val_loss: 0.0252\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0150 - val_loss: 0.0204\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0198 - val_loss: 0.0207\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0233 - val_loss: 0.0219\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0176 - val_loss: 0.0207\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0183 - val_loss: 0.0199\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0204 - val_loss: 0.0199\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0233 - val_loss: 0.0239\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0254 - val_loss: 0.0189\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0160 - val_loss: 0.0262\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0201 - val_loss: 0.0230\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0169 - val_loss: 0.0197\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0232 - val_loss: 0.0191\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0176 - val_loss: 0.0185\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0176 - val_loss: 0.0186\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0179 - val_loss: 0.0244\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0187 - val_loss: 0.0182\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0190\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0198 - val_loss: 0.0190\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0201 - val_loss: 0.0191\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0136 - val_loss: 0.0188\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0172 - val_loss: 0.0190\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0173 - val_loss: 0.0230\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0169 - val_loss: 0.0279\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0237 - val_loss: 0.0200\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0130 - val_loss: 0.0172\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0186\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0187 - val_loss: 0.0347\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0162\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0161 - val_loss: 0.0149\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0149 - val_loss: 0.0181\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0190\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0123 - val_loss: 0.0256\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0109 - val_loss: 0.0190\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0106 - val_loss: 0.0220\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0146 - val_loss: 0.0178\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0120 - val_loss: 0.0208\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0166\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0180\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0145\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0179\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0212\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0103 - val_loss: 0.0160\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0100 - val_loss: 0.0172\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0106 - val_loss: 0.0219\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0119 - val_loss: 0.0179\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0165\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0057 - val_loss: 0.0196\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0080 - val_loss: 0.0352\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0102 - val_loss: 0.0175\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0173\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0123 - val_loss: 0.0198\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0129 - val_loss: 0.0169\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0083 - val_loss: 0.0132\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0069 - val_loss: 0.0171\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0067 - val_loss: 0.0225\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0100 - val_loss: 0.0227\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0079 - val_loss: 0.0153\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0053 - val_loss: 0.0162\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0064 - val_loss: 0.0160\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0085 - val_loss: 0.0169\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0048 - val_loss: 0.0196\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0063 - val_loss: 0.0185\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0067 - val_loss: 0.0131\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0049 - val_loss: 0.0170\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0064 - val_loss: 0.0160\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.0036 - val_loss: 0.0182\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0051 - val_loss: 0.0189\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0048 - val_loss: 0.0139\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0056 - val_loss: 0.0161\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0023 - val_loss: 0.0159\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0038 - val_loss: 0.0217\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0045 - val_loss: 0.0202\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0029 - val_loss: 0.0210\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0034 - val_loss: 0.0185\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0032 - val_loss: 0.0189\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0032 - val_loss: 0.0205\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0037 - val_loss: 0.0203\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0024 - val_loss: 0.0182\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 0.0179\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0029 - val_loss: 0.0218\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0027 - val_loss: 0.0169\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0035 - val_loss: 0.0155\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0033 - val_loss: 0.0169\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A70CB83EE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 5s 42ms/step - loss: 0.0573 - val_loss: 0.0424\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0226 - val_loss: 0.0338\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0258 - val_loss: 0.0259\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0246 - val_loss: 0.0271\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0217 - val_loss: 0.0336\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0362 - val_loss: 0.0254\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0206 - val_loss: 0.0248\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0219 - val_loss: 0.0277\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0297 - val_loss: 0.0247\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0261 - val_loss: 0.0285\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0216 - val_loss: 0.0320\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0215 - val_loss: 0.0244\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0251 - val_loss: 0.0248\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0331 - val_loss: 0.0321\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0192 - val_loss: 0.0242\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0223 - val_loss: 0.0430\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0328 - val_loss: 0.0247\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0206 - val_loss: 0.0290\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0190 - val_loss: 0.0368\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0186 - val_loss: 0.0240\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0253 - val_loss: 0.0251\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0233 - val_loss: 0.0431\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0199 - val_loss: 0.0264\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0300 - val_loss: 0.0314\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0315 - val_loss: 0.0242\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0242 - val_loss: 0.0284\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0308 - val_loss: 0.0322\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0249 - val_loss: 0.0280\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0285 - val_loss: 0.0288\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0226 - val_loss: 0.0263\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0187 - val_loss: 0.0232\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0218 - val_loss: 0.0287\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0205 - val_loss: 0.0283\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0226 - val_loss: 0.0252\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0198 - val_loss: 0.0220\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0203 - val_loss: 0.0237\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0201 - val_loss: 0.0288\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0219 - val_loss: 0.0218\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0183 - val_loss: 0.0227\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0272 - val_loss: 0.0215\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0219 - val_loss: 0.0218\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0175 - val_loss: 0.0231\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0236 - val_loss: 0.0220\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0152 - val_loss: 0.0204\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0158 - val_loss: 0.0247\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0165 - val_loss: 0.0202\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0178 - val_loss: 0.0206\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0165 - val_loss: 0.0208\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0212 - val_loss: 0.0265\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0197 - val_loss: 0.0191\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0216 - val_loss: 0.0216\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0226 - val_loss: 0.0197\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0192 - val_loss: 0.0190\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0238 - val_loss: 0.0234\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0151 - val_loss: 0.0244\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0268 - val_loss: 0.0272\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0173 - val_loss: 0.0220\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0162 - val_loss: 0.0189\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0134 - val_loss: 0.0215\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0217 - val_loss: 0.0191\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0193 - val_loss: 0.0201\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0177 - val_loss: 0.0184\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0193 - val_loss: 0.0178\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0169 - val_loss: 0.0276\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0233 - val_loss: 0.0251\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0112 - val_loss: 0.0174\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0142 - val_loss: 0.0268\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.0200 - val_loss: 0.0164\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0136 - val_loss: 0.0179\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0189 - val_loss: 0.0219\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0168 - val_loss: 0.0200\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0168 - val_loss: 0.0254\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0160 - val_loss: 0.0252\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0222\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0163 - val_loss: 0.0313\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0160 - val_loss: 0.0181\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.0159\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0130 - val_loss: 0.0162\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0151 - val_loss: 0.0227\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0108 - val_loss: 0.0135\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0259\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0114 - val_loss: 0.0187\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0108 - val_loss: 0.0151\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0106 - val_loss: 0.0221\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0240\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0134 - val_loss: 0.0163\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0218\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0110 - val_loss: 0.0118\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0083 - val_loss: 0.0161\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0195\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0102 - val_loss: 0.0171\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0086 - val_loss: 0.0181\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0079 - val_loss: 0.0174\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0077 - val_loss: 0.0177\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0109 - val_loss: 0.0242\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0151 - val_loss: 0.0220\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0112 - val_loss: 0.0143\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0068 - val_loss: 0.0132\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0074 - val_loss: 0.0199\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0195\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0082 - val_loss: 0.0119\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0057 - val_loss: 0.0145\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0048 - val_loss: 0.0169\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0060 - val_loss: 0.0182\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0052 - val_loss: 0.0175\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0055 - val_loss: 0.0125\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0053 - val_loss: 0.0143\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0050 - val_loss: 0.0127\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0066 - val_loss: 0.0139\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0052 - val_loss: 0.0183\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0034 - val_loss: 0.0163\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0046 - val_loss: 0.0137\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0037 - val_loss: 0.0173\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0045 - val_loss: 0.0165\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0029 - val_loss: 0.0153\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0041 - val_loss: 0.0119\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0040 - val_loss: 0.0215\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0034 - val_loss: 0.0165\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A878418700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 36ms/step - loss: 0.0287 - val_loss: 0.0283\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0373 - val_loss: 0.0336\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0219 - val_loss: 0.0272\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0225 - val_loss: 0.0259\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0285 - val_loss: 0.0382\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0256 - val_loss: 0.0252\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0255 - val_loss: 0.0251\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0265 - val_loss: 0.0337\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0290 - val_loss: 0.0249\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0226 - val_loss: 0.0247\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0176 - val_loss: 0.0248\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0279 - val_loss: 0.0248\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0219 - val_loss: 0.0453\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0273 - val_loss: 0.0247\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0236 - val_loss: 0.0256\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0183 - val_loss: 0.0242\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0242 - val_loss: 0.0262\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0211 - val_loss: 0.0278\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0280 - val_loss: 0.0280\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0230 - val_loss: 0.0260\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0240 - val_loss: 0.0273\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0247 - val_loss: 0.0256\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0244 - val_loss: 0.0249\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0233 - val_loss: 0.0239\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0211 - val_loss: 0.0239\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0257 - val_loss: 0.0357\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0236 - val_loss: 0.0241\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0244 - val_loss: 0.0238\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0196 - val_loss: 0.0247\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0265 - val_loss: 0.0247\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0320 - val_loss: 0.0226\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0277 - val_loss: 0.0365\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0181 - val_loss: 0.0233\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0128 - val_loss: 0.0242\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0241 - val_loss: 0.0298\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0223 - val_loss: 0.0242\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0188 - val_loss: 0.0232\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0169 - val_loss: 0.0234\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0314 - val_loss: 0.0309\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0176 - val_loss: 0.0250\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0194 - val_loss: 0.0241\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0215 - val_loss: 0.0267\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0212 - val_loss: 0.0211\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.0219 - val_loss: 0.0215\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0167 - val_loss: 0.0243\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0149 - val_loss: 0.0229\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0201 - val_loss: 0.0204\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0205 - val_loss: 0.0250\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0246 - val_loss: 0.0251\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0225 - val_loss: 0.0232\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0156 - val_loss: 0.0199\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0210 - val_loss: 0.0193\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0197 - val_loss: 0.0230\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0198 - val_loss: 0.0211\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0189 - val_loss: 0.0245\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0250 - val_loss: 0.0212\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0142 - val_loss: 0.0187\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0166 - val_loss: 0.0185\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0170 - val_loss: 0.0178\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0166 - val_loss: 0.0229\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0213 - val_loss: 0.0287\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0210 - val_loss: 0.0176\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0234 - val_loss: 0.0192\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0186 - val_loss: 0.0186\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0232\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0232 - val_loss: 0.0187\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0233 - val_loss: 0.0195\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0136 - val_loss: 0.0208\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0164 - val_loss: 0.0172\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0172 - val_loss: 0.0235\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0132 - val_loss: 0.0210\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0153 - val_loss: 0.0296\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0146 - val_loss: 0.0247\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0137 - val_loss: 0.0287\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.0159 - val_loss: 0.0188\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0159 - val_loss: 0.0166\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0161 - val_loss: 0.0370\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0159 - val_loss: 0.0160\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0124 - val_loss: 0.0223\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0107 - val_loss: 0.0162\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0176 - val_loss: 0.0203\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0188 - val_loss: 0.0171\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0148 - val_loss: 0.0219\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0115 - val_loss: 0.0176\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0108 - val_loss: 0.0195\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0177\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0074 - val_loss: 0.0211\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0135 - val_loss: 0.0146\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0123 - val_loss: 0.0144\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0144\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0068 - val_loss: 0.0162\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 0.0169\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0107 - val_loss: 0.0203\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0138 - val_loss: 0.0144\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0088 - val_loss: 0.0189\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 0.0205\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0164 - val_loss: 0.0200\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0064 - val_loss: 0.0182\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0121 - val_loss: 0.0190\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0102 - val_loss: 0.0214\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0103 - val_loss: 0.0139\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0084 - val_loss: 0.0139\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0077 - val_loss: 0.0167\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0057 - val_loss: 0.0155\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0066 - val_loss: 0.0161\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0056 - val_loss: 0.0157\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0065 - val_loss: 0.0135\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0063 - val_loss: 0.0117\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0052 - val_loss: 0.0144\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0055 - val_loss: 0.0157\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0079 - val_loss: 0.0163\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0070 - val_loss: 0.0170\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0057 - val_loss: 0.0152\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0058 - val_loss: 0.0149\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0062 - val_loss: 0.0156\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0059 - val_loss: 0.0181\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0076 - val_loss: 0.0186\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0060 - val_loss: 0.0167\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0054 - val_loss: 0.0192\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0062 - val_loss: 0.0210\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0052 - val_loss: 0.0177\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0038 - val_loss: 0.0171\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0041 - val_loss: 0.0209\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0031 - val_loss: 0.0138\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.0043 - val_loss: 0.0250\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0038 - val_loss: 0.0162\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0037 - val_loss: 0.0174\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0034 - val_loss: 0.0171\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0035 - val_loss: 0.0243\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0033 - val_loss: 0.0156\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0043 - val_loss: 0.0221\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0066 - val_loss: 0.0153\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0033 - val_loss: 0.0197\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0028 - val_loss: 0.0219\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0026 - val_loss: 0.0182\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0207\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0034 - val_loss: 0.0218\n",
      "Epoch 140/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0031 - val_loss: 0.0209\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A7887B6700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 67ms/step - loss: 0.0696 - val_loss: 0.0294\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0333 - val_loss: 0.0304\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0233 - val_loss: 0.0266\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0242 - val_loss: 0.0307\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0304 - val_loss: 0.0398\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0278 - val_loss: 0.0272\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0192 - val_loss: 0.0248\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0308 - val_loss: 0.0257\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0258 - val_loss: 0.0249\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0242 - val_loss: 0.0263\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0327 - val_loss: 0.0247\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0215 - val_loss: 0.0333\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0242 - val_loss: 0.0254\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0178 - val_loss: 0.0292\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0267 - val_loss: 0.0331\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0233 - val_loss: 0.0265\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0267 - val_loss: 0.0263\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0187 - val_loss: 0.0244\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0230 - val_loss: 0.0263\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0243 - val_loss: 0.0253\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0245 - val_loss: 0.0239\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0270 - val_loss: 0.0263\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0224 - val_loss: 0.0306\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0224 - val_loss: 0.0239\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0229 - val_loss: 0.0268\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0212 - val_loss: 0.0234\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0171 - val_loss: 0.0241\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0200 - val_loss: 0.0271\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0387 - val_loss: 0.0261\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0310 - val_loss: 0.0301\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0224 - val_loss: 0.0230\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0229 - val_loss: 0.0226\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0281 - val_loss: 0.0236\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0199 - val_loss: 0.0280\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0232 - val_loss: 0.0220\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0182 - val_loss: 0.0229\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0191 - val_loss: 0.0220\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0181 - val_loss: 0.0219\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0234 - val_loss: 0.0222\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0238 - val_loss: 0.0251\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0288 - val_loss: 0.0218\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0304 - val_loss: 0.0288\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0152 - val_loss: 0.0205\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0209 - val_loss: 0.0210\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0182 - val_loss: 0.0248\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0216 - val_loss: 0.0273\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0231 - val_loss: 0.0204\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0198 - val_loss: 0.0212\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0197 - val_loss: 0.0207\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0221 - val_loss: 0.0225\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0232 - val_loss: 0.0205\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0155 - val_loss: 0.0190\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0195 - val_loss: 0.0200\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0259\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0208 - val_loss: 0.0190\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0164 - val_loss: 0.0202\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0187 - val_loss: 0.0243\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0203 - val_loss: 0.0180\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0192 - val_loss: 0.0173\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0271\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0234 - val_loss: 0.0210\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0163 - val_loss: 0.0184\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0164 - val_loss: 0.0175\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0214 - val_loss: 0.0241\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0186 - val_loss: 0.0229\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0160 - val_loss: 0.0170\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0184 - val_loss: 0.0230\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0146 - val_loss: 0.0156\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0192 - val_loss: 0.0197\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0225 - val_loss: 0.0221\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0211 - val_loss: 0.0199\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0146 - val_loss: 0.0199\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.0179 - val_loss: 0.0226\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0259 - val_loss: 0.0252\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0153 - val_loss: 0.0163\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0184\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0166 - val_loss: 0.0189\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0189 - val_loss: 0.0181\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0154 - val_loss: 0.0238\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0133 - val_loss: 0.0236\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0183 - val_loss: 0.0178\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0124 - val_loss: 0.0204\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0137 - val_loss: 0.0193\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0149 - val_loss: 0.0209\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0138 - val_loss: 0.0175\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0147 - val_loss: 0.0229\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0103 - val_loss: 0.0224\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0147 - val_loss: 0.0176\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0104 - val_loss: 0.0192\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0161 - val_loss: 0.0238\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0173 - val_loss: 0.0193\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0130 - val_loss: 0.0179\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0107 - val_loss: 0.0207\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0103 - val_loss: 0.0228\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0148 - val_loss: 0.0222\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0087 - val_loss: 0.0193\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0212\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0087 - val_loss: 0.0187\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A87ACA7F70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 36ms/step - loss: 0.0736 - val_loss: 0.0457\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0293 - val_loss: 0.0349\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0244 - val_loss: 0.0383\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0281 - val_loss: 0.0336\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0213 - val_loss: 0.0322\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0339 - val_loss: 0.0357\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0175 - val_loss: 0.0311\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0187 - val_loss: 0.0285\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0268 - val_loss: 0.0305\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0259 - val_loss: 0.0276\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0309 - val_loss: 0.0248\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0236 - val_loss: 0.0244\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0242 - val_loss: 0.0247\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0272 - val_loss: 0.0258\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0222 - val_loss: 0.0268\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0246 - val_loss: 0.0255\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0219 - val_loss: 0.0364\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0189 - val_loss: 0.0239\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0295 - val_loss: 0.0243\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0199 - val_loss: 0.0251\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0263 - val_loss: 0.0242\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0261 - val_loss: 0.0239\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0301 - val_loss: 0.0307\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0207 - val_loss: 0.0245\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0198 - val_loss: 0.0267\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0191 - val_loss: 0.0304\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0197 - val_loss: 0.0241\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0249 - val_loss: 0.0282\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0249 - val_loss: 0.0228\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0190 - val_loss: 0.0299\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0241 - val_loss: 0.0353\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0216 - val_loss: 0.0299\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0266 - val_loss: 0.0329\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0270 - val_loss: 0.0297\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0319 - val_loss: 0.0237\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0201 - val_loss: 0.0315\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0223 - val_loss: 0.0241\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0211 - val_loss: 0.0226\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0203 - val_loss: 0.0220\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0151 - val_loss: 0.0208\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0257 - val_loss: 0.0231\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0167 - val_loss: 0.0277\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0187 - val_loss: 0.0237\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0195 - val_loss: 0.0201\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0205 - val_loss: 0.0201\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0255 - val_loss: 0.0345\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0299 - val_loss: 0.0194\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0184 - val_loss: 0.0198\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0244 - val_loss: 0.0210\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0217 - val_loss: 0.0190\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0173 - val_loss: 0.0197\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0211 - val_loss: 0.0215\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0203 - val_loss: 0.0187\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0163 - val_loss: 0.0189\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0167 - val_loss: 0.0218\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0166 - val_loss: 0.0190\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0154 - val_loss: 0.0261\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0162 - val_loss: 0.0244\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0187 - val_loss: 0.0179\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0144 - val_loss: 0.0171\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0179 - val_loss: 0.0182\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0144 - val_loss: 0.0227\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0223 - val_loss: 0.0224\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0216 - val_loss: 0.0167\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0153 - val_loss: 0.0179\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0160 - val_loss: 0.0181\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0176 - val_loss: 0.0183\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0177 - val_loss: 0.0167\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0196 - val_loss: 0.0172\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0148 - val_loss: 0.0178\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0119 - val_loss: 0.0202\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0174 - val_loss: 0.0198\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0192\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0133 - val_loss: 0.0175\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0137 - val_loss: 0.0208\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.0163 - val_loss: 0.0162\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0135 - val_loss: 0.0169\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0110 - val_loss: 0.0187\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0163 - val_loss: 0.0200\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0153 - val_loss: 0.0194\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0127 - val_loss: 0.0196\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0124 - val_loss: 0.0261\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0153 - val_loss: 0.0178\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0123 - val_loss: 0.0185\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.0156\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0160\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0080 - val_loss: 0.0129\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0275\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0137 - val_loss: 0.0167\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0190\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0191\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0071 - val_loss: 0.0204\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0062 - val_loss: 0.0268\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0162\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0123 - val_loss: 0.0183\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0084 - val_loss: 0.0198\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0064 - val_loss: 0.0213\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0106 - val_loss: 0.0130\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0164\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0077 - val_loss: 0.0192\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0230\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0064 - val_loss: 0.0172\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0064 - val_loss: 0.0198\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0060 - val_loss: 0.0199\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0056 - val_loss: 0.0156\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0064 - val_loss: 0.0220\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0056 - val_loss: 0.0148\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0033 - val_loss: 0.0154\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0051 - val_loss: 0.0247\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0037 - val_loss: 0.0211\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0028 - val_loss: 0.0207\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0023 - val_loss: 0.0214\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0027 - val_loss: 0.0221\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0050 - val_loss: 0.0175\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0036 - val_loss: 0.0168\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 0.0241\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0022 - val_loss: 0.0203\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A8878CACA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 36ms/step - loss: 0.0615 - val_loss: 0.0282\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0374 - val_loss: 0.0274\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0231 - val_loss: 0.0368\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0306 - val_loss: 0.0269\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0263 - val_loss: 0.0463\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0284 - val_loss: 0.0267\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0208 - val_loss: 0.0363\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0168 - val_loss: 0.0256\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0193 - val_loss: 0.0276\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0193 - val_loss: 0.0247\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0235 - val_loss: 0.0252\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0332 - val_loss: 0.0292\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0257 - val_loss: 0.0364\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0220 - val_loss: 0.0291\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0246 - val_loss: 0.0338\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0313 - val_loss: 0.0246\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0186 - val_loss: 0.0244\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0255 - val_loss: 0.0288\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0228 - val_loss: 0.0268\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0190 - val_loss: 0.0263\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0186 - val_loss: 0.0270\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0202 - val_loss: 0.0237\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0297 - val_loss: 0.0366\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0225 - val_loss: 0.0235\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0266 - val_loss: 0.0237\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0224 - val_loss: 0.0253\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0230\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0245 - val_loss: 0.0231\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0246 - val_loss: 0.0228\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0213 - val_loss: 0.0235\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0207 - val_loss: 0.0257\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0324 - val_loss: 0.0272\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0279 - val_loss: 0.0221\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0204 - val_loss: 0.0274\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.0238 - val_loss: 0.0257\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0257 - val_loss: 0.0259\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0220 - val_loss: 0.0217\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0233 - val_loss: 0.0239\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0254 - val_loss: 0.0265\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0255 - val_loss: 0.0272\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0222 - val_loss: 0.0285\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0190 - val_loss: 0.0216\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0235 - val_loss: 0.0247\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0257 - val_loss: 0.0219\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0206 - val_loss: 0.0206\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0202 - val_loss: 0.0246\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0203 - val_loss: 0.0200\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0159 - val_loss: 0.0206\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0216 - val_loss: 0.0231\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0154 - val_loss: 0.0198\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0212 - val_loss: 0.0212\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0251 - val_loss: 0.0201\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0164 - val_loss: 0.0190\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0202 - val_loss: 0.0197\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0242 - val_loss: 0.0235\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0215 - val_loss: 0.0193\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0271 - val_loss: 0.0191\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0222\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0217 - val_loss: 0.0187\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0223 - val_loss: 0.0231\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0171 - val_loss: 0.0247\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0202 - val_loss: 0.0202\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0191 - val_loss: 0.0194\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0157 - val_loss: 0.0205\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.0176\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0178 - val_loss: 0.0210\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0194 - val_loss: 0.0167\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0184 - val_loss: 0.0193\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0182 - val_loss: 0.0205\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0197 - val_loss: 0.0203\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0164 - val_loss: 0.0217\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0168 - val_loss: 0.0172\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.0178\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0156 - val_loss: 0.0167\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0162 - val_loss: 0.0174\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0120 - val_loss: 0.0163\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0176 - val_loss: 0.0220\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0220 - val_loss: 0.0174\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0186 - val_loss: 0.0158\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0129 - val_loss: 0.0161\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0190\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0087 - val_loss: 0.0161\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.0260\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0158 - val_loss: 0.0219\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0146 - val_loss: 0.0153\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0106 - val_loss: 0.0172\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0123 - val_loss: 0.0219\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0158 - val_loss: 0.0186\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0129 - val_loss: 0.0158\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0187\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0101 - val_loss: 0.0182\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0106 - val_loss: 0.0210\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0093 - val_loss: 0.0135\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0178\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0080 - val_loss: 0.0147\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0084 - val_loss: 0.0180\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0125 - val_loss: 0.0170\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0162\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0120 - val_loss: 0.0148\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0070 - val_loss: 0.0148\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0163\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0068 - val_loss: 0.0169\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0126 - val_loss: 0.0153\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0103 - val_loss: 0.0172\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0103 - val_loss: 0.0148\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0171\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0186 - val_loss: 0.0196\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0186 - val_loss: 0.0228\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0158\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0065 - val_loss: 0.0202\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0076 - val_loss: 0.0241\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0089 - val_loss: 0.0198\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0068 - val_loss: 0.0179\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0084 - val_loss: 0.0157\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0039 - val_loss: 0.0135\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0034 - val_loss: 0.0147\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0035 - val_loss: 0.0164\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0038 - val_loss: 0.0170\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0029 - val_loss: 0.0150\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0044 - val_loss: 0.0182\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0046 - val_loss: 0.0145\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0037 - val_loss: 0.0161\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0032 - val_loss: 0.0160\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A70C6D7670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 36ms/step - loss: 0.0988 - val_loss: 0.0362\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.0261 - val_loss: 0.0335\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0280 - val_loss: 0.0349\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0258 - val_loss: 0.0258\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0226 - val_loss: 0.0378\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0259 - val_loss: 0.0257\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0226 - val_loss: 0.0246\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0261 - val_loss: 0.0306\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0217 - val_loss: 0.0390\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0278 - val_loss: 0.0244\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0244 - val_loss: 0.0245\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0238 - val_loss: 0.0271\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0223 - val_loss: 0.0379\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0315 - val_loss: 0.0268\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0258 - val_loss: 0.0262\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0217 - val_loss: 0.0244\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0216 - val_loss: 0.0293\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0230 - val_loss: 0.0254\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0256 - val_loss: 0.0238\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0341 - val_loss: 0.0307\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0281 - val_loss: 0.0264\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0292 - val_loss: 0.0253\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0196 - val_loss: 0.0235\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0255 - val_loss: 0.0267\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0250 - val_loss: 0.0244\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0216 - val_loss: 0.0236\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0232 - val_loss: 0.0242\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0229 - val_loss: 0.0249\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0225 - val_loss: 0.0269\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0251 - val_loss: 0.0236\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0234 - val_loss: 0.0246\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0196 - val_loss: 0.0243\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0225 - val_loss: 0.0261\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0204 - val_loss: 0.0279\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0193 - val_loss: 0.0263\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0207 - val_loss: 0.0249\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0186 - val_loss: 0.0226\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0316 - val_loss: 0.0219\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0234 - val_loss: 0.0219\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0210 - val_loss: 0.0213\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0179 - val_loss: 0.0212\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0191 - val_loss: 0.0239\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0183 - val_loss: 0.0214\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0218 - val_loss: 0.0205\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0182 - val_loss: 0.0203\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0215 - val_loss: 0.0223\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0238 - val_loss: 0.0221\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0304 - val_loss: 0.0214\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0151 - val_loss: 0.0201\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0167 - val_loss: 0.0248\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0177 - val_loss: 0.0269\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0255 - val_loss: 0.0220\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0249 - val_loss: 0.0208\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0254 - val_loss: 0.0200\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0217 - val_loss: 0.0199\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0185 - val_loss: 0.0227\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0157 - val_loss: 0.0218\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0186 - val_loss: 0.0217\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0173 - val_loss: 0.0190\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0177 - val_loss: 0.0203\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0198 - val_loss: 0.0189\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0174 - val_loss: 0.0179\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0243 - val_loss: 0.0209\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0168 - val_loss: 0.0204\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0151 - val_loss: 0.0189\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0197 - val_loss: 0.0187\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0196 - val_loss: 0.0175\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0162 - val_loss: 0.0193\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0172 - val_loss: 0.0198\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0217 - val_loss: 0.0171\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.0195\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0201 - val_loss: 0.0207\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0149 - val_loss: 0.0179\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0178 - val_loss: 0.0173\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0156 - val_loss: 0.0166\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0113 - val_loss: 0.0160\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0113 - val_loss: 0.0295\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0167 - val_loss: 0.0167\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0192 - val_loss: 0.0267\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0184\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 0.0162\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0146 - val_loss: 0.0172\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0100 - val_loss: 0.0154\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0173 - val_loss: 0.0192\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0185 - val_loss: 0.0215\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0162 - val_loss: 0.0166\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0112 - val_loss: 0.0220\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0107 - val_loss: 0.0155\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0207\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0089 - val_loss: 0.0180\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0122 - val_loss: 0.0181\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0149 - val_loss: 0.0150\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0106 - val_loss: 0.0124\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0079 - val_loss: 0.0188\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0076 - val_loss: 0.0180\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0084 - val_loss: 0.0141\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0066 - val_loss: 0.0128\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0120 - val_loss: 0.0158\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0201.0086  \n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0089 - val_loss: 0.0245\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0106 - val_loss: 0.0141\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0056 - val_loss: 0.0230\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0132\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.0076 - val_loss: 0.0142\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0045 - val_loss: 0.0130\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0075 - val_loss: 0.0187\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0051 - val_loss: 0.0234\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0065 - val_loss: 0.0195\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0082 - val_loss: 0.0193\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0080 - val_loss: 0.0177\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0046 - val_loss: 0.0207\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0058 - val_loss: 0.0196\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0061 - val_loss: 0.0176\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0062 - val_loss: 0.0126\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0051 - val_loss: 0.0160\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0044 - val_loss: 0.0181\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0049 - val_loss: 0.0151\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0061 - val_loss: 0.0137\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0042 - val_loss: 0.0173\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0029 - val_loss: 0.0157\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0038 - val_loss: 0.0190\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0027 - val_loss: 0.0186\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0027 - val_loss: 0.0134\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A86C506AF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 36ms/step - loss: 0.0713 - val_loss: 0.0307\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0314 - val_loss: 0.0315\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0309 - val_loss: 0.0258\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0161 - val_loss: 0.0312\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0227 - val_loss: 0.0274\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0278 - val_loss: 0.0309\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0233 - val_loss: 0.0407\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0312 - val_loss: 0.0383\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0246 - val_loss: 0.0245\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0210 - val_loss: 0.0266\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0294 - val_loss: 0.0243\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0261 - val_loss: 0.0251\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0266 - val_loss: 0.0242\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0268 - val_loss: 0.0341\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0253 - val_loss: 0.0266\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0241 - val_loss: 0.0239\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0322 - val_loss: 0.0250\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0242 - val_loss: 0.0304\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0202 - val_loss: 0.0238\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0174 - val_loss: 0.0235\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0166 - val_loss: 0.0244\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0237 - val_loss: 0.0258\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0303 - val_loss: 0.0276\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0222 - val_loss: 0.0294\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0258 - val_loss: 0.0285\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0172 - val_loss: 0.0235\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0236 - val_loss: 0.0405\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0223 - val_loss: 0.0230\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0200 - val_loss: 0.0231\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0258 - val_loss: 0.0228\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0206 - val_loss: 0.0222\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0175 - val_loss: 0.0225\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0195 - val_loss: 0.0240\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0237 - val_loss: 0.0270\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0239 - val_loss: 0.0217\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0171 - val_loss: 0.0220\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0186 - val_loss: 0.0219\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0237 - val_loss: 0.0226\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0187 - val_loss: 0.0218\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0236 - val_loss: 0.0214\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0178 - val_loss: 0.0236\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0224 - val_loss: 0.0230\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0217 - val_loss: 0.0254\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0231 - val_loss: 0.0206\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0221 - val_loss: 0.0201\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0175 - val_loss: 0.0206\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0184 - val_loss: 0.0215\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0275 - val_loss: 0.0215\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0148 - val_loss: 0.0223\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0182 - val_loss: 0.0239\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0243 - val_loss: 0.0207\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0172 - val_loss: 0.0190\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.0205\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0197 - val_loss: 0.0192\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0201 - val_loss: 0.0197\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0184 - val_loss: 0.0246\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0216 - val_loss: 0.0231\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0193 - val_loss: 0.0225\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0131 - val_loss: 0.0231\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0172 - val_loss: 0.0185\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0191 - val_loss: 0.0190\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0221 - val_loss: 0.0222\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0221 - val_loss: 0.0204\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0177 - val_loss: 0.0220\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0196 - val_loss: 0.0240\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0209 - val_loss: 0.0223\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0191 - val_loss: 0.0184\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0156 - val_loss: 0.0197\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0176 - val_loss: 0.0235\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0212 - val_loss: 0.0188\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0175 - val_loss: 0.0182\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0182 - val_loss: 0.0173\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0164 - val_loss: 0.0184\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0149 - val_loss: 0.0167\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0120 - val_loss: 0.0201\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0187 - val_loss: 0.0175\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.0146 - val_loss: 0.0170\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0082 - val_loss: 0.0272\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0129 - val_loss: 0.0230\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0120 - val_loss: 0.0209\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0160 - val_loss: 0.0168\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0139 - val_loss: 0.0234\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0126 - val_loss: 0.0176\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0161 - val_loss: 0.0176\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0125 - val_loss: 0.0164\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0120 - val_loss: 0.0162\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0139 - val_loss: 0.0180\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0120 - val_loss: 0.0222\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0209 - val_loss: 0.0177\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0168 - val_loss: 0.0141\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0131 - val_loss: 0.0130\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0112 - val_loss: 0.0171\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0146 - val_loss: 0.0216\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0126 - val_loss: 0.0172\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0183\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0102 - val_loss: 0.0193\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0164\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0145\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0089 - val_loss: 0.0124\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0067 - val_loss: 0.0195\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0279\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0132 - val_loss: 0.0161\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0135 - val_loss: 0.0218\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0095 - val_loss: 0.0163\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0066 - val_loss: 0.0157\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0149\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0088 - val_loss: 0.0139\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0058 - val_loss: 0.0169\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0044 - val_loss: 0.0135\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.0054 - val_loss: 0.0157\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0084 - val_loss: 0.0142\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0052 - val_loss: 0.0184\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0056 - val_loss: 0.0189\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0046 - val_loss: 0.0207\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0068 - val_loss: 0.0114\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0050 - val_loss: 0.0226\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0041 - val_loss: 0.0174\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0040 - val_loss: 0.0178\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0032 - val_loss: 0.0218\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0052 - val_loss: 0.0201\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0059 - val_loss: 0.0166\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0039 - val_loss: 0.0228\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0045 - val_loss: 0.0125\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0048 - val_loss: 0.0274\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0041 - val_loss: 0.0155\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0059 - val_loss: 0.0229\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0045 - val_loss: 0.0197\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0054 - val_loss: 0.0279\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0041 - val_loss: 0.0136\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0029 - val_loss: 0.0203\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0040 - val_loss: 0.0185\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0026 - val_loss: 0.0209\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 0.0205\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 0.0203\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0028 - val_loss: 0.0217\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0033 - val_loss: 0.0201\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0028 - val_loss: 0.0171\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0034 - val_loss: 0.0242\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0031 - val_loss: 0.0215\n",
      "Epoch 140/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0043 - val_loss: 0.0183\n",
      "Epoch 141/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0028 - val_loss: 0.0180\n",
      "Epoch 142/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 0.0239\n",
      "Epoch 143/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0026 - val_loss: 0.0205\n",
      "Epoch 144/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 0.0191\n",
      "Epoch 145/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0208\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A86F732A60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 36ms/step - loss: 0.0634 - val_loss: 0.0272\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0309 - val_loss: 0.0426\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0274 - val_loss: 0.0264\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.0273 - val_loss: 0.0255\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0229 - val_loss: 0.0381\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0216 - val_loss: 0.0270\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0202 - val_loss: 0.0245\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0241 - val_loss: 0.0543\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0340 - val_loss: 0.0253\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0234 - val_loss: 0.0280\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0253 - val_loss: 0.0261\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0151 - val_loss: 0.0281\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0266 - val_loss: 0.0252\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0328 - val_loss: 0.0316\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0255 - val_loss: 0.0376\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0259 - val_loss: 0.0259\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0263 - val_loss: 0.0272\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0277 - val_loss: 0.0257\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0308 - val_loss: 0.0236\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0239 - val_loss: 0.0241\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0285 - val_loss: 0.0372\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0294 - val_loss: 0.0308\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0229 - val_loss: 0.0267\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0221 - val_loss: 0.0233\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0258 - val_loss: 0.0237\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0308 - val_loss: 0.0227\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0236 - val_loss: 0.0230\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0266 - val_loss: 0.0228\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0275 - val_loss: 0.0248\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0248 - val_loss: 0.0239\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0196 - val_loss: 0.0266\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0230 - val_loss: 0.0227\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0196 - val_loss: 0.0240\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0235 - val_loss: 0.0332\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0231 - val_loss: 0.0329\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0224 - val_loss: 0.0262\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0199 - val_loss: 0.0271\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0213 - val_loss: 0.0234\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0251 - val_loss: 0.0224\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0222 - val_loss: 0.0219\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0203 - val_loss: 0.0245\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0155 - val_loss: 0.0207\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0196 - val_loss: 0.0231\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0224 - val_loss: 0.0240\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0236 - val_loss: 0.0224\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0189 - val_loss: 0.0205\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0229 - val_loss: 0.0216\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0205 - val_loss: 0.0204\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0136 - val_loss: 0.0192\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0164 - val_loss: 0.0189\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0163 - val_loss: 0.0199\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0272 - val_loss: 0.0203\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0154 - val_loss: 0.0191\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0125 - val_loss: 0.0188\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0203 - val_loss: 0.0182\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0154 - val_loss: 0.0193\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0146 - val_loss: 0.0206\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0174 - val_loss: 0.0197\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0158 - val_loss: 0.0197\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0159 - val_loss: 0.0173\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0195 - val_loss: 0.0172\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0177 - val_loss: 0.0277\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0157 - val_loss: 0.0179\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0160 - val_loss: 0.0186\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0164 - val_loss: 0.0174\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0191 - val_loss: 0.0221\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0188 - val_loss: 0.0184\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0164 - val_loss: 0.0197\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0276 - val_loss: 0.0249\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0194 - val_loss: 0.0174\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0146 - val_loss: 0.0196\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0137 - val_loss: 0.0181\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0129 - val_loss: 0.0185\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0155 - val_loss: 0.0202\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0148 - val_loss: 0.0257\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0134 - val_loss: 0.0170\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0149 - val_loss: 0.0158\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0120 - val_loss: 0.0197\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0127 - val_loss: 0.0131\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0162 - val_loss: 0.0168\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0131 - val_loss: 0.0153\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0133 - val_loss: 0.0164\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0135 - val_loss: 0.0155\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0157 - val_loss: 0.0193\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0126 - val_loss: 0.0176\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0121 - val_loss: 0.0161\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0113 - val_loss: 0.0173\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0110 - val_loss: 0.0187\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0110 - val_loss: 0.0157\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0129 - val_loss: 0.0159\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0150\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0109 - val_loss: 0.0124\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0108 - val_loss: 0.0212\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0169\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0079 - val_loss: 0.0142\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0083 - val_loss: 0.0182\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0146\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0095 - val_loss: 0.0161\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0088 - val_loss: 0.0179\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0073 - val_loss: 0.0158\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0087 - val_loss: 0.0133\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0056 - val_loss: 0.0194\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0081 - val_loss: 0.0165\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0065 - val_loss: 0.0212\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0260\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.0152 - val_loss: 0.0147\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0088 - val_loss: 0.0176\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0050 - val_loss: 0.0159\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0044 - val_loss: 0.0169\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A839598040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 5s 69ms/step - loss: 0.0423 - val_loss: 0.0500\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0302 - val_loss: 0.0373\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0309 - val_loss: 0.0260\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0264 - val_loss: 0.0254\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0231 - val_loss: 0.0250\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0316 - val_loss: 0.0266\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0225 - val_loss: 0.0248\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0357 - val_loss: 0.0270\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0301 - val_loss: 0.0246\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0261 - val_loss: 0.0250\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0203 - val_loss: 0.0247\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0217 - val_loss: 0.0245\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0196 - val_loss: 0.0260\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0193 - val_loss: 0.0245\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0263 - val_loss: 0.0334\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0220 - val_loss: 0.0241\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0251 - val_loss: 0.0241\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0189 - val_loss: 0.0240\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0290 - val_loss: 0.0247\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0265 - val_loss: 0.0294\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0294 - val_loss: 0.0281\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0249 - val_loss: 0.0246\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0207 - val_loss: 0.0236\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0216 - val_loss: 0.0250\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0211 - val_loss: 0.0250\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0244 - val_loss: 0.0240\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0211 - val_loss: 0.0323\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0159 - val_loss: 0.0248\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0248 - val_loss: 0.0242\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0265 - val_loss: 0.0257\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0202 - val_loss: 0.0236\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0226 - val_loss: 0.0228\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0289 - val_loss: 0.0315\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0328 - val_loss: 0.0230\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0225 - val_loss: 0.0228\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0267 - val_loss: 0.0296\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0200 - val_loss: 0.0215\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0212 - val_loss: 0.0219\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0152 - val_loss: 0.0253\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0215 - val_loss: 0.0218\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0189 - val_loss: 0.0223\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0190 - val_loss: 0.0211\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0166 - val_loss: 0.0215\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0165 - val_loss: 0.0229\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0237 - val_loss: 0.0228\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0195 - val_loss: 0.0201\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0221 - val_loss: 0.0201\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0195 - val_loss: 0.0209\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0204 - val_loss: 0.0236\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0211 - val_loss: 0.0205\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0220 - val_loss: 0.0239\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0193 - val_loss: 0.0229\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0154 - val_loss: 0.0198\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0222 - val_loss: 0.0201\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0176 - val_loss: 0.0224\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0201 - val_loss: 0.0216\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0175 - val_loss: 0.0193\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0185\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0187\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0202 - val_loss: 0.0178\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0161 - val_loss: 0.0197\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0210 - val_loss: 0.0207\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0161 - val_loss: 0.0179\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0174 - val_loss: 0.0319\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0192 - val_loss: 0.0266\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0227 - val_loss: 0.0176\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0174 - val_loss: 0.0317\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0212 - val_loss: 0.0202\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0167 - val_loss: 0.0162\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0175 - val_loss: 0.0183\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0152 - val_loss: 0.0156\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0148 - val_loss: 0.0152\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0138 - val_loss: 0.0187\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0171 - val_loss: 0.0196\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0157 - val_loss: 0.0234\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0168 - val_loss: 0.0170\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0170 - val_loss: 0.0202\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0126 - val_loss: 0.0167\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0168\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0135 - val_loss: 0.0241\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0122 - val_loss: 0.0158\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0139 - val_loss: 0.0290\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0151 - val_loss: 0.0192\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0156 - val_loss: 0.0202\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0141 - val_loss: 0.0213\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0135 - val_loss: 0.0210\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0162 - val_loss: 0.0215\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0229\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0112 - val_loss: 0.0181\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0173\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0088 - val_loss: 0.0182\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0108 - val_loss: 0.0209\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0083 - val_loss: 0.0144\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0080 - val_loss: 0.0175\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0100 - val_loss: 0.0186\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0119 - val_loss: 0.0171\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0074 - val_loss: 0.0175\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0080 - val_loss: 0.0183\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0083 - val_loss: 0.0157\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0052 - val_loss: 0.0201\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0093 - val_loss: 0.0290\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0119 - val_loss: 0.0191\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.0146 - val_loss: 0.0153\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0100 - val_loss: 0.0168\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0071 - val_loss: 0.0152\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0081 - val_loss: 0.0178\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0072 - val_loss: 0.0167\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0066 - val_loss: 0.0181\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0083 - val_loss: 0.0171\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0087 - val_loss: 0.0126\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0055 - val_loss: 0.0163\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0050 - val_loss: 0.0127\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0050 - val_loss: 0.0144\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0062 - val_loss: 0.0135\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0033 - val_loss: 0.0140\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0053 - val_loss: 0.0126\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0042 - val_loss: 0.0165\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0028 - val_loss: 0.0198\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0050 - val_loss: 0.0140\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0033 - val_loss: 0.0136\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0034 - val_loss: 0.0180\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0038 - val_loss: 0.0196\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0069 - val_loss: 0.0147\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0029 - val_loss: 0.0160\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0026 - val_loss: 0.0141\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0026 - val_loss: 0.0172\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 0.0171\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0033 - val_loss: 0.0153\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0031 - val_loss: 0.0177\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0039 - val_loss: 0.0172\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0023 - val_loss: 0.0205\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0031 - val_loss: 0.0211\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0030 - val_loss: 0.0186\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0038 - val_loss: 0.0178\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0025 - val_loss: 0.0201\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0026 - val_loss: 0.0198\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 0.0210\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.0187\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0026 - val_loss: 0.0163\n",
      "Epoch 140/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 0.0167\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A85DD30D30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 37ms/step - loss: 0.0437 - val_loss: 0.0351\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0253 - val_loss: 0.0269\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0286 - val_loss: 0.0257\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0222 - val_loss: 0.0387\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0274 - val_loss: 0.0322\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0228 - val_loss: 0.0246\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0256 - val_loss: 0.0338\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0242 - val_loss: 0.0250\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0321 - val_loss: 0.0244\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0281 - val_loss: 0.0289\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0270 - val_loss: 0.0295\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0271 - val_loss: 0.0305\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0286 - val_loss: 0.0273\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0217 - val_loss: 0.0310\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0206 - val_loss: 0.0263\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0276 - val_loss: 0.0243\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0299 - val_loss: 0.0249\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0261 - val_loss: 0.0247\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0289 - val_loss: 0.0238\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0275 - val_loss: 0.0267\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0279 - val_loss: 0.0249\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0211 - val_loss: 0.0237\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0187 - val_loss: 0.0232\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0189 - val_loss: 0.0232\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0256 - val_loss: 0.0259\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0182 - val_loss: 0.0252\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0320 - val_loss: 0.0317\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0273 - val_loss: 0.0352\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0352 - val_loss: 0.0242\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0317 - val_loss: 0.0223\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0192 - val_loss: 0.0261\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0252 - val_loss: 0.0263\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0262 - val_loss: 0.0230\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0224 - val_loss: 0.0225\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0244 - val_loss: 0.0215\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0194 - val_loss: 0.0215\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0237 - val_loss: 0.0211\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0183 - val_loss: 0.0210\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0206 - val_loss: 0.0239\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0221 - val_loss: 0.0267\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.0258 - val_loss: 0.0229\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0163 - val_loss: 0.0259\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0258 - val_loss: 0.0226\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0217 - val_loss: 0.0224\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0170 - val_loss: 0.0222\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0273 - val_loss: 0.0212\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0177 - val_loss: 0.0218\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0251\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0239 - val_loss: 0.0223\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0227 - val_loss: 0.0191\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0186 - val_loss: 0.0195\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0177 - val_loss: 0.0325\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0276 - val_loss: 0.0197\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0135 - val_loss: 0.0185\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0191 - val_loss: 0.0201\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0156 - val_loss: 0.0185\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0150 - val_loss: 0.0191\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0189 - val_loss: 0.0179\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0154 - val_loss: 0.0224\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0257\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0167\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0151 - val_loss: 0.0198\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0137 - val_loss: 0.0158\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.0178\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0133 - val_loss: 0.0169\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.0167\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0127 - val_loss: 0.0216\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0131 - val_loss: 0.0196\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0135 - val_loss: 0.0202\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0150 - val_loss: 0.0171\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0148 - val_loss: 0.0214\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0160 - val_loss: 0.0185\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0139 - val_loss: 0.0216\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0178 - val_loss: 0.0177\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0124 - val_loss: 0.0205\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0144 - val_loss: 0.0152\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0128 - val_loss: 0.0227\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0153 - val_loss: 0.0207\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0102 - val_loss: 0.0184\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0129 - val_loss: 0.0185\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0137 - val_loss: 0.0173\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0115 - val_loss: 0.0143\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0159\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0177\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0135 - val_loss: 0.0151\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0145\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0169\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0106 - val_loss: 0.0199\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.0114\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0081 - val_loss: 0.0242\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0071 - val_loss: 0.0133\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0107 - val_loss: 0.0177\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0072 - val_loss: 0.0122\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0132\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0078 - val_loss: 0.0130\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0093 - val_loss: 0.0131\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0069 - val_loss: 0.0136\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0065 - val_loss: 0.0106\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0057 - val_loss: 0.0162\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0052 - val_loss: 0.0152\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0048 - val_loss: 0.0112\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0052 - val_loss: 0.0130\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0048 - val_loss: 0.0112\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0041 - val_loss: 0.0125\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0062 - val_loss: 0.0126\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0031 - val_loss: 0.0133\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0059 - val_loss: 0.0245\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0084 - val_loss: 0.0158\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0039 - val_loss: 0.0122\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0041 - val_loss: 0.0151\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0036 - val_loss: 0.0137\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0032 - val_loss: 0.0166\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0048 - val_loss: 0.0147\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0023 - val_loss: 0.0155\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0023 - val_loss: 0.0172\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0026 - val_loss: 0.0231\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0033 - val_loss: 0.0237\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0041 - val_loss: 0.0246\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0061 - val_loss: 0.0202\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A70D17BC10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 37ms/step - loss: 0.0500 - val_loss: 0.0607\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0399 - val_loss: 0.0284\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0326 - val_loss: 0.0399\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0328 - val_loss: 0.0323\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0268 - val_loss: 0.0248\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0259 - val_loss: 0.0255\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0265 - val_loss: 0.0246\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.0257 - val_loss: 0.0252\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0225 - val_loss: 0.0266\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0275 - val_loss: 0.0297\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0311 - val_loss: 0.0282\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0277 - val_loss: 0.0243\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0305 - val_loss: 0.0246\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0196 - val_loss: 0.0253\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0198 - val_loss: 0.0247\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0229 - val_loss: 0.0257\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0261 - val_loss: 0.0250\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0225 - val_loss: 0.0250\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0244 - val_loss: 0.0236\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0247 - val_loss: 0.0273\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0236 - val_loss: 0.0353\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0245 - val_loss: 0.0260\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0283 - val_loss: 0.0250\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0165 - val_loss: 0.0236\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0226 - val_loss: 0.0234\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0202 - val_loss: 0.0228\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0267 - val_loss: 0.0331\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0190 - val_loss: 0.0245\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0250 - val_loss: 0.0232\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0230 - val_loss: 0.0228\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0254 - val_loss: 0.0225\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0214 - val_loss: 0.0224\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0255 - val_loss: 0.0353\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0203 - val_loss: 0.0241\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0219 - val_loss: 0.0230\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0249 - val_loss: 0.0251\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0166 - val_loss: 0.0237\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0147 - val_loss: 0.0219\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0222 - val_loss: 0.0254\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0188 - val_loss: 0.0202\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0250 - val_loss: 0.0231\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0150 - val_loss: 0.0215\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0206 - val_loss: 0.0196\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0171 - val_loss: 0.0201\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0188 - val_loss: 0.0199\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0170 - val_loss: 0.0199\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0180 - val_loss: 0.0196\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0158 - val_loss: 0.0206\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0204 - val_loss: 0.0191\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0172 - val_loss: 0.0186\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0202 - val_loss: 0.0205\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0143 - val_loss: 0.0265\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0212 - val_loss: 0.0235\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0133 - val_loss: 0.0184\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0186 - val_loss: 0.0195\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0178 - val_loss: 0.0189\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0168 - val_loss: 0.0173\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0198 - val_loss: 0.0201\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0181 - val_loss: 0.0187\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0215 - val_loss: 0.0248\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0182 - val_loss: 0.0170\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0187 - val_loss: 0.0171\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0204 - val_loss: 0.0212\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0193 - val_loss: 0.0209\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0160 - val_loss: 0.0174\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0200 - val_loss: 0.0229\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0185 - val_loss: 0.0165\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0212 - val_loss: 0.0167\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 0.0183\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0159 - val_loss: 0.0165\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0211 - val_loss: 0.0153\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0161 - val_loss: 0.0167\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0124 - val_loss: 0.0169\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0173 - val_loss: 0.0201\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0202 - val_loss: 0.0171\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0163 - val_loss: 0.0159\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0118 - val_loss: 0.0178\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0172\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0137 - val_loss: 0.0153\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0225\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0183\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0142 - val_loss: 0.0200\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0129 - val_loss: 0.0242\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0099 - val_loss: 0.0218\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0128 - val_loss: 0.0202\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0158 - val_loss: 0.0181\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0121 - val_loss: 0.0371\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0158 - val_loss: 0.0205\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0127 - val_loss: 0.0165\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 0.0199\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0103 - val_loss: 0.0152\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0085 - val_loss: 0.0157\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0088 - val_loss: 0.0236\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0139 - val_loss: 0.0169\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0104 - val_loss: 0.0201\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0089 - val_loss: 0.0131\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0114 - val_loss: 0.0293\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0213 - val_loss: 0.0219\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0160 - val_loss: 0.0179\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0199 - val_loss: 0.0161\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0130 - val_loss: 0.0200\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0150 - val_loss: 0.0164\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 0.0180\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0130 - val_loss: 0.0198\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0188\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0106 - val_loss: 0.0193\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0073 - val_loss: 0.0133\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0055 - val_loss: 0.0191\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0154\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0080 - val_loss: 0.0172\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.0059 - val_loss: 0.0139\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0067 - val_loss: 0.0173\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0050 - val_loss: 0.0260\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0061 - val_loss: 0.0181\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0066 - val_loss: 0.0179\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0051 - val_loss: 0.0189\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0050 - val_loss: 0.0187\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0032 - val_loss: 0.0268\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0043 - val_loss: 0.0187\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0043 - val_loss: 0.0243\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0047 - val_loss: 0.0191\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0031 - val_loss: 0.0205\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0035 - val_loss: 0.0279\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0048 - val_loss: 0.0226\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0035 - val_loss: 0.0274\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0032 - val_loss: 0.0260\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A86C6A20D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 5s 36ms/step - loss: 0.0628 - val_loss: 0.0277\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0390 - val_loss: 0.0263\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0208 - val_loss: 0.0322\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0457 - val_loss: 0.0263\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0292 - val_loss: 0.0251\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0211 - val_loss: 0.0321\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0274 - val_loss: 0.0253\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0187 - val_loss: 0.0251\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0246 - val_loss: 0.0304\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0208 - val_loss: 0.0330\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0302 - val_loss: 0.0258\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0285 - val_loss: 0.0249\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0201 - val_loss: 0.0308\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0267 - val_loss: 0.0254\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0258 - val_loss: 0.0351\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0251 - val_loss: 0.0307\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0232 - val_loss: 0.0280\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0249 - val_loss: 0.0239\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0242 - val_loss: 0.0280\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0198 - val_loss: 0.0254\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0277 - val_loss: 0.0244\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0252 - val_loss: 0.0241\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0225 - val_loss: 0.0238\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0211 - val_loss: 0.0256\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0216 - val_loss: 0.0251\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0158 - val_loss: 0.0255\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0191 - val_loss: 0.0242\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0222 - val_loss: 0.0264\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0349 - val_loss: 0.0225\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0218 - val_loss: 0.0228\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0217 - val_loss: 0.0226\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0259 - val_loss: 0.0222\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0187 - val_loss: 0.0227\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0200 - val_loss: 0.0276\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0273 - val_loss: 0.0227\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0241 - val_loss: 0.0302\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0183 - val_loss: 0.0211\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0229 - val_loss: 0.0209\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0215 - val_loss: 0.0342\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0172 - val_loss: 0.0237\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0214\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0320\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0247 - val_loss: 0.0291\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0207 - val_loss: 0.0200\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0192 - val_loss: 0.0208\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0251 - val_loss: 0.0198\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0197 - val_loss: 0.0331\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0236 - val_loss: 0.0198\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0213 - val_loss: 0.0241\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0150 - val_loss: 0.0240\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0208 - val_loss: 0.0230\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0187 - val_loss: 0.0244\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0236 - val_loss: 0.0205\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0179 - val_loss: 0.0194\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0202\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0153 - val_loss: 0.0206\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0144 - val_loss: 0.0186\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0301 - val_loss: 0.0328\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0218 - val_loss: 0.0268\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0184 - val_loss: 0.0188\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0238\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0219 - val_loss: 0.0179\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0222 - val_loss: 0.0182\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0171 - val_loss: 0.0180\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0158 - val_loss: 0.0179\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0160 - val_loss: 0.0197\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0201\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.0189 - val_loss: 0.0175\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0156 - val_loss: 0.0155\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0150 - val_loss: 0.0235\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0147 - val_loss: 0.0158\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0142 - val_loss: 0.0180\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0133 - val_loss: 0.0235\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0148 - val_loss: 0.0155\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0226 - val_loss: 0.0188\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0263\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0189 - val_loss: 0.0163\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0108 - val_loss: 0.0165\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0126 - val_loss: 0.0182\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0151 - val_loss: 0.0191\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0358\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0175 - val_loss: 0.0196\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0132 - val_loss: 0.0164\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0142 - val_loss: 0.0171\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0126 - val_loss: 0.0157\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0166 - val_loss: 0.0220\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0173\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0089 - val_loss: 0.0231\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0117 - val_loss: 0.0184\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0139 - val_loss: 0.0197\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0131 - val_loss: 0.0195\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0170\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0148 - val_loss: 0.0206\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0086 - val_loss: 0.0278\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0107 - val_loss: 0.0149\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0113 - val_loss: 0.0155\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.0189\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0119 - val_loss: 0.0184\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0126 - val_loss: 0.0151\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A8754F40D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 36ms/step - loss: 0.0391 - val_loss: 0.0279\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0402 - val_loss: 0.0283\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0246 - val_loss: 0.0304\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0268 - val_loss: 0.0270\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0318 - val_loss: 0.0257\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0223 - val_loss: 0.0253\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0238 - val_loss: 0.0342\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0264 - val_loss: 0.0246\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0207 - val_loss: 0.0251\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0258 - val_loss: 0.0246\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0226 - val_loss: 0.0252\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0238 - val_loss: 0.0281\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0199 - val_loss: 0.0342\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0271 - val_loss: 0.0256\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0261 - val_loss: 0.0241\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0274 - val_loss: 0.0362\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0228 - val_loss: 0.0268\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0304 - val_loss: 0.0252\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0213 - val_loss: 0.0259\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0207 - val_loss: 0.0505\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0351 - val_loss: 0.0280\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0244 - val_loss: 0.0316\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0284 - val_loss: 0.0263\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0235 - val_loss: 0.0238\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0189 - val_loss: 0.0242\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0191 - val_loss: 0.0254\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0310 - val_loss: 0.0254\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0235 - val_loss: 0.0230\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0254 - val_loss: 0.0230\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0254 - val_loss: 0.0250\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0329 - val_loss: 0.0231\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0312 - val_loss: 0.0248\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0238 - val_loss: 0.0238\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0174 - val_loss: 0.0237\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0188 - val_loss: 0.0221\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0221 - val_loss: 0.0259\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0165 - val_loss: 0.0222\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0212 - val_loss: 0.0284\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0191 - val_loss: 0.0216\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0197 - val_loss: 0.0225\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0263 - val_loss: 0.0292\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0176 - val_loss: 0.0245\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0160 - val_loss: 0.0245\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0225 - val_loss: 0.0230\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0208 - val_loss: 0.0201\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0148 - val_loss: 0.0249\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0182 - val_loss: 0.0199\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0185 - val_loss: 0.0227\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0182 - val_loss: 0.0210\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0183 - val_loss: 0.0221\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0196 - val_loss: 0.0210\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0205 - val_loss: 0.0236\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0205 - val_loss: 0.0228\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0168 - val_loss: 0.0214\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0178 - val_loss: 0.0207\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0212 - val_loss: 0.0198\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.0222 - val_loss: 0.0189\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0219 - val_loss: 0.0191\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0183 - val_loss: 0.0191\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0156 - val_loss: 0.0223\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0192 - val_loss: 0.0187\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0159 - val_loss: 0.0176\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0240 - val_loss: 0.0177\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0184 - val_loss: 0.0171\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0176 - val_loss: 0.0273\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0220 - val_loss: 0.0223\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0216 - val_loss: 0.0179\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0174 - val_loss: 0.0237\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0225 - val_loss: 0.0178\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0161 - val_loss: 0.0137\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0162 - val_loss: 0.0247\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0165 - val_loss: 0.0184\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0147 - val_loss: 0.0169\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0141 - val_loss: 0.0174\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0115 - val_loss: 0.0242\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0135 - val_loss: 0.0172\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 0.0219\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0173 - val_loss: 0.0235\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0167 - val_loss: 0.0152\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0085 - val_loss: 0.0151\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0258\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0138 - val_loss: 0.0171\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0167 - val_loss: 0.0209\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0157 - val_loss: 0.0165\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 0.0310\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0241 - val_loss: 0.0155\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0150\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0102 - val_loss: 0.0152\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0090 - val_loss: 0.0167\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0133 - val_loss: 0.0214\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0119 - val_loss: 0.0173\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0117 - val_loss: 0.0169\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0110 - val_loss: 0.0206\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0069 - val_loss: 0.0201\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0119 - val_loss: 0.0155\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0250\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0198\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0118 - val_loss: 0.0181\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0079 - val_loss: 0.0209\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0143\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A86F64C040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 38ms/step - loss: 0.0663 - val_loss: 0.0282\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0331 - val_loss: 0.0263\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0275 - val_loss: 0.0352\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0259 - val_loss: 0.0254\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0249 - val_loss: 0.0310\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0300 - val_loss: 0.0264\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0239 - val_loss: 0.0251\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0266 - val_loss: 0.0256\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0235 - val_loss: 0.0267\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0315 - val_loss: 0.0404\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0293 - val_loss: 0.0275\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0271 - val_loss: 0.0255\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0246 - val_loss: 0.0246\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0307 - val_loss: 0.0277\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0296 - val_loss: 0.0321\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0261 - val_loss: 0.0242\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0261 - val_loss: 0.0284\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0213 - val_loss: 0.0240\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0251 - val_loss: 0.0238\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0237 - val_loss: 0.0387\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0323 - val_loss: 0.0306\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0259 - val_loss: 0.0239\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0184 - val_loss: 0.0236\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0239 - val_loss: 0.0247\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0233 - val_loss: 0.0264\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0189 - val_loss: 0.0359\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0351 - val_loss: 0.0234\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0229 - val_loss: 0.0243\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0232 - val_loss: 0.0232\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0259 - val_loss: 0.0267\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0192 - val_loss: 0.0230\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0159 - val_loss: 0.0231\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0289 - val_loss: 0.0224\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0210 - val_loss: 0.0220\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0187 - val_loss: 0.0219\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0194 - val_loss: 0.0248\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0189 - val_loss: 0.0233\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0240 - val_loss: 0.0212\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0189 - val_loss: 0.0342\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0293 - val_loss: 0.0219\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0233 - val_loss: 0.0264\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0243 - val_loss: 0.0225\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0264 - val_loss: 0.0206\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0226 - val_loss: 0.0273\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0219 - val_loss: 0.0204\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0196 - val_loss: 0.0201\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0243 - val_loss: 0.0196\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0200\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0194 - val_loss: 0.0209\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0207 - val_loss: 0.0194\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0147 - val_loss: 0.0324\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0213 - val_loss: 0.0195\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0227 - val_loss: 0.0197\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0173 - val_loss: 0.0359\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0306 - val_loss: 0.0206\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0209 - val_loss: 0.0207\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.0183 - val_loss: 0.0193\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0210 - val_loss: 0.0223\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0151 - val_loss: 0.0190\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0139 - val_loss: 0.0216\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0177 - val_loss: 0.0196\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0152 - val_loss: 0.0226\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0243 - val_loss: 0.0215\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0252 - val_loss: 0.0202\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0134 - val_loss: 0.0183\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0206\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0175 - val_loss: 0.0184\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0216 - val_loss: 0.0284\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0257 - val_loss: 0.0192\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0252 - val_loss: 0.0186\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0133 - val_loss: 0.0196\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0173 - val_loss: 0.0158\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0157 - val_loss: 0.0235\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0197 - val_loss: 0.0190\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0173 - val_loss: 0.0195\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0151 - val_loss: 0.0172\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0168 - val_loss: 0.0243\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0212 - val_loss: 0.0170\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0148 - val_loss: 0.0172\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0152 - val_loss: 0.0178\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0218 - val_loss: 0.0230\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0195 - val_loss: 0.0174\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0146 - val_loss: 0.0183\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0109 - val_loss: 0.0278\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0191 - val_loss: 0.0199\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0132 - val_loss: 0.0158\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0163\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0161 - val_loss: 0.0232\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0179\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0165 - val_loss: 0.0144\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0130 - val_loss: 0.0172\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0147 - val_loss: 0.0168\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0119 - val_loss: 0.0197\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0150\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0161\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0112 - val_loss: 0.0150\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0088 - val_loss: 0.0228\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0142 - val_loss: 0.0201\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0119 - val_loss: 0.0173\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0191\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0110 - val_loss: 0.0205\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0075 - val_loss: 0.0202\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0109 - val_loss: 0.0168\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.0170\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0123 - val_loss: 0.0176\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0172\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0081 - val_loss: 0.0222\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0080 - val_loss: 0.0226\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0088 - val_loss: 0.0239\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0087 - val_loss: 0.0178\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0115 - val_loss: 0.0156\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0116\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0062 - val_loss: 0.0198\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0052 - val_loss: 0.0185\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0084 - val_loss: 0.0169\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0045 - val_loss: 0.0142\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0057 - val_loss: 0.0150\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0053 - val_loss: 0.0173\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0044 - val_loss: 0.0212\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0058 - val_loss: 0.0173\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0054 - val_loss: 0.0169\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0029 - val_loss: 0.0174\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0042 - val_loss: 0.0190\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0043 - val_loss: 0.0144\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0042 - val_loss: 0.0185\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0047 - val_loss: 0.0182\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0041 - val_loss: 0.0170\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0041 - val_loss: 0.0183\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0044 - val_loss: 0.0165\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0055 - val_loss: 0.0205\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0043 - val_loss: 0.0183\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0034 - val_loss: 0.0201\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0036 - val_loss: 0.0172\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0025 - val_loss: 0.0182\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 0.0177\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0024 - val_loss: 0.0205\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0028 - val_loss: 0.0177\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0030 - val_loss: 0.0164\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.0032 - val_loss: 0.0272\n",
      "Epoch 140/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0045 - val_loss: 0.0191\n",
      "Epoch 141/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0025 - val_loss: 0.0182\n",
      "Epoch 142/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0032 - val_loss: 0.0234\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A8767338B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 67ms/step - loss: 0.0807 - val_loss: 0.0394\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0278 - val_loss: 0.0272\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0224 - val_loss: 0.0269\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0247 - val_loss: 0.0307\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0267 - val_loss: 0.0356\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0280 - val_loss: 0.0283\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0242 - val_loss: 0.0254\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0249 - val_loss: 0.0277\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0214 - val_loss: 0.0278\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0248 - val_loss: 0.0242\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0226 - val_loss: 0.0249\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0223 - val_loss: 0.0246\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0248 - val_loss: 0.0242\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0284 - val_loss: 0.0299\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0174 - val_loss: 0.0361\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0346 - val_loss: 0.0271\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0285 - val_loss: 0.0242\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0230 - val_loss: 0.0252\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0263 - val_loss: 0.0247\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0304 - val_loss: 0.0267\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0240 - val_loss: 0.0250\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0248 - val_loss: 0.0281\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0261 - val_loss: 0.0235\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0236 - val_loss: 0.0235\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0254 - val_loss: 0.0306\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0238 - val_loss: 0.0237\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0213 - val_loss: 0.0236\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0166 - val_loss: 0.0233\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0237 - val_loss: 0.0279\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0289 - val_loss: 0.0253\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0199 - val_loss: 0.0298\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0270 - val_loss: 0.0227\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0210 - val_loss: 0.0229\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0222 - val_loss: 0.0227\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0209 - val_loss: 0.0226\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0169 - val_loss: 0.0267\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0194 - val_loss: 0.0251\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0201 - val_loss: 0.0215\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0152 - val_loss: 0.0347\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0290 - val_loss: 0.0487\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0227 - val_loss: 0.0217\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0220 - val_loss: 0.0226\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0174 - val_loss: 0.0219\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0247 - val_loss: 0.0286\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0215 - val_loss: 0.0220\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0186 - val_loss: 0.0220\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0205 - val_loss: 0.0212\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0163 - val_loss: 0.0324\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0219 - val_loss: 0.0272\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0172 - val_loss: 0.0209\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0231 - val_loss: 0.0202\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0193 - val_loss: 0.0195\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0158 - val_loss: 0.0203\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0235 - val_loss: 0.0209\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0131 - val_loss: 0.0192\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0148 - val_loss: 0.0200\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0170 - val_loss: 0.0198\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0188 - val_loss: 0.0288\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.0152 - val_loss: 0.0221\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0184 - val_loss: 0.0225\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0199 - val_loss: 0.0185\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0138 - val_loss: 0.0195\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0150 - val_loss: 0.0260\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0201 - val_loss: 0.0188\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0199 - val_loss: 0.0224\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0173 - val_loss: 0.0202\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0148 - val_loss: 0.0203\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0200 - val_loss: 0.0220\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0163 - val_loss: 0.0177\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0141 - val_loss: 0.0368\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0241 - val_loss: 0.0183\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0161 - val_loss: 0.0170\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0142 - val_loss: 0.0194\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0199 - val_loss: 0.0189\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0122 - val_loss: 0.0192\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0177 - val_loss: 0.0157\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0115 - val_loss: 0.0191\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0150 - val_loss: 0.0157\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0164 - val_loss: 0.0173\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0160 - val_loss: 0.0169\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.0165 - val_loss: 0.0176\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0146 - val_loss: 0.0201\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0163 - val_loss: 0.0212\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0114 - val_loss: 0.0163\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0121 - val_loss: 0.0263\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0158 - val_loss: 0.0180\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0171 - val_loss: 0.0165\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0140 - val_loss: 0.0160\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0095 - val_loss: 0.0190\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0113 - val_loss: 0.0173\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0218\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0130 - val_loss: 0.0202\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0099 - val_loss: 0.0189\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0123 - val_loss: 0.0152\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0114 - val_loss: 0.0184\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0115 - val_loss: 0.0132\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0153 - val_loss: 0.0211\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0229\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0077 - val_loss: 0.0229\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0093 - val_loss: 0.0155\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0081 - val_loss: 0.0215\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0091 - val_loss: 0.0162\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0137 - val_loss: 0.0153\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0127 - val_loss: 0.0211\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0070 - val_loss: 0.0172\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0051 - val_loss: 0.0197\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0071 - val_loss: 0.0169\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0062 - val_loss: 0.0193\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0063 - val_loss: 0.0218\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0074 - val_loss: 0.0190\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0063 - val_loss: 0.0223\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0046 - val_loss: 0.0169\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0053 - val_loss: 0.0221\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0048 - val_loss: 0.0198\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0041 - val_loss: 0.0214\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0060 - val_loss: 0.0203\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0034 - val_loss: 0.0147\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0085 - val_loss: 0.0201\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0077 - val_loss: 0.0133\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0060 - val_loss: 0.0182\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0039 - val_loss: 0.0181\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0069 - val_loss: 0.0187\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0044 - val_loss: 0.0196\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0036 - val_loss: 0.0193\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0035 - val_loss: 0.0176\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0024 - val_loss: 0.0188\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A879A2D790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 35ms/step - loss: 0.0733 - val_loss: 0.0417\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0271 - val_loss: 0.0270\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0332 - val_loss: 0.0299\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0267 - val_loss: 0.0251\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0259 - val_loss: 0.0248\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0252 - val_loss: 0.0269\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0248 - val_loss: 0.0269\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0190 - val_loss: 0.0278\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0244 - val_loss: 0.0356\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0323 - val_loss: 0.0243\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0304 - val_loss: 0.0261\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0257 - val_loss: 0.0247\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0243 - val_loss: 0.0264\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0214 - val_loss: 0.0252\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0234 - val_loss: 0.0329\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0294 - val_loss: 0.0247\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0265 - val_loss: 0.0243\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0197 - val_loss: 0.0238\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0281 - val_loss: 0.0381\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0296 - val_loss: 0.0240\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0280 - val_loss: 0.0286\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0251 - val_loss: 0.0290\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0260 - val_loss: 0.0328\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0182 - val_loss: 0.0235\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0184 - val_loss: 0.0231\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0199 - val_loss: 0.0263\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0215 - val_loss: 0.0315\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0256 - val_loss: 0.0224\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0239 - val_loss: 0.0227\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0215 - val_loss: 0.0280\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0197 - val_loss: 0.0265\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0164 - val_loss: 0.0223\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0237 - val_loss: 0.0231\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0191 - val_loss: 0.0218\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0178 - val_loss: 0.0217\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0238 - val_loss: 0.0269\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0212 - val_loss: 0.0213\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0176 - val_loss: 0.0211\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0210\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0200 - val_loss: 0.0231\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0156 - val_loss: 0.0226\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0194 - val_loss: 0.0212\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0190 - val_loss: 0.0264\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0205 - val_loss: 0.0205\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0177 - val_loss: 0.0215\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0206 - val_loss: 0.0211\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0167 - val_loss: 0.0263\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0290 - val_loss: 0.0205\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0196\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0141 - val_loss: 0.0205\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0174 - val_loss: 0.0219\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0201 - val_loss: 0.0283\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0150 - val_loss: 0.0191\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.0190 - val_loss: 0.0187\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0213\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0238 - val_loss: 0.0201\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0235 - val_loss: 0.0191\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0156 - val_loss: 0.0177\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0193 - val_loss: 0.0179\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0155 - val_loss: 0.0192\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0177 - val_loss: 0.0247\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0161 - val_loss: 0.0177\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0144 - val_loss: 0.0163\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0141 - val_loss: 0.0201\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0204 - val_loss: 0.0289\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0197 - val_loss: 0.0182\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0178 - val_loss: 0.0212\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0183 - val_loss: 0.0246\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0227 - val_loss: 0.0178\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0178 - val_loss: 0.0235\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0110 - val_loss: 0.0370\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0155 - val_loss: 0.0205\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0189 - val_loss: 0.0215\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0147 - val_loss: 0.0205\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.0223\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0129 - val_loss: 0.0162\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0167 - val_loss: 0.0204\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0201 - val_loss: 0.0173\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.0183\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0161 - val_loss: 0.0270\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0142 - val_loss: 0.0182\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0112 - val_loss: 0.0158\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0190\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0147 - val_loss: 0.0191\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0128 - val_loss: 0.0200\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0089 - val_loss: 0.0255\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0126 - val_loss: 0.0165\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0175\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0069 - val_loss: 0.0164\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0209\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0137\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0099 - val_loss: 0.0153\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0078 - val_loss: 0.0172\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0082 - val_loss: 0.0170\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0081 - val_loss: 0.0125\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0084 - val_loss: 0.0180\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0154 - val_loss: 0.0245\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0141 - val_loss: 0.0166\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0193\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0153\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0087 - val_loss: 0.0144\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0077 - val_loss: 0.0157\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0072 - val_loss: 0.0218\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0067 - val_loss: 0.0171\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0073 - val_loss: 0.0142\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0072 - val_loss: 0.0133\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0052 - val_loss: 0.0154\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0051 - val_loss: 0.0152\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0067 - val_loss: 0.0178\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0043 - val_loss: 0.0151\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0045 - val_loss: 0.0154\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0035 - val_loss: 0.0151\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0084 - val_loss: 0.0170\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0070 - val_loss: 0.0182\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0068 - val_loss: 0.0169\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0052 - val_loss: 0.0144\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0061 - val_loss: 0.0156\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0039 - val_loss: 0.0177\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0037 - val_loss: 0.0187\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0034 - val_loss: 0.0168\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0025 - val_loss: 0.0161\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0032 - val_loss: 0.0147\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0030 - val_loss: 0.0174\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0031 - val_loss: 0.0184\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0031 - val_loss: 0.0149\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A70D74FCA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 57ms/step - loss: 0.0549 - val_loss: 0.0274\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0321 - val_loss: 0.0332\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0221 - val_loss: 0.0287\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0231 - val_loss: 0.0272\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0304 - val_loss: 0.0275\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0256 - val_loss: 0.0285\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0316 - val_loss: 0.0325\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0183 - val_loss: 0.0272\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0248 - val_loss: 0.0342\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0300 - val_loss: 0.0276\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0268 - val_loss: 0.0253\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0243 - val_loss: 0.0341\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0274 - val_loss: 0.0256\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0229 - val_loss: 0.0251\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0253 - val_loss: 0.0242\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0270 - val_loss: 0.0241\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0216 - val_loss: 0.0238\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0242 - val_loss: 0.0271\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0240 - val_loss: 0.0241\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0344 - val_loss: 0.0240\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0237 - val_loss: 0.0250\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0246 - val_loss: 0.0238\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0260 - val_loss: 0.0250\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0311 - val_loss: 0.0327\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0271 - val_loss: 0.0341\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0284 - val_loss: 0.0273\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0285 - val_loss: 0.0247\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0264 - val_loss: 0.0236\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0206 - val_loss: 0.0280\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0207 - val_loss: 0.0228\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0202 - val_loss: 0.0359\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0249 - val_loss: 0.0419\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0268 - val_loss: 0.0237\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0240 - val_loss: 0.0228\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0169 - val_loss: 0.0297\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0221 - val_loss: 0.0217\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0186 - val_loss: 0.0216\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0195 - val_loss: 0.0292\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0206 - val_loss: 0.0212\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0187 - val_loss: 0.0228\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0172 - val_loss: 0.0218\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0260 - val_loss: 0.0202\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0163 - val_loss: 0.0223\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0237 - val_loss: 0.0210\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0229 - val_loss: 0.0203\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0150 - val_loss: 0.0238\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0257 - val_loss: 0.0209\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0206 - val_loss: 0.0326\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0155 - val_loss: 0.0206\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0160 - val_loss: 0.0193\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0260 - val_loss: 0.0219\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0177 - val_loss: 0.0235\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0175 - val_loss: 0.0221\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0127 - val_loss: 0.0198\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0221 - val_loss: 0.0214\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0153 - val_loss: 0.0192\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0259 - val_loss: 0.0258\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0182 - val_loss: 0.0214\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0161 - val_loss: 0.0228\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0289 - val_loss: 0.0184\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0183 - val_loss: 0.0309\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0282 - val_loss: 0.0282\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0214 - val_loss: 0.0196\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0196 - val_loss: 0.0215\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0249 - val_loss: 0.0180\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0151 - val_loss: 0.0227\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.0202 - val_loss: 0.0230\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0170 - val_loss: 0.0165\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0159 - val_loss: 0.0174\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0162 - val_loss: 0.0170\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0152 - val_loss: 0.0158\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0124 - val_loss: 0.0278\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0273 - val_loss: 0.0176\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0143 - val_loss: 0.0217\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0179 - val_loss: 0.0185\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0168 - val_loss: 0.0201\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0141 - val_loss: 0.0177\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0147 - val_loss: 0.0160\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0109 - val_loss: 0.0169\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0093 - val_loss: 0.0174\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0145 - val_loss: 0.0189\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 0.0227\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0119 - val_loss: 0.0149\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0124 - val_loss: 0.0211\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0100 - val_loss: 0.0216\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0143 - val_loss: 0.0288\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0130 - val_loss: 0.0192\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0101 - val_loss: 0.0184\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0109 - val_loss: 0.0172\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0104 - val_loss: 0.0266\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0169 - val_loss: 0.0150\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0158\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0122 - val_loss: 0.0109\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0080 - val_loss: 0.0232\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0100 - val_loss: 0.0154\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0124 - val_loss: 0.0133\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0077 - val_loss: 0.0160\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0101 - val_loss: 0.0156\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0077 - val_loss: 0.0162\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0080 - val_loss: 0.0187\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.0080 - val_loss: 0.0220\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0117 - val_loss: 0.0137\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0081 - val_loss: 0.0152\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0037 - val_loss: 0.0148\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0048 - val_loss: 0.0187\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0074 - val_loss: 0.0160\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0055 - val_loss: 0.0198\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0058 - val_loss: 0.0139\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0049 - val_loss: 0.0169\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0035 - val_loss: 0.0128\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0037 - val_loss: 0.0162\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0083 - val_loss: 0.0202\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0079 - val_loss: 0.0193\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0054 - val_loss: 0.0196\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 0.0214\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0027 - val_loss: 0.0123\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0081 - val_loss: 0.0275\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0143 - val_loss: 0.0200\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0060 - val_loss: 0.0183\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0027 - val_loss: 0.0178\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0038 - val_loss: 0.0134\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0031 - val_loss: 0.0208\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0024 - val_loss: 0.0177\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A881A275E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 5s 39ms/step - loss: 0.0585 - val_loss: 0.0272\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0306 - val_loss: 0.0448\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0359 - val_loss: 0.0350\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0241 - val_loss: 0.0257\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0192 - val_loss: 0.0250\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0279 - val_loss: 0.0266\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0310 - val_loss: 0.0421\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0306 - val_loss: 0.0315\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0205 - val_loss: 0.0249\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0241 - val_loss: 0.0300\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0188 - val_loss: 0.0244\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0209 - val_loss: 0.0301\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0220 - val_loss: 0.0265\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0262 - val_loss: 0.0245\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0224 - val_loss: 0.0245\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0173 - val_loss: 0.0396\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0214 - val_loss: 0.0245\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0224 - val_loss: 0.0352\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0308 - val_loss: 0.0297\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0219 - val_loss: 0.0346\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0317 - val_loss: 0.0243\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0247 - val_loss: 0.0347\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0246 - val_loss: 0.0259\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0240 - val_loss: 0.0268\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0204 - val_loss: 0.0253\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0259 - val_loss: 0.0241\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0192 - val_loss: 0.0281\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0218 - val_loss: 0.0269\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0301 - val_loss: 0.0295\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0248 - val_loss: 0.0227\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0252 - val_loss: 0.0220\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0219 - val_loss: 0.0221\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0219 - val_loss: 0.0268\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0221 - val_loss: 0.0218\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0190 - val_loss: 0.0258\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0257 - val_loss: 0.0296\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0202 - val_loss: 0.0216\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0232 - val_loss: 0.0226\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0273 - val_loss: 0.0241\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0238 - val_loss: 0.0229\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0179 - val_loss: 0.0218\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0238 - val_loss: 0.0209\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0199 - val_loss: 0.0219\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0203 - val_loss: 0.0200\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0233 - val_loss: 0.0200\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0225 - val_loss: 0.0205\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0224 - val_loss: 0.0253\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0271 - val_loss: 0.0204\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0166 - val_loss: 0.0206\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0179 - val_loss: 0.0236\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0249 - val_loss: 0.0207\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0154 - val_loss: 0.0218\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0199 - val_loss: 0.0187\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0195 - val_loss: 0.0219\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0193 - val_loss: 0.0200\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0190 - val_loss: 0.0194\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0231 - val_loss: 0.0202\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0223 - val_loss: 0.0188\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.0151 - val_loss: 0.0201\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0185 - val_loss: 0.0179\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0185 - val_loss: 0.0180\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0222 - val_loss: 0.0206\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0159 - val_loss: 0.0189\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0168 - val_loss: 0.0189\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0117 - val_loss: 0.0195\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0194 - val_loss: 0.0227\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0134 - val_loss: 0.0162\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.0174\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0170 - val_loss: 0.0207\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0161 - val_loss: 0.0202\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0144 - val_loss: 0.0154\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0121 - val_loss: 0.0206\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0138 - val_loss: 0.0171\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0192\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0139 - val_loss: 0.0165\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0224\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0139 - val_loss: 0.0183\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0153 - val_loss: 0.0221\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0164 - val_loss: 0.0149\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0153 - val_loss: 0.0131\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 0.0186\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.0212\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.0166\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0109 - val_loss: 0.0168\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0127 - val_loss: 0.0184\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0107 - val_loss: 0.0186\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0134\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0169\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0161 - val_loss: 0.0141\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0108 - val_loss: 0.0212\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0275\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0164 - val_loss: 0.0146\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0174\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0078 - val_loss: 0.0145\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0051 - val_loss: 0.0157\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0081 - val_loss: 0.0236\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0151\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0114 - val_loss: 0.0325\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0136 - val_loss: 0.0194\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0128 - val_loss: 0.0196\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0081 - val_loss: 0.0194\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0126\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0071 - val_loss: 0.0174\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0076 - val_loss: 0.0167\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0054 - val_loss: 0.0165\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0069 - val_loss: 0.0168\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0167\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0102 - val_loss: 0.0156\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0049 - val_loss: 0.0181\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0059 - val_loss: 0.0163\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A85FC3B9D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 37ms/step - loss: 0.0504 - val_loss: 0.0302\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0224 - val_loss: 0.0338\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0318 - val_loss: 0.0261\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0210 - val_loss: 0.0260\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0213 - val_loss: 0.0357\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0250 - val_loss: 0.0249\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0257 - val_loss: 0.0258\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0281 - val_loss: 0.0278\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0235 - val_loss: 0.0255\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0182 - val_loss: 0.0248\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0180 - val_loss: 0.0244\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0300 - val_loss: 0.0243\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0247 - val_loss: 0.0356\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0264 - val_loss: 0.0243\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0283 - val_loss: 0.0387\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0292 - val_loss: 0.0238\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0237 - val_loss: 0.0267\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0191 - val_loss: 0.0260\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0244 - val_loss: 0.0240\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0279 - val_loss: 0.0237\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0248 - val_loss: 0.0240\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0220 - val_loss: 0.0267\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0203 - val_loss: 0.0233\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0314 - val_loss: 0.0231\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0212 - val_loss: 0.0229\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0174 - val_loss: 0.0375\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0289 - val_loss: 0.0249\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0184 - val_loss: 0.0311\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0213 - val_loss: 0.0227\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0187 - val_loss: 0.0231\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0193 - val_loss: 0.0223\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0191 - val_loss: 0.0368\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0267 - val_loss: 0.0253\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0279 - val_loss: 0.0221\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0204 - val_loss: 0.0290\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.0243 - val_loss: 0.0229\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0228 - val_loss: 0.0248\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0152 - val_loss: 0.0215\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0181 - val_loss: 0.0216\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0238 - val_loss: 0.0216\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0203 - val_loss: 0.0249\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0195 - val_loss: 0.0210\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0259 - val_loss: 0.0205\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0212 - val_loss: 0.0198\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0171 - val_loss: 0.0203\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0195 - val_loss: 0.0241\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0270 - val_loss: 0.0215\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0187 - val_loss: 0.0216\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0148 - val_loss: 0.0191\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0252 - val_loss: 0.0194\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0209 - val_loss: 0.0231\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0225 - val_loss: 0.0200\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0139 - val_loss: 0.0200\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0158 - val_loss: 0.0187\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0209 - val_loss: 0.0284\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0185 - val_loss: 0.0196\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0222 - val_loss: 0.0218\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0145 - val_loss: 0.0199\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0171 - val_loss: 0.0195\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0213 - val_loss: 0.0211\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0168 - val_loss: 0.0167\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0179 - val_loss: 0.0220\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0160 - val_loss: 0.0199\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0165 - val_loss: 0.0190\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0213 - val_loss: 0.0296\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0200 - val_loss: 0.0188\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0184 - val_loss: 0.0155\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0130 - val_loss: 0.0187\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0191 - val_loss: 0.0183\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0166 - val_loss: 0.0166\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0118 - val_loss: 0.0230\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0217 - val_loss: 0.0198\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0161 - val_loss: 0.0197\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0142 - val_loss: 0.0190\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0144 - val_loss: 0.0188\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 0.0195\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0154 - val_loss: 0.0175\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0148 - val_loss: 0.0172\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0122 - val_loss: 0.0203\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0139 - val_loss: 0.0159\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0122 - val_loss: 0.0250\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0132 - val_loss: 0.0174\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 0.0199\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0103 - val_loss: 0.0325\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0110 - val_loss: 0.0222\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0311\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0155 - val_loss: 0.0200\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0125 - val_loss: 0.0269\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0135 - val_loss: 0.0142\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0112 - val_loss: 0.0192\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.0191\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0128 - val_loss: 0.0183\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0064 - val_loss: 0.0192\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0109 - val_loss: 0.0153\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0060 - val_loss: 0.0184\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0065 - val_loss: 0.0177\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0109 - val_loss: 0.0153\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0080 - val_loss: 0.0182\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0052 - val_loss: 0.0183\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0147\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0123 - val_loss: 0.0274\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0110 - val_loss: 0.0154\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0184\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0157\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0065 - val_loss: 0.0200\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0084 - val_loss: 0.0160\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0049 - val_loss: 0.0208\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0062 - val_loss: 0.0187\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0042 - val_loss: 0.0210\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0062 - val_loss: 0.0149\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0046 - val_loss: 0.0176\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0040 - val_loss: 0.0188\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0045 - val_loss: 0.0210\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0069 - val_loss: 0.0159\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0036 - val_loss: 0.0227\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0062 - val_loss: 0.0199\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0053 - val_loss: 0.0214\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0055 - val_loss: 0.0166\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0053 - val_loss: 0.0192\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A7887B68B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 4s 35ms/step - loss: 0.0814 - val_loss: 0.0448\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0399 - val_loss: 0.0294\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0197 - val_loss: 0.0285\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0233 - val_loss: 0.0297\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0240 - val_loss: 0.0251\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0276 - val_loss: 0.0378\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0355 - val_loss: 0.0246\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.0247 - val_loss: 0.0277\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0243 - val_loss: 0.0248\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0239 - val_loss: 0.0291\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0173 - val_loss: 0.0243\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0303 - val_loss: 0.0266\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0221 - val_loss: 0.0244\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0264 - val_loss: 0.0333\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0285 - val_loss: 0.0338\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0277 - val_loss: 0.0242\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0250 - val_loss: 0.0260\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0223 - val_loss: 0.0241\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0216 - val_loss: 0.0237\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0208 - val_loss: 0.0242\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0273 - val_loss: 0.0253\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0218 - val_loss: 0.0241\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0266 - val_loss: 0.0298\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0192 - val_loss: 0.0232\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0218 - val_loss: 0.0247\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0231 - val_loss: 0.0266\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0264 - val_loss: 0.0231\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0197 - val_loss: 0.0232\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0233 - val_loss: 0.0265\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0241 - val_loss: 0.0278\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0244 - val_loss: 0.0224\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0265 - val_loss: 0.0360\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0203 - val_loss: 0.0250\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0241 - val_loss: 0.0220\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0190 - val_loss: 0.0281\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0165 - val_loss: 0.0219\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0206 - val_loss: 0.0213\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0240 - val_loss: 0.0376\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0233 - val_loss: 0.0302\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0170 - val_loss: 0.0208\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0271 - val_loss: 0.0215\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0207 - val_loss: 0.0207\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0197 - val_loss: 0.0255\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0267 - val_loss: 0.0212\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0147 - val_loss: 0.0226\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0191 - val_loss: 0.0215\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0198\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0191 - val_loss: 0.0261\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0209 - val_loss: 0.0193\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0191 - val_loss: 0.0217\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0167 - val_loss: 0.0205\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0152 - val_loss: 0.0209\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0155 - val_loss: 0.0196\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0123 - val_loss: 0.0197\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0226 - val_loss: 0.0188\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0244 - val_loss: 0.0267\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0198 - val_loss: 0.0241\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0136 - val_loss: 0.0218\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0183 - val_loss: 0.0207\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0185 - val_loss: 0.0182\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0197 - val_loss: 0.0207\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0170 - val_loss: 0.0176\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0132 - val_loss: 0.0197\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0232 - val_loss: 0.0219\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0134 - val_loss: 0.0202\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0167 - val_loss: 0.0240\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0199 - val_loss: 0.0254\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0209 - val_loss: 0.0154\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0138 - val_loss: 0.0196\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0136 - val_loss: 0.0185\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0167 - val_loss: 0.0211\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0194 - val_loss: 0.0317\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0253 - val_loss: 0.0191\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0155 - val_loss: 0.0182\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0218 - val_loss: 0.0232\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0212 - val_loss: 0.0171\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0155 - val_loss: 0.0175\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0169 - val_loss: 0.0218\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0147 - val_loss: 0.0190\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0149\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0102 - val_loss: 0.0198\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0153 - val_loss: 0.0182\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0109 - val_loss: 0.0161\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0159 - val_loss: 0.0159\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0119 - val_loss: 0.0272\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0137 - val_loss: 0.0169\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0122 - val_loss: 0.0183\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0132 - val_loss: 0.0154\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.0112 - val_loss: 0.0162\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0135\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0122 - val_loss: 0.0176\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0152 - val_loss: 0.0185\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0121 - val_loss: 0.0173\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0142 - val_loss: 0.0239\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0170 - val_loss: 0.0150\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0109 - val_loss: 0.0167\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0164\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0106 - val_loss: 0.0145\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0065 - val_loss: 0.0161\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0095 - val_loss: 0.0110\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0070 - val_loss: 0.0197\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0124 - val_loss: 0.0181\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0173 - val_loss: 0.0167\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0085 - val_loss: 0.0189\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0083 - val_loss: 0.0227\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0069 - val_loss: 0.0177\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0068 - val_loss: 0.0165\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0067 - val_loss: 0.0198\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0061 - val_loss: 0.0187\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0066 - val_loss: 0.0196\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0089 - val_loss: 0.0201\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0058 - val_loss: 0.0158\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0042 - val_loss: 0.0169\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0059 - val_loss: 0.0161\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0056 - val_loss: 0.0189\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0069 - val_loss: 0.0161\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0062 - val_loss: 0.0173\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0057 - val_loss: 0.0179\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0044 - val_loss: 0.0138\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0051 - val_loss: 0.0158\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0037 - val_loss: 0.0190\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0029 - val_loss: 0.0202\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0053 - val_loss: 0.0161\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0030 - val_loss: 0.0193\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0031 - val_loss: 0.0166\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0029 - val_loss: 0.0171\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0026 - val_loss: 0.0184\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0034 - val_loss: 0.0167\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0039 - val_loss: 0.0156\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0055 - val_loss: 0.0154\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A70CA3E820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "model_result = find_best_parameters(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'units': 2, 'Accuracy': 0.9067542313759934},\n",
       " {'units': 4, 'Accuracy': 0.9148718470463989},\n",
       " {'units': 6, 'Accuracy': 0.9123050409074144},\n",
       " {'units': 8, 'Accuracy': 0.9110465157454521},\n",
       " {'units': 10, 'Accuracy': 0.9099801562565917},\n",
       " {'units': 12, 'Accuracy': 0.9243174553331273},\n",
       " {'units': 14, 'Accuracy': 0.9114345549404714},\n",
       " {'units': 16, 'Accuracy': 0.9326666736486335},\n",
       " {'units': 18, 'Accuracy': 0.9088542362980333},\n",
       " {'units': 20, 'Accuracy': 0.9075590633179237},\n",
       " {'units': 22, 'Accuracy': 0.9069429596058576},\n",
       " {'units': 24, 'Accuracy': 0.9384075046467772},\n",
       " {'units': 26, 'Accuracy': 0.9315789135724518},\n",
       " {'units': 28, 'Accuracy': 0.919967394919909},\n",
       " {'units': 30, 'Accuracy': 0.9077018332869516},\n",
       " {'units': 32, 'Accuracy': 0.9077333252714435},\n",
       " {'units': 34, 'Accuracy': 0.926296770684507},\n",
       " {'units': 36, 'Accuracy': 0.9196045295879887},\n",
       " {'units': 38, 'Accuracy': 0.9077966279957012},\n",
       " {'units': 40, 'Accuracy': 0.9157350148575311},\n",
       " {'units': 42, 'Accuracy': 0.904616279869144},\n",
       " {'units': 44, 'Accuracy': 0.9250689045063195},\n",
       " {'units': 46, 'Accuracy': 0.9370822609589363},\n",
       " {'units': 48, 'Accuracy': 0.9264325832822975},\n",
       " {'units': 50, 'Accuracy': 0.9282642440537776},\n",
       " {'units': 52, 'Accuracy': 0.9267635427614623},\n",
       " {'units': 54, 'Accuracy': 0.9333195667148529},\n",
       " {'units': 56, 'Accuracy': 0.9216613837190223},\n",
       " {'units': 58, 'Accuracy': 0.9281767516128319},\n",
       " {'units': 60, 'Accuracy': 0.9310870819588282},\n",
       " {'units': 62, 'Accuracy': 0.9261335918316458},\n",
       " {'units': 64, 'Accuracy': 0.9270987367505567},\n",
       " {'units': 66, 'Accuracy': 0.9246547785441364},\n",
       " {'units': 68, 'Accuracy': 0.8957292483077796},\n",
       " {'units': 70, 'Accuracy': 0.9278309693755468},\n",
       " {'units': 72, 'Accuracy': 0.9139240268615467},\n",
       " {'units': 74, 'Accuracy': 0.9293146216074976},\n",
       " {'units': 76, 'Accuracy': 0.921522580132887},\n",
       " {'units': 78, 'Accuracy': 0.9126526980899543},\n",
       " {'units': 80, 'Accuracy': 0.9161476303054185},\n",
       " {'units': 82, 'Accuracy': 0.9170762819022586},\n",
       " {'units': 84, 'Accuracy': 0.917204698951908},\n",
       " {'units': 86, 'Accuracy': 0.9222686278077239},\n",
       " {'units': 88, 'Accuracy': 0.9301505787870112},\n",
       " {'units': 90, 'Accuracy': 0.9136238911790654},\n",
       " {'units': 92, 'Accuracy': 0.9296761142360304},\n",
       " {'units': 94, 'Accuracy': 0.9343727407886284},\n",
       " {'units': 96, 'Accuracy': 0.9185974372340202},\n",
       " {'units': 98, 'Accuracy': 0.9188190782770258},\n",
       " {'units': 100, 'Accuracy': 0.9298654502721457},\n",
       " {'units': 102, 'Accuracy': 0.9339294827663535},\n",
       " {'units': 104, 'Accuracy': 0.8921184917081102},\n",
       " {'units': 106, 'Accuracy': 0.9350429664425929},\n",
       " {'units': 108, 'Accuracy': 0.9154447586194986},\n",
       " {'units': 110, 'Accuracy': 0.9282164979049313},\n",
       " {'units': 112, 'Accuracy': 0.9200409818270939},\n",
       " {'units': 114, 'Accuracy': 0.9220613031865885},\n",
       " {'units': 116, 'Accuracy': 0.9151601600786907},\n",
       " {'units': 118, 'Accuracy': 0.9354256412020988},\n",
       " {'units': 120, 'Accuracy': 0.9197798001611742},\n",
       " {'units': 122, 'Accuracy': 0.9338314720704236},\n",
       " {'units': 124, 'Accuracy': 0.9297163569203113},\n",
       " {'units': 126, 'Accuracy': 0.9374640180514734},\n",
       " {'units': 128, 'Accuracy': 0.9298534787435058},\n",
       " {'units': 130, 'Accuracy': 0.9244815541467105},\n",
       " {'units': 132, 'Accuracy': 0.9231485497249701},\n",
       " {'units': 134, 'Accuracy': 0.923426332914833},\n",
       " {'units': 136, 'Accuracy': 0.9372786572553039},\n",
       " {'units': 138, 'Accuracy': 0.9270666119771714},\n",
       " {'units': 140, 'Accuracy': 0.9327497970106471},\n",
       " {'units': 142, 'Accuracy': 0.930629692685145},\n",
       " {'units': 144, 'Accuracy': 0.9206437446795096},\n",
       " {'units': 146, 'Accuracy': 0.92358939391679},\n",
       " {'units': 148, 'Accuracy': 0.9310772549669591},\n",
       " {'units': 150, 'Accuracy': 0.9264809997124053},\n",
       " {'units': 152, 'Accuracy': 0.9316344655901506},\n",
       " {'units': 154, 'Accuracy': 0.9316633692966229},\n",
       " {'units': 156, 'Accuracy': 0.9187498842416213},\n",
       " {'units': 158, 'Accuracy': 0.915083449273713},\n",
       " {'units': 160, 'Accuracy': 0.9218872950408696},\n",
       " {'units': 162, 'Accuracy': 0.9217691615602116},\n",
       " {'units': 164, 'Accuracy': 0.9359812932543856},\n",
       " {'units': 166, 'Accuracy': 0.9231855315815763},\n",
       " {'units': 168, 'Accuracy': 0.9214117126351963},\n",
       " {'units': 170, 'Accuracy': 0.9148672579286863},\n",
       " {'units': 172, 'Accuracy': 0.9130694585563026},\n",
       " {'units': 174, 'Accuracy': 0.9230120802197561},\n",
       " {'units': 176, 'Accuracy': 0.9299671791123004},\n",
       " {'units': 178, 'Accuracy': 0.9248902122039533},\n",
       " {'units': 180, 'Accuracy': 0.916634679445806},\n",
       " {'units': 182, 'Accuracy': 0.9217061877163818},\n",
       " {'units': 184, 'Accuracy': 0.9252325014562313},\n",
       " {'units': 186, 'Accuracy': 0.9173292509182633},\n",
       " {'units': 188, 'Accuracy': 0.9168154773789429},\n",
       " {'units': 190, 'Accuracy': 0.9148461228700309},\n",
       " {'units': 192, 'Accuracy': 0.9277787898532325},\n",
       " {'units': 194, 'Accuracy': 0.9238358243342403},\n",
       " {'units': 196, 'Accuracy': 0.9266813509843487},\n",
       " {'units': 198, 'Accuracy': 0.9194565320497837},\n",
       " {'units': 200, 'Accuracy': 0.9269656280931136},\n",
       " {'units': 202, 'Accuracy': 0.921871631071153},\n",
       " {'units': 204, 'Accuracy': 0.9236961885052367},\n",
       " {'units': 206, 'Accuracy': 0.9100911160587453},\n",
       " {'units': 208, 'Accuracy': 0.9335895708565166},\n",
       " {'units': 210, 'Accuracy': 0.9295725729952216},\n",
       " {'units': 212, 'Accuracy': 0.9079829915636815},\n",
       " {'units': 214, 'Accuracy': 0.917084108967273},\n",
       " {'units': 216, 'Accuracy': 0.9240724032406106},\n",
       " {'units': 218, 'Accuracy': 0.9300515935678753},\n",
       " {'units': 220, 'Accuracy': 0.9240550911690008},\n",
       " {'units': 222, 'Accuracy': 0.9246784649051782},\n",
       " {'units': 224, 'Accuracy': 0.9270848645878449}]"
      ]
     },
     "execution_count": 654,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of units doesn't have a significant effect on the accuracy of our model. I have also tried different: depth of my model, validation_split, dropout level for different layers, batch_size. The conclusion I got, that our top accuracy is around 93-94% and for better performance - I should make a WINDOW bigger, but in this case I would need much more data. However, 94% is more than enough to see the trend and approximate sales amount for each week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buliding the final model with found parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Playing with some other parameters and layers (LSTM, Bidirectional LSTM & GRU) manually I came up with the next model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.GRU(128, activation='tanh', return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    tf.keras.layers.GRU(64, activation='tanh', dropout=0.2),\n",
    "    tf.keras.layers.Dense(1)\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "17/17 - 4s - loss: 0.0568 - val_loss: 0.0471\n",
      "Epoch 2/300\n",
      "17/17 - 0s - loss: 0.0311 - val_loss: 0.0311\n",
      "Epoch 3/300\n",
      "17/17 - 0s - loss: 0.0289 - val_loss: 0.0320\n",
      "Epoch 4/300\n",
      "17/17 - 0s - loss: 0.0269 - val_loss: 0.0279\n",
      "Epoch 5/300\n",
      "17/17 - 0s - loss: 0.0279 - val_loss: 0.0276\n",
      "Epoch 6/300\n",
      "17/17 - 0s - loss: 0.0277 - val_loss: 0.0271\n",
      "Epoch 7/300\n",
      "17/17 - 0s - loss: 0.0298 - val_loss: 0.0402\n",
      "Epoch 8/300\n",
      "17/17 - 0s - loss: 0.0288 - val_loss: 0.0287\n",
      "Epoch 9/300\n",
      "17/17 - 0s - loss: 0.0303 - val_loss: 0.0262\n",
      "Epoch 10/300\n",
      "17/17 - 0s - loss: 0.0237 - val_loss: 0.0292\n",
      "Epoch 11/300\n",
      "17/17 - 0s - loss: 0.0253 - val_loss: 0.0257\n",
      "Epoch 12/300\n",
      "17/17 - 0s - loss: 0.0235 - val_loss: 0.0260\n",
      "Epoch 13/300\n",
      "17/17 - 0s - loss: 0.0245 - val_loss: 0.0269\n",
      "Epoch 14/300\n",
      "17/17 - 0s - loss: 0.0240 - val_loss: 0.0251\n",
      "Epoch 15/300\n",
      "17/17 - 0s - loss: 0.0241 - val_loss: 0.0247\n",
      "Epoch 16/300\n",
      "17/17 - 0s - loss: 0.0249 - val_loss: 0.0303\n",
      "Epoch 17/300\n",
      "17/17 - 0s - loss: 0.0253 - val_loss: 0.0277\n",
      "Epoch 18/300\n",
      "17/17 - 0s - loss: 0.0252 - val_loss: 0.0251\n",
      "Epoch 19/300\n",
      "17/17 - 0s - loss: 0.0253 - val_loss: 0.0341\n",
      "Epoch 20/300\n",
      "17/17 - 0s - loss: 0.0253 - val_loss: 0.0246\n",
      "Epoch 21/300\n",
      "17/17 - 0s - loss: 0.0247 - val_loss: 0.0245\n",
      "Epoch 22/300\n",
      "17/17 - 0s - loss: 0.0242 - val_loss: 0.0300\n",
      "Epoch 23/300\n",
      "17/17 - 0s - loss: 0.0234 - val_loss: 0.0247\n",
      "Epoch 24/300\n",
      "17/17 - 0s - loss: 0.0247 - val_loss: 0.0289\n",
      "Epoch 25/300\n",
      "17/17 - 0s - loss: 0.0244 - val_loss: 0.0263\n",
      "Epoch 26/300\n",
      "17/17 - 0s - loss: 0.0236 - val_loss: 0.0275\n",
      "Epoch 27/300\n",
      "17/17 - 0s - loss: 0.0254 - val_loss: 0.0256\n",
      "Epoch 28/300\n",
      "17/17 - 0s - loss: 0.0226 - val_loss: 0.0240\n",
      "Epoch 29/300\n",
      "17/17 - 0s - loss: 0.0229 - val_loss: 0.0241\n",
      "Epoch 30/300\n",
      "17/17 - 0s - loss: 0.0222 - val_loss: 0.0246\n",
      "Epoch 31/300\n",
      "17/17 - 0s - loss: 0.0224 - val_loss: 0.0239\n",
      "Epoch 32/300\n",
      "17/17 - 0s - loss: 0.0232 - val_loss: 0.0320\n",
      "Epoch 33/300\n",
      "17/17 - 0s - loss: 0.0253 - val_loss: 0.0265\n",
      "Epoch 34/300\n",
      "17/17 - 0s - loss: 0.0244 - val_loss: 0.0261\n",
      "Epoch 35/300\n",
      "17/17 - 0s - loss: 0.0239 - val_loss: 0.0238\n",
      "Epoch 36/300\n",
      "17/17 - 0s - loss: 0.0243 - val_loss: 0.0237\n",
      "Epoch 37/300\n",
      "17/17 - 0s - loss: 0.0224 - val_loss: 0.0292\n",
      "Epoch 38/300\n",
      "17/17 - 0s - loss: 0.0252 - val_loss: 0.0236\n",
      "Epoch 39/300\n",
      "17/17 - 0s - loss: 0.0238 - val_loss: 0.0246\n",
      "Epoch 40/300\n",
      "17/17 - 0s - loss: 0.0217 - val_loss: 0.0236\n",
      "Epoch 41/300\n",
      "17/17 - 0s - loss: 0.0247 - val_loss: 0.0278\n",
      "Epoch 42/300\n",
      "17/17 - 0s - loss: 0.0227 - val_loss: 0.0261\n",
      "Epoch 43/300\n",
      "17/17 - 0s - loss: 0.0237 - val_loss: 0.0238\n",
      "Epoch 44/300\n",
      "17/17 - 0s - loss: 0.0233 - val_loss: 0.0236\n",
      "Epoch 45/300\n",
      "17/17 - 0s - loss: 0.0230 - val_loss: 0.0259\n",
      "Epoch 46/300\n",
      "17/17 - 0s - loss: 0.0227 - val_loss: 0.0237\n",
      "Epoch 47/300\n",
      "17/17 - 0s - loss: 0.0233 - val_loss: 0.0255\n",
      "Epoch 48/300\n",
      "17/17 - 0s - loss: 0.0207 - val_loss: 0.0232\n",
      "Epoch 49/300\n",
      "17/17 - 0s - loss: 0.0219 - val_loss: 0.0232\n",
      "Epoch 50/300\n",
      "17/17 - 0s - loss: 0.0226 - val_loss: 0.0230\n",
      "Epoch 51/300\n",
      "17/17 - 0s - loss: 0.0236 - val_loss: 0.0232\n",
      "Epoch 52/300\n",
      "17/17 - 0s - loss: 0.0219 - val_loss: 0.0239\n",
      "Epoch 53/300\n",
      "17/17 - 0s - loss: 0.0209 - val_loss: 0.0237\n",
      "Epoch 54/300\n",
      "17/17 - 0s - loss: 0.0216 - val_loss: 0.0233\n",
      "Epoch 55/300\n",
      "17/17 - 0s - loss: 0.0217 - val_loss: 0.0236\n",
      "Epoch 56/300\n",
      "17/17 - 0s - loss: 0.0213 - val_loss: 0.0227\n",
      "Epoch 57/300\n",
      "17/17 - 0s - loss: 0.0215 - val_loss: 0.0252\n",
      "Epoch 58/300\n",
      "17/17 - 0s - loss: 0.0211 - val_loss: 0.0225\n",
      "Epoch 59/300\n",
      "17/17 - 0s - loss: 0.0218 - val_loss: 0.0235\n",
      "Epoch 60/300\n",
      "17/17 - 0s - loss: 0.0212 - val_loss: 0.0225\n",
      "Epoch 61/300\n",
      "17/17 - 0s - loss: 0.0216 - val_loss: 0.0226\n",
      "Epoch 62/300\n",
      "17/17 - 0s - loss: 0.0208 - val_loss: 0.0232\n",
      "Epoch 63/300\n",
      "17/17 - 0s - loss: 0.0225 - val_loss: 0.0224\n",
      "Epoch 64/300\n",
      "17/17 - 0s - loss: 0.0203 - val_loss: 0.0233\n",
      "Epoch 65/300\n",
      "17/17 - 0s - loss: 0.0208 - val_loss: 0.0230\n",
      "Epoch 66/300\n",
      "17/17 - 0s - loss: 0.0205 - val_loss: 0.0220\n",
      "Epoch 67/300\n",
      "17/17 - 0s - loss: 0.0204 - val_loss: 0.0238\n",
      "Epoch 68/300\n",
      "17/17 - 0s - loss: 0.0206 - val_loss: 0.0217\n",
      "Epoch 69/300\n",
      "17/17 - 0s - loss: 0.0215 - val_loss: 0.0226\n",
      "Epoch 70/300\n",
      "17/17 - 0s - loss: 0.0206 - val_loss: 0.0223\n",
      "Epoch 71/300\n",
      "17/17 - 0s - loss: 0.0213 - val_loss: 0.0221\n",
      "Epoch 72/300\n",
      "17/17 - 0s - loss: 0.0195 - val_loss: 0.0282\n",
      "Epoch 73/300\n",
      "17/17 - 0s - loss: 0.0213 - val_loss: 0.0239\n",
      "Epoch 74/300\n",
      "17/17 - 0s - loss: 0.0218 - val_loss: 0.0241\n",
      "Epoch 75/300\n",
      "17/17 - 0s - loss: 0.0198 - val_loss: 0.0218\n",
      "Epoch 76/300\n",
      "17/17 - 0s - loss: 0.0196 - val_loss: 0.0242\n",
      "Epoch 77/300\n",
      "17/17 - 0s - loss: 0.0199 - val_loss: 0.0211\n",
      "Epoch 78/300\n",
      "17/17 - 0s - loss: 0.0207 - val_loss: 0.0214\n",
      "Epoch 79/300\n",
      "17/17 - 0s - loss: 0.0193 - val_loss: 0.0224\n",
      "Epoch 80/300\n",
      "17/17 - 0s - loss: 0.0195 - val_loss: 0.0206\n",
      "Epoch 81/300\n",
      "17/17 - 0s - loss: 0.0196 - val_loss: 0.0206\n",
      "Epoch 82/300\n",
      "17/17 - 0s - loss: 0.0185 - val_loss: 0.0206\n",
      "Epoch 83/300\n",
      "17/17 - 0s - loss: 0.0184 - val_loss: 0.0207\n",
      "Epoch 84/300\n",
      "17/17 - 0s - loss: 0.0181 - val_loss: 0.0210\n",
      "Epoch 85/300\n",
      "17/17 - 0s - loss: 0.0190 - val_loss: 0.0203\n",
      "Epoch 86/300\n",
      "17/17 - 0s - loss: 0.0179 - val_loss: 0.0199\n",
      "Epoch 87/300\n",
      "17/17 - 0s - loss: 0.0184 - val_loss: 0.0221\n",
      "Epoch 88/300\n",
      "17/17 - 0s - loss: 0.0195 - val_loss: 0.0205\n",
      "Epoch 89/300\n",
      "17/17 - 0s - loss: 0.0173 - val_loss: 0.0216\n",
      "Epoch 90/300\n",
      "17/17 - 0s - loss: 0.0180 - val_loss: 0.0247\n",
      "Epoch 91/300\n",
      "17/17 - 0s - loss: 0.0206 - val_loss: 0.0206\n",
      "Epoch 92/300\n",
      "17/17 - 0s - loss: 0.0178 - val_loss: 0.0220\n",
      "Epoch 93/300\n",
      "17/17 - 0s - loss: 0.0177 - val_loss: 0.0203\n",
      "Epoch 94/300\n",
      "17/17 - 0s - loss: 0.0217 - val_loss: 0.0287\n",
      "Epoch 95/300\n",
      "17/17 - 0s - loss: 0.0190 - val_loss: 0.0192\n",
      "Epoch 96/300\n",
      "17/17 - 0s - loss: 0.0198 - val_loss: 0.0202\n",
      "Epoch 97/300\n",
      "17/17 - 0s - loss: 0.0197 - val_loss: 0.0241\n",
      "Epoch 98/300\n",
      "17/17 - 0s - loss: 0.0176 - val_loss: 0.0204\n",
      "Epoch 99/300\n",
      "17/17 - 0s - loss: 0.0196 - val_loss: 0.0240\n",
      "Epoch 100/300\n",
      "17/17 - 0s - loss: 0.0187 - val_loss: 0.0207\n",
      "Epoch 101/300\n",
      "17/17 - 0s - loss: 0.0169 - val_loss: 0.0186\n",
      "Epoch 102/300\n",
      "17/17 - 0s - loss: 0.0178 - val_loss: 0.0189\n",
      "Epoch 103/300\n",
      "17/17 - 0s - loss: 0.0169 - val_loss: 0.0186\n",
      "Epoch 104/300\n",
      "17/17 - 0s - loss: 0.0156 - val_loss: 0.0194\n",
      "Epoch 105/300\n",
      "17/17 - 0s - loss: 0.0165 - val_loss: 0.0184\n",
      "Epoch 106/300\n",
      "17/17 - 0s - loss: 0.0160 - val_loss: 0.0193\n",
      "Epoch 107/300\n",
      "17/17 - 0s - loss: 0.0156 - val_loss: 0.0192\n",
      "Epoch 108/300\n",
      "17/17 - 0s - loss: 0.0164 - val_loss: 0.0179\n",
      "Epoch 109/300\n",
      "17/17 - 0s - loss: 0.0160 - val_loss: 0.0188\n",
      "Epoch 110/300\n",
      "17/17 - 0s - loss: 0.0154 - val_loss: 0.0181\n",
      "Epoch 111/300\n",
      "17/17 - 0s - loss: 0.0161 - val_loss: 0.0178\n",
      "Epoch 112/300\n",
      "17/17 - 0s - loss: 0.0167 - val_loss: 0.0209\n",
      "Epoch 113/300\n",
      "17/17 - 0s - loss: 0.0152 - val_loss: 0.0191\n",
      "Epoch 114/300\n",
      "17/17 - 0s - loss: 0.0157 - val_loss: 0.0178\n",
      "Epoch 115/300\n",
      "17/17 - 0s - loss: 0.0161 - val_loss: 0.0175\n",
      "Epoch 116/300\n",
      "17/17 - 0s - loss: 0.0181 - val_loss: 0.0211\n",
      "Epoch 117/300\n",
      "17/17 - 0s - loss: 0.0148 - val_loss: 0.0178\n",
      "Epoch 118/300\n",
      "17/17 - 0s - loss: 0.0140 - val_loss: 0.0181\n",
      "Epoch 119/300\n",
      "17/17 - 0s - loss: 0.0141 - val_loss: 0.0151\n",
      "Epoch 120/300\n",
      "17/17 - 0s - loss: 0.0142 - val_loss: 0.0157\n",
      "Epoch 121/300\n",
      "17/17 - 0s - loss: 0.0149 - val_loss: 0.0169\n",
      "Epoch 122/300\n",
      "17/17 - 0s - loss: 0.0143 - val_loss: 0.0168\n",
      "Epoch 123/300\n",
      "17/17 - 0s - loss: 0.0149 - val_loss: 0.0183\n",
      "Epoch 124/300\n",
      "17/17 - 0s - loss: 0.0145 - val_loss: 0.0163\n",
      "Epoch 125/300\n",
      "17/17 - 0s - loss: 0.0141 - val_loss: 0.0161\n",
      "Epoch 126/300\n",
      "17/17 - 0s - loss: 0.0138 - val_loss: 0.0147\n",
      "Epoch 127/300\n",
      "17/17 - 0s - loss: 0.0132 - val_loss: 0.0153\n",
      "Epoch 128/300\n",
      "17/17 - 0s - loss: 0.0125 - val_loss: 0.0147\n",
      "Epoch 129/300\n",
      "17/17 - 0s - loss: 0.0123 - val_loss: 0.0162\n",
      "Epoch 130/300\n",
      "17/17 - 0s - loss: 0.0119 - val_loss: 0.0157\n",
      "Epoch 131/300\n",
      "17/17 - 0s - loss: 0.0110 - val_loss: 0.0149\n",
      "Epoch 132/300\n",
      "17/17 - 0s - loss: 0.0141 - val_loss: 0.0228\n",
      "Epoch 133/300\n",
      "17/17 - 0s - loss: 0.0139 - val_loss: 0.0182\n",
      "Epoch 134/300\n",
      "17/17 - 0s - loss: 0.0131 - val_loss: 0.0138\n",
      "Epoch 135/300\n",
      "17/17 - 0s - loss: 0.0094 - val_loss: 0.0145\n",
      "Epoch 136/300\n",
      "17/17 - 0s - loss: 0.0093 - val_loss: 0.0131\n",
      "Epoch 137/300\n",
      "17/17 - 0s - loss: 0.0096 - val_loss: 0.0135\n",
      "Epoch 138/300\n",
      "17/17 - 0s - loss: 0.0094 - val_loss: 0.0168\n",
      "Epoch 139/300\n",
      "17/17 - 0s - loss: 0.0105 - val_loss: 0.0152\n",
      "Epoch 140/300\n",
      "17/17 - 1s - loss: 0.0111 - val_loss: 0.0127\n",
      "Epoch 141/300\n",
      "17/17 - 0s - loss: 0.0088 - val_loss: 0.0135\n",
      "Epoch 142/300\n",
      "17/17 - 0s - loss: 0.0092 - val_loss: 0.0179\n",
      "Epoch 143/300\n",
      "17/17 - 0s - loss: 0.0096 - val_loss: 0.0142\n",
      "Epoch 144/300\n",
      "17/17 - 0s - loss: 0.0073 - val_loss: 0.0136\n",
      "Epoch 145/300\n",
      "17/17 - 0s - loss: 0.0074 - val_loss: 0.0187\n",
      "Epoch 146/300\n",
      "17/17 - 0s - loss: 0.0084 - val_loss: 0.0140\n",
      "Epoch 147/300\n",
      "17/17 - 0s - loss: 0.0072 - val_loss: 0.0115\n",
      "Epoch 148/300\n",
      "17/17 - 0s - loss: 0.0074 - val_loss: 0.0135\n",
      "Epoch 149/300\n",
      "17/17 - 0s - loss: 0.0066 - val_loss: 0.0121\n",
      "Epoch 150/300\n",
      "17/17 - 0s - loss: 0.0065 - val_loss: 0.0123\n",
      "Epoch 151/300\n",
      "17/17 - 0s - loss: 0.0066 - val_loss: 0.0134\n",
      "Epoch 152/300\n",
      "17/17 - 0s - loss: 0.0057 - val_loss: 0.0128\n",
      "Epoch 153/300\n",
      "17/17 - 0s - loss: 0.0072 - val_loss: 0.0137\n",
      "Epoch 154/300\n",
      "17/17 - 0s - loss: 0.0060 - val_loss: 0.0142\n",
      "Epoch 155/300\n",
      "17/17 - 0s - loss: 0.0064 - val_loss: 0.0124\n",
      "Epoch 156/300\n",
      "17/17 - 0s - loss: 0.0109 - val_loss: 0.0138\n",
      "Epoch 157/300\n",
      "17/17 - 0s - loss: 0.0069 - val_loss: 0.0118\n",
      "Epoch 158/300\n",
      "17/17 - 0s - loss: 0.0059 - val_loss: 0.0141\n",
      "Epoch 159/300\n",
      "17/17 - 0s - loss: 0.0067 - val_loss: 0.0116\n",
      "Epoch 160/300\n",
      "17/17 - 0s - loss: 0.0055 - val_loss: 0.0113\n",
      "Epoch 161/300\n",
      "17/17 - 0s - loss: 0.0058 - val_loss: 0.0104\n",
      "Epoch 162/300\n",
      "17/17 - 0s - loss: 0.0057 - val_loss: 0.0123\n",
      "Epoch 163/300\n",
      "17/17 - 0s - loss: 0.0043 - val_loss: 0.0149\n",
      "Epoch 164/300\n",
      "17/17 - 0s - loss: 0.0053 - val_loss: 0.0108\n",
      "Epoch 165/300\n",
      "17/17 - 0s - loss: 0.0054 - val_loss: 0.0149\n",
      "Epoch 166/300\n",
      "17/17 - 0s - loss: 0.0078 - val_loss: 0.0134\n",
      "Epoch 167/300\n",
      "17/17 - 0s - loss: 0.0062 - val_loss: 0.0114\n",
      "Epoch 168/300\n",
      "17/17 - 0s - loss: 0.0060 - val_loss: 0.0124\n",
      "Epoch 169/300\n",
      "17/17 - 0s - loss: 0.0043 - val_loss: 0.0117\n",
      "Epoch 170/300\n",
      "17/17 - 0s - loss: 0.0042 - val_loss: 0.0148\n",
      "Epoch 171/300\n",
      "17/17 - 0s - loss: 0.0065 - val_loss: 0.0114\n",
      "Epoch 172/300\n",
      "17/17 - 0s - loss: 0.0068 - val_loss: 0.0110\n",
      "Epoch 173/300\n",
      "17/17 - 0s - loss: 0.0050 - val_loss: 0.0107\n",
      "Epoch 174/300\n",
      "17/17 - 0s - loss: 0.0042 - val_loss: 0.0103\n",
      "Epoch 175/300\n",
      "17/17 - 0s - loss: 0.0063 - val_loss: 0.0125\n",
      "Epoch 176/300\n",
      "17/17 - 0s - loss: 0.0048 - val_loss: 0.0160\n",
      "Epoch 177/300\n",
      "17/17 - 0s - loss: 0.0042 - val_loss: 0.0160\n",
      "Epoch 178/300\n",
      "17/17 - 0s - loss: 0.0038 - val_loss: 0.0117\n",
      "Epoch 179/300\n",
      "17/17 - 0s - loss: 0.0039 - val_loss: 0.0121\n",
      "Epoch 180/300\n",
      "17/17 - 0s - loss: 0.0030 - val_loss: 0.0118\n",
      "Epoch 181/300\n",
      "17/17 - 0s - loss: 0.0035 - val_loss: 0.0144\n",
      "Epoch 182/300\n",
      "17/17 - 0s - loss: 0.0032 - val_loss: 0.0122\n",
      "Epoch 183/300\n",
      "17/17 - 0s - loss: 0.0044 - val_loss: 0.0127\n",
      "Epoch 184/300\n",
      "17/17 - 0s - loss: 0.0033 - val_loss: 0.0129\n",
      "Epoch 185/300\n",
      "17/17 - 0s - loss: 0.0034 - val_loss: 0.0120\n",
      "Epoch 186/300\n",
      "17/17 - 0s - loss: 0.0032 - val_loss: 0.0132\n",
      "Epoch 187/300\n",
      "17/17 - 0s - loss: 0.0033 - val_loss: 0.0128\n",
      "Epoch 188/300\n",
      "17/17 - 0s - loss: 0.0028 - val_loss: 0.0123\n",
      "Epoch 189/300\n",
      "17/17 - 0s - loss: 0.0031 - val_loss: 0.0129\n",
      "Epoch 190/300\n",
      "17/17 - 0s - loss: 0.0030 - val_loss: 0.0129\n",
      "Epoch 191/300\n",
      "17/17 - 0s - loss: 0.0033 - val_loss: 0.0151\n",
      "Epoch 192/300\n",
      "17/17 - 0s - loss: 0.0038 - val_loss: 0.0139\n",
      "Epoch 193/300\n",
      "17/17 - 0s - loss: 0.0038 - val_loss: 0.0118\n",
      "Epoch 194/300\n",
      "17/17 - 0s - loss: 0.0035 - val_loss: 0.0130\n",
      "Epoch 195/300\n",
      "17/17 - 0s - loss: 0.0042 - val_loss: 0.0152\n",
      "Epoch 196/300\n",
      "17/17 - 0s - loss: 0.0044 - val_loss: 0.0104\n",
      "Epoch 197/300\n",
      "17/17 - 0s - loss: 0.0043 - val_loss: 0.0114\n",
      "Epoch 198/300\n",
      "17/17 - 0s - loss: 0.0030 - val_loss: 0.0104\n",
      "Epoch 199/300\n",
      "17/17 - 0s - loss: 0.0029 - val_loss: 0.0126\n",
      "Epoch 200/300\n",
      "17/17 - 0s - loss: 0.0033 - val_loss: 0.0146\n",
      "Epoch 201/300\n",
      "17/17 - 0s - loss: 0.0033 - val_loss: 0.0123\n"
     ]
    }
   ],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    min_delta = 0.001,\n",
    "    patience = 40,\n",
    "    restore_best_weights = True\n",
    ")\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=6, validation_split=0.3, callbacks=[early_stopping], epochs=300, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2a83968d1c0>"
      ]
     },
     "execution_count": 677,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJUAAAJcCAYAAABAA5WYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAEAAElEQVR4nOzdd5xcZdn/8c89ZUu2l/S26b2RhJCE0HsVBAVFQYqCYuMRRUVEfXh+FkRUFBUREEFE6dJ7QicJgfTe+26215md8/vjnrN1Zne2JWeT7/v14nV2Zs6cuWeyROfLdV23cRwHERERERERERGRjvAd6gWIiIiIiIiIiEjvo1BJREREREREREQ6TKGSiIiIiIiIiIh0mEIlERERERERERHpMIVKIiIiIiIiIiLSYQqVRERERERERESkwxQqiYiIyCFljHneGHO5B9ZxqzHmHz1w3SuMMW81uV1hjBmZyLmdeK0e+SyNMfcbY/63u68rIiIivVvgUC9AREREeh9jTEWTm32AWqA+evsrjuM8lOi1HMc5szvX1t2MMYOBrcA4x3E2tnjsCWCj4zjfSfR6juOkd9O6bgVGO45zWZNre/qzFBERkcOLKpVERESkwxzHSXf/AbYB5za5ryFQMsb0+v+A5TjOTuBV4AtN7zfG5AJnAQ8cinWJiIiIHGoKlURERKTbGGNOMMbsMMZ8zxizB7jPGJNjjPmvMWa/MaY4+vOQJs95wxhzdfTnK4wxbxljbo+eu9kYE7f6xhhzkzFmozGm3BizyhhzQZPH2ryWMWaEMebN6HNfBvLbeGsP0CJUAi4BVjmOs7ytdcRYs2OMGR39Oc8Y87QxpswY8wEwqsW5vzXGbI8+vsQYsyB6/xnAD4DPRtvpPo7xWfqMMTcbY7YaY/YZY/5ujMmKPlYQXcflxphtxphCY8wP23j/Ld/DNcaYDcaYA9H1D4reb4wxv4m+XpkxZrkxZnL0sbOin025MWanMeY7Ta53jjFmmTGmxBjzjjFmapPHvhc9v9wYs9YYc3Ki6xQREZGepVBJREREutsAIBcYDnwZ+/837oveHgZUA3e18fw5wFpsyPNL4F5jjIlz7kZgAZAF/AT4hzFmYILXehhYEn3sZ0Bbs4ieAPKNMcc2ue8LNFYptbeOeP4A1AADgSuj/zT1ITAd+3k+DPzbGJPiOM4LwP8B/4pWh02Lce0rov+cCIwE0mn9uR8LjANOBm4xxkxob8HGmJOA/wd8JrrurcAj0YdPA44DxmI/i88ARdHH7sW2RmYAk4HXotebAfwN+AqQB/wZeNoYk2yMGQdcD8yOPu90YEt7axQREZGDQ6GSiIiIdLcI8GPHcWodx6l2HKfIcZzHHMepchynHLgNOL6N5291HOcex3HqsaHNQKB/rBMdx/m34zi7HMeJOI7zL2A9cHR71zLGDANmAz+KrnMh8Ey8BTmOUw38G/gigDFmDDATG/Qkso5WjDF+4NPALY7jVDqOs4IWrXSO4/wj+vmFHcf5NZCMDYES8XngDsdxNjmOUwF8H7ikRUviT6J/Rh8DHwOxwqlY1/2b4zhLHcepjV53rjGmAAgBGcB4wDiOs9pxnN3R54WAicaYTMdxih3HWRq9/8vAnx3Hed9xnHrHcR7Azug6BjunKzn6vKDjOFtazrUSERGRQ0ehkoiIiHS3/Y7j1Lg3jDF9jDF/jrZhlQELgexoqBLLHvcHx3Gqoj/GHG5tjPlik7apEmwFTNM2tnjXGgQUO45T2eTcre28rweAi40xKdgqpRcdx9mX4Dpi6YvdNGV7vDUYY75jjFltjCmNXjcrgeu6BrW43tbo6zUN6PY0+bmKOJ9zW9eNBlZFwGDHcV7DVkP9AdhnjPmLMSYzeuqnsTOotkbbDudG7x8O/I/72UXf51BgkOM4G4BvAbdGr/eI22onIiIih55CJREREeluTovb/4OtrpnjOE4mtj0KIF5LW0KMMcOBe7DtUXmO42QDKxK87m4gxxiT1uS+Ye085y3gAHA+cBnRqqIurGM/EMYGKK3WEJ2f9F1sC1lO9LqlTa7b8nNuaRc2sGl67TCwt53ntafZdaOfYR6wE8BxnN85jjMTmIhtg7sxev+HjuOcD/QDngQejV5iO3Cb4zjZTf7p4zjOP6PPe9hxnGOjr+kAv+ji+kVERKSbKFQSERGRnpaBnaNUYuyOaT/upuumYUOG/QDGmC9hK4Ta5TjOVmAx8BNjTFJ0VtK57TzHAf6ODTWyaWyX69Q6oi15jwO3Rqu5JtJ8rlMGNgTaDwSMMbcAmU0e3wsUGGPi/f+5fwLfNnYgeTqNM5jC7a2tHf8EvmSMmW6MSY5e933HcbYYY2YbY+YYY4JAJXZeVCT6GX/eGJPlOE4IKMO2SYIN5K6NPs8YY9KMMWcbYzKMMeOMMSdFX6cG+3sUabUiEREROSQUKomIiEhPuxNIBQqB94AXuuOijuOsAn4NvIsNWKYAb3fgEp/DDvI+gA26/p7Ac/6Orfj5V3SeUFfXcT225WwPcD92oLnrRexntQ7bblZD81a5f0ePRcaYpbT2N+BBbLvh5ujzv57guuJyHOcV4EfAY9iKr1HYnfDAhl73AMXRNRcBv4o+9gVgS7QF8lrsbCYcx1kMXINtmysGNmAHjIOdp/Rz7O/OHmyV0/e7+h5ERESkexj7H91EREREREREREQSp0olERERERERERHpMIVKIiIiIiIiIiLSYQqVRERERERERESkwxQqiYiIiIiIiIhIhwUO9QK6S35+vlNQUHColyEiIiIiIiIicthYsmRJoeM4fWM9dtiESgUFBSxevPhQL0NERERERERE5LBhjNka7zG1v4mIiIiIiIiISIcpVBIRERERERERkQ5TqCQiIiIiIiIiIh122MxUEhERERERERFvCYVC7Nixg5qamkO9FGlHSkoKQ4YMIRgMJvwchUoiIiIiIiIi0iN27NhBRkYGBQUFGGMO9XIkDsdxKCoqYseOHYwYMSLh56n9TURERERERER6RE1NDXl5eQqUPM4YQ15eXocryhQqiYiIiIiIiEiPUaDUO3Tmz0mhkoiIiIiIiIiIdJhCJRERERERERE5LBUVFTF9+nSmT5/OgAEDGDx4cMPturq6Np+7ePFivvGNb3To9QoKCigsLOzKknsVDeoWERERERERkcNSXl4ey5YtA+DWW28lPT2d73znOw2Ph8NhAoHY0cisWbOYNWvWwVhmr6VKJRERERERERE5YlxxxRVce+21zJkzh+9+97t88MEHzJ07lxkzZjBv3jzWrl0LwBtvvME555wD2EDqyiuv5IQTTmDkyJH87ne/a/d17rjjDiZPnszkyZO58847AaisrOTss89m2rRpTJ48mX/9618A3HTTTUycOJGpU6c2C728TpVKIiIiIiIiItLjfvLMSlbtKuvWa04clMmPz53U4eft2LGDd955B7/fT1lZGYsWLSIQCPDKK6/wgx/8gMcee6zVc9asWcPrr79OeXk548aN47rrriMYDMa8/pIlS7jvvvt4//33cRyHOXPmcPzxx7Np0yYGDRrEs88+C0BpaSlFRUU88cQTrFmzBmMMJSUlHX4/h4oqlURERERERETkiHLxxRfj9/sBG+xcfPHFTJ48mW9/+9usXLky5nPOPvtskpOTyc/Pp1+/fuzduzfu9d966y0uuOAC0tLSSE9P58ILL2TRokVMmTKFl19+me9973ssWrSIrKwssrKySElJ4aqrruLxxx+nT58+PfKee4IqlURERERERESkx3WmoqinpKWlNfz8ox/9iBNPPJEnnniCLVu2cMIJJ8R8TnJycsPPfr+fcDjc4dcdO3YsS5cu5bnnnuPmm2/m5JNP5pZbbuGDDz7g1Vdf5T//+Q933XUXr732WoevfSioUklEREREREREjlilpaUMHjwYgPvvv79brrlgwQKefPJJqqqqqKys5IknnmDBggXs2rWLPn36cNlll3HjjTeydOlSKioqKC0t5ayzzuI3v/kNH3/8cbes4WBQpZKIiIiIiIiIHLG++93vcvnll/O///u/nH322d1yzaOOOoorrriCo48+GoCrr76aGTNm8OKLL3LjjTfi8/kIBoPcfffdlJeXc/7551NTU4PjONxxxx3dsoaDwTiOc6jX0C1mzZrlLF68+FAvQ0RERERERESiVq9ezYQJEw71MiRBsf68jDFLHMeZFet8tb+JiIiIiIiIiEiHKVQSEREREREREZEOU6gkIiIiIiIiIiIdplBJREREREREREQ6TKGSiIiIiIiIiIh0mEIlj/nhE8u59sElh3oZIiIiIiIiIiJtUqjkMfvKa9l6oOpQL0NERERERESk1zvxxBN58cUXm9135513ct1118V9zgknnMDixYsBOOussygpKWl1zq233srtt9/e5ms/+eSTrFq1quH2LbfcwiuvvNKB1cf2xhtvcM4553T5Ot1BoZLHBP2GUH3kUC9DREREREREpNe79NJLeeSRR5rd98gjj3DppZcm9PznnnuO7OzsTr12y1Dppz/9KaecckqnruVVCpU8Juj3EVaoJCIiIiIiItJlF110Ec8++yx1dXUAbNmyhV27drFgwQKuu+46Zs2axaRJk/jxj38c8/kFBQUUFhYCcNtttzF27FiOPfZY1q5d23DOPffcw+zZs5k2bRqf/vSnqaqq4p133uHpp5/mxhtvZPr06WzcuJErrriC//znPwC8+uqrzJgxgylTpnDllVdSW1vb8Ho//vGPOeqoo5gyZQpr1qxp8/0dOHCAT33qU0ydOpVjjjmGTz75BIA333yT6dOnM336dGbMmEF5eTm7d+/muOOOY/r06UyePJlFixZ17cMFAl2+gnSrgM9HqN451MsQERERERER6V7P3wR7lnfvNQdMgTN/Hvfh3Nxcjj76aJ5//nnOP/98HnnkET7zmc9gjOG2224jNzeX+vp6Tj75ZD755BOmTp0a8zpLlizhkUceYdmyZYTDYY466ihmzpwJwIUXXsg111wDwM0338y9997L17/+dc477zzOOeccLrroombXqqmp4YorruDVV19l7NixfPGLX+Tuu+/mW9/6FgD5+fksXbqUP/7xj9x+++389a9/jfv+fvzjHzNjxgyefPJJXnvtNb74xS+ybNkybr/9dv7whz8wf/58KioqSElJ4S9/+Qunn346P/zhD6mvr6eqquujd1Sp5DFJAbW/iYiIiIiIiHSXpi1wTVvfHn30UY466ihmzJjBypUrm7WqtbRo0SIuuOAC+vTpQ2ZmJuedd17DYytWrGDBggVMmTKFhx56iJUrV7a5nrVr1zJixAjGjh0LwOWXX87ChQsbHr/wwgsBmDlzJlu2bGnzWm+99RZf+MIXADjppJMoKiqirKyM+fPnc8MNN/C73/2OkpISAoEAs2fP5r777uPWW29l+fLlZGRktHntRKhSyWNspZJCJRERERERETnMtFFR1JPOP/98vv3tb7N06VKqqqqYOXMmmzdv5vbbb+fDDz8kJyeHK664gpqamk5d/4orruDJJ59k2rRp3H///bzxxhtdWm9ycjIAfr+fcDjcqWvcdNNNnH322Tz33HPMnz+fF198keOOO46FCxfy7LPPcsUVV3DDDTfwxS9+sUtrVaWSx9iZSmp/ExEREREREekO6enpnHjiiVx55ZUNVUplZWWkpaWRlZXF3r17ef7559u8xnHHHceTTz5JdXU15eXlPPPMMw2PlZeXM3DgQEKhEA899FDD/RkZGZSXl7e61rhx49iyZQsbNmwA4MEHH+T444/v1HtbsGBBw2u+8cYb5Ofnk5mZycaNG5kyZQrf+973mD17NmvWrGHr1q3079+fa665hquvvpqlS5d26jWbUqWSxwT9hjpVKomIiIiIiIh0m0svvZQLLrigoQ1u2rRpzJgxg/HjxzN06FDmz5/f5vOPOuooPvvZzzJt2jT69evH7NmzGx772c9+xpw5c+jbty9z5sxpCJIuueQSrrnmGn73u981DOgGSElJ4b777uPiiy8mHA4ze/Zsrr322k69r1tvvZUrr7ySqVOn0qdPHx544AEA7rzzTl5//XV8Ph+TJk3izDPP5JFHHuFXv/oVwWCQ9PR0/v73v3fqNZsyjnN4VMXMmjXLWbx48aFeRpfd/uJa7n5zIxv/76xDvRQRERERERGRLlm9ejUTJkw41MuQBMX68zLGLHEcZ1as89X+5jEBv6E+4hCJHB5hn4iIiIiIiIgcnhQqeUzQb/9IQhG1wImIiIiIiIiIdylU8pig3wAQ0rBuEREREREROQwcLmN3Dned+XNSqOQxDZVKYVUqiYiIiIiISO+WkpJCUVGRgiWPcxyHoqIiUlJSOvQ87f7mMQG1v4mIiIiIiMhhYsiQIezYsYP9+/cf6qVIO1JSUhgyZEiHnqNQyWOS1P4mIiIiIiIih4lgMMiIESMO9TKkh6j9zWPc9rdwvSqVRERERERERMS7FCp5TEP7m0IlEREREREREfEwhUoeo/Y3EREREREREekNFCp5TMCnSiURERERERER8T6FSh4TDLihkiqVRERERERERMS7FCp5TNDntr+pUklEREREREREvEuhkse4lUphVSqJiIiIiIiIiIcpVPKYgCqVRERERERERKQXUKjkMUG/BnWLiIiIiIiIiPcpVPKYxlBJ7W8iIiIiIiIi4l0KlTwm6Lftb+GIKpVERERERERExLsUKnmMW6lUF1aoJCIiIiIiIiLepVDJY9xQKRxR+5uIiIiIiIiIeJdCJY8J+LX7m4iIiIiIiIh4n0Ilj9GgbhERERERERHpDRQqeUxQlUoiIiIiIiIi0gsoVPKYhkolDeoWEREREREREQ9TqOQxAV+0UkmDukVERERERETEwxQqeYwxhqDfqP1NRERERERERDxNoZIHBf0+wgqVRERERERERMTDFCp5UMBntPubiIiIiIiIiHiaQiUPSgr41P4mIiIiIiIiIp6mUMmDAj6FSiIiIiIiIiLibQqVPCgYMITV/iYiIiIiIiIiHqZQyYOCPh91qlQSEREREREREQ9TqORBdvc3VSqJiIiIiIiIiHcpVPKggN9oppKIiIiIiIiIeJpCJQ8K+n2EIqpUEhERERERERHvUqjkQUG/IRRWpZKIiIiIiIiIeJdCJQ8K+n2EIwqVRERERERERMS7FCp5UMDvo06DukVERERERETEwxQqeVCS3xDWoG4RERERERER8TCFSh4U8Pm0+5uIiIiIiIiIeJpCJQ8KBnyE1f4mIiIiIiIiIh6mUMmDgj5DnSqVRERERERERMTDFCp5UNCv9jcRERERERER8TaFSh4UDBi1v4mIiIiIiIiIpylU8qCAz6f2NxERERERERHxNIVKHpSkQd0iIiIiIiIi4nEKlTwo4DOaqSQiIiIiIiIinqZQyYOCfh/hiIPjqFpJRERERERERLxJoZIHBf0GgJBa4ERERERERETEoxQqeVDQb/9YwhG1wImIiIiIiIiINylU8qBANFQKhVWpJCIiIiIiIiLe1KOhkjHmDGPMWmPMBmPMTTEeTzbG/Cv6+PvGmILo/QXGmGpjzLLoP3/qyXV6TZLb/qZKJRERERERERHxqEBPXdgY4wf+AJwK7AA+NMY87TjOqianXQUUO44z2hhzCfAL4LPRxzY6jjO9p9bnZQ2VStoBTkREREREREQ8qicrlY4GNjiOs8lxnDrgEeD8FuecDzwQ/fk/wMnGGNODa+oVGmYqaVC3iIiIiIiIiHhUT4ZKg4HtTW7viN4X8xzHccJAKZAXfWyEMeYjY8ybxpgFsV7AGPNlY8xiY8zi/fv3d+/qDyF397c6VSqJiIiIiIiIiEd5dVD3bmCY4zgzgBuAh40xmS1PchznL47jzHIcZ1bfvn0P+iJ7iiqVRERERERERMTrejJU2gkMbXJ7SPS+mOcYYwJAFlDkOE6t4zhFAI7jLAE2AmN7cK2eEvBFB3WrUklEREREREREPKonQ6UPgTHGmBHGmCTgEuDpFuc8DVwe/fki4DXHcRxjTN/ooG+MMSOBMcCmHlyrpwQDGtQtIiIiIiIiIt7WY7u/OY4TNsZcD7wI+IG/OY6z0hjzU2Cx4zhPA/cCDxpjNgAHsMETwHHAT40xISACXOs4zoGeWqvXBH1uqKT2NxERERERERHxph4LlQAcx3kOeK7Ffbc0+bkGuDjG8x4DHuvJtXmZO6g7rEolEREREREREfEorw7qPqK57W/a/U1EREREREREvEqhkgep/U1EREREREREvE6hkgcFA2p/ExERERERERFvU6jkQQGf2t9ERERERERExNsUKnlQkt/+sYTV/iYiIiIiIiIiHqVQyYMC0d3fQqpUEhERERERERGPUqjkQcFopVIookolEREREREREfEmhUoeFHQrlcKqVBIRERERERERb1Ko5EFupVI4olBJRERERERERLxJoZIHNc5UUvubiIiIiIiIiHiTQiUPCvqiM5U0qFtEREREREREPEqhkgf5fAa/zyhUEhERERERERHPUqjkUUG/Iaz2NxERERERERHxKIVKHhX0+ahTpZKIiIiIiIiIeJRCJY8KBnyqVBIRERERERERz1Ko5FEBzVQSEREREREREQ9TqORRQb+PkCqVRERERERERMSjFCp5VFLAp0olEREREREREfEshUoeFfAZwhGFSiIiIiIiIiLiTQqVPCro91EXVvubiIiIiIiIiHhT4FAvQFp46WaoLCLo/7za30RERERERETEs1Sp5DUHNsPujwn6fWp/ExERERERERHPUqjkNYEUCFcT8BtCan8TEREREREREY9SqOQ1wRQI1RD0+wipUklEREREREREPEqhktcEUiFcbUMlzVQSEREREREREY9SqOQ1DZVKhnC92t9ERERERERExJsUKnlNtFIp4DPUqVJJRERERERERDxKoZLXBJIB6OMLq1JJRERERERERDxLoZLXBFMBSDUhzVQSEREREREREc9SqOQ1gRQAUn0hQqpUEhERERERERGPChzqBUgLbqUSdYTqzSFejIiIiIiIiIhIbKpU8ppopVKKCRFW+5uIiIiIiIiIeJRCJa+JViqloPY3EREREREREfEuhUpe485UMrWEIhEcR8GSiIiIiIiIiHiPQiWviVYqJRPCcaA+olBJRERERERERLxHoZLXBJIBSKYOgLBCJRERERERERHxIIVKXhOIVio5tQDUaVi3iIiIiIiIiHiQQiWvCdqZSg2VShrWLSIiIiIiIiIepFDJa6KVSkEnBEBIlUoiIiIiIiIi4kEKlbwmWqmURLT9LaxQSURERERERES8R6GS10QrlZIiNlTSoG4RERERERER8SKFSl7jD4LxEYwO6lb7m4iIiIiIiIh4kUIlrzEGAqkEHTuoW6GSiIiIiIiIiHiRQiUvCiQTiLiVSmp/ExERERERERHvUajkRcHUhlAprEolEREREREREfEghUpeFEghUB/d/U2hkoiIiIiIiIh4kEIlLwqmEnDcSiW1v4mIiIiIiIiI9yhU8qJACv567f4mIiIiIiIiIt6lUMmLgqn46msADeoWEREREREREW9SqORFqlQSEREREREREY9TqORFwZSGSqVwRKGSiIiIiIiIiHiPQiUvCjRpfwur/U1EREREREREvEehkhcFkjHhaKikSiURERERERER8SCFSl4UTG0MlcIKlURERERERETEexQqeVEgBRMd1B2OqP1NRERERERERLxHoZIXNVQqOdRp9zcRERERERER8SCFSl4USAEgmRDhelUqiYiIiIiIiIj3KFTyomAqAH1MHSFVKomIiIiIiIiIBylU8qJopVK6P6z2NxERERERERHxJIVKXhStVEr3h9X+JiIiIiIiIiKepFDJiwLJAKT51P4mIiIiIiIiIt6kUMmLArZSKc0XJqRKJRERERERERHxIIVKXhS0M5XSfCFVKomIiIiIiIiIJylU8qJopVIfX5iwQiURERERERER8SCFSl4UrVTqY+rU/iYiIiIiIiIinqRQyYsaKpXU/iYiIiIiIiIi3qRQyYuilUqpRqGSiIiIiIiIiHiTQiUvilYqpZo6whG1v4mIiIiIiIiI9yhU8qImlUp1YVUqiYiIiIiIiIj3KFTyooAbKqlSSURERERERES8SaGSF/mDYPwko5lKIiIiIiIiIuJNCpW8KphKiqkjVK9KJRERERERERHxHoVKXhVIIUWVSiIiIiIiIiLiUQqVvCqYSpJTS1ihkoiIiIiIiIh4kEIlrwqkkIza30RERERERETEmxQqeVUwhSSnTu1vIiIiIiIiIuJJCpW8KpBKMrUKlURERERERETEkxQqeVUgmWBE7W8iIiIiIiIi4k0KlbwqmEoQtb+JiIiIiIiIiDcpVPKqQArBiNrfRERERERERMSbFCp5VTCVYKSOiAP1EbXAiYiIiIiIiIi3KFTyqkAKAacGQNVKIiIiIiIiIuI5CpW8KphKIFILQFiVSiIiIiIiIiLiMT0aKhljzjDGrDXGbDDG3BTj8WRjzL+ij79vjClo8fgwY0yFMeY7PblOTwqkEKi3oVIofBAqlfavg9sGwoFNPf9aIiIiIiIiItLr9VioZIzxA38AzgQmApcaYya2OO0qoNhxnNHAb4BftHj8DuD5nlqjpwVT8TshfEQIRQ5CqHRgI4SqFCqJiIiIiIiISEJ6slLpaGCD4zibHMepAx4Bzm9xzvnAA9Gf/wOcbIwxAMaYTwGbgZU9uEbvCiQDkEwdofqD0P5WV2mPtRU9/1oiIiIiIiIi0uv1ZKg0GNje5PaO6H0xz3EcJwyUAnnGmHTge8BP2noBY8yXjTGLjTGL9+/f320L94RAKgDJhAgfjEHdoSp7dMMlEREREREREZE2eHVQ963AbxzHabNsxnGcvziOM8txnFl9+/Y9OCs7WIIpAKRQd3B2f6tTqCQiIiIiIiIiiQv04LV3AkOb3B4SvS/WOTuMMQEgCygC5gAXGWN+CWQDEWNMjeM4d/Xger0lWqmUYg5S+1tDpVJ5z7+WiIiIiIiIiPR6PRkqfQiMMcaMwIZHlwCfa3HO08DlwLvARcBrjuM4wAL3BGPMrUDFERUoQZNKpdDBqVRS+5uIiIiIiIiIdECPhUqO44SNMdcDLwJ+4G+O46w0xvwUWOw4ztPAvcCDxpgNwAFs8CTQWKl00AZ1R0MlDeoWERERERERkQT0ZKUSjuM8BzzX4r5bmvxcA1zczjVu7ZHFeZ1bqWQO0kylULRCSZVKIiIiIiIiIpIArw7qliaVSuGDMlOp2h7rVKkkIiIiIiIiIu1TqORV0Uql5IO2+5tbqaRQSURERERERETap1DJqwLuoO6D1f6mQd0iIiIiIiIikjiFSl4VDZWSTejgDupWpZKIiIiIiIiIJEChklcFm+7+dhAHdWv3NxERERERERFJgEIlrzro7W/uoG61v4mIiIiIiIhI+xQqeVVDpZLa30RERERERETEexQqeZXPj+MLkmLqCEcOYvtbqAoi9T3/eiIiIiIiIiLSqylU8rJACinUURc+CKFSXRX4AvZndyc4EREREREREZE4FCp5WTCVFOoIR3q4/a0+BJEQpPWztzWsW0RERERERETaoVDJywLJJJs6Qj1dqeRWJqX3tUcN6xYRERERERGRdihU8rJgKsmECPV0pZI7pDu9f/S2KpVEREREREREpG0KlTzMBFLoY0KE6g9SpZLb/qZQSURERERERETaoVDJy4KppJo6wj0dKrntbmn5zW+LiIiIiIiIiMShUMnLAimkmBCh+h5ufwtV26Pa30REREREREQkQQqVvCyYSip1B6H9LVqZlK7d30REREREREQkMQqVvCyQQoo5CKGSO6g7Tbu/iYiIiIiIiEhiFCp5WTCVZOoI93j7m7v7mwZ1i4iIiIiIiEhiFCp5WSCFZOqoO1i7vyVngj9ZoZKIiIiIiIiItEuhkpcFUkh2Qj1fqeS2vyX1gaQ0tb+JiIiIiIiISLsUKnlZMIWkgzmoO5gGSeka1C0iIiIiIiIi7VKo5GWBVIKECdeHe/Z16qrAF4BAEiSnq/1NRERERERERNqlUMnLgikAmFBNz75OqBqCfezPan8TERERERERkQQoVPKyQCoAvvrqnn2dUGWTUEmVSiIiIiIiIiLSPoVKXuZWKtXX9uzr1FXZId2gSiURERERERERSYhCJS9zK5XCPd3+VmWHdIMqlUREREREREQkIQqVvCxaqeSP9HCoVFfZWKmUrN3fRERERERERKR9CpW8LGBDJV99Xc++TqgagrYqSu1vIiIiIiIiIpIIhUpeFg2V/PUHuf2tvhbqQz37miIiIiIiIiLSqylU8rJo9VDgYLa/JaVH71MLnIiIiIiIiIjEp1DJy6KVSoFIT7e/VUGwye5voBY4EREREREREWmTQiUvO1iVSqHqxjDJPWpYt4iIiIiIiIi0QaGSl0UrlYI9WankOLYqyR3UnZxhj6pUEhEREREREZE2KFTysoZKpdqee436OnDqY7S/qVJJREREREREROJTqORl0UqlJKcWx3F65jXciqSkJru/gUIlEREREREREWmTQiUvi4ZKyYQI1fdQqBSqssdgy93f1P4mIiIiIiIiIvEpVPIyn496EyTF1BGORHrmNULV9qj2NxERERERERHpAIVKHhf2J5NCHaFwT7e/RUOl5GilknZ/ExEREREREZE2KFTyuHpfCsnUEeqxSqUW7W/uUe1vIiIiIiIiItIGhUoeF/Enk2JChOp7KFSqi4ZKbtubz2+DJbW/iYiIiIiIiEgbFCp5XL0/hRTqCB+sQd1gh3UrVBIRERERERGRNihU8jgnYEOlup6qVGoIlVIb70tKU/ubiIiIiIiIiLRJoZLHRaKVSj3X/uYO6k5rvC85XYO6RURERERERKRNCpU8zgmkkGxCan8TEREREREREU9RqORxTiC5Z9vfWg7qdn9W+5uIiIiIiIiItEGhktcFDsKgbn+y3fXNpUolEREREREREWmHQiWPcwKpJJtQz81UClU1H9IN0VBJlUoiIiIiIiIiEp9CJa8L9vSg7qrmrW8QbX87AiqVSnfAyz+GSA99tiIiIiIiIiKHMYVKHmcCqdFQqafa3yqbD+mGxt3fnB56Ta9Y+zy8fSeUbDnUKxERERERERHpdRQqeV3QnanUU+1v1ZDUIlRKSgOnHsK1PfOaXlFTEj2WHdJliIiIiIiIiPRGCpU8ziSlEjARQqEeCnjqYlQqJaVHHzvMW+BqSu2xVqGSiIiIiIiISEcpVPI4X8AGPk5PhUqhKoVKqlQSERERERER6TCFSh7nS0oGIFJX1TMvUFcVu/0NDv8d4FSpJCIiIiIiItJpCpU8zhetInLCNT3zAqFKCLbY/S05WqlUe7hXKpU1P4qIiIiIiIhIwhQqeZw/KRUAp666Z14g5qDuI6z9TZVKIiIiIiIiIh2mUMnjfMk2VCLcQ6FSXayZSkdY+5t7FBEREREREZGEKVTyOL9bRRTqgfY3x9Gg7qZHEREREREREUmYQiWPC/RkpVKoGnDaaH87jCuVHEftbyIiIiIiIiJdoFDJ40zQDZV6oFIpFA2qWg7qbmh/O4wrlcI1EAnZnzWoW0RERERERKTDFCp5XcCGSiZc2/3XDkUrkVpWKgVTwfgO793fmra8qVJJREREREREpMMUKnldIBkA0xPtb3VV9uhWQ7mMsS1wh3P7mxsqGZ8qlUREREREREQ6QaGS1wXdSqWeaH+LhkYt29/AtsDVlXf/a3qFGyplDFKlkoiIiIiIiEgnKFTyukAKAP76Hmh/cyuVWra/wZFTqZQ9VJVKIiIiIiIiIp2gUMnr3Eql+oM4qBuilUpHQKiUNdTurFcfOrTrEREREREREellFCp5XU9WKjW0v6W2fiw548gY1J01JHpb1UoiIiIiIiIiHaFQyeuMoZYk/D1RqdRm+1sa1B0BoVL2UHusLY1/roiIiIiIiIi0olCpF6gzSfgjLSqV9q6EZf/s2oVD7u5vR2j7mz8J0vtHbx/BlUrrXoS7joZwD1TDiYiIiIiIyGFLoVIvUGeSCTStVApVwyOfh6evh/pw5y8cam9Q92FeqZSSBcmZ9vaRvAPczqVQuBbKdh7qlYiIiIiIiEgvolCpF6gzSfidusY73vwFFG+GSBhKt3fhwtFQKRBjptKRsPtbShakREOlI7lSqabEHsv3HNJliIiIiIiISO+iUKkXCJskgu6g7j3L4e3fQb+J9nbx5s5fOFRpAyVfjF8Dt/0tEun89b2sptRWKalSCaqL7bF896Fdh4iIiIiIiPQqCpV6gZBJJuDUQqQenv4GpObAhX+xDx7oQqhUVxW79Q0gOR1wGlvkDje1ZdFKpSx7+0iuVKousUdVKomIiIiIiEgHKFTqBcK+ZIKRWvjgL7BrKZz5C+g3CfzJXaxUqoo9pBtspRIcvi1wDTOVMuxtVSqpUklEREREREQ6RKFSLxDyJdO/fi+8+jMYfSpM/rRtWcsZDsVbunDhNiqVktLt8XAd1u2GSv4gBPvY20eqhplKew/pMkRERERERKR3UajUC4R9yfR39gEOnHMHGGMfyBkBB7Z0/sJ1VRCMMaQbjpxQCexcJVUqqVJJREREREREOkShUi9Q70+2P5x0M2QPa3wgp8C2vzlO5y58pLa/hWogXNO481tK5pE7U8lxNFNJREREREREOkWhUi9Q2nc2r9QfRcmUK5s/kDvCVhJVFnbuwnWVbQzqdmcNHYaVSm5VUkq2PSZnHrntb3WVEAmB8SlUEhERERERkQ5RqNQLpC+4lqtD3+H9rS2Cj5wR9tjZYd2hajtPKJaGSqXDMFRyq5Lc9reUI7j9zZ2nlDMC6sqhtvyQLkdERERERER6D4VKvcDUIVmkBH28t6mo+QO5bqi0pXMXDlU1hkctHc7tb25VUtOZSkdq+5s7T6nfBHvUsG4RERERERFJkEKlXiA54GfW8Fze3dgiVMoeDhg40MlKpbrKI3NQt1udo0qlxnlKDaGShnWLiIiIiIhIYhIKlYwxacYYX/TnscaY84wxwZ5dmjR1zMhc1uwpp7iyrvHOYApkDupC+1tVG+1vh3OopEqlBm6lUt/x9qi5SiIiIiIiIpKgRCuVFgIpxpjBwEvAF4D7e2pR0trcUXkAvL+5RbVSTkHnKpUi9XYHtHjtb4Ek8AUP7/a3ZHf3tywIV0N96NCt6VBxq7b6TbRHVSqJiIiIiIhIghINlYzjOFXAhcAfHce5GJjUc8uSlqYMziY16Oe9TQeaP5AzonOVSqFqe4xXqQSQnO793d/2LIeVT3bsObEqleDIrFZyK5Wyh0IwDSo0U0lEREREREQSk3CoZIyZC3weeDZ6nz+BJ51hjFlrjNlgjLkpxuPJxph/RR9/3xhTEL3/aGPMsug/HxtjLkhwnYetpICPWQU5recq5RbYIKCuqmMXDEXPT2ojVEpKb1WpVFYT4gv3vs+KnaVxnnSQvf07eOJaqA8n/pzaMjD+xiqtlGioVOuR93QwVReDL2D/rDP6q1JJREREREREEpZoqPQt4PvAE47jrDTGjAReb+sJxhg/8AfgTGAicKkxZmKL064Cih3HGQ38BvhF9P4VwCzHcaYDZwB/NsYEElzrYeuYkXms3VtOUUVt4505ndwBzg2L2qpUSkq328w38dRHO1m0vpD3Nx+I86SDrHy3bV3btyrx59SU2iolY+ztI7pSqQRSsu1nkTFQM5VEREREREQkYQmFSo7jvOk4znmO4/wiOrC70HGcb7TztKOBDY7jbHIcpw54BDi/xTnnAw9Ef/4PcLIxxjiOU+U4jlt6kgI4Cb2bw1zjXKUmgU6uGyp1sAXOrVRqM1RKa1ap5DgO//xgO0DzYOtQctu1di5J/DluqORyf+7IDnC15fDwJZ3fec8rqoshNcf+nDFAlUoiIiIiIiKSsER3f3vYGJNpjEnDVhGtMsbc2M7TBgPbm9zeEb0v5jnREKkUyIu+5hxjzEpgOXBtk5Cp6bq+bIxZbIxZvH///kTeSq82ZXAWfZL8vLepSQucW6nU0XDDnakUb1C3+1iTUGnFzjJW7bbBS1FFXbxnHVxuZU2HQ6XMxtspnahU2rMC1j0Pmxcm/hwvqimB1Gz7s1up5CjDFRERERERkfYl2v420XGcMuBTwPPACOwOcD3GcZz3HceZBMwGvm+MSYlxzl8cx5nlOM6svn379uRyPCHo9zG7ILf5XKXUHEjO6nilUov2t9LqED99ZhUlVU3CouSMZoO6//nhNlKCPobmplJU6YFKpbqqxuqinUsTf17LSiW3/a0jlUpuRU9vr+xpWakUqurY5yAiIiIiIiJHrERDpaAxJogNlZ52HCdE+y1pO4GhTW4Pid4X85zozKQsoNkkasdxVgMVwOQE13pYO2ZkHuv3VVDotp8ZY4d1d3SmUkP7WyoAz36ym7+9vZlfvri28ZykNKizoVJlbZinl+3irCkDKchLo6jSA5VKFdEqpexhsH914jvV1ZTFbn/rSKWS23ZXtivx53iRO1MJbKUSaK6SiIiIiIiIJCTRUOnPwBYgDVhojBkOtPcN/ENgjDFmhDEmCbgEeLrFOU8Dl0d/vgh4zXEcJ/qcAED0tcZHX/+I585VatUC19H2N7dSKdr+9vaGQgD++cG2xp3dmrS/PfvJbipqw1x69DDy0pK80f5WHg12xp8DTgR2f5zY81pVKmXYY6cqlXp5AFNd0rxSCXp/9ZWIiIiIiIgcFIkO6v6d4ziDHcc5y7G2Aie285wwcD3wIrAaeDS6c9xPjTHnRU+7F8gzxmwAbgBuit5/LPCxMWYZ8ATwVcdxCjv65g5Hkwdlkp4caB4q5Y6Akm0QqU/8Qk0GdUciDu9sLOSUCf3J6ZPET55ZieM40d3fbPXPIx9uY3S/dGYNzyE3Ldkbg7rd8GPcmfaY6FylmtLG6hwAf9C2AdaUduC1o4FWeS+uVIrUQ21p85lK0PjeRERERERERNoQSOQkY0wW8GPguOhdbwI/xQ7WjstxnOeA51rcd0uTn2uAi2M870HgwUTWdqQJ+H3MLshpPlcpZwREQlC6A3KGJ3ahJoO6V+8po7gqxJmTB3DyhH58//HlPPPJbs5LSodwDet2F7N0Wwk3nz0BYwx56UlU1tVTE6onJejv/jeZKLcFrf9kyCmAnYvbf059CEKVzSuVwM5V6kilktt6V9aLq3rcEM2tVErvb4+qVBIREREREZEEJNr+9jegHPhM9J8y4L6eWpS0be6oPDbur2RfWY29I6fAHjsyrLvJoG639W3+6Hw+M2sokwZl8n/PrqbOb+ctPf7+OoJ+w4VHDQEgPz0J4NDPVSrfA/4kG4oMnpnYsG53blJyZvP7UzI7NlPJbXurKoSwB6q2OqO62B7dqq3kdEjK6P0tfSIiIiIiInJQJBoqjXIc58eO42yK/vMTYGRPLkziO2ZkdK7S5gP2jtwR9tiRYd2hKsBAIJm3NxQxqm8aA7JS8PsMPzlvEnvKanhji61meu3jTZw2aQC5aTZMyktLBmhsgQtVw51TYMXjXX1rHVO+x1bXGGNDpdLt7bdu1ZTYY1crlcr3NOyc11Ax1dtUl9ijW6kEdq5ST1Qqharhrtmw4dXuv7aIiIiIiIgcEomGStXGmGPdG8aY+UB1zyxJ2jNpUBYZyYHGFrjMweALdmxYd10VJKVRV+/wweYDHDs6v+GhWQW5nD99EM+vKwegvqacS2cPa3g8161Ucod171tlZzptXti1N9ZRFXsah0sPnmmPu9qpVnKDo5ahUkcqlULVNpwaOM3e7q0tcDXRSqVWoVIPVCqVbIPCdbD9g+6/toiIiIiIiBwSiYZK1wJ/MMZsMcZsAe4CvtJjq5I2+X2Go0fkNg7r9vntLKWOtL+FqiDYh4+2FVMdqmdek1AJ4PtnTqDG2Pa3kZkO86K7zgHkRyuVCt1KpT0r7LFwXefeUGeV722cAzRgKhh/+8O63TlCXalUciuTBs2IrqONYd2OA6/+rPEz8pKGSqXsxvsyBvZMpZJ7zQq11omIiIiIiBwuEt397WPHcaYBU4GpjuPMAE7q0ZVJm+aOymNzYSU7S6IFYzkjOlapFKqCJDtPyWcaW+pcA7JSOG3GKADOHpeJz2caHsuLViodcGcq7Y0GJvvXdu7NdFbTSqWkPtB/YudDpY5UKrmVPA2hUhtBScU+WHQ7LPHgCLLqNiqVHKd7X8v9jDSvSURERERE5LCRaKUSAI7jlDmO437zvqEH1iMJOm5sXwDeWr/f3pFTYGcqJRoG1FVCMI23NxYxZUg2WanBVqecPWsMAKePSm12f58kPylBX+OgbrcKp6oQqg509K10TqjGhiLpAxrvGzzThkptfQYNoVKLQd3JmY2PtccNRvpNAH8ylLVRqeTOuWov7DoU3Eold1A32Eql+trGwKm7uJVK2llORA6V574La58/1KsQEREROax0KFRqwbR/ivSUMf3S6Z+ZzKL1duc2ckfY9q1Ew4BQFfWBFJZtL+HY0XkxT0nqNxYwpB5Y3ex+Ywx5acm2/c1xYO9KyIrOXDpY1UpuC1pG01Bplg2GijbGf17cSqUsCFdDfagDrz2w/cHWJVvtcc8KG4R5SU0JBNMgkNR4n/t5dvfwcXeAenuD1EVEeoLjwOK/KVQSERER6WZdCZW6uT9GOsIYw7Gj+/LWhkLqI45tf4PEW+DqqigNB6mPOMwflR/7nOQMW42zc3Grh/LSk+yg7pJtUFsKky+0DxQeylApOqy7raqgmlLAQFJG8/uTo5VLibTAle8GXwBScyFzUNstXW6lUiTU2CboFdXFzecpgQ3KoPsritzrVe6DSH33XltEpD2hKvv3cEd2+RQRERGRdrUZKhljyo0xZTH+KQcGHaQ1ShzHjc2npCrEyl2ltlIJEh/WHapif22A5ICPo4bnxD8vTktZXlqSnankBiXjzoRAChSu78Q76QQ3yHEHdQP0HWcrb9oMlcps65uvxa++2w5Xm0ALXPle23bn89kQpr32t0C0fXBnOzvTHWzVJc3nKQFkRD/P7p595F7PiUDl/u69tohIe9x230Rn54mIiIhIQtoMlRzHyXAcJzPGPxmO4wQO1iIltvnRHdsWrS+0M5Ug8UqlUBW7qnzMLsglJeiPf96QWbai5cCmZnfnpSdTVFEbnadkoP9kyBtz8Nrf3JDCrawBuwveoBntVyq1bH2DjlcqueGLu1tavDlOxVtg4DQbQnltrlJ1cfN5StA4o6onKpXc6jDNVRKRg62mxB5VqSQiIiLSrbrS/iaHWH56MhMHZrJo/X4IptqAI8FKpfraSvZV+xqCqbgGz7LHHc1b4PLSkiisrMPZu9xWSSWnQ9+xB7H9bY9tQevTYh7U4KNgzycQrov9vHihUkOlUgJfOCr2NoZZmQNtW0W8Id/FW+3n41Z8eUlNSev2t6Q+9vPpzkolx7HXGzjN3tZcJemtVjwOD33mUK9COkOVSiIiIiI9QqFSL7dgTD5LthZTVRdu3AEuAfW1lVSRzPw4Q7ob9JsQbSlrESqlJ1EXjuDsXmGrlADyx0HJdqir6vgb6ajyvZDWr3Ub2+CZUF8Xf35RTSkkd0OlUnqTSiWIHcKEa6FsJ2QPt2FX0frGLzZeEGumEjRWX3Xn69TXwqDp9rYqlaS32vQGrH/RW/8eS2JUqSQiIiLSIxQq9XILxvQlVO/w/qYDdlh3i/a39XvL+e5/PuadjYU4TVq0fOFqIoFUJg2KEbA05baUtapUSiaNanwlm2HAFHtn37GAY8OTnta0Ba2p9oZ1d7VSKVxrQxJ3QHhDqBRjrlLJdsCxYZ+7rl0ftX39gynWTCWI7mjXjZVK7rUGTgNM9+8sJ3KwVOyzR3dXR+k93GpSVSqJiIiIdCuFSr3crIIckgM+Fq7fb8Od8l3w11Nh9X9xIvX86KkVPLp4B5+7533Ovestnlq2k1CojoATIj83B7/PtP8iQ2bCnuUQqmm4Ky89iXFmu73RtFIJYP+6bn6XMTRtQWsqa4itIupoqORWL7X3haNhllM0VMqMrqEsRvVNyRZ7zCmwwRx4pwUuVAPh6tYzlSBaqdSdoVL0s8kaAmn53VeptOlN2PZe91xLJBGV0VCpWKFSr+NWl4UqoT58SJciIiIicjjRsO1eLiXo5+gRuby1vhDOugb8QXj3LvjX56nOGEHBgZM5+bSrSEtL569vbeKbjyzjzvQwrwOD+7UzT8k1eJbdinnPchg6G4jOc/JFv1gNiIZKeaPA+A7OXKXyPTBkduv7jWl7flFtWdcqldwqm/SWlUoxghK3FTGnwLaZ5Y32zg5wbitIW5VKjmM/z65yP7OMAfZz667A6vnvQiQM1y/unnWKtKciunNhgm3G4iHu33lg/57vk3vIliIiIiJyOFGl0mFgwZh81u+rYHdFGI6+Bq5fQuTT97Gzys/Pg3/l6o8u5HMjqnjl28dz7+WzGJ9nd3sbOTDBUGlIdFh3k7lKuWlJTDDbqAtkQNZQe2cg2bbg9fQOcPUhqCpsrBZqafBRULiu9fDsSH38UMkfhEBq/IHbrpaVSsFUG8zEC5X8yY3zl7w0rLu62B7jzVSKhKDqQPe8lvvZpA/ovtY6x7HVIkUbYN/qrl9PpD2O0xiQqv2t92k6B6u2/JAtQ0RERORwo1DpMLBgTF8AW60E4A/wvDOXUyt/wsK592IcB/5+Pr7iTZw8oT93f2YCALnZMapUYskcBBmDms1Vyk1LYoJvK/vTxjSvEuk7Dgp7eKZSQ7VQjJlKEH9+kVuF5FYltZSS2X6lUstQCWwIE6v9rXgL5AxvHCY+eKbdta4sxvwlgJdvsbtLHQzuF6xYlUru59pdbWrle2yQl9THzsHqjlCpYp9t3wNY/XTXryfSntoyO3Ae1P7WG7WsVBIRERGRbqFQ6TAwfkAG+enJLIqGSuH6CL9+aS1j+2cw/9RPwxefspUnfz8fSrZBKLo7W1KfxF9kyMxmlUopfsN4s50dSSObn5c/1laP9OTMCndL+lgzlSD+/CK3CilWpRLYHeDam6lUsQeMH/o0qfLKGBh7UHfxVtv65mpriPiuj+Dt38Jbd7T9+t3FrVSKN1MJuq9NrXx34zUzBtq5NJH6rl3TbT8KpMAqhUpyELhDuo1PlUq9UdNKJQ3rFhEREek2CpUOA8YYFozJ560NhUQiDv9ZsoNNhZV857RxdhB3v/HwhSfsf5194Dwo2mifGOxAqDR4lv0iXxmthireTB9Ty0bfiObn9R1nA6yenDlS4VYLxalUSs2JPb+ovVAp0Uql9P6N1Udgh3W3DGAcJ1qpVNB4X//J4AvGDpXeucse9yyPX8nUndqbqQTdW6nUsFveAHAiULm/a9d0v9RPuxT2rWz8nRbpKW6o1G+SDYwjkUO7HumYmlJIyrA/q1JJREREpNsoVDpMLBiTz4HKOj7aXsJvX13PjGHZnDqxSegycBpc9rj9Mv/kV+19HQmVGuYqRQORPcsBWOUMa35e/lh77Mlh3U1n9MQTa35Rd1Qqle9pHWZlDLQteU2rs6qL7ReX7OGN9wVT7FDzlusq2QYrn4DRp9rb619qew3doc2ZSm6o1F2VSnsa/6zSu+nabvvR3K/Z46qnunY9kfa4O78NnW3b4Nw2XOkdakpsOzKoUklERESkGylUOkwcO9q2Y33n3x+zu7SGG08fh2m5I9aQWfC5f9lKEehY+9vA6bbtw52rtHcFEXx8UtuiBS1/jD325LDu8r12LWl9458zeKYNn0p3Nt7nfpGIW6mUlVilUsu2u4yB0eqbfY33Nd35ralBR8HOj5pXObz3JzuX6tw7IWsYrHux7TV0h+oSwEByjM8ikAypud1TqRSJtKhU6qbWuuItNqDKH2M/U81Vkp7mVioNOdoe1QLXu1SXNG4qoUolERERkW6jUOkw0S8zhfEDMthcWMmCMfnMGxVnZ7eCY+HSh6Fggd2pLVHJ6dBvYuNcpT0r2J88jN1VLYKrlCwbHBSuS/zauz+GA5sTP79ijw2U/IH45wxuUVkFibW/JTJTqeWA8MxB9tg0hHG/cLYMlQbPhLpyKIoOM68ugaUPwKQLIWsIjD0dNr0BoZq219FV1cX2c/DF+SsgI0ZLX6de54Bth2yYqRT97Cq6eO2SrY1VBxPPszOpSrZ17ZoibanYZ8Nsd2ZbT7b4SverKYHsaGVte7t8ioiIiEjCFCodRo4bayt3vnv6+LZPHHUSXPHf+LugxeO2lEUisHcFB9LHcqCyjkjEaX5e/tjEK5XK98J9Z8NTX0t8HeV74+/85hoQY36R+0UiOc77Tm5nplK4DqqKYlQqRatwmu4A11CpNLz5uS2HdS+5H+oqYN719vbY0+0g9S1vxV9Hd6gpiT1PyZUxoHsqlVrultews1w3tL+5rYUTzrPH1c907ZoibanYa8NsNyjWDnC9R6gGwjWQ3g/8SapUEhEREelGCpUOI187YTSPfPkYpgyJU4nTVUNm2WBm11Io3U5FzgTqIw6l1aHm5/UdB4Xr7bDq9rxyq63c2fYuVBYlto7y3Y0hRTyBZBgwpWOhUkqWDXTqQ7Efd2eotJqpFKNSqXgL9MmD5Izm5+aPscNidy6xIdX7f4IRx9uZV2AryQKpsL6HW+Cqi2PPU3K5c6K6qiFUigZx/qDdOa8rgVV9CMp2NAZ2eaOg/xTtAic9q3I/pPWzs9EyBqr9rTdp2JggO7HZeSIiIiKSMIVKh5GsPkGOGZnXcy/gtpQtuR+AcN+JABRV1jY/L3+sDYraCw62fwgfP2wHVDsRWPdCYuuo2Nt+qAS2KmjXssbt693df+K1zblhU215/NeF1pVKaX3BF2gRKm1t3foG4PPDoOl2Z7oV/7HPmf+NxseDqTDyBDtXKZFQrrOqS9qpVOpvA6Gu7nDlfiZN/7wyBtpqs84q3W5/X5p+vhPPg+3vd99wcZGWKvbZShewVXKqVOo9GlqfsxPb5VNEREREEqZQSRLXdxwkpcOKxwDwD5wKQFFFXevzoO0WuEgEnr/RDlu+6G+QORjWPtf+GiL1tmKgrZ3fXO78osLo/KLasvjzlKCxHdD9r9otNew616JSyeez62nZ/hYrVHLXtWc5vP1bO6dq1MnNHx97mq2C6Mlh59XF7YRKA8Gpb5yh1Vkt298gGlh1oVLJ/TLfdGe9CecBjlrgpOc0DZVyCjRTqTepLrHH1GxbPapKJREREZFuo1BJEufz2yG1oSrok09m38EAFFW2CJXyo6FSW8O6lz1khyuf9jMb5ow7Cza8CnVVba+hcr+tUmnZghZLy/lFNaVth0pupVK8LxyxAhJXxgAo32V/rg/baprs4a3Pc9cVCcH+NTDv63bnt6bGnGaPPdkCV1Ni/6t9POPOhMwh8PfzuxbUlO+24VUgufG+jAFda62LNa+q33hbIadd4KQnOI7d3dHdcTJnOJTttC2s4n3ufyhIyYnOzotTjSoiIiIiHaZQSTpmSLQFbsBkctNtUFBU0aL9Lb2fDW/iVdpUl9hZSkPnwJSL7X3jz4Jwtd35rC0N7VQD2z4PIG80JGc1VtvUlLY9nNx9LF5rRPkeu/uT+8WyqcyBjZVKZTshEm6jUukoe8wYCJMvav141hA7I2jdS/HX2hWO0377W9YQuOY1W0n1r8tg0a87145Xvqf1n1V6NFRy2xI7qmSrbTfMHNz8/gnn2QHnlYWdu65IPDWlUF/XWKWYPRxwbHgs3udWKqVk2X/U/iYiIiLSbRQqSce4c5X6Tya3TxIAhS3b34yx1UrxKpXe/IXdRe3MXzZW6Qw/1v4X5LXPtv367iyeRNrffD4YPKNJpVJJ1yqVKvbYQb0+f+vHMgY1VjK5A3zjhUqZg2HsGXDSzRBIin3O2NPs8PLq4vjr7azactva1tagbrDVYFc8a4OvV38KT1wL4dq2n9NSrKHqGQNstVlnw5/irZA1tPWfw8Tz7HXXtPM7JNJRFfvssaH9LVolpxa43kGDukVERER6jEIl6Zhhx9jqn5EnEPD7yOkT5EDL9jewrUixKpX2rYH3/wwzL7cDq12BJBhzKqx9oe0Klgq3BS2B9jewrWZ7V0Kouv32t3YrldoYEJ4xAGpLoa6ySXtWQexzjYHP/QtmXBZ/LWNOt8HPxtfin9NZblDVVqWSK5gCn/4rnHgzfPIIPHCu/SwTFatSyb3d2blKxVuat765Bky1FSSaqyTdrbJlqFRgj9oBrndoVqmkQd0iIiIi3UmhknRMWj7ctNUGQEBeenLr3d8A+o61X8SaVtrs/hievBaS0+GkW1o/Z/zZUFUIOz6M//puNVBav8TWO3imbUXbszyBmUrRx9qaqRQvVMocZI9lu23oYfyt27M6YsgsSM3tmRa4hvki2YmdbwwcfyOcd5fdYS3RoCsSib1Tn3u7s3OVSuLsrGeM/b3c9q6da9VRlYU9E+JJ7+f+rrp/72QMBF9QO8D1FjWldpMJf7BxplJXd7YUEREREUChknRGk8HSuWlJrdvfoHFY9/51sP1DeOgz8OfjoGgjnHMnpOW1fs7oU+0Xtbbal8r3QJ/8+G1jLbnDund8aL9IdKVSqaKNUKlp9U3xVsgeCv5AYmuMxee3Acn6lzo/eyiejlQqNTX1MxBIgS1vJ3Z+VaGttmpVqRT9DDtTqVRbYVsn4w1BHzYX6ipgzycdv/bC2+HBC6GyqOPPlcNbxX57dCuVfH7777gqlXqHphsTpGQCjt0ZVERERES6TKGSdEl+elLrQd1gK5UAHrsa7j3Fhjon3QzfWg6TL4x9sZRMGLHAhkrxhkLHqnxpS8YAWzG0eaGdt9NWqOQPQiDV/lftlupDdue5eLOcmoVKW+K3vnXEmNOg+kDjTKju0nR77Y4IJMOQ2bD1rcTObxiq3uIzc6s93KqzjmiYVxUnVBo+zx63vdvxa297B3Bga4KhmRw5KvfZ6sPU3Mb7sodrplJvUV3S+Pdde7PzRERERKRDFCpJl+SlJceeqZQ93FYUhWvgtP+1YdJxN7YfZIw7Cw5sjD/ku3xP4w5MiRp8FGxeZH9ObmP3N4g/b8Md1Bu3/S0aKpXtsl8041XSdMTok+0X2XUvdP1aTXW2UglsaOO2ErbHDY1aVioFkuzvRmdCpfbmVWUOsp/91nc6dt2aMvu+wO4gJ9JUxV6766Ovyf9k5hSo/a23aLpJQ3sVqSIiIiLSIQqVpEvy0pMorgoRrm8xn8Lnh699YMOkeV+3c5QSMe4se4zXAhdr8HN7Bs+EUKX9ua1KJYi/M1BDQBInVErOgKQMKFpv2766o1IpNceGOKufiV+51RkdnanU1PD5tuJr2/vtn+tWKsUKATMGdDJUin6Jzy6If87webDtvY59Zjs+tO8rOVOhkrRWsb+x9c2VM9xWEqrixfuqSxr/vlOlkoiIiEi3UqgkXZKXngzAgaoY1UppeXb3sI7IGgyDZsDa51o/FonYNpREd35zuXOVoP1QKW6lUjQAaatKKnNgY9jSHaES8FHGCbZqa+/KbrkeYCuV/MkQTO34c4fMtnOvEmkRK2/jM8sY0PiZdkTJVjtwt09u/HOGzbXBXuH6xK+77V0wPph9FexbCVUH4p+7YzHcfWzb58jhpWJv61DJrUbUXCXvqylprJJ1/zdAlUoiIiIi3UKhknRJXpodmF0UY1j3tqIqqus6MWR63Nn2i3t5i93BqorsTm7x5hoB9RGHW59eyTH/9ypXP7CYvyzcyMeREThEh4unZFFaFWL5jlKe/WQ3D7yzhceW7ODV1XtZvOUAVSaNcFWM1q6G+UBtVEllDLCVStAtoVJdOMI3PxlGPT5Y+XiXr9fAnS/SZOB6S/vLa/njGxsItaxAS+pj2wkTCpV2xx+qnt7ZSqUt9st8G2tvnKvUgRa4be/BgKkw9gx7u633t+R+2LscNr2R+PWld6vc33rHSXeul1rgvK+mVJVKIiIiIj2kC9tTiTSGSi3nKpVWhzjjtwu59Ohh/OiciR276Piz4PX/hXXPw8wrGu93K1viVCpV19XzjUc+4uVVezlubF827CvnldU2mHo5eTBjzA7Ovmc5K2vi7zr2h2AN4327Wbd8N2dOaRIgle8FjJ2rEk/GoMafuyFU+mDzAbbVpvFu0iTmr3gMc9KP2g5TElVd3O48pUc+2MavX15Hkt/H1QtGNn9w+Dx45/dQVwlJafEvUr43fgiXMQCnYh+n3v4qVx03hkuPHpbY2ou3Qu7Its/JG23/nLa+2/z3J55wnQ0xZ14Bg46yw9q3vAUTzm19bn24sYpu69vxh873FutespVw864/1CvxLsexM9Vatb+NsEdVKnlbfcjuCNlQqaSZSiIiIiLdSaGSdInb/lbYYge4F1bspqqunueX7+bmsydgOhKG9JtoQ5l3/wgjjofc6Je3eIOfgeLKOq564EM+2l7CT86bxOXzCgDYV1bDh1uKqXhzGhTtYMHkkVzQfzBDc/swNKcPfTOSqawNU1IdorQ6RMHbQ8nYvoFvPrKMjJQgx47Jty9Qscd+qfS38a+MO6w7ObNzQ7BbcAOxp+rncmzxX2DXR7ZKqKuabq8dxzsbiwD47SvrOX/6YPpmJDc+OPxYeOs3sP0DGHVi/IuU744/gypjAMapp7RwD/cs9HPJ7KHt/444jv0C39Zrgg3ehh2TeKXS7o8hXA3D59qqqmFzYEucSqVt79qKuWBax4eBe9E7v7PzpOZ8xe5+KK1VF0Mk1DpUSs2xc9RUqeRt7qYCLSuVFCqJiIiIdAu1v0mX5KfHbn97fOlOjIFdpTWs3NXB//NuDJx9hw1y/nw8rHra3h9nRs/2A1V8+k/vsGJXGXd//qiGQAmgX2YKZ08dyIyzroZRJ3HThfO4esFITp80gImDMumbkUxBfhrTh2Zz/Ni+DB80kBx/DSP7pvHlBxezbHtJ42u3t+ucG3bltNOelQDHcXh1zV5G9k3jxfpZ1JsArHisS9ds0E6lUk2oniXbijllQj+qQ/X86sU1zU8YNsfOH2ovVCnf02aoBNDPlLCpsJIPtxS3v+7K/RCqSmxnvWHzoGQblO5s/9xt79rj0GPscfixsHdF7JlJq5+BQAoccy3sWwWVRe1f36si9bBzqd2hcd/qQ70a76rcb48t29+Msf+uuzsSijdVl9ijO0spmGp31VT7m4iIiEi3UKgkXZKZEsTvMxRVNlYq7Syp5v3NB7h8bgE+Ay+t7MTsnNEnw1cWQt4oePQL8Pz3oHS7faxJuLNqVxkX3v0OheW1PHT1HM6YHKfdatRJ8IUn7K50bUnOxISq+PvlM8hPT+aK+z5g/d7yxHadawiVChJ7j23YsK+C7Qeq+dL8EdQnZbEhYw6sfNIOK++q6tLGVpAYlmwtpi4c4fNzhnPlsSN4dPGOxnAN7E53A6e1PXeoPhwdqh6v/c3ePyRQQnpygEc+3Nb+ut2KkEQ+34a5Su+2f+62d21LndtWWXAs4LQOzRwH1vwXRp8CY06LPrcXVyvtW924K+Kujw7tWrysIjrbrWWlEtiAU+1v3ubudun+nWdM/A0ZRERERKTDFCpJl/h8hty0pGYzlZ5aZqtDrpw/gtkFuby0am+8p7ctpwCufBHmXAfv/wkW3m4rbKI7yhVX1nH1Ax/iN4bHrpvH7II2dgRLVHTeRr/kEP+4ag5Bv48v3PsB9WW72991LjM6U6lFJc2KnaUUV8bYHa8Nr6zeB8ApE/oxaVAWzzMXynbAjg86dJ2Y2qlUentDIQGfYfaIXL5+0mjy05O59emVRCJO40nD59s5RKGa2Bep3A9OJP5nFg0Gp2bVcN70QTy3fDdlNaG21+1+eY8OSN5TWsP+8trY5w6YYluT2qumikTskO5h8xrvG9xkrlJTu5ZC2U4Yf0509lJK/Da53mDHh/boCyhUakuF/XcxZqiUU2DDTsdp/Zh03d5VXf9s3VCpactvcqYqlURERES6iUIl6bK8tCQKo+1vjuPwxNKdzBqew7C8Ppw2aQBr9pSztaiycxcPJMGZP4fP/sNuJR8d0hyJOHz70WUUVtRxzxdnMaZ/Rve8GXfeRul2huX14cGrjqa2rhZTVUhFML/t52YPs20Vfcc33LW1qJLz7nqLk379Bo8u3o6T4BekV1fvZdKgTAZmpTJpcCYPFk/ECaTAig7sAle0ETYvbH5ffQjqytucqfTOxiKmDc0mPTlARkqQm84cz7LtJTzxUZNWsuHzob4Wdi6JfZF2dsuLRFuJxqdXcsnsodSEIjy9bJd9sLokdkVW8WZ7zLZDvb/y4GK+9a84YYjPD0OPbr9SqXAdVB+wM5hcgWT73K0tQqXVz9gAZuzp9vdyyOzW5/QmOxdDaq6t6lKoFJ/b/har/TVnuJ3H5QZP0n22fwh3z20d7naU2/7WtDpTlUoiIiIi3UahknRZfnoyRdFB3at2l7F+XwWfmjEYgNMm2i9iL3e2Wsk14Vz4+hIbLgF/fGMDb6zdz4/OnciUIVldu3ZT7jbhfz4e7j2N8Rvv55EzffhwuHtJpW2Fiye9H1y7CKZd0nDXw+9vwxhDQX4a3/3PJ3z2L++xYV8b18DupLd0WzEnT7Cf3ZTBWRSFUqgYeiKsetLOwmnPlrfhLyfCA+fBxtcb73eH1sapVCqrCfHJjhLmj8pruO/CGYOZPjSbn7+whnK3mmj4XMDErwRqGKoee6bS9rIwRU4Gw4JlTBmcxYSBmfzrw+1QWQi/Pwqe+XrrJxVvtXNtktKoC0dYtbuMDzYfoKI2HHsNw+fauUexZiO53NBp+Lzm9xccC3uazFVyHDvbq2AB9Mltfo77pbW32bEEhsyyVVd7V0I4TtXXka5irw0TYwWxblWiWuC6366l9rh/TdvntSdmpVKWKpVEREREuolCJemy3LQkiqLtXU8s3UnQbzh7iq1QGZrbhwkDM3lpZexQyXEcrn1wCd/450dUxgsHXOl9IXMQ72ws5I6X13HetEFcNifBregTVXAsXPcunPB9OxT65R8x7vnPArDHyebTd7/DB5vbCCn6T2rYRasmVM+ji7dz6oT+PHbtPH5+4RTW7innzN8u4vYX11ITih0OvbF2HxHHtr4BTB5sQ7NVuafYL7htzTICWPUUPHiBDbnyx8JjV0NZkyogiDtT6YNNB4g4MHdUY1WWz2f4yXmT2F9ey12vbYg+P8e+13iVOu1UKq3cVcY+J4f+pgRjDJfMHsrynaUUPfsTu7vaRw/Z1pemSrY2hH7r95UTqncI1Tu8vynOsGy3pW37+7EfBxsqpfVtqIBr4M5VckOn/WvgwEYbbrqGz4+e817863tVTZl9T4NnwaAZdnezvSsO9aq8qWK//R3xxfifSzeE1g5w3c/9fTywuWvXaTmoG1SpJCIiItKNFCpJl+WlJ1FUUUd9xOGpj3dxwrh+5KQlNTx+2sT+LN56gMKK1pUQ//1kNy+s3MPTH+/ioj+9y66S6jZfa19ZDd/45zJG5Kfx/y6c0v429J3RfyKc8D249i345sdw+v/B1M/y7auuID8jmcvufZ/nlu9u9zLPLd9NcVWIy44Zjs9nuOToYbz6P8dz7tRB3PX6Bm54dFnMdrhXV++jX0YykwfZL0Gj+qaTEvTxWv0Mu5V9W7vAfXAPPHq5HaR91Uvw2QchVA3/vsK2vlVHd1mLU6n0zsYikgM+ZgzLbnb/tKHZfGbWEP729maed9/78Pmw/QN73RZqincBpvWOWVErdpayn2zSQ4UAfGr6YCYEdpG96iGY8hk7DPz125o/qXhLQ2XI6t222ssYWLS+MPZnMXgm+JPanqu07V0YNrf1bn2DZzafmbT6Gft+xp/deM6QWdHr98IWuF1LASdaqTQjep9a4GKq3Bd7nhI0qVTactCWc8TYu9Ieu7q7Xk2J/Xc5OosP0EwlERERkW6kUEm6LD89mYraMK+v2cf+8loujLa+uU6b1J+IA6+tbj53pCZUz8+fX8OEgZncd8Vsdhyo4vw/vN18p7EmwvURro9WNN192UzSkgM99ZYa5RTA3K/BhX9hyKBBPHbtPCYPyuRrDy/lvrfb/i/o/3hvKyPz05jXpJUsPz2ZOz47nRtPH8dzy22Y1lRdOMKb6/Zz0vh++Hw26PD7DBMHZvLRnjoYd4Ztw2oZ5DgOvPozeO47MPYM+OJTtk2r7zg473e2WuflH8duBWninY2FzC7IJSXYepe8m86cwMRBWVz30FJueWoFdUPn2mquXcsaztlXVsO3HvmIJxYuoTYlH/yx/4xW7iqjJqUfvujOWll9gvw6699UkkzNKbfBvG/YndZ2LLZPqA9D6c6Gnd9W7y4jJejj2NH5LFy3P+ZrEEyxrV3x5iqV7oSSbTZUaimQbGcmbVlkb69+2s5ZatrOF0y1lT69cVi3O6R78Ew7oyo1V6FSPBV744ajJPWxj3U2+CjfC//4dGO7qFiRiN2dELoeKlWXtP77LiUTaku7dl0RERERARQqSTfIi1Yl3fvWZjJSApw4vvkXsIkDMxmcncpLq5p/cbr3rc3sLKnmR+dM4MTx/Xj8q/NICfr47J/f5b+f2LClsjbMuxuL+OMbG7js3vf5YPMBbrtgMmO7azB3B+WkJfHwNcdw6oT+/OSZVfzzg20xz1u5q5Sl20r43JxhDeFQU9ceP4oZw7L50ZMr2FvWuIOaOyPInafkmjw4i5W7SolMutAOlt70pp33s+Y5ePkWuOdEWHQ7HPXF6FDzPo1PnnIRHP1leO8PsPQBe1+MSqXCilrW7ClnbpMQrKnctCT+/ZW5XLNgBH9/dyuXvxINjLa+Rag+wj0LN3Hi7W/w3PI9DPKXsM+JXQ3lOA4rd5Xiyxxov7BH6mHDK0ysfJ/fhS7g+U11cMx10CcfXv2pfVLZDnDqG9qNVu0qY9yATE4c149NhZVsP1AV87UYPteGJXUxHnfDpqZDupsqWAB7ltvQbM/y5q1vDdefB7s/htq252R5zo4ltjUyNdtWaQ0+qlk4KE1U7I89pNuVM7x5+1vJNlj0a3jqegi3s+vj2udgwyuw8bXuWevhonizDaxTsmyo1JUd4GpKW7f7Jmfaf2c7ct11L8HKJzu/DhEREZHDlEIl6bLcaKj07qYizp4ysFWVizGG0yb1Z+H6woa5SfvKavjD6xs4bWJ/5kXn94zpn8GTX53PlMFZXP/wR5x6x5tMufVFLr3nPX75wlr2ldVy4+njuPCoIQf3DbaQEvRz92UzOXZ0Pj95ZiUb9lW0Oucf720jOeDjopmx1+r3GX598TTq6iN877FPGtrgXlm9l+SArcBpavLgLCrr6tmcM9d+Ifr3FfDLEfDIpfDuH8EXhDN+Duf+LnZ10Gm32aqa1c/Y2zFCpfeis4nmxQmVAJICPn549kTuvXwWq8uT2egMZsvSlznzt4u47bnVzBmZx0vfPo5RqeVsrk2nPtL6S9u+8loKK+pIyx9sg6KKvfDizTg5I3gz61M88sF2SE6H474Dm9+ETW80fmnPHo7jOKzeU8bEgRkcN9Z+Tm9tiNMCN2weRMJ2p7OWtr1r2wkHTI39XHeu0os/tLfHnxPjnPn2PbQ1t8lrHMdWKg2e1XjfoBm2MiRW+HYki0Si7W9945+TPRwObIIl98N9Z8GdU2wY+tGDsOODtq/v/t7sW9X2eUcat/Vt7BkQqrQD/DurpiR2pZITgbrWf3fHtfCXjSF3W6oOtJ4HJyIiInIYU6gkXZaXntzw86datL65Tps4gLpwhEXrbavS7S+tJVQf4QdnTWh1rYeumcOX5hcwMDuV608aw31fms1HPzqV175zAl87cXTPvZEO8PsMv/7MNFKDfr75yEfUhhuHbpfXhHhq2U7OmzaI7D5Jca8xsm86N50xnjfW7ueRD7fjOA6vrtnL/NH5pCY1D+bc+Uor9tTACTfZMOPkW+BLz8P3t8PVL9vqnngzpgJJcPH9ts0Jmg+tjXpnYxEZyQGmDG5/N72TJ/TnuW8sYGOfaeQWLSUcCnHv5bP42xWzKchPo69TzI5wFsu2F7d67spdtu0kf2CBvePNX8L+1ZhTf8qnZo/k/c0H2LS/AmZdCZlD7Be54mirYc5wdpfWUFIVYuLATEb1TWdgVkrD71UrQ4/G7lIXowVu23swdHbcFr2GuUpb34IBUyB3RIzrz7E7g3V3C5zjwNIHYf3Lie321xElW6Gq0M5Tcg2aYcMxDeturqbEhpLx2t/AtmSW7YRnvgmV++Gkm+ErC2lzd0SXO+RdIURze1cCBsadaW93pQWuuiR2pRJ0rMLwwCa7jvaqz17/P7jvDBtIioiIiBwBDsJQGjnc5afb4GRwdipHF+TGPGd2QQ7ZfYK8tHIvQ3L68O8lO7hmwUgK8tNanZsc8PPjcyf16Jq7Q//MFH550TSu+ftifv3SuoaA7ImPdlJVV89lxwxv9xpfnFvAS6v28r//XcWAzBS2H6jm2uNHtTpvTP90kgI+Vu4q4/yzvmbnPHVU9lC49BHYsjBmkPLOhkLmjMwl4E8sax6UnUr/My7A/8RzvDr0b/iL58HWmdB/Ism1Rew3uexas5+Zw5v/TqzYWWY7roYW2DuW3GeHfk84l4uH1HLHy+t4fOlOvnP6OBugPR1tIzJ+yBzC6nW2omrCwEyMMSwYk88LK/ZQH3Hwt2w1TM2G/pPtTKRRJ9kgxRj7RXPvSrvLXzzBlMa5ShPOi31OUpoNZNrbka+j3r4TXrnV/pw11LY1zrgMMgd1/drunKqWoRLAzqXRIK4X2vAKZBdAfjcGzxXROXDxBnWD/bPxJ8HY02Dg9MZgt//ktn8vKvbZsNT4VanU0r6VdkfGfhPt7eLNNgDujJqSxuu4UqKhUk1ZYv9OVZfYXSnBhrL5Y+Kfu2+Vbbkr3d64O6CIiIjIYUyVStJlfTOSSfL7uGDG4JjzgwACfh8nj+/Pq2v28dNnVpHbJ4nrT/JG1VFXnDqxP5+fM4y/LNzEW+sLcRyHB9/dypTBWUwbmt3u830+wy8vmooxhmv/sQSAk8a3/gIb9PuYMCCD5Tu6OFx22Bw47sZWd+8sqWZLUVVDK2Ki/OPOgMkX4d/7Cbz0Q/tf6H9RAEBK7mBeW7Ov1XNW7iplRF4afXKbtAaefhsYQ7/MFGYOy2GhW3k07VLIGwN7l0PWEPAHWL3b7to0fqD9YrhgTF/KasJ8sqMk5hq3jP4c9fvXwr2nwG8mwws/sK1KOPHnKbkKFthjrNY31/D5NozpQuvY6t1l1ISiFUkrHreB0uRPw8UPQN5ouxPebybDPz9nXysR8ebF7FgMgVTo1yS4zRho5wb11mHddZXwyOfhpZu797rRQfJthko5w+1ukYNmNK8UHD4v7u6IQGOV0vizoHy3bZsSa+9K6D/JDpGHLlYqlbauzEyO3q5NcAc4t1ISoHB92+cWrrPH/WsSu7aIiIhIL6dQSbqsT1KAZ75+LF8/ue2Q6LRJ/SmtDvHBlgN8+9SxZKYED9IKe9bNZ09kdL90bnh0GS+u3MP6fRVcdsywhJ8/JKcPt5w7kdpwhEmDMhmYlRrzvEmDs1ixq7Rh/lJ3endjdJ7S6PjzlGJKyYSL7oVvr4D/WWcroRb8D0y6gD4TTmPV7jL2lNY0e8rKXWVMHJRpQ4xAqg2O3EoZYP7ofJbvLKWkqs5WVJ0UnWnkDuneXcbwvD6kR3f/O3Z0PsbAovWt565U1Ia5+IOxTK+6mz9kf4eavAnw4T3wyo9t21rTap1YjrkWPvco9J8Y/5yCYyESatxRrYM+3l7Cmb9dxD0LN9kQ4olrYegxcP4fYdKn4ItPwjc+gvnfsDN47j0V3vpN/Paare/AH+fBo1+MHSztXGw/76bVasbY++KFSpVFsP6VTr2/g2LjaxCusVVl8UKczqiMhptttb/FM3xeq90Rm9n+PviTYdrn7G1VK1l1lXBgs630CqbawLOzoVKk3u7y1rL9rWmlUiIObGr8uWhD/POqDjT+zri714mIiIgc5hQqSbcYNyCD5EDrbeibOm5MX1KCPsb1z+CS2UMP0sp6XmqSn99dMoOSqhDXP/wRGSkBzpsWe7ZUPBfPHMJXjh/J9W3MjJoyOIvymjDbD1R3dcmtvLOhkLy0JMb268Kuehn97QyUk26Gi+/n6OnTAXhjbWO1UklVHTuKq5k8OMvOefrKm3DOnc0uc+yYPBynMehiwvkw5jQYfQoAq3eXM2FAZsP5OWlJTB2cFXOu0h9e38D+8lq+eOIU/nhgNkdvvobnz3wLLvgzXPgX277WlpQsGHt62+cMnQPG16kWOMdx+MULtqJh6cfL4J+XQNZguORh237nyh0Jp9wKX18M48+2lUz/uKD5VvTVxfD0N+C+M+0OZKufhnUvNn/BcK3drW7IzNaLGTTDVlnEmjPz32/BQ5+GnUs6/B4PijXP2WNdRafDvZgSqVSKZ/h8e4z3e7HtPbvr3qDp9rZCCGvfGsCxlUpgZ1Z1NlRyK5FaDupOjv49V5tg5acbKiVnth0qNX1MlUoiIiJyhFCoJAdNapKfey+fzZ++MDPhuT29xcRBmXz3jHGEIw4XzRzSatB2e4wxfP/MCZw5ZWDcc9xh3ct3drEFrgXHcXhnYxFzR+XFbV/sjLH90xmUlcLrTUKlVbvsl7xJg6KhUN9xzcMTYOqQbNKTA407uvl88Pl/w/xvUlkbZktRpa10amLBmL4s3VZCWU1jlcq2oiruXbSZC48azI2nj+e5by5gVL90rvvPBm5YM57y0XHmJHVUSqbdQa4Tw7oXrS/knY1FzOxnuLnkR9RHIvD5/0BanIqx1BzbEnfu72Db+3D3PBscrXgc7jra7jg293pbOZY/Fl78vg2SXHtWQH2dnRXV0qAZgAO7P2l+/86lNqACePVnHX6PCQvX2uvv6GBwVR+GdS/A2DPtfKKNr3Xfmir22Z0VY+yW2K70vvbPINaw7lC1DfeGzrGVOClZjTueHencYfFudWDOiM6HStUl9hhvUHfClUqbIWMQ9JvQdqjktr7lFCgkFBERkSPG4fXNXjxv/uh8RsQYzn04uHL+CO763AxuOHVsj1x/7IB0gn7Dil3dGyptLqxkT1lNh+cptccYw4nj+/HW+sKG3fHctU8aFH+HuaDfxzEjc3l7Q+t2tjV7ynEcO6S7qQVj8qmPOI3VTcBtz60i4Dd874zxAAzPS+PfX5nLN08ew5PLdnLSr9/kt6+sZ19Z8/a89ry8ai+f+sPblFY3abMqONZWyOxaZr8AVxe3u2tbJOLw8+fXcELWHv6RdgdDzH6em3g75LUe1N6MMTDzclvllTEQHv4M/OdLkDkQrnndzqdKzYYz/p+tsHjv7sbn7owO6R4co+3PbUFs2QL36k/troEnfB82vQ6bF7a9vphvNoEd7N7/Eyy63bb3vflLGxYlYvv7UH0Apl1i2xm7M1Sq3G+rlOLtqtie4fNsRVLL979zqW2ZHHaMvXa/SWp/c+1dCcE0O3Qdorvr7YJQx/49BeyQbmhdqeS2vyU6U+nAJrv7Y96Y9kMlfxKMOR32r9UOcCIiInJEUKgk0k18PsM5UweR0UOzopIDfsb2z2BFN1cq/feT3QDMG9XBeUoJOHFcPyrr6lm8pRiw85QGZaWQm5bU5vPmj85nS1EV2w80H37tDumeMLB5m96MYTmkJfkbWuDe3lDIiyv38rUTR9M/s7ESKuD38e1Tx/Kf6+YxcWAmv3llHfN+/hpf/+dHfLjlQLvzqt5ct5+vPbSUZdtL+GBzk8HKI0+A+lr4y/Hw22l2WPlPc+Hnw+Cfl9rB4GW7Gs+vD7P4+fv4cdF3uL/2BlILV/Kb9G/zwM4O7O7Wdxxc/aodvH7Gz+Hq1xpbqcC2C449Exb+qrFNbseHtuIiK0Z7Zno/yBwCu5oMAt+80AZJC/4H5n8LMgfbkKkjc72WPWw/jw2vxj+nYj8svB1GngiTL7SDye8/O7EKlbXP2S/yo0+2O/ztXNp9Q68r9kJa384/f/h822LVsgppe3RI99A59th/oq1s6YF5ab3O3pX28/BF/+9JTgHg2JbOjopXqZSUbltWOzJTKXeEDXwr9sZ/XuF6yB0FAyZDuBpKtnR8zSIiIiK9jEIlkV5k8qAsVuzsvmHdK3aW8vvX1nPGpAEU9EAF2bzReSQFfA27wK3YWcrENqqUXMeOtlVT72xsXq20ancZmSkBBmc3H2aeFPAxd1Qei9YXEq6P8NNnVjEkJ5Wrjh0R8/pHDcvhgSuP5vXvnMDl8wp4c+0+Lv7Tu5x319t8vL0k5nPe21TEl/++mFH90vH7DMu2Fzc+OPoUuPIl+OxDdsD26f/PVvZM/JRtOXvmm3DHBPjTsfDs/+D8dipHf/hthgeKiZz6M7hhFX2O+ixLthV3rHIqmGJnWB1zXfPB267Tb4u2lf3U3t6xOPY8Jdeg6Y2VSo4Dr/zEBkmzr7avdfx3bTC17oXE1rf2BXjqejun6cmvxg973vg/O6D5zF/Cp/8KF95jK3fuPhaW/TN+2OI4NlQacZydkzPqJMCBzW8mtr72VOzr3Dwl1/B59tiyBW7b+7Y1rk+uvd1voq2aKd3e+dc6HDgO7FvZOE8JoqESnWuBa6hUavF3jjH29yWRSqW6Shsk5Y6E/DH2vnjVSoXr7Dl9J9jb+zRXSURERA5/CpVEepHJQ7Iorgqxq8mOapsLK7n6gQ+58v4PCdUn3m5RXVfPNx/5iLy0ZP7fhVN6Yrn0SQpwzMg8Xl+zj6q6MJsKK5k8OLPd543ul06/jGTe2lDU7P7Vu8uYMDATE6MdacGYvmwtquIXL6xh7d5yfnjWBFKCbc+2GpGfxo/Omch7PziZ/7tgCvvKa7jgj29z27OrqK5rbFn6aFsxV93/IUNz+/CPq45mXP8MPt7epGLMGBg2ByacAzM+D3O/CifcBOf9Dr71CXz1PTjlJ5CUAYvvY3dgMNfU3cDazyzEN/8bkJrD6ZMG4Djw0qq97X4+CcsbZdey7CFY95LdGj3WPCXXoBm2KqO62IY1OxfD8d9rnHs1/fO2EuPVn7Xf2rPtffj3FTBgClzxLFQVwnPfaX3e3pW2kmv21dA32jo69TNw3dv2uU9ea1vjYtm/1q533FnR9R9lt4vvrha4roZKWUMge1jzYd2RiG3Zc6uUoDFEOdLn8JTvtr97/bopVHIrlVq2v4H9PUmkUunAZnvMHQl50Y0UYoVK4Tp7bv5YW0UIsP8I//MUERGRI4JCJZFeZHJ0QPXyHaVU19Xz65fWcvpvFvL2hiJeW7OP376yPuFr/ezZVWwqrOSOz0wjp512tK44cVxfNhVW8sKKPThO2/OUXMYYjh2dzzsbColEbJVKfcRhze7yVkO6XQvG2OqmexZt5piRuZwxeUDCa+yTFOBzc4bx8g3Hc8nRw7hn0WZOv3Mh72woZOWuUi7/2wfkZyTz0NVzyEtPZvqwbD7eXtKwtnbejB3we+y34MrnKf/ubs4p/S6VI07nuHH9G04b2z+dEflpvLhyT/xrdcaC70BaP3jsans71jwllztXaedSGxzljbZBkssfhBN/YKtJVj4e/zr7VttZT5mD7ODxgvk2ZFvxGCz/T+N5jgMv/sAOTj7hpubXyB4GV/zXVoG9/v+gsnnACMDaZ+1x3JnR9QVg5HGw8fWut5JFInamUloXQiWwLXBb32lcT+E6W0Ez7JjGc/rauV9H/LBu9/03rVRK7wfBPp2sVIoGvy3b38DOVUqkUsnd+S13pP0HEztUKt4MTr0NlVIybSupKpXES+rDtmq1u9qDRUREohQqifQiEwZm4vcZHv5gG6fc8Sa/f20DZ08dyJs3nsBnZg3hD29saDasOp4XV+7h4fe38eXjRjJvdPcO6G7pxHH2S/kf39gIkFClEti5SkWVdazZY7e431pUSXWovtWQbteI/DSG5KTiM3DLOZNiVjO1JzMlyP9dMIVHvnwMPgOf++v7XPynd0lPDvDQ1XMa5jNNH5pNeW2YTYUVHX6NexZt4UBlHd87Y3yzNRpjOG1Sf97dWERpVaiNK3RQSiaccqud7WP8zecuteSGSq/caqssTvxh67a6SRdC/8l27lF9jHWWbIcHL4RAMnzhcbsLGsD8b9sqqWdvaJwvte5F2PSGDZTcVrCmfH447Taoq4A3f9768bXP2zVnNplFNeok20bW1kDlRFQX25AgvX/757Zl+DxbpVUYDXwb5ik1CZVSs6MhxBE+rLvlzm9gQ9mcgs63v/mCNpRqKTnTtmW2xw2VckbY3+nsYbF/t9yd39wWuX7jVakk3rLnE1j0a1jz7KFeiYiIHGYUKon0IilBP2P6pbNw3X7Skv3868vH8JvPTqdfZgq3njeJEXlpfPtfyyiurIt7jb1lNdz02CdMHpzJ/5w6rsfXXJCfxsj8NDbsqyA3LYkBTQZnt2V+NOxyd4Fbvdt+AZwYJ1QyxvA/p43llnMmxq1mStQxI/N44VvH8ZXjR1KQl8Y/rp7DkJzGL6YzhmYD8NG2kg5dd/uBKu5ZtJmzpw5kWvQaTZ0xaQDhiMNra7uxBQ5g2qU20Bk8E5LamJ3VJxeyh9svHwOm2plQLfl8cNKP7JftZQ/Z+6qLYfuHdv7RPy60IdBljze2LoENpy74sw2invqabRd66Yd2R63ZV8dfU7/xMPMK+PBe2L+u8f7yvXZG1Lizm58/6iR7jNcCt/4VWPp3qKuK/birIvpnkN6FQd1gK5WgsQVu2/vQJ7/1Ln/9J8LeIz1UWmXDtdSc5vd3NlSqLrGBXayAOSWzsZKpLQc22WHt7o5x+WMaA8KmWoZKfcfb8xLZ+VDkYKiOzgE80me3iYhIt1OoJNLLfP+sCdx2wWSe/cYC5oxs3LGtT1KA3106g6LKWr772Ccxh3lHIg43PLqMmlCE314yg6TAwfkr4MTxtlpp0qDY85BiGZCVwuh+6bwVDZVW7S4l4DOM6Z8e9zkXzBjCFfNjD+fuqJSgn++fOYHnvrmAkX2bv+aovulkJAdYFmeodyy14Xq++tBSAn7DTWeMj3nOtCHZDMhM4YUV3dwC5/PBF56Ez/+7/XPdaqWTf9y4A1dLY0+HIUfDiz+EX460u7vde4qdf1S+By79p90Bq6W8UXDaz2Dja+y+6zRb8XHa/9q2urac8H0bhr18S+N9654HHBh/VvNzcwpsm1KsUKlwA/zr8/D01+E3k2wrSNnu2K9ZaYfLd7n9LXckpA9oHNa97V07T6nlvwf9JtpgIlb1Vzwl22w4d7hwd35ryQ2VOtrSWFMSe54SRCuVEmx/y2nyd0reaCja2HothevtzorJ0Z0p+02AcE3nwjCRnuCGSiUKlUREpHspVBLpZY4f25fPzxlO0N/6X9/Jg7P43hnjeXnVXv7xfuMW3OH6CK+u3suX7v+QtzcUccu5ExnVN344093cFrhE5ik1dezofD7YfIDacD2rd5czqm86yYG2h28fDD6fYerQrA6FSj/77yqW7yzljs9MZ2hujHac6HVPm9SfN9ftbzYovFskp8eeLdPSnK/A8TfB6JPjn2MMnPkLG46MP8cGQ5c+Atcvhhs3QsGx8Z876yr29TuWgSUfsSvvGBtQtSe9Lyy4wQZJm6I7u615zlZV9YsRQow6CTYvah64ROpthVQgGT77D9uWtugOuHMKPP5l2LmkeVBQEQ2Vutr+Zox9ra1v22sWb7ZD3VvqNxEiocTb9go3wO9nwtu/7dr6vCJcB4Vrm89TcuUUQKjSzrjqiOqS1ju/uVIyEx/UnTuy8XbeaLuW8hZhpLvzm6thBzi1wIlHqFJJRER6iEIlkcPMlfNHcPzYvvzvf1fx+pp93P7iWub/4jWuemAxK3eV8Z3TxnLJ7KEHdU1Hj8jl4plDOH/6oPZPbmL+6HyqQ/V8tK2EVbvKutzW1p2mD81mzZ7yhMKfp5bt5B/vbeMrx4/k1IlthxRnTBpATSjCm+s6+AW6uwyfByd+P3bLUFODj7Izk877Hcz7uh2WnT8GAu0MfTeGX6V8nafq5/HntOvafx3XnOsga5htmasps7OYxp0V+/mjTrJf/Hd80Hjf+3+284zO+AVMOBcueQi+sRRmXQmr/wv3nAR3z4N37oKK/U1CpS62v4H9TMt2wieP2ttN5ym53AqdRId1v/JjqK+D1U93fX1eULgOImE7r6slt1Koo1U/NSXxg1S3Uqmt6qdQjf1zaxkqQfPwz3FspVL+2Mb7tAOceE1NiT2WbGvzNBERkY5SqCRymPH5DLdfPI2MlCBfuv9D/vjGBiYNyuLPX5jJu98/ietPGtOpIdZdkRTw8auLp8Udsh3PnJG5+H2GZz7exZ6yGiYMzOihFXbc9KE51EccVuxqey7L+r3lfP/x5RxdkMuNp7U/w+roEblk9wl2/y5wHlFWE+KpjQ7fCl/P0zv6JLaDHkAwBU75MexZDk9cC/W1rVvfXAUL7FBytwWuaKNtdRtzOky7pPG83JFw1i/hhlVw9h0QTLWh1R3j4d27wJ8Uv32qI9y5Su/eBf7k2MPS88faNScyrHvrO7Dmv7aCZ88nULqz62vsCY6T+Ewh933Hq1SCToRKpfH//FIybYgVqo7//JKtgNN+qFSx1wZUTUOl5HQbgmoHOPGK6hJ7LNupWV8iItKtFCqJHIb6ZiTz18tn8f0zx/PW907ib1fM5vRJA2K2zHlZZkqQqUOyeGzpDgAmDuxY+1xPmh4dtL2sjWHdlbVhrntoKX2S/Pz+czMIJPD5B/w+TpnQn1dX76UuHOmm1XrHyyv3Ulcf4fNzhlFcFWrY3S8hkz9tB46vfdaGBcPmxT4vJROGHm1DpUgEnrreBkTn3hm7sik1G2ZfBde8Bl99D465zn7p6jcx8UqqtvQdb4dPl++2M6sCya3PCSTbSq/2hnVHInaWVcYguPh+e9+6F7q+xp7wyaPwq9GNbTdt2bvC7tTmhjZNZQ+zx3ih0rqXYu/k5g7qjiU5GnC3NVfJ3fmtaaiUORgCqbb90NVySLer33i1v4l3uP8eRsKNGxGIiIh0g971DVNEEjZ9aDZfOX4Ug7JTD/VSuuTY0fnUhGy44qVKpb4ZyQzOTo07V8lxHH74xHI27a/gd5fOoH+Cu94BnD5pAGU1Yd7bVNRNq/WOZz7ZxeDsVK47wYYH73bkPRoDp91mfx5zmt1RLp6RJ8KuZfDmL2DbO3DG/4PMBNov+02wM6JuWG1Dpu7g8zUGYLHmKTW89kTY107728rHYddSOPlHMHC6reLxaqi0+mmoPpDYFuZ7V9rwLdbQ9mCKDdFihUo7l8LDF7eeLeU4bVcquaFSW3OVGkKlJoO6fT47cL4oVqjUpFIJ7PspWg/14fivIXKwNA13NaxbRES6kUIlEfG0+aPzAeiXkUxeeowKj0No+rDsuKHSG+v28+SyXXz7lLHMG5XfoesuGJNPRkqAB97Z0vVFdoPX1+7j2/9aRkVt174cH6is4631hZw7bRCDs1MpyOvDuxsLO3aRYXPgM3+Hk25u+7xRJwEOvPlzGH0qTP9cx17HHwBf54bCr9lTxh/f2EB909a+gmgL3LC58Z/Yb6KddxKr6gbsjJ9XfgIDpsDUz9qQbeyZdnh5XWWn1tpjIhHY8pb9ecXj7Z+/d2Xs1jdXToEdmt3SRw/a46oWs6Vqy8Gpj1+plJJgpVJKNvTJbX5/3mgbFrkK10MwrXVo2W+inXvlhlMih1J1ceNulhrWLSIi3Uihkoh42oxh2aQG/R2ex3QwzBiazc6SavaV17R67E9vbGRQVgrXnjCqw9dNCfr56gmjeXXNPt5JIHSpqLVVTfcs3MT1Dy/lhF+9zpf/vpgDlV3fbn793nKuf2gpT3y0k2898lHzoKSDXlixh3DE4ZypAwGYOyqP9zcdIFzfwTa/iedDzvC2zxk0w+78lZwJ5/62e9rYErBo/X4uuvtdfvnCWhZvOdD4wJSL4eivwMgT4j/ZHdYdbw7PB3+B0m22ksoNvMadYedLbXqjO5bfffYut4OBc0fatVW28XtcdcC2BrrvP5acgtaVSnVVsPw/kJxld47bv7bxMXcocZPd3374xHJeWBHdta2hUqmNmWgHNjWvUnLljYbirY27C7o7v7X8Hes33h41rFu8oLrYBtKgYd0iItKtFCqJiKclB/zcfvE0vnXKmPZPPsjizVX6aFsx728+wFULRnZ6jtWX5hcwODuV255dHXeYdag+wlceXMyUW1/kkr+8x23PreajbSWM7pfOG2v3c+7v32LFzvhfmqvqwm1WH5XVhPjyg0tITQrwjZPH8Mrqffz8+fhfkA9U1vHkRzvjhkTPfLyLkflpTIru4jd3VD7ltWFW7kpga/eO8gfgvN/DZx+ErMHdf/0Y/r14O1+670MGZafg9xne2tAkSEnvZ4eCB9toR+3nhkoxWuCqDsDC223bX9Ngatg8G5Csfb5b3kO32bzQHs/8pa0YamuXul0f2WO/NiqVckdA+S5breVa/bStNDrnjsbbLncocbT9rSZUz8MfbOPRxTui9ydYqdR0npIrb7R9T27I1XLnN1f+OMBoWLd4Q3UxZA2x891UqSQiIt1IoZKIeN7ZUwcyY1jOoV5GK5MHZxHwmVYtcH9+cxNZqUEumT2009dOCfr57hnjWLmrjMc/ir27169eXMuLK/fypXkjuO+K2Sy++RTevukk/nr5bP597VwijsOn736Hx5bsaPa8nSXV3PbsKubc9ipH3/YKTy1rff1IxOGGfy1j+4Eq/vj5o7jh1LFcPnc49yzazD8/aP1fud/ZUMgZdy7kW/9axm9fXd/q8X1lNby3uYhzpg1q2H3wmJG2rahDc5U6YuL5rSqDHvlgG49+2L1fqBzH4bevrOfG/3zCnJG5/Oe6eUwbksXC9R1s7csebtuoYg3rXvgrqCuHU3/a/P5AEow+Gda/ZFvOvGLzIhu+jD4F8sa03QL34b3RwevHxD/H3QGuaYXF0gdt6DP50zDk6OYtcG4FUrT9bUdxFY4Dn+wowXGc9mcqhevsa8UKldyB3EUbbNth6fbYoVJSH1tRp0olOdQcx4ZKqTmQNVQzlUREpFspVBIR6aSUaFte01Bp0/4KXly1hy8cM5y05DYGSSfg3KmDmDYki9tfXEt1XfMtoF9YsYe/LNzEZccM45ZzJ3Li+H7kN5k5NW1oNs98/ViOGpbD//z7Y255agVLthZz/cNLOe6Xr/O3t7dwwvh+TBqUyTcfWcb3H/+EmlDja/z+tQ28snofN589gaNH2PDnR+dM5PixffnRkyt4J1qFE6qP8MsX1vD5e98nIyXA6ZP68/vXNvDG2n3N1vvc8t04DpwbbX0D6JeRwph+6byz8eAMJP9kRwk/eGI5339iOWv2dE91VKg+wvce+4TfvLKOTx81hPuuOJrMlCALxvRl+Y4SSqo60ILo89lB4fuahErhOnjzl7b17agv2sdbGnuG3c1p90ddf0PdoT4MW9+BEcfZlrDJF8LWt6E8xo5Te1fZ3fzmXAvJ6fGv6YZKbnVQ0UbY+hbMuMy+xoRzYc8njXOXGtrfsgHYUlgFQGFFHbtKa5pUKsWZX1W6HZxInEqlaEtr0YbGgd0td35z9Z2gSiU59EJVdr5Xao7dTVGVSiIi0o0UKomIdMH0odl8sqO0YdbQPYs2E/T7uHxeQZev7fMZbj5nInvKarhnUeOw3y2Fldz474+ZNiSLH50Tfw5NfnoyD151NF8+biR/f3crn777Hd5cu5+rjh3Bwu+eyO8vncE/rzmG604YxT8/2M6n/vA2m/ZX8Nqavdz56jounDG42fsI+H38/nMzGNk3jWv/sYQ31+3n4j+9yx/f2MhnZw3lma8fy28vmcH4ARl8+1/L2FVS3fDcZz7ZzfgBGYzp33wHv3mj8li85QB14Z6tsgnVR7jpseXkpSeTmRLglidX2oqVOF5auYe739jY7nXve3szjy7ewTdOHsPtF08lKWD/Z3XBmHwiDh0PzPpNsEOrHQe2fwB/Pg5evw0mfqp1lZJrzGlgfLDWI7vA7V5mq6oKFtjbky60Ac2qp1qf+/adtjprzlfavmZDqBQNjT76h33P06ID2CeeZ49r/muPbvtbtFJp64Gqhkt9sr0EkjIAE7/9zQ2nYoVKqTnQJ98O6y6MVuXFqlQCO1epaAPUh9p4cyI9zN35rWmlUht//4mIiHSEQiURkS6YPjSbitowG/dXsK+8hseW7uCimUPom9E9O9XNLsjljEkD+NObG9lXVkNNqJ7rHlqKz2f4w+ePIjnQ9g5lAb+PH5w1gb98YSY/PX8S7/7gZH5w1gQGZ6c2PP69M8Zz35dms7eshnN//xbf/OcyJg7M5P8unNLQqubKTAly7+WzbXD2tw/YuL+Cuz43g59/eip9kgKkBP388fNHUReO8PV/fkSoPsKO4iqWbC3m3GmDWq1v7qg8qurq+WRHSbd8XvH87a3NrNpdxk/Pm8T3zhjPB1sO8PjS2G2FH28v4fp/fsSvXlxDcTvDzl9cuZepQ7K44dSxzT6raUOzyUgOsKijLXD9J0H1AXjqa3DvabaS5nOPwkX3Nhs63UyfXBg6B9Z5ZK6SO0/JDZX6jbfzolY81vy84i120PbMK1rvsNZSWl8bPhVvsZVQyx62YVpmtPItpwAGTG1sgWsxqHtbUSVpSX6CfsMnO0ttVVhyRvz2N3fHtlihEkR3gNtoQyXji39e3wkQCdlzpfNqK2ybpJdaPHuTpqFS9lAIVTbeJyIi0kUKlUREumD6sGzADuu+/+0thOojXLMgzhfMTrrpzPGE6iPc8fI6fvTkClbvLuPOz05nSE6fhK9x2qQBfHFuAelxWvJOHNePZ7+xgAkDM0kO+vjTZTNJCcYOrIbm9uHeK2Zz0cwhPPeNBZwztXlYNLJvOj//9FSWbC3mVy+u5dlP7I5b5zRpfXPNGZGHMZ2o6OmAbUVV/OaVdZwyoT9nTB7AZ2YNZcawbP7f86sprW5eQVJYUcu1/1hCatBPxIHXW7TxNXWgso6l24o5aXy/Vo8F/T6OGZXHovX726yIasUd1r3sYTj6y/C192Ds6e0/b+wZsGc5lO5o/9yOKNpoK6c6YvNC+z7S+zbeN+lC2P5e8/W983sbyMz9WvvXNKZxB7gNr0DFHpjxhebnTDwPdnwAZbtspZLxRSuSYEtRFQX5aYwfkNkYYCZntlGptAmS0m2YFUv+aBsoFa6LzsJKiX2edoDrHiufgGdvgJ2LD/VKeqeWlUqgHeBERKTbKFQSEemCEXlpZKYEeGtDIQ++t5UzJw9gRH5at75GQX4aXzimgEc+3M6/l+zg6yeN5sQYQUZXDcpO5d/XzuWt753E0Ny2A6vpQ7O5/eJpcc87d9ogvjh3OH9ZuIm/LNzEtCFZDM9r/bnkpCUxYUAm7/ZQqOQ4Dj98cjl+Y/jZpyZhjMHnM/zs/MkcqKzj1y81bkMfqo/w1YeWUlxVx0NXz6F/ZjKvrI4xByjqjbX7cBw4eXz/mI8fNyafHcXVbC2qivl4TMPmwvxvwVUv2d3ikjPafQoA4860x3Xd1AJXUwov/AD+cDTcczLsWpbY88J1sO29xiol1+QL7XHlk/ZYvtcO2p52SeK787mh0kcP2rCnZdg2IdoCt/q/tlIpJctWJAHbDlRRkJfGlCFZfLKj1O6omJLZONC7pQObIGeEDbNiyRsNlftsyBGv9Q3sY8Z35M1VWvsCLLqj+65XuM4e9x9hn2N3aVmpBJqrJCIi3UahkohIF/h8hmlDs3n6412U14T5ynGjeuR1vnHyaPLSklgwJp9vndLGl9guMsbErVDqqB+ePYEpg7MoqqyL2frmmjcqjyXbipsNCgcI10e47+3NXWqNe3LZThatL+S7Z4xnYFZqw/2TB2fxxbkFPPjeVpbvsMHCbc+u5oPNB/jFp6cyeXAWJ0/oz5tr91Mbro957dfW7KNvRjKTBmXGfPzYMbbKZdH6/YkvOJAEp/4Ehh6d+HPAhhc5I7o+VykSsWHP72fCe3+EaZdCnzx45HOxB223tHMxhKvtkO6m8kbBwGmwMroL3Ht/tIOD538r8bXlFNjKqXUv2DDKH2z+eN9xkD8OVj9tw6LokO5wtAVzWF4fpg3JorwmzJaiyvYrlXJHxF9L3mh7LNkWf0g3QDDVrntfjB39Dmcf/Ble+1+oOtA913PbB/evbfs8iS1WpVJ3VzWKiMgRS6GSiEgXzRiaDcAxI3OZFv25u2X3SeK175zA/V86Gr8vTvWExyQH7Hyly44ZxkUzh8Q9b+6oPOrCEZZua5zxURuu52sPL+Unz6zi/D+8zQ+fWN6xndSw7Wk/++9qZgzL5rJjhrd6/IbTxpKXlszNT63g34u3c/87W7jq2BGcP91Wzpw6oT+VdfW8t6n1F+NQfYQ31+3npHH98MX58yjI68OQnNSOz1VqIRJxeHzpDkqr2hj2bIytVtq80G5z3xF1lbZ1bsVj8NeT4Onr7YygL78O598Fl/7Tfin912UQrm37WpsXAQYK5rd+bNKFsHMJ7P7EzseZeL5tI0tUTgHU10IkDDO+GPuciefZneaKNjYM6d5dWkOo3mF4bh+mDrH3fbKjNFqpFCNUitTbiqh4c5IA8poESW1VKoGdq3SkVdjsXQlOPWx4tXuuVxQdiH6kfY7dpWmo1CcPAql2WLeIiEg3UKgkItJFx4zMA+CrJ3TgC3InZKUGe02g5Bqa24f//dQUsvskxT3n6BG5+H2moQWuqi7M1Q8s5sWVe7npzPF8ad4IHvlwOyf9+k0e/XC7bV1qx4qdpXzzkY8oqw7x/y6cEvNzy0wJ8sOzx/Px9hJu/M8nzBuVx/fPHN/w+NxReaQG/by8ak+r5y7eUkx5TZiTJsRvQzTGsGBMPu9uLCJc3/kBw/e9s4UbHv2Y37yyru0Tx55hQ5e3f2srlja9Adveh90fw5a3YcXj8N6f4JVb4cmvwn1nw6/Hw/8Ngj8dC/+5Esr3wIX3wJUvwqAZ9roDp8IFf7Lzip75Vtu7Rm1ZZM9PzWn92KQL7PFfl9nd4Rbc0KHPoSbDVljUDJwFfeMEORPOtTvN7VraUKnkth8Oz0vj/7d33+Ft1Wcbx7/He2/HSTxjZ++9AyGEvQmzrDJbRguFlo6XUkoHFEppS4EChULLLnvvhISE7EX2tBM7y3vE2zrvHz8ptmPJljziJL4/18Ul++jonCPLStCd53l+A3pFEBLox5rcEs+VSqW5Zrh2a6FSXD/T1gZth0pJQ03IVVPR+n7Hi4MFUOGsauuM4fEN9Y2r8fW0NsLOUlUM/sGmcs6yTAtcqWYqiYhI53A/sVVERLw2tX8CC+4+qc05ROJeZEggI5Kj+XZ7IaVVdVz//DJW7irmoYtGcsl4EyRcNC6Fe99dx91vruXVZbu4bGIaA5MiGdArgnDn8PHqugbeX7OHF5fsYs3uEkIC/fi/s4YwuLf79jSA80cn8+aKPHKKDvLY5WMI8G/8t5aQQH9OGJjAFxsO8Lvz7Garu321aT9B/n5M75/Q6nObMSCRV5buZk1uCePS21jhzI3t+RU89Mkm/P0s3lyRy92nDyIsyMNf3elTzayhr//U+kH9AiC8F0SnQOZJEJ9p2rniskwLWYCblQuHngczfwnzHjAhydQftdynrgp2LzEDxt2JTYfk8aZFrv9s0w7ng5VVfZho+7Ew5jxO9rRT75FmcHZJzqGV33KKTOVWenwYAf5+DO9r5iqR4mH1t7ZWfgPzM4pJMxVNbYVK6dNg/sOQswgGntr6vscD12D3mDTY+gU01LVsVfRFSY4z5MuCou3mNQvx/J4WN6qKTdDr+jMsOlWVSiIi0mkUKomIdAIFSh0zJSueZ+bv4PKnF7P1QDmPXT6Ws5qsFje0bxSv/2AKb63K48GPN3L3G2sP3ZccE0pmYjhrc0spraojKzGc35wzlAvHphAd2vqHWcuy+Pe1E2hw2G5nSc0eksSn6/ezfk8Zw5OjD23/ctMBJmfFHwq0PJmaZVa3m7+lwOdQqcFh89P/rSEk0J8/XjCCW19eyftr9nDphDT3D/APhNuWQdleM9eorrrxNigMIpIgorf5cOnXjkLlE+42gcHn95rZRYcHJLuXmjlJh89TamrExSZUmu5blRLAkqIwbq95jEkNQz2HSpZlWuAWPXao/S2nsJKgAD96R5kV2kakRPPK0l04MiPxc1epVOysimktVAITxFWXQnh86/ulTYGAENj+Vc8IlVzzo6bdYVZs2/Vt678TbSncZm6HnG2q8Aq2Qsq4Dl9mj+IKlVxiUmHv6m67HBEROb6o/U1ERLrd1Kx46h022/MrePrq8c0CJRc/P4uLxqWw+Jcn89VdJ/LUVeP46akDGZ8RS9HBWmYMSOCVGyfzxZ0ncu20fm0GSi6B/n4eh5PPGtwLy4LPNzQOqc4uOMiO/IPMGuRhufkmYsKCGJkSwzfbfJ+r9PT8HazaVcL95w3jzBG9GZgUwYuL22hZCY01lUTJ48xco/6zzYfxrFmQNMwEIO0JlMA87oJ/muO8fhWsfqX5/Tvng+VvQhRPJtwAN37lfuZSG1bvLiGfWNbv8TBc22XIeeb2UPvbQdLiwg7NvhqVEkN1nYOC+hATgtVVN3980Q4TAkW2/B1sZvqdcHobVWEAgSHmZ7Jjbtv7Hg/2r4OwBBh5KfgHdXx4fIFzntLgc8xt/saOHa8nqippHipFp0Jloe/z10RERNzo0lDJsqzTLcvabFnWNsuyfuHm/mDLsl5z3r/EsqwM5/ZTLMtaYVnWd87bWV15nSIi0r0m9ovj6inpvHjDJE4a5HlOEUCAvx+ZiRGcNqw3t80awN8uG8OHP57BP743lilZ8c3a1DoqPiKYcWmxfLGxMVT6atMBAGYNTvLqGDP6J7B6dwmlVa0M2j7M5n3lPPr5Fs4Y3ptzR/XFsiyunJzOd3mlHVoNr8OCwuHKt00b2zs/hA/vgnrnAPXsBWYOU2utSf4BJvDykW3brMktwd/PYmfBQcqrW/lZJo+DsVebGVOYSqX0JpWEI1NMxdnuSmeVWU1588cX7TRDwdsK3zKmwahLvXsCWbPMkOmyPd7tfyzbv8EEj8ERpkJpy8etz+FqS+E2CI2D5LFmLpCGdfuuRaWSs9pRK8CJiEgn6LJQybIsf+Bx4AxgKHC5ZVlDD9vteqDYtu3+wKOA65/8CoBzbNseAVwD/LerrlNERLpfcIA/9583nAkZvs8d6mqzhyaxfk8Ze0qqABMqDegVQVq8dy2PMwYk0OCwDw0ib0tdg4O7/reayJAAfn/+8EMh2fljkgkN9OeltqqVulpEIlz9Lky5DZb9C54/Cwq2mZXdOtLm1IrswkpKKus4ebAJHDfuLfe8s58fnPsYpE/Btm12FVU2e60y4sOJDAlge7mzOq1pC1xFvlnBLml45z6BrJPM7Y55nXvco42jwYQ+ScPM9wNPN5Vfrmqj9ijcZloN/fzN/Kr8zZ1zrT3J4aFStJlVp7lKIiLSGbqyUmkisM227R22bdcCrwLnHbbPecALzq/fAE62LMuybXuVbduuf85bD4RaluVmcqiIiEjXmj3EVCR9uXE/5dV1LNlZ2Oqqb4cbkxZLWJA/32zL92r/J+ZuZ11eGX+4YDjxEY1/9UWFBHL+mL68uybPp6qnLuEfAKf9AS56zsxZ+uc0cNRDvxldcro1u0sAuHJyOmBW9/NGfkUNlbUNZMSHH9rm52cxMiWaTc5V1qlucqyv7oe6g3Dizzvjshv1GmaGqG8/zlvgirOhrhJ6Of8N0Vkt1qFV4Aq2QsIA83XiIFUqtUdV8aEZY4CZqQRaAU5ERDpFV4ZKyUDTfwLJdW5zu49t2/VAKXD4xMs5wErbtmsOP4FlWTdZlrXcsqzl+fne/c+6iIiIL7ISw+mXEM7nGw/wzdYC6hpsTvay9Q0gKMCPKZnxLNja+lylgooafv/BBh77aivnje7L6cNbzvT53sR0quscvL3yKGlbGT4HbvzSrCQXFAGpk7vkNKt3lxAa6M/UrHh6RQa3PVfJaVdhJUCLqrKRKTFsLHK2SboqlfJWwsr/wqQfQmIbK7r5ys8PMmeauUoOR+ce+2jiWvnNVakUkwpJI9o/V6mmHCr2mUolgMTBULILaio6fq09RV21CfqaVipF9Dbzz1SpJCIineCoHtRtWdYwTEvcD9zdb9v207Ztj7dte3xiYtsDU0VERHxlWRazh/Ti2+0FvLdmD9GhgYxNi/HpGNMHJJBTWMmtL63k3dV5lFY2VhqVVNby0CebOOGhuTy3cCfnjU7md+e7b78akRLNqJRoXlyyC7sjc2o6U68h8IMFcMu3ZpW5LrBqdwkjUqIJ8PdjWN8o1u/xrlIpxxkqpR+2OuPI5GhKHKHmm+oyE/R8fDeEJ/Iv/0u48T/LefDjTbyxIpfVu0tan+HkraxZcDAfDqzv+LGOVvvXA5YJf1wGnga7F0Nlke/Hc638dihUGmRuC7Z06DJ7lOoSc9s0VPIPgKhkzVQSEZFO0fpayB2TB6Q2+T7Fuc3dPrmWZQUA0UAhgGVZKcDbwNW2bW/vwusUERFp1ewhSTyzYCcfr9vHuaP6EuDv27/JXDI+la0HKvhs/T4+/G4v/n4WEzPiGNQ7kjdX5FJRW885I/ty++wBZCVGtHqsKyanc/cba1m6s4hJmW0sZw/UNzjw97M6dYB5C0FhEJTWJYeuqW9g454yrp2WAcDw5Gjmby2guq7B46p9LjmFB/GzICX2sFApNYZynNtqymDtq5C7jMUjf8/vv8glOSaUeZsPUNfQGNzNGZvCI5eMavV8n67fx7zNB/jD+SMOrTZ3SOZMc7t9LvQe0ebzPiYdWA/xWc3DxUFnwII/w9bPvR9s7lLgDJVc7W+9hpjb/M1mcLe0rcrZ59k0VAJTRVaqSiUREem4rgyVlgEDLMvqhwmPLgO+d9g+72EGcX8LXAR8Zdu2bVlWDPAh8Avbthd24TWKiIi0aVx6LDFhgWZYtA/zlFzCgwP44wUj+P15w1mdW8KXG/fzxYYDPL8om9OGJfGTUwYyuHcrq6Y1cc7Ivvz+gw28uGRXi1CpsraejXvLWJdXxvo9pazLK2PL/nIumZDKHy/o/iAjr6SKl5fkcMfsgQR6Gcxt3FtObYOD0akxAAzrG02Dw2bTvvJD2zzJKaqkb0woQQHNz9U3OoTAsGhoAErzYNm/OJg4hmtWZDJjQALPXzsRh3PI97YDFby8ZBcfrN3DHy4Y3mqQ9e+FO1m8o4hRKTFcNvGwkC2qr6ng2TEXpv3Yq+d+zHGt/NZU37EQ3svMVfI1VCrcBlgQ2898H9sP/AI1V8kXnkKl6FTI/ubIX4+IiBx3uixUsm273rKs24BPAX/gOdu211uWdT+w3Lbt94Bngf9alrUNKMIETwC3Af2Bey3Lute57VTbtg901fWKiIh4EuDvx6zBvXh39R5OHNj+dms/P4uxabGMTYvlZ6cN9qra5nChQf7MGZfCi4tz+HJjX3YWHGRdXinr9pSxI78Ch7O4Jj48iGHJ0USHBvLK0l1cMyWDQb0j233tneFPH2/ivTV7mN4/kSlZbVdZAazeZT4Uj3a2HA5PNuHb+j2lbYdKhZWku1mlz7IsMlP6QA7w7ePYNWX8uO6nJESG8vfLxuDvZ+GPRVZiBFmJEQT6W3y9JZ8VOcVM65/g9lyVtfWsyCnGz4IHP9nEqcN6Exce1HynzJNgxb/NnJvAEK+efwsN9bD1M+g/GwKC2t7/SKk9aFZ6G3lJ8+1+fjDwVNjwHjTUgX+g98cs3AoxaY0/K/8AU7WkUMl7rVUqle/x/TURERE5TJfOVLJt+yPbtgfatp1l2/YfnNvudQZK2LZdbdv2xbZt97dte6Jt2zuc239v23a4bdujm/ynQElERLrNz08fzAvXTiQmrPM+yPsaKLlcMSmNugab619Yzu8/3MiSnUVkxIfz45MH8K+rx/PtL2ex/J7Z/Oe6iTxxxVgiggN4+NPu/SC+I7+CD9aahV2/3VHo9eNW7y6hV2QwvaNMsJAcE0p0aCDr8toe1p1TeJD0Jiu/NTUiNY4KOwRqSvk6/DQWVKbx5JVjiT08CAIm9YsnwM/im22eh60v2VlEXYPN/501lIrqev70sZufd9YsqK+GXd+2ee0eff0gvHo5LHik7X0LtpnB1kdiOHj+JsBuWakEMPAM02aYs8i3YzZd+c1FK8D5prVKJdsBZXtaPkZERMQHXdn+JiIictxIigohKaqd1SWdrH+vSP597QT8LIthfaNIiAj2uG9seBA3z8zioU82s3RnERP7xR3BK2305LztBPr70TcmlMU+hkqjU2MOzYSyLIvhyW0P6y6rrqO4sq7FkG6XkSnRlBOGZflzV+F5/G7OMEamxLjdNzw4gLFpsSxsJVRauLWAoAA/rpiUxoHyap76egeXTEhhXHqTn3fGNNO+tWMuZJ3U+hN3J+dbEyYFhsOix2D8tRDZ2/2+eSvgX7NNcBAYbla0Sxxs/hv3/eZLzHcG18pvvYa2vC/rJPAPhi2fQOaJ3h3PtqFwO6RPbb49cQisfwdqK7tsMPxxpbVKJTBzlWLTj+w1iYjIceWoXv1NRERE3DtpUC9OHJjYaqDkcu3UfiRFBfPgxxs7vGpcXYODooO1Pj1md1Elb6/K4/KJaZwyNInVu0qormto83EllbVkF1Yean1zGd43mk17y6lr8FyBs8u18pub9jeAkSkxPF1/Fj+puYlTJgzn0gmtDxqf1j+B7/JKKfbw3L/ZVsCEjFhCAv358awB9I0O4f/eXkd902sMCofUSWZYt6+qS+Htm0yFyXUfQ0MtzHvA/b4NdfDe7RCRBGf9BcZeDSHRsGMefPEb+Oinvp+/Lfs3QGBY4/yjpoLCod8JsOlDExZ5o3wv1B1sXPnNJXEQYJvWOGlbVTFY/hB8WOtrtPP3vUTDukVEpGMUKomIiBznQoP8uWP2QFbuKuGzDfvbfRzbtrn5xRXM/svXlFbVef24p+Zvx7LgBydmMiUzntoGBytzitt83OrdJQAtZicN7RtFbYODbQcqPD42xxkqpcW5b39LiAjm69iL2NtnNved66Zl6zDTB8Rj2+5b9w6UV7NpXznT+5t5W+HBAdx7zjA27Svn+UXZzXfOmgn71sJBz1VPbn10t1kC/sJnoM8omHA9rPyPWQntcIufgP3fwRkPmf3OeBCufhfu2gSTbob1b0PZXt/O35b968zqbH4e/tdy+BwoyYGdX3t3vAJnaNSi/W2wuT2gFjivVBWbKqXDV3+MTja3WgFOREQ6SKGSiIhID3DxuBQyE8N5+NPNzatnfPDFxgN8sfEARQdreX5htleP2VdazevLcrloXCp9okMZnxGLv5/l1Vyl1btLsCwYkRzdbPtw5/fr8jy3wGUXHgQ8VyoBvPaDKbz2g8lezbYamRJDRHCA27lKrra4GQMah3ifNiyJWYN78ejnW9hXWt24c+Ysc7tjXuM2hwO2fg5f/d5U/Bxu3Zuw9lU44WeQNslsO+FuCIqAz3/TfN/ibJj7AAw6C4ac0/JYk24CRwMsf671J7xrSWOw0xbbhgMb3Le+uQy7AMLiYcnT3h2zcJu5PbxSKT4L/AI0V8lbrlDpcIGhEJ5oZm6JiIh0gEIlERGRHiDA34+7TxvMtgMVvLky1+fHV9U2cN976xmYFMGswb149psdXlUrPT1/Bw22zS0zswCIDAlkeHI03273LlQa0CuCyJDmq1P1iw8nPMif9Xs8D+veVVhJQkQw4cGex0cmRgYTFuTdeMlAfz8mZ8a7nau0YGsBsWGBDO0TdWibZVncd84w6h02v/uwSVDUdzSExJgWuKpi+PZx+Mc4eOkimP8wPDkFXrrYLPdu26Y66YOfQPJ4EyS5hMfD9J/Alo8bl4a3bfjgTvDzhzMfalmdAhCXCQNPN6FSfY37J1uyC/5zLvz7DO8qmioOQGUhJA33vE9gCIy9xlxvcU7bxyzcZtrpIvs23+4faIImdxVa0pKnUAlMK2VPq1Sybdi5wPs2TBERaZNCJRERkR7itGFJjEmL4dHPt1JV2/ZMo6aenLeNvJIq7j9vOHeeMpCy6vo2q5UKKmp4eWkO549OJrXJwOwpmfGsyS2hsrbe42Nt22aNc0j34fz8LIb2jWq1Uimn6GCrVUrtMb1/PDmFlewuqmx2nQu3FTC1fwJ+fs1DnLT4MG46IZMP1+5lb2mV8+L9zbDq9W/DI0Pg01+Z2UdznoW7tsBJ/2eGbD9/FvzrZHjtKlNZNOcZ8D8sAJt8M0Qlw2e/NtVO696E7V/CyfdCdIrnJzLpB1BZAOvecn+/q/qpthLeuNbMaGrN/nXmNqmVSiUwrXjQdpUUmCqp+Cz37XSJgyB/Y9vHkNZDpZjUnjdTKXc5vHC2GZYvIiKdQqGSiIhID2FZFr84fTD7yqq563+reXd1HtsOVNDgaP1f7bMLDvLPr3dw/ui+TM6MZ3hyNKcMTWqzWunZb3ZSU+/glpOymm2fnBlHXYPNilbmKu0qqqS4so7Rqe4/EA/rG82GvWU4PFx7TmFl54dKzva2pi1w2w5UsL+shhn9E9w+5pxRptJm7qb8xo3D54DlByMvhh8sgOs+gREXQWQSnHg3/GQ9nPUIVBbBnpVwxp9MhdHhAkNh1j1mnxXPwSe/gORxMOGG1p9I5kwzm2jJky0rNnIWwfq3YNodcM7fYNe38OX9rR/vgLMSq1cbs6miU2DwWWYWVF1V6/sWbmvZ+uaSONi0+bV1DPGiUim3Z1XtFGeb26Id3XoZIiLHE4VKIiIiPcikzHiumZLOFxsPcPurq5n9l68Zcd+nXPTkIh6fu61FBZNt29z3/nqCAvz41ZlDDm2//eQBrVYrlVTW8p9F2Zw9si9ZiRHN7puQEUeAn8XiVuYqeRrS7TKsbxSVtQ3sdM5Oaqq6roF9ZdWkexjS3V5ZiREkRQU3C5UWbDVfTx/gPlQa0CuC5JhQvtp0oHHj0PPgV7lw7mPQZ2TLBwWGmmDoRyvgtuUw5krPFzXyUkgaAR/eZUKoc/5mqqFaY1mmWmnvGti9pHG7w2GCqahkmHa7Cb3GXw+L/g4bP/B8vP3rIaK3aclry8SboKrIVFV5Ul9jhnrHD3B/f+JgsB2Nc5fEs6rSViqV0qChBg7mu7//eFSWZ25LfW8BFhER9xQqiYiI9DC/PW846397Gp/cMYM/XzyKS8an0mDbPPzpZk768zzeWpl7qALo8w37mbc5nztmD6BXVMihY7RWrVR0sJabX1zJwdoGbj2sSgnM6mgjU1qfq7RqVwmhgf4MTIpwe39rw7pziyux7daHdLeHZVlM75/Iom0Fh34+32wrICM+jJRY9+eyLItZg3uxcFsB1XW+tRzi599y9TN3+5zyW/P11Nug9wjvjj3yUgiJhsVPNm5b/ZIJmmb/FoKcz+f0B6DPaHjnFija6f5Y+9e33frmkjEDEofAkqc8V8gU7TShkafn7loBrrvmKr1/Byz8W/ec2xcN9VDTSqgUnWpue1ILXLlzRphCJRGRTqNQSUREpAcK9PdjcO8oLhqXwn3nDuPtW6bx+g+mkBgZzJ2vr+GCJxbyzdYCfvv+BgYlRXLN1IwWx3BXrbRhTxnn/uMbVuwq5pGLRzG4d1SLxwFMzoxnbW4pB2vcz1Vak1vCiORoAvzd/69K/14RBAX4uR3WnV1gZh51dqgEMH1APMWVdWzYW0ZtvYPFOwo9Vim5zBrSi6q6BpbsLOr06wGg/8lw6zI4+T7vHxMUbgZnb3zffMCuLoMvfwupk0wrnktAMFzyAljA61dDXXXz4zTUm3AnqY3WNxfLgok3wr61kLvM/T6HVn5rGUge2m75w4FumKtUshtW/BuW/uvobxurdgaurc1UAijtQSvAqVJJRKTTKVQSERERACb2i+PdW6fxyMWj2FdWzZXPLnEO5x5GoJtw5/BqpQ/W7mHOk4uob7B5/QdTmDPO87DoKVnx1DtslruZq1Rb72D9njJGp8V4fLwJxSJZv6dlpVJOkStU6tz2N4BpWY1zlVbvLqGytoHp/RNbfcyUzHhCAv2Y27QFrrMlDnQ/1Lo1E24AbFj2LCz4s2mDOv2BlqvGxWbABU+ZIOj1q6Bwe+N9RdtNC1Vb85SaGnkpBEfB0qfd31+41dw6299q6x18sWE/tivECQg2M6byNzV/3J5V8OFP4WDLFfo6zbo3zG3prqN/Lk+V873VZqVSTwqV9phbhUoiIp1GoZKIiIgc4udnMWdcCnN/OpOfnjqQX5wxmEmZnmfluKqVrvzXEm57eRVD+0bx3o+meZyF5DIuPZZAf8ttC9xXm/ZTW+9o8xjD+kazLq+sMWxw2lV4kMjgAGLDAlt9fHv0igphYFIEC7cV8M3WfPwsE5C1JiTQn2lZCXy5aX+La+1Wsekw6ExY/qxpgxv1PTPo251BZ8DpD5rl2B+fCB/cCeX7TesbeF+pBBAcAaOvgPXvmGMcrmCbWREvxFS5vbZ8Nzf8Z3nzqrRegxvb38r2wts3w9MzYdkzsPE976/FV2v/1xjG7JjXdefpDG2FSqExpgWyR4VKzva3sj2myk5ERDpMoZKIiIi0EBYUwG2zBvDDEz20IDm5qpW+yyvl8ompvHzjJHpFhrT6GNfxR6XE8O1hw7p3FVZy9xtrGdY3ilmDe7Vx7ihKq+rILW6+Clh2YSXpCWFYh1fcdJLp/RNZurOILzcdYGRKDNGhbYdXJw3uxe6iKrbnV7i93+Gw2bq/vLMvtW2TbzZtUv5BMPs3be97+2rTNrfyBfj7aFjwF9OKljjIt/NOuAEcdbDi+Zb3Hbbym6vCa9O+Jj+fxMGmUmjuA/DYWFNBNO0OCI6Gfd/5di3e2rcODqw3Q8yjU4/+ZenbCpXADOs+1kKl6jLYOd/3xzXUQ8U+CO8FdoP5WkREOkyhkoiIiHTIQ3NG8t/rJ/LHC0YQHNDGymNNTMmKZ11eKeXVZtB3dV0DP3xxBQD/vHIcIYGtH2tYXzOs+w8fbuTp+dv5cO1eVu8uYWfBwU5f+a2p6QPiqXG26M1oY56Sy0nOgOwrDy1wf/9qK6c8Op/P1h/hD7rp02DExXDaHyCyd9v7R/aGs/8Cty411Uv7vzMBT0Cwb+dN6A/9Z5sWuMMrfgq3HgqVqusaWLTdtLM1C90SB5tg4OsHYcAp5npO+a0ZVL5vnW/X4q3vXge/ABh2IWSeaIINh4/D14+kQ6FSjOd9YtKPvVBpxb/hhXOhwsdV6yr2mwHwqRPN9z1pQLmISBdSqCQiIiIdEhsexIwBiT5XBk3OjKfBYbM823z4vffddWzYW8ZfLxtNalzbQ7aH9IlkSmY8C7cX8MePNnHryys5//GF7CqqJCOh84d0u0zsF0+An3mu0/t7Fyolx4QyuHek21Bpf1k1T31t5vP87sMNvq8S1xGWBXP+BeO+79vj4rPgoufglsVwyX/ad+6Tf2MGhv/nPHjle2ZWU2URVBYeWvlt6c4iqusc+PtZbGkaKvWfDeOvg2s/NueP62e29x5uWvI6O+xxOOC7NyDrZAiPh8yTTIXXntWde57O5FWlkjNUOpraMttSuB2woWCLb49zzVNKm2xuNVdJRKRTBHT3BYiIiEjPNDYtliB/PxbvKGR/WTWvL8/lx7P6M2twklePDw7w55WbzAfEsuo68oqryC2u4kB5NacO9aLqpp0iggMYkxbD+j1ljElr5QP7YWYN7sXT83dQVl1HVEhjy9yfP91Mg8PmT3NG8PM3v+Pp+Tv48ckDuuLSO1+vIe1/bJ+RpsJo8ROw4BF4fBIMOt3c56xUmrc5n6AAP04cmMiGpjOVQmPg7EdbHrP3CKg7CEU7TTVUZ8lZaFYOO+V+832/E83tjrmQ4mEOVXerKgYsMzfJk5g0qKs0w80jWh84f9QoyTG3hdsgY5r3jyt3hkopzkqlUlUqiYh0BlUqiYiISLcIDfJndGoM76/Zw73vrWfGgARunz2wXceKCglkSJ8oThmaxBWT0kmM9LEdy0e/OGMID180iqAA7/9XatbgXtQ7bBZsaVydbP2eUt5Ymcs1U9O5dEIaZ43owxPztpFbXNkVl330CQyBGXfCj1aYVeE2fmC2O1d+m7flAJMz4xmVEk1eSRUHa9oYrtx7hLndt7Zzr3PtaxAUYQabgwlgeo84uod1VxWbYed+rbSRxqSZ22OpBa7YFSpt9e1xrkqlhAGmekuVSiIinUKhkoiIiHSbyVnx7CmtJiE8iL9dNgZ/v64Zrt3ZxqXHctbIPj49ZkxaLDFhgXy5yax4Zts2f/xoI9Ghgdx2kglRfnWWqfz5w4cbO/eCj3aRveH8x+GmuaYCKT6L3UWV7Mg/yMyBiQxIigRg6wH3g84PSRxs5h7t78S5SnXVsOE9GHIOBDVpq8ycCbuXQO3BzjtXZ6oqbr31DcwKgAAl2V1+OZ3C0dAYBhVs8+2xZXkQEGJ+JtEpCpVERDqJQiURERHpNqcP601KbChPXDmOuPCg7r6cLuXvZ3HiwES+3pyPw2Ezd/MBFm4r5PaTBxAdZtrhkmNCuXVmfz5et4+F2wraOOJxqO8YMyvJspi32cyfmjkokYGuUKmtFfICgiFhUOeuALf1U6gpNQPNm8o8CRpqIefbzjtXZ/ImVIpONbfHSqVS2R6zaiBWOyqV9kJkHzNHLDpVoZKISCdRqCQiIiLdZmjfKL75+SxGp8Z096UcEbMG96LwYC0rdxXzx4820S8hnCsmpTfb58YTMkmLC+M3762nrsHRTVfa/eZtzictLox+CeGkxYURFODXdqUSOFeA68RQae3rEJHUOEfJJW0K+AeZuUpHI29CpZAos4+rpexo55qnlDwWirOhoc77x5btgahk87UqlUREOo1CJREREZEj5MSBifhZcPcba9l2oIKfnz64xVymkEB/fn32ULYdqOCFRdndc6HdrLqugUXbC5k5yKwq6O9nkZUY0XwFOE96j4DyvWb4dEdVFsHWz2D4HPA/bH2boDCzktjROlfJm1AJGleAOxa4wq+sk8FRb4Ilb5XlQVRf83V0iqk+qy7t9EsUEelpFCqJiIiIHCExYUGMS49lR8FBJmbEcdow9yvdzR7Si5mDEvnrF1spqKg5wlfZ/ZbuLKKqroGZgxpXJBuYFMHW/V5WKoHv1Uq7l8K2L8ysnnrnz3zDu6bFbeQl7h+TOdPMb6o44Nu5jgSvQ6W0YydUKskBLMg6yXxf4GULnG2boDHKOQctOsXcluZ1+iWKiPQ0CpVEREREjqBTh/bGsuD/zhqCZbkfTG5ZFvecNYSKmnpeXHyMtCY51dY7KKms7dAx5m3OJyjAjymZCYe2DUyKJK+kigqvV4DzIVQq2QX/PgNenAP/GAe/T4JHhsCXvzUr0fUZ7f5xmc5wY8fX3p/rSHA4oLrEt1DJ0UWtlnkrTGDXGUp2mWqjXkPN997OVaosNOHgofY35ywptcCJiHRYQNu7iIiIiEhnuWZqBrOG9CIrMaLV/fr3imTW4F68uDiHH56YRUhgK0vDHyVKq+q47OnFlFfXMe+nMwnwb9+/X87bcoDJmfGEBjU+5wG9zM9r6/5yxqS1EpaExZnwwJdQadFjgAWXv2YqfEpyTKtV6W4Y930z3NmdPqMgJMa0wI282P0+3aGmDGyHd6FSbAY01MDBA2YVvs720c/MkOyfrAe/Dv57dnGOadcLjYHwRO8rlcqcFUlN29/AvL4iItIhCpVEREREjqCgAL82AyWX66b148pnl/D+mj1cPD61i6+sY6rrGrjxheVs3FsGwMLthZw4MLGNR7W0u6iSHfkHufKwAeaHVoA7UNF6qASmWmn/Ou9OWJEPK/8DIy+FQaf7drF+/pB5ogmVbNtz+HSkVRWbW28rlcBUAXV2qORwwIFNUHcQdi+G9KkdO15JDvQ7wXwdPwAKt3n3uLK95jbSGSpFJIFfgCqVREQ6gdrfRERERI5S0/rHMygpkucWZmPbttt9Siprue3llczfkt+uc1TW1uNwuD+2t+obHNz28iqW5RTxyMWjiA4N5M0V7fvAPm+zmU/UdJ4SQGpcGMEBfmz1Zlh30nDI3wx11W3vu/QpM0Np2u3tuVwzV6ks1/uA40jwKVRyhnddsQJc6W4TKAGse6tjx6qvMSu4ua43oX/7K5X8/M3XCpVERDpMoZKIiIjIUcqyLK6bnsHGvWV8u6PQ7T73vbeeD9bu5drnl/k8f6mwooaZD8/jnH98w458L4Zgu2HbNr946zu+2Lif+88dxpxxKZwzqg+frt9HebUPS747zducT1pcGP0Swpttb1wBzsth3XYD5G9sfb/qMlj6NAw5GxIH+nytQJO5SvPa9/iu4FOo5KyAK+mCUCl/s7mNToMN70BDG/OwWlOaC9gQ6wyV4gdAZUHjc21N2R6w/CGiV+O26FS1v4mIdAKFSiIiIiJHsfNGJxMXHsRz32S3uO+z9ft4Z/UefnBCJicOTOSed9bx+w820OBl5dGv311HSWUducVVnP3YN7y10vfKjQc+3sQbK3K5Y/YArpqSAcCFY1OoqXfw8Xf7fDpWdV0Di7YXMnNQotsh5mYFOC8qlbwd1r3iebOs/LSf+HSdzcT1M9UzC/8GCx6Bwu3tP1Zrairguze8C2Z8CZWCwiEsoWtWgHOFeifeDQfzIXtB+49VnG1uXe16CQPMbYEXFWJle0xrn1+TuWTRKapUEhHpBAqVRERERI5iIYH+XDEpjS837Se74OCh7SWVtfzq7XUM7RPFT08bxNNXjeP7UzP41zc7+eGLK6isbT18+GDtHj76bh+3zx7Ax7fPYHjfaO58fQ13vr6ag22tsOb0zPwdPD1/B9dMSef2kwcc2j4mNYZ+CeG86WNINXfTAarqGlq0vrkMSIpkT2l12xVQsf0gKAL2tTJXqb4Gvn3czOhJGefTdbZwzl9NaPHl/fDYWPjndJj/58ZZPp1hwSPw5vXwv2vabuvzJVQCU/3TFZVKBzZBZB8YcZF5Pda92f5jua4vpkmlEni3Alz5nsbWN5foFBM2daR6SkREFCqJiIiIHO2umpxOgJ/F84uyD2277731lFTW8vDFIwn09yPA34/7zh3GfecM5cuN+7n0qcXsK3UfPuSX1/Drd9YxKiWaH5yQSd+YUF6+cRK3nzyAd1blcfZj3xwauO3Jgq35PPDxRs4c0ZvfnDOsWWWRZVnMGZvMkp1F7C6q9Oo5vr58N7e/upp+CeFMzUpwu0/TYd2t8vODpGGtVyqteQUq9sH0O726vlZlzYIbvoA71sFpf4SAEPjqd/D8WWZYdUc5GmDNqxCVAps+gBfnmAorT6pKzG1IjHfHj0nrukqlxEEQGAqDz4KN70N9bfuOVZwDfoGN4VBsuhm27c0sqzJ3oVKqaZGs8K2aTsRnDocJgmvKTeBbkQ/l+8xwf5HjgEIlERERkaNcr6gQzhnZl9eX76a0qu5Q29tts/ozrG90s32/P60f/7pmPDvyKzjr7wv4ZmtBs/tt2+aed77jYG0Df754FAH+5n8HA/z9+MkpA3n5xslU1tZz6VPfsi7PfXCxu6iSH7+yigG9IvnzxaPw82vZqnb+mGQA3lmV1+pzq2twcN9767n7jbVM7BfH27dMJSTQ3+2+A5PMqnnbvJ2rtH+d+w9ujgbTrtZntBm03VliUmHKrSZguuBpKNoOO77q+HF3zDPVNqf9AeY8a1ZS+/dZUL7f/f5VxaYyKCDIy+tOg5LdnROAuTgcZqZS4hDz/fA5UF0CO+a273glOaa6yNXC5h9oKtK8GdZdtqdx5TeXaOcsKbXASVeybXhiEvwhCR5IgT9lwJ/7wyODTGWjyHFAoZKIiIjIMeC66f2orG3gmfk7+L931jGkTxS3zOzvdt9Zg5N497ZpxIUHcdVzS/j7l1sPrfD23po9fLp+P3edMpABzsqfpiZnxvPGD6cSGRLIlc8uaVGxVF3XwM0vraC+weafV40jLCjA7TWkxIYxOTOOt1bleVy5ruhgLVc/u5TnF2Vz/fR+PH/tBGLCPAchqbFhhAT6scXbuUo1Ze7buja+B0U7YPpPwM3spk4x7HwIi4fl/+74sVa/bKqOBp1hWsm+95oJrJ471TyPw1UVe9/6BqalzFEH5Z3Yrle6G+oqoddg833mSeY5tLcFrmRX45Bul/j+bVcqVZdBbYX79jdQqCRdq2wPFGyBoefBKb+D0x+EM/8MsRmwd013X51Ip1CoJCIiInIMGJ4czcR+cfxj7jaKD9by54tHEhTg+X/l+veK5N3bpnH+6GT+8vkWvv/8MjbvK+c3761nTFoMN8zI9PjY1LgwXr5xEqGB/lzxryVs3mdCHNu2+fU761iXV8ajl45usULb4S4cm8LOgoOs2l3S4r6Ne8s49x/fsGJXMY9cPIpfnz30UNWUJ35+Fv17RbClrfY38Dysu6EeFvzFBBJDzmn7OO0VEAyjr4DNH3dstlJViWl5G3GxOSZA/9lwzfumBe7Z00yVUbPHFENojPfncM0p6swWuPxN5tZVqRQQBEPPhU0fQl2V78crzmm8TpeE/mYwuqPB8+PK9pjbFqGSqaTTCnDSpQqcKyBOuBGm/Rgm3wwTb4Q+o7pmjplIN1CoJCIiInKMuH56PwBuPall25s7YUEB/OWSUfzxghEs3l7I6X+bT5Wz7c3fTctaU+nx4bx842QC/Cyu+Ndith0o5+Wlu/jfilx+PKs/s4cmtXn+M4b3JiTQjzdXNK8G+XDtXi58YhF1DQ5e/8EU5oxLafNYLgN6RXq3AlyvoWD5NQ+VGurhrRth31o48RfNVwPrCuO+b+b2rHqx/cdY/zbUV8Po7zXfnjIerv0Eag/Ce7c1b13zuVLJuaJaZ4ZKB5wrvyUOatw2fI6pGtr6uW/HqqmAygI3lUoDoKGm9WCozNl+eXioFBxpKqdUqSRdKd8ZKiUObr49Jt283zqz5VSkmyhUEhERETlGnDasNx/+eHqzldbaYlkW35uUxlu3TGV432h+c84wshIjvHpsv4RwXrlpMmBx2dOLue+99Zw4MJHbZw/06vGRIYGcNqw376/ZQ019Aw6HzSOfbebWl1cypE8k7982ndGpMV4/F4ABSRHsLa2mrK0V4AJDTejgCpUa6uHtm2D9W3DK/TDyYp/O2y7xWdDvRFj5QuvVNK1Z/bKp9uk7puV9vQabOUs75sHyZxu3+xwqOecLdWblRL5z5bemFVMZMyC8l+8tcK6wq0WlkvN9UNBKC5yrpe/wUAnMXCWFStKV8jeb92L4YYsPxKZDQ60GxctxQaGSiIiIyDFkWN9ot4Ox2zI8OZr3fzSd701K8+lxWYkRvHLjJGwbekeH8LfLRrdZ5dTUhWNTKKuu593Ve7jpv8t57KttXDo+lVdumkyvqBBfnwYDezlXgPN2WPe+dc5A6QcmzJj9W5h2u8/nbbfx15pKmm1f+v7Ygq2Qu9RUKXma/TTu+5B1Mnx+r2kFA99DpcBQiEjq3FDpwMaW1Rl+/ma2zJZPzUpY3nJdV2xG8+3xzlCpsJVh3a72t8g+Le+LTlGoJF0rf7N5Hxz+/o3JMLfFaoGTY59CJRERERFp1YCkSD6/80Q+uG1Gq4O03ZneP4FekcHc/cZa5m7O57fnDuPBOSMIDmhf69lA53DxbQe8HNZdugv+dw2sewNm3wfT72jXedtt0FkQnggrPAzsXvCImYvkCj+aWv0yWP4w8hLPx7csOO8fZjW0d242FVG+hkrgXAGuk9rfHA4znLjXkJb3DZ8D9VWw+RPvj+f64H14pVJ4AoREt74CXFkehCU0zqNqKjpFM5WkaxVshgQ3lZ2uVk7NVep6Jbsh59vuvorjmkIlEREREWlTXHgQ0WGBPj/O38/imqkZJEQE8+L1k7hmagZWB1ZcS4kNJTTQny1eVSoNN7ebPoCTf2NWezvSAoJgzJWw5RMozWt+3zePmmXFdy+Bf5/ZvGrG0QBrXjVDuSN7t36OqL5mRandS2Deg2YlN59DpfTOq5oo3WVWfms6T8kldRJEJfvWAleSA4FhLVuILMtUK7VVqeSu9Q1MqFRdalaIE+lsBwugsrBlxR6Y1ktQpdKR8Pmv4dXLu/sqjmsKlURERESkS90yM4ulvzqZKVnxHT7WoRXgvBnW3XesqVI5+Tcw484On7vdxl4DtgNW/bdx25Kn4Iv7YPhFcN2n5sPnv89s/JC5Yx6U72k5oNuTEReb1ezmP2y+b0+lUlmeaRXsqAOHrfzWlJ8fDDoDshd4P2fKtfKbuzAyYUDrM5XK9poQy51o54B4tcBJVzi0AqKbSqXAENOSqUqllj67B1a/0jnHsm3YucBUbyo87jIKlURERESkS1mW1a45UJ4M6BXh3UylsDj42TavAiWHw/bq3Muyi1iXV+rVvofE9YOsWbDyPya0Wfkf+PhuGHw2XPBPSJsEV78L1SXw/FlQtMO0voXEmADGG5YFZ/8VwpzBna+hUmw6OOobB1t3RL6bld+aSp1kVoE7sMG745XktFz5zSW+vwnfajz8PpTlQZSbeUrQWC2iUKlrLH0Gdi9te7+CrY3zwI4nnlZ+c+nM6sDjRXUpfPs4fPpLz+9pX+RvNitHQuNKkNLpFCqJiIiIyDFlQFIk+8qqKa1qYwU48DzguondRZXMeGgud7+xhoZWwqUvNuznsqcXc+4/vuEPH26gqtaHFd3GXWs+1HxwO7z3Y9PWdtFzZhYSQPJYuOZ9E7b8+yzTsjfiYvezgDwJT4Bz/w5+ARCX6f3jwFQqQedUThzYBJF9m6/81lTKBHPrTeBg22bWU4yHAfOuFeAK3VQr1VVBVVHr7W+guUpdobYSPv45LH267X3f/gG8eoV5rbuKw2Gq1o6k/M0QFOG5Ui42XZVKh8v51lR1VhV7nkPni+wFjV8f3n4snUahkoiIiIgcUwb3NsO6F2zN7/CxSqvquPb5ZRRU1PD68lzuen019Q2OFvst2l7ALS+vZHjfKC6fmMYzC3Zyxt/ms2RHoXcnGnSGWWFt1YuQMR0ufbFlYNRnFFzzATTUQH21961vTQ0+C36ZC0nDfHucawh2Zwzrzt8EvTxUZ4BZxS08EXKXtX2sqmKoKWs5pNslvr+5dRcquaquPH2oj+xtBqGrUqnz7VsLdgMUZ7e9b+E2U922d03XXc/aV+Fvo8ycoyPFNaTbU7Adk+5sOfUiHO8psheAfxCkTYVFj0FddcePFxhuvi7T+7yrKFQSERERkWPKtP4JDOsbxX3vraewoqbdx6mtd3DziyvIKTzI89dO5GenDeKd1Xv4yetrmgVLq3eXcOMLy8mID+P5ayfyhwtG8PKNk3DYcOnTi/nNu+s4WNPGLCL/QJj1axh6Plz+KgSGut+v93C47jM473HoO6Z9T8zTsVsTnQJY7kMlXypIXCu/eWr5AfMhO2Wid5VKrkoOT+1vcZmA5X4FONeKepEe2t/8/E3gpFCp8+WtMLdthUqVRablCcxg+q6ye4kJa/ev77pzHC5/c+vvg5g0U5WjSrlG2QvMnw0n/RIq9jefQ+cr24bsb2DwmWD5df37fO+arq22O4opVBIRERGRY0pQgB9/uWQ0ZVX13PPOOux2/I+8bdv839vfsWh7IQ9eOJIpWfHcelJ/fn76YN5fs4fbX1tNXYODzfvKuea5pcQ7V6+LDQ8CYGpWAp/cMYNrp2Xwn8U5nPG3BazaVdz6ScdeBZe8AMERre+X0N+sGNeBVfJ8FhBswpfDZ7xU5MOTU2GJF21MYEKgusrWP0wDpE6Aou1wsI1KL9f1eKpUCgyFmFT3lUquUMlTpRKYME2hUudzhUoH81ufjeMKnUJi4Lv/dV3Vzr515tY156irVZeaSjl3Q7pdXEGp5ioZVSWwdy30mwEZM0y4tPDv7f+dyN9kFkDInGn+bOvK9red8+GpE2DrZ113jqOYQiUREREROeYM6h3JnacO5ON1+3h39R6fH//EvO38b0UuPz55AHPGpRzafvPMLH515mA+XLuXH/53BVc+u4SQQD9eumESvaJCmh0jLCiA35wzjNdumkKDw+aif37L43O3tTqX6agWk9a8UqmhHt641gzUXvg371Zrc6141cvNym9NpUw0t221wLVVqQQQPwAKW6lU8jSoG0wgpVCp8+WtgABnxVxrc4NcodKU28xA5e1fdf61OBoah8K7fj+7Wv4Wc9tqpVIntpzu+w42vNfx43SnnEWAbdqDLQtO+BmU7oK1r7fveDud85QyppvwuCvb37Z8am53zOu6cxzFFCqJiIiIyDHpxhmZjEuP5d5317Gv1LvZG/UNDt5amcvDn27mvNF9+cnsAS32uemELO45awhfbjpAfYODF6+fRGpcmMdjTuwXx0e3z+CM4b15+NPNfO+ZxewpqWr38+o2senNP+DO/YNpRxlyrvlA5s0HpgNtrPzm0neMGSie20YLXHGOqWIJifa8T8IAs3rY4RVrZXsgOBqCIz0/NjrFzLXxJjAT7xwsNGHRwNPM9621wBXvNLcTrjcrF67ppKXkmyraaarn4MhVKrnCq9beB1HJZqZXZwzr/uoP8OYNHZ9B1J2yv4GAEEgeb74fcAr0Hgnf/KV978/sBWaFx5j0rm9zdYWh2d903TmOYgqVREREROSY5O9n8cjFo6hrsLn7zbUt2uDySqp4fuFO7nnnO656dgkzH57L4F9/wp2vr2FCRiwPXTQSy0OL2Q0zMvn39yfwxs1TGZDUSijhFB0ayGOXj+HPF4/iu7xSzvjbAt5dndeu1rzOZts2767OI6+toCsmzYRHDXWw6UPzYW7sNTDnXxAa5918k/zNZuW31kIggKAw6D2i7blKJTmtVymBGYZcWwE7v26+vSyv9SolMKGS3QDl+1rfrzute9NUih0r9qwyt8PnmNtWQ6VsM7Q9LA6GXwSbPjJtUJ1pv7P1rc+oI1epVLAZ/IM9t20C+AeY37+Otr/Ztqn4a6gxs6OOVdnzzcqQgc6KUMuCGXeZ1tYN7/h2LIcDchaaNjrLguhkEzJ3xZ/HZXtNJVx4oqkY6+zf32OAQiUREREROWZlJITzqzMHM39LPi8t2UVBRQ3/+Tabi55cxLQHv+K+9zfw3uo9lFTWMSw5mptOyOShOSP597UTCQ7wb/XYJw3uRVZiG/OPmrAsi4vGpfDRj2eQER/G7a+u5sInF7Esu6ijT7NDVu8u4fZXVzPz4bn8+p117C31EC65BgdnL4C3b4Y+o+GMh8y8pZGXmqCpso3nkr+x9ZXfmkqZaNqkGloZcl6c0/oHczDhRcIgeO0q86HOpXwvRPVt/bHRqeb2aGyBq6uG934Mb1wHn9/beddYcQDeuaXrPvzmrQAsyDrJVIq1FSrFZpivR11mghFfA4S27F9nBjUPPd+02B2JFeDynSu/+bX+Z4ypDuxgqFScbZ4XmNk+x6LKIjP3qt8JzbcPOdf8HBf8xbdAyDVPKWO6+T4qxayoWenlap2+cFUpzbgLsGHX4s4/x1FOoZKIiIiIHNOunJzOjAEJ3P/+Bib98UvufXc9ZdV1/PTUgcz76UzW3nca7/9oOo9/byx3nz6YSyakEhEc0GXXk5EQzlu3TOOhi0ayp6SKi//5LTf+ZznbDrQysLgLbdxbDsAZw/vw6rJdnPjQPH7z7jr2lx3WKuMKb/73ffDzg0v+01g1MOYKaKg1w5Q9cTjMLJnENuYpuaRONG1JBzysyOVwmHa8tiqVQmPgqrdMm9uLc0y7E5jKBG9DJVcb1tGicDs8OxtWvmCGtoMJ9TrD+rdh9Uuw7YvOOd7h8laYWULBkea1K2rlZ1uU3Rgq9R1jAoQ1r3Xu9exbZ+Zu9Rllvj8SLXD5m1sf0u0Sk97xSqXc5eY2NO7YDZWazlNqys/PhDX718GWT7w/XnaTeUrgXN2Srllpb/tXEN7LVHX6BzWeuwdRqCQiIiIixzTLsnjoopFMzornhydm8skdM/jsJydy26wBZCSEd8s1+ftZXDI+lXk/PYmfnTaIb7cXctpf5/P7DzbgOMKDvDfvKyM8yJ+/XjqauT+dyZxxyby0ZBczHprLFxv2N+4Yk2Zuq8vgwn81D3N6jzCVS621wJVkQ32VD5VKE8ytpxa4gwdM5UpblUpgPjRe+ZYJvl680LSklO8zrXitie8PQRGNH8yPBhveg6dnQslu+N7rcN7jJqTZ+H7nHN/1obet1sP2sG0TKiWPM9/HZniuVKqvNe2Wsf3M95ZlqpV2LWo9iPLV/nXQe3jj0OyuboGrrTRhaFsrIIJ5jx08YB7TXrnLIDDcrC6ZtwJqytt/rO6S/Y0Z7O76vWlq+EUQnQZLn/HheAvMY1x/hkU7V4Ds7BXgHA7YMReyZpmW3pQJpu2uh1GoJCIiIiLHvD7Rofznuon87LTBDO4d1d2Xc0hokD+3ntSfr382k0vGp/Cvb3Zy/wcbjuispU37yhnYOxI/P4uU2DAeuHAkX901k/6JEdz95loKKmrMjtEpJsA5+dcwYHbLA4250rSX7V3j/kQHXMOJvQyVYtIgIsnzCnCuCg5XJUtbeg02IUzZXnj+TMBuu1LJPwCSx7Y9MPxIWfh3eP0qE3b9cEHjsOsh55gPqwdbad/Z9gX8a3brAYXD4awKoWvm75TsMq1YyWPN97EZpr3L4Wi5b+lu027Z9PUdcQlgtX/Fr8NVlZjzJA03vwtBkV1fqVS4FbBN1VVbYjLMbUdWgMtdZn7eWbPMfDDX63ssyV5gKhcDglve5x8Ag88yv//eDCJ3OCB7IfSb0bgtylmpVNbJodK+Naalrv/J5vv0aebPx+qyzj3PUU6hkoiIiIhIF4uPCOaPF4zgumn9eH5RNn//ctsROa9t22zeX87g3s2HjafFh/HXy0ZTUV3PPW+vMyGXfyDcvsY5G8SNEReb1ZlWvej+fm9WvGrKssy/7HuqmHHNmvGmUskldaJp23MFUlHJXjxmkmmRqume9sRDCrbCV7+DwWfDdZ80Vo6BCZVsB2z+yPPjv37IBAyttUC5Zs1Ep5oKno5UyLiTt8LcNq1Uaqg1860O52o5bBoqxaSaMGDNK50zVHm/s7Wy9wjz+5Y4sOsrlVyhlbeVStD+uUp1VbBvLaSMN7/H/sHHXgtcZZH5XWwaAh0uc6aZieRNEJq/EaqKmrfShSeYn01nt79t+9J5fSeZ24xp5n3aw+YqKVQSERERETkCLMvinrOGMGdsCo9+sYUXFmV3+TkPlNdQUlnHIDcr2A1MiuTOUwfyyfp9vLt6j+siPR8sNMaEG2tfd18xkL/JhDhtrfzWVOpEEy5U5Le8z7VqV0yq98cDGHgqnP8EhMZCLy/mO6VOMhUee1Z63se24ZtHYf8G367FW7YNH/3UhHZn/aVlxUbvkSZk8tQCt3dN4wfurZ95Po9ryfNpt4OjvnGlts6St8J8eE8aZr6Pc7a2uWuBc21z7eMy8jLzO9EZ7Xmu3yHX9SQO7vpKpfzN4BcAcZlt7+sKTNs7V2nvWvM6pkyAwFDzfjp8FcSjnet3MqOVUCljmvmZ7pjrw/GahEquFeA6u/1t+1zz3oxINN+nTAS/QMj5pnPPc5RTqCQiIiIicoT4+Vn8ac4IThmaxG/eW8+7qzv5Q85hNu0z81UGeWgJvHFGJmPTYrj33XXsK/WitWTMlVBdAps+aNxm27D2f7D5Y9Nm5IuUieb28Ba4op2w5GlTtRMY6tsxwczmuXund4FUynhz21oVROF2+OI++OI3vl8LmJ/Pujc937/+bdgxD2b9GiKTWt5vWWYlrB1z3bfWLH0GAsMgfTps/dxzlU/2AlOlNHyO+b6zW+DyVkKfkabqDRqrkDyFSv7BENG7+fah55r5Omte6fj17F9nBlhH9jHfJw6Cin1QVdzxY3uSv8kESgFBbe8b0cs81/ZWKrneN8nO3+F+J5oW1bZWaTyaZH9jfnf7jvW8T3CkCc52zGv7eDvnm7CuaaUfmMC7M9vfasph92LTdugSFGaq9LJ71lwlhUoiIiIiIkdQgL8fj10+hsmZcdz1+hrmbjrQZefavM8EEIe3v7n4+1k8csloahsc/OKttW3Peso4wQzAdbXAle+DV6+At24wH9jPeNC3C+w72lQgNA03bBs+uMNsP/Nh347XVGtVV02FxkLCINjtYbYTNK6UtvVz3+fflOyGd2+BN66DZc+2vL+mHD79lal4mHC95+MMPtu0kh1eiVRVDN+9YdoTR1wEpbvcV+PYtplLkzEdwuLM3CZP86zao6Ee9q5uPmw5OhUsP8+hUmyGWeGrqeBIGHSGWe3O3SwmX+xzDul2/S4cGta9pWPHbU3+Zt9aQGPSPA8zb0vuMvN4VxDZ7wRzeyy1wGUvMNWCbYVwmSfBntWtB2YOh/N33E3VU3Rq51Yq7VxgqsRc85RcMqaZCsDubqc9ghQqiYiIiIgcYSGB/jxz9XiG9InilpdWsu1A13wA2bSvnF6RwcSGe/7A1i8hnF+eMYR5m/N5bVkbM0f8/GDMFaZiYNFj8Pgk2P4lnPp7uO5T71p+mgoMNUu9Nw031rxijj/7N20P2u4sqRPNsG5PIca2z81QccuCFS/4duz5zmCs34nw4Z0tHz/vQRPOnf0o+Pm3fo3hvZpXiQGsesmsujfxRhhwitnmrgXONU/J1RaUOsmEeZ01ND5/E9RVNg+V/APNAHh3oUlRtuch7ANOMauiHVjf/utxNMCBjZA0onGbK+zpqrlK9bVQtMOElN6KTe9ApdLyxlUUwQzsDoromlCpthIW/q39rXruHCyAAxtan6fkkjkTsFt/bgc2mJC1aeubS3QylO8x4Wdn2P6VqbBKndR8e8Z00067u+fMVVKoJCIiIiLSDSJDAvnXNeMJDfLnR6+sorquodPPsXlfOYM8VCk1ddXkdKZkxvO7Dzawu6iN4c2jv2duP7vHfEj/4Tcw9UetByKtSZlo2qYa6sxspU9/ZT6ojW+laqezpU4yH0YL3QxQr6syLTrDLoABp8Gq/5pr9UbRTlj9Eoy9Bq74H/SfDe/fDqtfNvfvXw+Ln4SxVze24Xni529WwdryWeNMK4cDlv0LUiebYdTRKdBrmPtQ6fBZMykTTMhUtMO759KWw4d0u8RmtAyVbLuxUskd1+Bj1yDk9ijcbsI21zwlMFV2AaFdN1epaLsJFLxdARFMq1ZxO1Z/K9sDZbnNQyX/QEif2jWh0pIn4fN7TZD8zaMmQOsob+YpuSSPM6v3tdYC526ekktUshmiXbHP58t0a/uX5roPn3+WOslUWfagFjiFSiIiIiIi3SQpKoQ/XzySjXvLeOCjjZ167PoGB1sPVHhsfWvKz8/i4YtHUlXXwP9W5La+c0wanPJbOONhuPZjSBjQsQtNnWA+/O9fB5/+0rSNnPP3lm1RXSnVOdvJ3YyhnIVm5an+s2H8tVCxv/VV2Jqa/7D5gDnjLvPh89IXIfNEeOcWWPMafHCnGWw++z7vjjfkHKg72DiwePuXZqj1xBsb9xlwCuz6tuXspewFZml113DoVA/zrNorb4V5LodXq8VmNK705lJZBLXlLYd0u0T1MeHY9q/afz2uId29m8z58vPr2hXgDq38NtD7x8SmQ02p73OeXK9b01AJTAtc4VYTOnmjpgIOtPHzqK2Eb5+A9Gmm3euL++CpGR0PTrK/gcBw6Dum7X39A0xFU2vDujd9ALH93M9Si04xt53RAle004SxTecpuQQ5n0+OQiURERERETkCZg1O4vrp/Xjh2xw+W99J/4oOZBdWUlvv8Dik+3ApsWGkxoWxPd+LVrxpt8Okm9pfndTsxM5wY96f4Lv/mQCmlw+VHp0hfgCExJgWuMNt/cKsypYx3QRL0amw/Lm2j1mwzbTyjb/ehCRg2v0ue8Uc6+2bTIvMKfebGUfeyJhhghvXKnBLnzEtcUPObdxnwKlm1kvTig7bNgFAxvTm84WCozpvWHfeSlNNcvgsq9gMOJjffMaMK2TyVKkEkHWSCcdqD7bvevavA8u/ZdVQV64Al78ZsMzvk7fauwJc7jLwDzIVak15M1eprho2vAevXwMP94cnJpkZQZ6s/A9UFphB8pe9BJe/ZoKm58+Et2+G6tLWr7W+FuY+YMLUt34Ab94Ib1xvBtSnTW4c7N6WzJmmwq1oZ8v79qwywem477t/7KFQqY0WX2+4ws7D5ym5pE8z74f2/u4eYxQqiYiIiIh0s7tPH8Tw5Ch+9sZa9pRUdcoxNztXfvOmUsklMyGc7V0038mj6BSzOteWj80smhl3Htnzg6lgSZ3ofhn7bV+YD4mBoSZEG3uNCWwKt7d+zK8fNGHU9J803x4UBt97zVQ5ZJ0Mo6/w/joDgmDgGaZSqmCraXMb9/3mQ45TJ0JwdPMWuPzNJhRo2hbk529CoNYGlHur9qCZZ3N46xs0BkdN5wa52uFaDZVmmcHkOYvad0371kHCwJbtSYmDTNuYu1X0Oqpgs6k8Cgrz/jGxzlDJ17lKucvNPLLDn1/SCDN83l2oVLgd3v6hCZJev8pU04y50lQffniX+5a2+lpY9HfzHkifYrYNOh1uXQLT74TvXofnzzatq+7UVcGr3zPvh53zTVCYu8yEQGHxMO4a75+zqy3SXQvcwr+ZkHT8te4fG5VsbjtjBbjtX5lWyvj+7u/PmAGOOvd/nhyHFCqJiIiIiHSz4AB/Hrt8LPUNDu54dTX1DR1c9Qqz8pufBf17RXj9mKzECLILD+JwdNLwZm9YVmMr1jl/a/kh+UhJmWjaopq2IRVnm1Yi1wBsgLFXmQqYFc97PtaBjWZFtok3QURiy/uDwuGqt+HKN31v8xtytrnGt39gVlY7/EO0f6Cp8tn2ReMQ7mxnFcrhs2ZSJ5lh2DXlvl3D4fauNbOEWguVms5VclUquap03EmfakK59rbA7V/XvPXNxVW5VLC1fcdtTf5m34Z0gwl0wLdVBRvqTChzeOsbmN+njBkmwGk6hD13OTx7Cmz8AIadB1e9A3dugrP+bFpZCzbD4sdbHm/tayaIOTzsDQozw/Qvf838LJ87rWW1VU0FvHSx+V0852/wk3Vwx1q4fTX8eCXcthSGnuf9804YAJF9W4ZKRTtgw7sw/jpTyedOSJQJnTra/tZQZ362WSd5XmEybZL5M6KHtMApVBIREREROQr0Swjn9xcMZ2l2EX/5fEuHg51N+8rJSAgnJND7FrXMxAiq6xzsKe2caimvzfwVXPxCYyVEdzg0Y2hF47ZtX5jb/rMbt0X2NgOzV70I9TXujzXvAbMK17TbWz+npw+lrck62QybzlthAiZ3K+QNOAXK9zbOFcpZaCo1Dq8MSp1ghhfnrWhxCJ/sWWlu+45teV+sc25S01CpKBsierde0RMYaoKl9gzrriwyQUhSK6FSZ89Vaqg34Uqij6FSaKypLPOl/W3/OjPny9Nw934nmDYv1xD2LZ/CC+dAcCT84Gs473ETivgHmPsHnQ6Dz4avH2oebjkazFDuPqPN7507A2bD1e+aSrjnTm+cz1RdCi9eaCrNLnjKc1uaLyzLXPfOr821uSz6h5ldNvnm1h8fnQKlbcyMa0veCqgp89z6Bubn3GdUjxnWrVBJREREROQoccGYFOaMTeGJeduZ8dBcHvlsMzu8mXHkxub95T61vgFkJoYDsCP/CM8C6TUYhp1/ZM95uORxpvKn6YyhbV+aaprD21zGXwtVRWYuzeH2rjVVE5Nv9n5Wki+CwswHeYAJN7rfxxWCbf3MOU/pm+bzlFySnaFER1vg8laYWVORSS3vOxSaZDdua23lt6ayTjYVNJ6CgLoq96vX7V9vbt1VKsWkg39w54dK+9dBQ40JE3wVm+Zb+1vucnPrrlIJoN+J5nbnfFj5X3jlclPlc/3nEJ/l/jGnP2BuP/ll47YN75gV7Wbc1XoAmjYJvv+RqVb79+lmDtkL55q5Qhf/G0Zd6v1za0vmTFOpt2+t+b4i36ywOOoyE/i2JirZtD52xI6vAavtFesypkPecvM7epxTqCQiIiIichR5cM4I/nbZaLJ6RfD43G3MeuRrzn98IS8tyfG6La6ytp5dRZUMTGpfqOTVsO7jTXCEWX7eFSrV15oPkP1nt/xA3W+mqcBZ8e/GbbUHTZj0/o9NC86UW7vuWqffaT7ou1s6HcyH6z6jYOvnULDFDMp2t29oDCQO6fiw7rwVkOymSgnMzy42vWWo5Gnlt6Zcq2t5aoF78wb4x8SWQ6ZdFVruKpX8A0zA0tnDul2zn9Kn+v7YmHTfKpVyl0FEkgny3EkYYOaUff0neO82s+Lg9z+EiF6tXEManHi3WUFt8ycmjFzwF9PON/jstq+p93C47hPzu//SHNMCetnLvrW3eSNzprl1tcAt+aepGJzaRlUgQHRyx9vfsheY4ehtBcYZ081MsM5aXfEoplBJREREROQoEujvx3mjk/nPdRP59pcn86szB1NV28D/vb2OC55YdGgAd2u27q/Atn0b0g2QGBFMZEjAka9UOlqkTjIBiaPBrMxWd7B565uLn3OWUc5CWPQYvHoFPJQJr19t2ofOeMgENl0leSycfG/r1SMDTjVhkWulOE8BVOoE88HX0c45XiW7TUjkWsXPndiMxlCpvsa0pnlTqdRriAlH3IVKOYtMAOIXAK9d0Twk2rcOwhJM8OJO4qDOr1TKWWiCRnftiG2JzTC/N7aXLa+5y0yVkqfX37JMC1z5Xhh5qZl7FOzFnwWTbzXtgR//zFQp7V9nZil5O/crLhOu+xRGXAJXvgEDT/Xucb6I6AW9hsH2uWZm07JnTBtogoeh2U1Fp5g2vfZWD9VVmfeUa4W91qRNhrSp3r+mxzCFSiIiIiIiR6mkqBBuOiGLT+6YwePfG8uekirOeewbHp+7rdWqJVfwNKh3lE/nsyyLzMQIdhT0wEolMKFSbYVZyWzr5+AX6PkD5OgrzJLun91j2nzGXgPXfAB3bTGtON1twKlmXtKiv5vhxrEeKoNSJ0F1CRRua995tn3uPN8pnveJzTCVOA6Hc2aP7fl6mrIsU620Y17zGTq2bX7ukX3NjCD/YDMQ2rUCmWtIt6fQJXGwuY7OWvLd4TAhV/q09j0+Jh3qq6DiQOO2yiJ48SJ49lTzu+gKJw4WmpY/T/OUXE76Pzj/n+a/pqsDtiYgCM56xPxs3rrJVC8Nn+Pbc4nsDXOe8S54aa+sk2DXYlj6lJndNO0O7x4XlWJuy/a077y7l5rqI1d7YWtCouG6j02V2HFOoZKIiIiIyFHOsizOGtmHz35yAqcMS+LhTze3WrW0aV85IYF+pMX5sLS5U1ZCeA+uVHJW2+xeYuYppU8xbXHuhCeYlqIbvoSfrIczH4J+MxqHH3e35HFmnlF1qft5Si4pTZ5ze2z93IQPCQM97xObYeYNle9trFjyplIJTKhUVQx7VjduW/+WqSibdY+pOvreqyaQeeUys5LdgY3uW99cEgcBduetAFew2czYak/rG5j2QGicq5S/BZ6ZZQZSl+bBSxeZldu2fdHYTuVpnlLTY46+3PfVBTOmw8jLTHgy7XazmuDRJnOm+X2a+wCkT287YHOJTja37R3WvXO+WdWtOxcUOAopVBIREREROUbERwTz+PfG8uQVY9lbaqqW1uWVtthv8/4yBiZF4u/n++pimYnh7C2t5mBNfWdc8rElJh3Ce8H6d+DAeujfSvUNmBAqZbzvH9yPBD//xtY9T61vYIaQh8RA7lLfz1Ff45w7dUrrrXiuAKk4G4p2Nt/WlsyTAKuxBa6+Br64z4RGroqw5HEw518maPrvBSZwaDVUcq0A10lzlVxLx7c3VIpxhkrFOSbM/NdsE45d8wH8eBWc/SiU7YUX58DbPzAD5fuO6Zxrd+eMB805x1zddefoiPSpporQUQfT7/D+cVEdDJWyF5jWU29aCXuQo/BPPxERERERac0ZI/rwyR0nEBUawK/fXYfD0Xxux+Z95QzycUi3S1aiqczZWdADq5UsywRF2c7Bz+7mKR1Lhl1gWvRcw43d8fMzz7k9K8DlLDJzpwa0MTunaahUnA2BYa0PjW4qPN4MHd/+pfl+6TOmPevU35ngzGXI2XDaHxoredyt/OYSl2lmMXXWXKWcRc4Ww4z2PT4mzdwufsK08UWnwE1zzapqAUEw/jr48UrTmhYUbtrsgsI759rdCY015/S2be5ICwo37XW9R/r2HnWFSmXtGNZdU2FCy7ZWfeuBFCqJiIiIiByDEiKC+eUZQ1i1q4Q3VjT+y3tBRQ0FFbUM8nFIt0umM1TqkSvAgZkxBCYk6DWke6+lowafBXfvaGyv8iRlIuRvhKoS346/9XMzz6hfGx+0o1NNdY0rVIrNaL2y6XD9TzbzbIpzYP7DkHVy48pwTU2+xfwXnmhWLfPEP9BUaHVGpZJtO+cpTfXtOTUVFGYq5PasNAHd9Z82Bk0uAcEw4Qa44zu46p0OX/Yx7+Ln4fsf+PYzDwwxvxvtqVTatRgc9V07K+oYpVBJREREROQYdeHYZManx/LgJ5sorawDGod0D/ZxSLdLenwYloXmKg2Y3f6Q4GjiTatO2mRz++6tvn3g3vqZaa1rq2omIMgMSS7OhuKdvlf0ZM0CuwFe/Z6ZEXXK/e73syw4/QG4c1PbVTadtQJc8U4zKyqjnUO6XabcCifdA5e91Ppr5ud/9Mzt6k4hUWYYtq+iktsXKu382rTcuUJnOUShkoiIiIjIMcqyLO4/bzgllbX8+TNTdbHp0Mpv7atUCgn0JyU2tOdWKvUdC0PPg3HXdveVHDkZ083Q621fwD8mwIJHzOyi1hTthMKtra/61lRchglgirO9W/mtqZSJEBRhVnUbc0XrrW3gXeiSONhcT121b9dyuJxF5ra9K7+5TL8DTvxZ85Y+6XzRKe7b32orW28B3TnfBM5Bvi9+cLxTqCQiIiIicgwb2jeKq6dk8NKSHNbllbJ5Xxnx4UEkRga3+5hZiRE9t1IpIAgu+Y8ZyNtTWBac8DO4dampCvryfnhismlv82TbF+a2rXlKLrEZsHct1FX6XqkUEGTajgJC4aT/8+2xnvQdA7YD3rweKovaf5zshRAW3/rqd3L0iE4xK+od7sO74NnZjSFhU1XFsG+t5il5oFBJREREROQY95NTBhIXHsSv313Hpn3l7a5ScslMiGBnwcEWA8DlOBebbtqvrnzTzEB66SJY8YL7fbd+ZgZex2d5eewMsyqb62tfnfkwXPsRRPX1/bHuDDwdTv09bPkU/jnDfZjgjZyFHZunJEdWVDLUlps2Spd938GaV8zXn99r5mQ1lbPIBJCap+SWQiURERERkWNcdGggv3AO7V6bW9rxUCkxnKq6BvaVdbA1yAu2bfPwp5u49aWVXX4u8VL/2XDzt6Yy4/NfQ/n+5vfXVZl2oP5etr5B8yApzsf2NzAVJp1ZPWZZMPVHcP1nZnD382fBvD+Bo8H7Y5TmQklOx1vf5MiJTjG3TecqffZrCI0xIWPuMtj4XvPH7FwAASGQMv6IXeaxRKGSiIiIiMhx4MIxyYxLjwVgcCeESnBkVoD76xdbeXzudj78bi/7j0CIJV4KCIKzHzUB0qe/an5f9kKor/a+9Q2ahEpWy5XNulPyWPjhAhhxMcz7I7xwDuR5GXDmfGtu06d23fVJ5zoUKjlb4LZ9CTvmwgl3w6SbIXEIfPFbaKhrfMzO+WaYfUD7W4qPZwqVRERERESOA35+Fn+4YDiDe0cyNSuhQ8fKSowAun4FuH8v3MnfvtzKxIw4AJbu7MBsmx5uXV4pt728kroGR+cdNGEATL8T1r1hPny7bP3MzDfyZcUz13DuqOSj78N5cCRc+DRc8JQZBv7MSfD82WZu1OGtUE3lLITgKEhqY3C4HD2iks1tWa6pSvv8XohJhwnXmwHvp/wWirbDiufNfgcL4MB6zVNqhUIlEREREZHjxODeUXxyxwmkxnVshaJekcFEBAewowsrld5elctv39/AqUOT+M/1EwkP8mdZtkKl9vp8w34+WLuXnMLKzj3w9J9AfH/48E5TtWTbsPVTM18mMNT744TGmgCmPfOUjpRRl8FP1ps2qMLt8OIc+Od0WPs6ONyEdTmLTAWLVmw7dkT2BsvftL+tfc2EiLN/0xh0DjgV0qfDvAehphyyF5jt/U7svms+yilUEhERERGRZizLIjMxnB0FXVOp9OXG/fz0f2uZkhnP3y8fQ0igP2PTY1Wp1AG5xVUA5BR28msWGGLa4IqzYf7DJmwpzoYBPsxTAjPDaPgcGHxW515fZwuONLOWbl8D5z8Jjnp460b439Vm2XmXinwo2Kx5SscaP38z7L1wG3z1e+g7FoZd2Hi/ZcEp90NlASx6zMxTCoqAvqO77ZKPdgHdfQEiIiIiInL0yUwIZ1l2cacfd1l2Ebe8tJKhfaJ4+upxhASaKo9J/eL482dbKKmsJSYsqNPPe7zLKzGBR6dXKoGpShp1OSz8u2kHAjPM21fn/LVTL6tLBQTB6O/ByMtgyZPw6f9B6Vlw+asQmQS7nKvFKVQ69kQlw4b3ABsufKblyn0p42DYBSZUCo01M7P8A7vlUo8FqlQSEREREZEWMhMjyCuporK2vtOO6XDY/PKt7+gdHcLz104gMqTxg9rEfvEAXRJk9QRdVqnkcurvITgCVr4ACQPbt4LbscjPD6bcCpe9BPmb4F+z4cBG0/oWGAZ9RnX3FYqvopMBGwad6Xku2Mn3mmHdZXmap9QGhUoiIiIiItKCa1j3zk5sgft84362HajgzlMGEh/RfFjzyJRogvz9WLqzsNPO11PUNzjYV2pWzssp6oJKJYDwBBMsAfT3sfXteDD4LLj2I2iogWdPhQ3vQsoEU9Ekx5a4TDNXafZ9re8z4XrzdabmKbWmS0Mly7JOtyxrs2VZ2yzL+oWb+4Mty3rNef8Sy7IynNvjLcuaa1lWhWVZ/+jKaxQRERERkZYyE8OBzlsBzrZtnpi3nbS4MM4a0afF/SGB/oxOjWGpKpV8tr+8hnqHjWV1Ufuby+gr4KxHYOptXXeOo1nfMXDDlxCdCuV71fp2rJpyG9w0FxIHtb7fyb8x7Y6qRmtVl4VKlmX5A48DZwBDgcstyxp62G7XA8W2bfcHHgX+5NxeDfwa+GlXXZ+IiIiIiHjWLyEcy+q8UOnb7YWs2V3CTSdkEuDv/mPIxH5xrMsr5WBN57Xc9QR5zta34X2jyS2upL7BzUplncGyYMINZtBxTxWTCtd9ArPugfHXdffVSHuExngXFAWFwaAzuvxyjnVdWak0Edhm2/YO27ZrgVeB8w7b5zzgBefXbwAnW5Zl2bZ90LbtbzDhkoiIiIiIHGEhgf70jQ5le35FpxzviXnbSYwM5qJxKR73mdgvjgaHzcpdqlbyRW6xqU6a2j+eugabvaX6GNWlQqLghJ9BRGJ3X4lIt+vKUCkZ2N3k+1znNrf72LZdD5QC8d6ewLKsmyzLWm5Z1vL8/PwOXq6IiIiIiDSV1SuCHQUdD5XW5pbwzbYCrp/e79Bqb+6MTY/Fz4KlO4s6fM6exFWpNCXTfJTq0hY4EZEmjulB3bZtP23b9njbtscnJiolFhERERHpTJkJ4ezMP4ht2x06zpPzthMVEsAVk9Ja3S8iOIDhydEKlXyUV1JFQkQwg3pHApBT1EUrwImIHKYrQ6U8ILXJ9ynObW73sSwrAIgGtNyDiIiIiMhRICsxnIO1Dewvq2n3MbYdqOCT9fu4ekoGkSGBbe4/MSOOVbtLqKlvaPc5e5rc4iqSY0NJigwhKMBPlUoicsR0Zai0DBhgWVY/y7KCgMuA9w7b5z3gGufXFwFf2R39ZxAREREREekUmYkRAG3OVVqyo5BzHvuGsx9bwJsrcqmtbxwU/dTX2wny9+P70zK8OufEfnHU1jtYm1va5r5mRbltnPm3BZRW1nl1/ONRXkkVKbGh+PlZpMeFkVOoSiUROTK6LFRyzki6DfgU2Ai8btv2esuy7rcs61znbs8C8ZZlbQPuBH7herxlWdnAX4DvW5aV62blOBERERER6UJZzlDpu7xSty1wBRU13Pn6ai59ejFFB2upqXNw1//WMOOhr3hy3nY27Svj7VV5XDYhlYSIYK/OOSEjDmh7rlJZdR0/+O8KHvpkMxv2lvHtjp7Z8OBw2OQVV5ESEwpAenyYKpVE5IgJ6MqD27b9EfDRYdvubfJ1NXCxh8dmdOW1iYiIiIhI65KigokPD+LBjzfx329zmDkokZmDejE5M4731uzhoU82U1lbz60nZXHbSQMICfTj6y35/GvBTv70ySb+9MkmAvwsbjwh0+tzxoYHMTApgqU7i7j1JPf7bNlfzg//u4Kcokp+ecZg/vL5FpZlF3H68N6d9MyPHQUVNdQ2OEiJdYVK4SzcVoht21iW1c1XJyLHuy4NlURERERE5NhlWRYf3T6DLzbuZ97mfN5ZlcdLS3Ydun9yZhy/P384/XtFHto2c1AvZg7qxYY9ZTy/aCf9EiJIiQ3z6bwT+8Xxzqo91Dc4CPBv3lzx/po93P3GWsKDA3jlxslM7BfHV5sOsCy7Zw733u1c+S05trFSqaqugfzyGnpFhXTnpYlID6BQSUREREREPEqKCuGKSelcMSmd2noHy7OLWLi9gIFJkZw7qq/HapihfaN46KJR7TrnxH7xvLh4Fxv3ljMiJRowFTkPfLSJN1fmMj49lsevGEuSMzSZkBHHk19v52BNPeHBPesjTl6JCZVcwV16fDgAOUWVCpVEpMt15aBuERERERE5jgQF+DG1fwI/O20w541O7rL2qonOuUpLdhbS4LD577fZzPrzPN5dncfNM7N4+cbJhwIlgAn94mhw2KzaVdIl13M0yy0285OSXTOV4ky4lF2gYd0i0vV6VowvIiIiIiJHvd7RIaTFhfH+2r28u3oP3+WVMjUrnvvPG9as1c5lbFoMfhYszS5i+oCEbrji7pNXXEVsWOChCq3k2FD8/Sx2FWlYt4h0PYVKIiIiIiJy1JnYL443VuSSFBXMY5eP4eyRfTxWRkWGBDK0bxTL2lgx7niUV1J1aJ4SQKC/H8kxoWRrBTgROQIUKomIiIiIyFHnlplZDEqK5PJJaUR4MSdpfHocry7bRV2Dg0D/njPlI7e4iqzE8Gbb0uPD2FWo9jcR6Xo9509bERERERE5ZmQmRnDjCZleBUpgKpuq6xysyyvt4is7eti2TV5xVYvV9dLjw8hR+5uIHAEKlURERERE5Jg3wTnce1l2z2mBKzpYS1Vdw6Eh3S7pceGUVNZRWlnXTVcmIj2FQiURERERETnmJUYG0y8hnKU7i71+TPHBWm54YTmb95V34ZV1nbySKgBSYg8LleJN5VJOkVrgRKRrKVQSEREREZHjwvj0WFbkFOFw2F7t/+gXW/hi437+/NnmLr6yrpFbbEKl5BahkpmxpGHdItLVFCqJiIiIiMhxYUK/OIor69ieX9Hmvlv2l/PSkl0kRATz+Yb9bNpXdgSusHPlFbsqlZrPVEqLM99rWLeIdDWFSiIiIiIiclyY6JyrtLSNuUq2bfO7DzYQHuTP/344hfAgf56ct/1IXGKnyi2uJDI4gOjQwGbbQ4P8SYoKVqWSiHQ5hUoiIiIiInJcSI8PIyEimGU7Ww+V5m4+wIKtBdwxeyD9EsK5cnI676/ZQ3bBsVXZk1dS1aL1zSU9LpxdCpVEpIspVBIRERERkeOCZVlM7BfLsmzPw7rrGhz8/oONZCaGc9WUdACun96PAH8//vn1sVWtlFtc1WJIt0t6fBjZan8TkS6mUElERERERI4bEzLiyCupYo9zZbTD/ffbHHYUHOSes4YQ6G8+DvWKCuHS8am8uTKXvaXuH3c0yiuuajFPySU9PowD5TVU1TYc4avquF+9/R3XPLe0uy9DRLygUElERERERI4bE5xzlZa5matUfLCWv36xhRkDEjhpUK9m9910QiYOG56ev+OIXGdHlVbVUV5TT3KMp0olswLcrqJjqwXOtm0+XbePr7fkH3PtiCI9kUIlERERERE5bgzpE0VEcABL3cxVevSLLRysbeDXZw/Fsqxm96XGhXH+6GReWbqLwoqaI3W57ZZbbMIijzOV4k0F07HWArej4CCFB2sBeGd1XjdfjYi0RaGSiIiIiIgcN/z9LMamx7I8uxjbttmRX8F/F+dw84sreGnJLq6YlMbApEi3j715ZhY19Q6eW7jz0LaDNfV8sWE/f/hwA+v3lB6pp9GmvGLTpudxplKcs1LpGBvW7RqynhYXxjur8rBtu5uvSERaE9DdFyAiIiIiItKZJmbE8ufPtjDtwa/YU1oNQHJMKJeMT+WuUwd5fFz/XhGcMbw3/1mUQ1hQAAu25rMip5i6BhNsfPTdPj6+YwZRIYFH5Hm0JtcZKnlqf4sOCyQmLPCYq1Raml1EfHgQt53Un7vfXMvq3SWMSYvt7ssSEQ9UqSQiIiIiIseV04b1JjMhnNFpMfz+/OHM++lMvvn5STxw4QiiQ1sPhG6Z2Z/ymnoe/nQzJZV1XDetHy/fMInXbprMvrJq7nl7XZdVzzz0ySa+98xir46fV1JFaKA/ceFBHvdJjws75mYqLcsuYnxGLKeP6E1wgB/vrFILnMjRTJVKIiIiIiJyXBmQFMlXP53ZrscOT47mgx9NJzEymKSokGb3/WT2AP782RZmDkrkwrEpnXCljapqG/jvtzmU19Qzb3M+Jw3u1er+ucWVJMeGtpgN1VR6fDirdhd36nV2pX2l1ewuquKaKRlEhQQye2gS76/dyz1nDz20Up+IHF30zhQREREREWlieHJ0i0AJ4OaZ/ZnYL45fv7OOnE5uK/tswz7Ka+oJDfTniXnb2tw/r6TK4zwll/T4MPKKq6itd3TWZXappc4V+yb2Myv4XTA6maKDtSzYmt+dlyUirVCoJCIiIiIi4gV/P4tHLx2Nv5/Fj19dTV1D54U1/1ueS0psKHefPohl2cUsy265el1TucVVHucpufRLCMdhw6pdx0a10rKdRYQH+TO0TxQAJwxMJDYskLdX7Tki588uOMjT87dTXddwRM4ncjxQqCQiIiIiIuKl5JhQHpwzkjW7S/jrF1s65Zh5JVUs3F7AnLEpXDYhjfjwIJ6Y67la6WBNPSWVdaTEhrV63NOG9aZXZDAPfLwJh8PznKby6jqenLed0qq6dj+HzrAsu4ix6bEEOFvdggL8OHtkXz5bv4/y6q67tuKDtfz2/fWc8ujX/PGjTXy4dm+XnUvkeKNQSURERERExAdnjujDpeNTeWLedh79fAufrNvLpn1lzSpcKmrqWb+nlI++28s/v97O0p2eK4/eXpmLbcNF41IIDfLnuun9mLs5n/V7St3un1fiXPmtjfa38OAA7j59MKt3l/DeGs/VPr99fwN/+mQTT329vdXjdaXSyjo27y9nQkZcs+3nj0mmpt7Bp+v3d/o5a+obeGb+Dk58eC4vLMrmonEpJEUF8/mGzj+XyPFKg7pFRERERER8dO85Q9m8v5y/fbm12fY+0SHUNTgoqKhttj06NJAv7jyRxMjgZttt2+aNFblMzowjNc5UHl05OZ0n523nyXnb+cf3xrY4d26xWdGtrfY3gAvHJPPComwe/HgTpw5LIiyo+UfAT9fv440VuUQGB/Dy0l38aNYAQoP82/4BdLLlOUXYNi1CpbFpMaTFhfHOqjwuGtd5w9Fziyu5/JnF7C6qYuagRH55xhAG9Y7knne+462VeVTXNRASeOR/DiLHGoVKIiIiIiIiPgoPDuCdW6dRVl1HTkElOwoqyC6oJKfwIIH+fqQnhJERH056fBgOB8x5chH3f7CBxy4f0+w4y3OKyS6s5EezBhzaFh0ayJWT03l6/nayCw6SkRDe7DE78s2Q8NQ2KpUA/Pws7j1nKBf/81uenr+DO2YPPHRffnkNv3zrO4YnR/GrM4bwvX8t4a1VuVwxKb0jP5p2WZpdRKC/xZi0mGbbLcvi/DHJPPbVVvaXVbsdoN4e767ew+6iKp6/dgIzBzWutHfq0N68uHgXC7cVcPKQpE45l8jxTO1vIiIiIiIi7RQVEsiIlGjOG53M7bMH8JdLR/Oni0Zyy8z+nDmiD8P6RjMiJZpbT+rP+2v2MHfTgWaPf2N5LuFB/pwxonez7ddNzyDA34+n5je2pFXVNvDAxxt54ONNZMSHkRDRvOrJkwkZcZw1sg///Ho7e0tN65xt2/zizbVU1NTz6CWjmZIVz4jkaJ77Zmer85e6yrKdRYxIjnZbHXT+6L7YNry3uvMGdi/dWcTApIhmgRLA5Mx4IoMDfG6Bq6lvYM6Ti/hCrXPSwyhUEhERERER6WI/nJlJ/14R3PPOOg7W1ANQWVvPh9/t5cwRfVq0pfWKDOGS8Sm8uSKP/WXVfLO1gNP+Op+nvt7BnLHJvHPrNPz8LK/P/4vTB+Ow4aFPNgPw2rLdfLnpAD8/fTADkiKxLIvrp/dje/5Bvt6a33lP3AvVdQ18l1fKhH5xbu/PTIxgVGoMT83fwXPf7OzwQPEGh82KnGImujlfUIAfJw5K5IuN+2nwIVxbtauEFTnFPL1gR4euTeRYo1BJRERERESkiwUH+PPghSPIK6ni0c/NqnGfrNtHRU09F49PdfuYH5yQRYNtc+lT33Lls0vw97N4+cZJPHTRKGLCgnw6f2pcGDfO6Mfbq/J4d3Uev/tgA1Oz4rl2asahfc4c0YekqGCe+2Znu59ne6zaVUJdg83EDPehEsD95w4jNS6U+z/YwOQ/fskv31rLhj1l7Trfxr1lVNTUt5jf5HLqsN4UVNSyenex18dctL0QMBVQu4sq23VdIscihUoiIiIiIiJHwPiMOK6YlMZzC3eyNreEN1bkkhYXxoSMWLf7p8aFcf7oZHKLq7jtpP58fPsMpmYltPv8t8zsT2JkMLe/uho/P4s/XzyqWbVTUIAfV0/JYMHWAjbvK2/3eXy1dGcRlgXj0z2HSqNSY3j7lml88KPpnDuqL2+vyuPMvy/g5hdXYNu+testca7E565SCWDmoEQC/S0+86GV7dvtBaTGhWJZ8ObKXJ+uR+RYplBJRERERETkCLn79MEkRARzx6urWbS9kIvGpWBZntvY/njhcBb9chY/PW1Qh1cjCw8O4JdnDAbgd+cNp6+b1eO+NzGNkEA/j9VK6/eUsu1AOfUNjg5dS1PLsosYlBRJdFhgm/sOT47mTxeNZMkvZ3P1lHQ+XrePLfsrfDrf0p2FpMWF0Sfa/aDzqJBAJmfG8/l670KlgzX1rNpVwtkj+zIlM563Vub5HHSJHKsUKomIiIiIiBwh0aGB/PbcYewoOIhlwZxxKa3uHxzgT6/IzlnxDODCsSks+7/ZnD8m2e39seFBXDg2hbdX51FQUXNo+77San743xWc9fdvmP2X+Qy991NO/+t8bn91FU/M29buOUf1DQ5W7ir22IrmSXRYILfN6o9lwUff7fX6cbZtsyy77fOdOjSJHQUH2Xag7cBqWXYR9Q6bqVnxXDg2hV1FlSzP8b51TuRYplBJRERERETkCDp9eG/OH92Xs0f2JdlNtVBXS4xsfdW466b1o7bewUuLd9HgsHl+4U5m/+Vr5m05wM9OG8RfLhnFtdMz6BMdwvLsYh76ZDO/fW99u65l/Z4yKmsbPA7pbk2vyBAmpMfxybp9Xj9me34FRQdrmdTG+WYPTQLwahW4b7cXEuTvx/j0OM4Y3puwIH/eXKEWOOkZAtreRURERERERDqLZVn89bIx3X0ZHvXvFcHMQYn8d3E2X27az9rcUk4YmMjvzxtOWnxYi/3veec7/rc8l9+cM8yrFramlmU75xv5WKnkcvrw3tz/wQZ25FeQmRjR5v5tzVNy6RMdyojkaD7bsI+bZ2a1uu+i7YWMSYshNMj/0DV9uHYv9507rMMtiyJHO1UqiYiIiIiISDM3TM+koKKWPSXVPHb5GF64doLbQAngsglp1NQ7eGd1ntfHzy2u5OUlu3hl6S5S40LpHd2+Fr/Th/cG4GMvq5WW7SwiMTKYdA/PpalThyaxencJB8qrPe5TUlnLuj2lzQaozxmbQnlNvU+DvkWOVQqVREREREREpJlp/eN56YZJfHnniZwzqm+rw8SHJ0czIjmaV5buanVA9fo9pfz2/fXMemQe0/80l1+9/R2VtQ3cecrAdl9n35hQRqfGeNUCZ9s2S3YWMbFfXKvPx+WUYUnYNny58YDHfRbvKMK2YWr/+EPbpmTG0zc6RC1w0iMoVBIREREREZFmLMtiWv8Er9vZLpuYyqZ95azeXeL2/vzyGi57ajEvL9lFSmwY95w1hM9/cgKLfjGLC8a0Pqy8LWcM7813eaXsLqpsdb/c4ir2llZ73Wo3KCmS1LhQPlvvObD6dnsBoYH+jEqJObTNz8/i/DHJLNiaz4Eyz1VOIscDhUoiIiIiIiLSIeeO6ktooD+vLt3t9v5HPttMVV0DH90+g/9cN5EbZmQyICnSq4qhtpwxvA8An7YS/kCT+U1eDgW3LItTh/Zm4fZCKmrq3e6zcHshE/vFERTQ/KP1nHEpOGx8agkUORYpVBIREREREZEOiQwJ5NxRfXl/7Z4WAcy6vFJeW76ba6dlkOXFMG1fpcWHMbRPVJtzlZbuLCIqJIBBSZFeH/vUoUnU1jt4Y3nLsOxAWTXbDlQwNSu+xX1ZiRGMTo3hzRV5rbYEihzrFCqJiIiIiIhIh102MZXK2gbeW73n0Dbbtvnt++uJCwviRycP6LJznzG8NytyitlX6rndbOnOIiZkxOHn53111MR+ccwYkMDDn24mr6Sq2X3f7igEaDaku6k5Y5PZvL+c9XvKvD6fyLFGoZKIiIiIiIh02OjUGAb3juSVpbsObftg7V6WZRfz09MGERXi3Xym9jhjROstcPnlNewoOOh165uLZVn88YIROGy45+3vmlUdLdxWQHRoIEP7Rrl97Dmj+hIU4MefPtlEfYPDp/OKHCsUKomIiIiIiEiHWZbFZRNS+S6vlHV5pVTVNvDARxsZ2ieKS8andum5+/eKYECvCD5et9ft/b7OU2oqNS6Mn542iLmb83lvTWMV1qLthUzOjMPfQ+VTTFgQvz13GAu2FvDb9zeoDU6OSwqVREREREREpFNcMCaF4AA/Xl22i6fmb2dPaTW/OWeox+ClM50xvDdLdxZRWFHT4r6lO4sIDfRneHJ0u479/akZjE6N4bfvb6DoYC27iyrJLa7y2PrmcvnENG46IZP/Ls7h3wuz23VukaOZQiURERERERHpFNFhgZw1og/vrNrDP7/ezlkj+zAps+Ug665w+vA+OGz4bMP+Fvct3VnE2PQYAv3b9xHY38/iT3NGUl5dx/3vr2fR9gIApvVv+7n94vTBnDYsid99uIEv3FzbkXKwpp6Vu4q77fxyfFKoJCIiIiIiIp3msolpVNTUY9vwyzMGH7HzDukTSXp8GO+t3kNBRQ0Oh2k3K62qY+O+MiZk+N761tSg3pHcMrM/76zew5PztpMYGezVanZ+fhZ/vXQMI5Kj+fGrq1iXV9qh62ivBz7eyIVPLGL9nu45f3c7UFbNq0t3ceN/lnP6X+fz41dW8c+vtzN/Sz4FbqrbxDsB3X0BIiIiIiIicvyYkBHLfcim0gAAEklJREFUyYN7MbV/AimxYUfsvJZlcdaIPjwxbzvjf/8Fgf4WvSJDCA/2x7bbN0/pcLeclMVH3+1l64EKzhvdF8vyrq0vNMiff109nvMfX8j1LyzjnVun0Sc6tMPX46388hpeX54LwN+/3MpTV40/YufuTvvLqnll6S6+3HiA75xhXnJMKAOSIliRU9xsRtawvlG8/oMphAcrJvGFfloiIiIiIiLSaSzL4tnvT+iWc982qz8jU2LYV1rFvrIa9pdVs7+smt7RoYxNi+3w8YMD/PnTRSO55J/fMmtwL58e2ysqhGe/P4GL//kt5zy2kAcuHMEpQ5M6fE3e+PfCndQ1OLhgTDJvr8pj/Z5ShvVt33ypY0VZdR2XP7OYnQUHGZsWy89OG8TsIUkMTIo4FAaWVNayYW8Zy3YW8+gXW3h9+W6undavm6/82GIdLxPox48fby9fvry7L0NERERERESOc8UHa4kJC/S6UqmpjXvLuPP1NWzcW8ZF41K495yhRIUEdsFVGuXVdUx98CtmDEjggQtHMv1PXzE1K/64rlZqcNjc+J/lzN+Sz4s3TGKyF3O9LnpyEfvLq5l710wC2jl763hlWdYK27bd/sLoJyUiIiIiIiLig9jwoHYFSgBD+kTx7q3T+NGs/ry9Ko/TH53PN1vN4G/btimrrmN7fgWLdxRSUlnb4Wt9eckuyqvr+eGJWUSHBnLdtH58un7/cT1b6ZHPNvPVpgP85txhXgVKADfMyGR3URWfru++YerHIrW/iYiIiIiIiBxBQQF+3HXqIE4eksRdr6/mymeXkBwTSkFFDTX1jkP7JceE8ulPTiCinXN+auobePabnUzrH8/IlBgArpvej+cW7jwmZivZts1ry3azJreUAD8L/yb/DUyK5NxRfQkKaF4r8/6aPTwxbzuXT0zjyklpXp/rlKFJpMeH8cyCHZw5one7Q8OeRqGSiIiIiIiISDcYnRrDhz+ewRPztpNbVEliZPCh/2rrHdz95lr++NFG/njBiHYd/+2VeRwor+Evl4w+tM1VrfS3L7ce1bOVausd3PPOd7y+PJdYZ6thfYMDhw11DQ5q6h088tlmbpyRyWUTUwkLCmBdXik/e2MN49Nj+e25w3wKhvz9LK6f3o97313PipxixndwtcCeQjOVRERERERERI5Cf/hwA88s2Ml/r5/IjAGJPj22wWFzyl++JizYn/dvm94sYCmtqjuqZyuVVNbywxdXsHhHET+e1Z87Zg/Ez6/x+m3bZv7WAh6fu42lO4uICw/imikZvL58Nw7b5r3bppMYGezzeStr65nywFdMzow7Kn8u3UUzlURERERERESOMXedOojMxHB+/sZayqvrWtxv2zYvLcnhF2+uZV1e8xlJn2/Yx46Cg/zwxKwWFTvRoYFcP73lbKWa+gaWZxfxxopcig52fJ5Te+wsOMiFTyxiZU4Jj146ijtPHdQsUAKzwuCJAxN5/QdT+N8PpzAqJZpHv9hCQUUNT181vl2BEkBYUABXTk7jsw37yS442BlP57inSiURERERERGRo9TKXcVc9OQiLp2QygMXjjy0vbqugV+9/R1vrczD38+iwWEzsV8c10/vx+whSVz4xEJKqur46q6Z+Pu1bANzVSuNSI5mXHosS3cWsXp3yaGZTkEBfpw3qi/XTM1gePKRaZFbtK2AW15eiQU8ffV4JvjQgrZxbxkNDrvD13qgrJrpf5rLZRNTuf+84W3uX1FTzxvLd1NeXU+9w6bBYVPvsHHYNueO6nvEfnZdqbVKJc1UEhERERERETlKjU2L5cYZmTw1fwenD+/DiQMT2V1UyQ9fXMGGvWX8ZPZAvj/VtH49vyibH/x3Bb2jQthXVs0fLhjuNlACU610w/RMHv1iC0t2FjGsbxRXTk5nYr84ekeF8Pry3by1Mo//rchlfHosl0xIBRv2lVWzt7Sa/WXVlFfXccvM/pw0uFeHnuOKnCL+/uU2vt6ST1ZiOM99fwLp8eE+HWNIn6gOXYNLr6gQzh3dl/8tz+XOUwYSExbkcd9l2UXc+fpqdhdVHdrm72fhb5lh4iNToo+LUKk1qlQSEREREREROYpV1zVw1t8XUFnbwL1nD+WXb39Hg8Pmb5eNZtbgpEP71Tc4+GzDfp79ZielVXV88KPphAT6ezxufYODNbklDOod5XaFudKqOv63fDf/XZxDTmHloe3x4UH0jg6hoqaeXUWV3H3aYH54YqbbwdgNDpt5mw/Q4LDpGxNKn+gQ4sKDsCyLxTsKeeyrrSzcVkhceBA3zOjH1VMy2r3aXWfZtK+M0/+6gJ+dNohbT+rf4v7aegePfrGFf369ndTYMP5yyShGp8bg72cdl6vGtVappFBJRERERERE5Ci3encJFz6xEIcNg5IieeqqcWQk+FbN014Oh83GfWVEhQTSKyqY4AATVFXVNvDTN9bw4dq9nDe6L3+aM/JQiGXbNl9tOsBDn2xm8/7yZscLDvAjLjyIvaXVJEQE84MTMrlichphQUdPM9VVzy5hw54yrp6SQUZCGGlxYWTEh5NfUcMdr65mw94yLpuQyj1nD+32EKyrKVQSEREREREROca9sCibbQcq+OWZg4+aAMa2bR6fu40/f7aFkSnRPH3VePJKqvjTx5tYml1ERnwYd506iPT4MPaUVLO3tIo9JVXsL6thTFoMl09Ma7WaqruszS3htpdXsauossV98eFBPHDhCE4d1rsbruzIU6gkIiIiIiIiIl3ms/X7+MlrqwE4WNtAQkQwt88ewGUTUgn0P3YXnq+ua2B3USXZhZXkFB6kvLqeKyent3uFuWORQiURERERERER6VKb95Xzm/fWMTUrgeun9yP8OG8L6ym0+puIiIiIiIiIdKlBvSN59aYp3X0ZcgQduzVoIiIiIiIiIiLSbRQqiYiIiIiIiIiIzxQqiYiIiIiIiIiIzxQqiYiIiIiIiIiIzxQqiYiIiIiIiIiIzxQqiYiIiIiIiIiIzxQqiYiIiIiIiIiIzxQqiYiIiIiIiIiIzxQqiYiIiIiIiIiIzxQqiYiIiIiIiIiIzxQqiYiIiIiIiIiIzxQqiYiIiIiIiIiIzxQqiYiIiIiIiIiIzxQqiYiIiIiIiIiIzxQqiYiIiIiIiIiIzxQqiYiIiIiIiIiIzxQqiYiIiIiIiIiIzxQqiYiIiIiIiIiIzxQqiYiIiIiIiIiIzxQqiYiIiIiIiIiIzxQqiYiIiIiIiIiIzxQqiYiIiIiIiIiIzxQqiYiIiIiIiIiIzyzbtrv7GjqFZVn5QE53X0cnSQAKuvsipFvote+59Nr3XHrteya97j2XXvueS699z6XXvuc6Xl77dNu2E93dcdyESscTy7KW27Y9vruvQ448vfY9l177nkuvfc+k173n0mvfc+m177n02vdcPeG1V/ubiIiIiIiIiIj4TKGSiIiIiIiIiIj4TKHS0enp7r4A6TZ67XsuvfY9l177nkmve8+l177n0mvfc+m177mO+9deM5VERERERERERMRnqlQSERERERERERGfKVQSERERERERERGfKVQ6yliWdbplWZsty9pmWdYvuvt6pGtYlpVqWdZcy7I2WJa13rKs253b77MsK8+yrNXO/87s7muVzmdZVrZlWd85X+Plzm1xlmV9blnWVudtbHdfp3Quy7IGNXlvr7Ysq8yyrDv0vj8+WZb1nGVZByzLWtdkm9v3uWX83fl3/1rLssZ235VLR3l47R+2LGuT8/V927KsGOf2DMuyqpq8///ZbRcuHebhtff4Z7xlWb90vu83W5Z1WvdctXSUh9f9tSavebZlWaud2/WeP4608pmuR/19r5lKRxHLsvyBLcApQC6wDLjctu0N3Xph0uksy+oD9LFte6VlWZHACuB84BKgwrbtP3fn9UnXsiwrGxhv23ZBk20PAUW2bT/oDJRjbdv+eXddo3Qt55/3ecAk4Fr0vj/uWJZ1AlAB/Me27eHObW7f584PmT8CzsT8TvzNtu1J3XXt0jEeXvtTga9s2663LOtPAM7XPgP4wLWfHNs8vPb34ebPeMuyhgKvABOBvsAXwEDbthuO6EVLh7l73Q+7/xGg1Lbt+/WeP7608pnu+/Sgv+9VqXR0mQhss217h23btcCrwHndfE3SBWzb3mvb9krn1+XARiC5e69Kutl5wAvOr1/A/IUkx6+Tge22bed094VI17Btez5QdNhmT+/z8zAfRmzbthcDMc7/UZVjkLvX3rbtz2zbrnd+uxhIOeIXJl3Ow/vek/OAV23brrFteyewDfNZQI4xrb3ulmVZmH80fuWIXpQcEa18putRf98rVDq6JAO7m3yfi4KG457zXyzGAEucm25zlkM+pxao45YNfGZZ1grLsm5ybkuybXuv8+t9QFL3XJocIZfR/H8w9b7vGTy9z/X3f89yHfBxk+/7WZa1yrKsry3LmtFdFyVdyt2f8Xrf9wwzgP22bW9tsk3v+ePQYZ/petTf9wqVRLqRZVkRwJvAHbZtlwFPAlnAaGAv8Ej3XZ10oem2bY8FzgBudZZNH2KbvmT1Jh+nLMsKAs4F/ufcpPd9D6T3ec9kWdb/AfXAS85Ne4E027bHAHcCL1uWFdVd1yddQn/G92yX0/wfkfSePw65+Ux3SE/4+16h0tElD0ht8n2Kc5schyzLCsT84fOSbdtvAdi2vd+27Qbbth3AM6gM+rhk23ae8/YA8Dbmdd7vKn913h7oviuULnYGsNK27f2g930P4+l9rr//ewDLsr4PnA1c4fyQgbP1qdD59QpgOzCw2y5SOl0rf8brfX+csywrALgQeM21Te/544+7z3T0sL/vFSodXZYBAyzL6uf8l+zLgPe6+ZqkCzj7q58FNtq2/Zcm25v21F4ArDv8sXJssywr3DnID8uywoFTMa/ze8A1zt2uAd7tniuUI6DZv1rqfd+jeHqfvwdc7VwVZjJmoOtedweQY5NlWacDdwPn2rZd2WR7onNwP5ZlZQIDgB3dc5XSFVr5M/494DLLsoIty+qHee2XHunrky41G9hk23aua4Pe88cXT5/p6GF/3wd09wVII+eKILcBnwL+wHO2ba/v5suSrjENuAr4zrXEKPAr4HLLskZjSiSzgR90x8VJl0oC3jZ/BxEAvGzb9ieWZS0DXrcs63ogBzPUUY4zziDxFJq/tx/S+/74Y1nWK8BMIMGyrFzgN8CDuH+ff4RZCWYbUIlZEVCOUR5e+18CwcDnzj//F9u2/UPgBOB+y7LqAAfwQ9u2vR30LEcZD6/9THd/xtu2vd6yrNeBDZiWyFu18tuxyd3rbtv2s7Scnwh6zx9vPH2m61F/31vO6lsRERERERERERGvqf1NRERERERERER8plBJRERERERERER8plBJRERERERERER8plBJRERERERERER8plBJRERERERERER8plBJRERExEeWZTVYlrW6yX+/6MRjZ1iWta6zjiciIiLSVQK6+wJEREREjkFVtm2P7u6LEBEREelOqlQSERER6SSWZWVblvWQZVnfWZa11LKs/s7tGZZlfWVZ1lrLsr60LCvNuT3Jsqy3Lcta4/xvqvNQ/pZlPWNZ1nrLsj6zLCvUuf+PLcva4DzOq930NEVEREQAhUoiIiIi7RF6WPvbpU3uK7VtewTwD+Cvzm2PAS/Ytj0SeAn4u3P734GvbdseBYwF1ju3DwAet217GFACzHFu/wUwxnmcH3bNUxMRERHxjmXbdndfg4iIiMgxxbKsCtu2I9xszwZm2ba9w7KsQGCfbdvxlmUVAH1s265zbt9r23aCZVn5QIpt2zVNjpEBfG7b9gDn9z8HAm3b/r1lWZ8AFcA7wDu2bVd08VMVERER8UiVSiIiIiKdy/bwtS9qmnzdQOMczLOAxzFVTcssy9J8TBEREek2CpVEREREOtelTW6/dX69CLjM+fUVwALn118CNwNYluVvWVa0p4NaluUHpNq2PRf4ORANtKiWEhERETlS9K9bIiIiIr4LtSxrdZPvP7Ft+xfOr2Mty1qLqTa63LntR8C/Lcv6GZAPXOvcfjvwtGVZ12Mqkm4G9no4pz/wojN4soC/27Zd0knPR0RERMRnmqkkIiIi0kmcM5XG27Zd0N3XIiIiItLV1P4mIiIiIiIiIiI+U6WSiIiIiIiIiIj4TJVKIiIiIiIiIiLiM4VKIiIiIiIiIiLiM4VKIiIiIiIiIiLiM4VKIiIiIiIiIiLiM4VKIiIiIiIiIiLis/8Hy5XfqQQYEwMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (20, 10))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Train and Validation losses')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['Train loss', 'Validation loss'], loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 103 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A8689F35E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "The accuracy of the model is 0.928853171007842\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(X_test)\n",
    "Accuracy = []\n",
    "for i in range(prediction.shape[0]):\n",
    "    error = abs(prediction[i] - y_test[i])\n",
    "    Accuracy.append(float(1 - error))\n",
    "\n",
    "#The accuracy of the model     \n",
    "print(\"The accuracy of the model is\",  sum(Accuracy)/len(Accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Sales')"
      ]
     },
     "execution_count": 679,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "prediction = scaler.inverse_transform(prediction)\n",
    "y_test = scaler.inverse_transform(y_test)\n",
    "y_train = scaler.inverse_transform(y_train)\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_range = len(prediction)\n",
    "plt.plot(np.arange(plot_range), np.array(y_test), label='Test data')\n",
    "plt.plot(np.arange(plot_range), np.array(prediction),label='Prediction')\n",
    "plt.title('Test and Prediction data')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('Weeks')\n",
    "plt.ylabel(\"Sales\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting of the next 6 month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best solution I came up with is predicting 1 week, using some window of weeks before -> append this week to the dataset -> predict the next week using updated data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sales(data, weeks=24, model=model, window=16):\n",
    "    scaled_data = scaler.transform(data)\n",
    "    for i in range(weeks):\n",
    "        X = scaled_data[-window:].reshape(1, 16, 1)\n",
    "        predicted_value = model.predict(X) \n",
    "        scaled_data = np.append(scaled_data, predicted_value)\n",
    "    old_data = scaler.inverse_transform(scaled_data[:-weeks].reshape(scaled_data[:-weeks].shape[0], 1))\n",
    "    predicted = scaler.inverse_transform(scaled_data[-weeks:].reshape(scaled_data[-weeks:].shape[0], 1))\n",
    "    \n",
    "    return old_data, predicted    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_data, prediction = predict_sales(sales_per_week, window=WINDOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Sales amount')"
      ]
     },
     "execution_count": 682,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 10)) \n",
    "range_history = len(old_data)\n",
    "range_future = list(range(range_history, range_history +\n",
    "                        len(prediction)))\n",
    "plt.plot(np.arange(range_history), old_data, \n",
    "             label='Old_data')\n",
    "plt.plot(range_future, prediction,\n",
    "             label='Forecasted by GRU')\n",
    "      \n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Time step (weeks)')\n",
    "plt.ylabel('Sales amount')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our prediction is not 100% accurate, but it gives the clear trend for the sales in the next 6 months. For better prediction we need more data or data which is recorded day by day (It would make the \"data\" smoother and help the algorithm to learn better).\n",
    "\n",
    "To better see the dynamic within real dates - we can return the date values on our graphic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Sales amount')"
      ]
     },
     "execution_count": 683,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 10)) \n",
    "plt.plot( label='Old_data')\n",
    "plt.plot(sales_per_week.reset_index().Date.astype('datetime64[ns]'), old_data)\n",
    "plt.plot(pd.date_range('10/26/2017', periods=24, freq='7D'), prediction, label='Forecasted by GRU')\n",
    "      \n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Time step (weeks)')\n",
    "plt.ylabel('Sales amount')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case we need a new dataframe with all data for further analysis - we can transform data from numpy to pd.Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.DataFrame(pd.date_range('10-26-2017', periods=24, freq='7D'), columns=[\"Date\"])\n",
    "sales = pd.DataFrame(prediction, columns=[\"Sales\"])\n",
    "\n",
    "predicted_values_df = pd.concat([dates, sales], axis=1)\n",
    "predicted_values_df['Date'] = predicted_values_df['Date'].dt.date\n",
    "updated_data = pd.concat([sales_per_week.reset_index(), predicted_values_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now in predicted_values_df we have only new data, which we have predicted. And in updated_data we have the whole dataset + predicted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-10-26</td>\n",
       "      <td>457828.457344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-11-02</td>\n",
       "      <td>476925.730892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-11-09</td>\n",
       "      <td>475460.450046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-11-16</td>\n",
       "      <td>525248.687454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-11-23</td>\n",
       "      <td>740162.759088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017-11-30</td>\n",
       "      <td>485967.762744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2017-12-07</td>\n",
       "      <td>441729.802668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2017-12-14</td>\n",
       "      <td>408503.483842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2017-12-21</td>\n",
       "      <td>404598.500581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017-12-28</td>\n",
       "      <td>508634.295382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>473154.027779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2018-01-11</td>\n",
       "      <td>363888.968885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2018-01-18</td>\n",
       "      <td>384815.940517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2018-01-25</td>\n",
       "      <td>360326.349960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>311909.022991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2018-02-08</td>\n",
       "      <td>299349.748917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2018-02-15</td>\n",
       "      <td>357442.683302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2018-02-22</td>\n",
       "      <td>422303.274160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2018-03-01</td>\n",
       "      <td>535169.992184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2018-03-08</td>\n",
       "      <td>644557.570201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2018-03-15</td>\n",
       "      <td>503305.158903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2018-03-22</td>\n",
       "      <td>501321.801308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2018-03-29</td>\n",
       "      <td>503728.293905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2018-04-05</td>\n",
       "      <td>535217.319098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date          Sales\n",
       "0   2017-10-26  457828.457344\n",
       "1   2017-11-02  476925.730892\n",
       "2   2017-11-09  475460.450046\n",
       "3   2017-11-16  525248.687454\n",
       "4   2017-11-23  740162.759088\n",
       "5   2017-11-30  485967.762744\n",
       "6   2017-12-07  441729.802668\n",
       "7   2017-12-14  408503.483842\n",
       "8   2017-12-21  404598.500581\n",
       "9   2017-12-28  508634.295382\n",
       "10  2018-01-04  473154.027779\n",
       "11  2018-01-11  363888.968885\n",
       "12  2018-01-18  384815.940517\n",
       "13  2018-01-25  360326.349960\n",
       "14  2018-02-01  311909.022991\n",
       "15  2018-02-08  299349.748917\n",
       "16  2018-02-15  357442.683302\n",
       "17  2018-02-22  422303.274160\n",
       "18  2018-03-01  535169.992184\n",
       "19  2018-03-08  644557.570201\n",
       "20  2018-03-15  503305.158903\n",
       "21  2018-03-22  501321.801308\n",
       "22  2018-03-29  503728.293905\n",
       "23  2018-04-05  535217.319098"
      ]
     },
     "execution_count": 700,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_values_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>272996.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-02-13</td>\n",
       "      <td>346172.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-02-20</td>\n",
       "      <td>423308.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-02-27</td>\n",
       "      <td>387812.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-03-05</td>\n",
       "      <td>528118.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2014-03-12</td>\n",
       "      <td>669367.640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2014-03-19</td>\n",
       "      <td>490228.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2014-03-26</td>\n",
       "      <td>494630.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2014-04-02</td>\n",
       "      <td>367991.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2014-04-09</td>\n",
       "      <td>382757.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2014-04-16</td>\n",
       "      <td>424015.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2014-04-23</td>\n",
       "      <td>428185.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2014-04-30</td>\n",
       "      <td>526028.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2014-05-07</td>\n",
       "      <td>517240.540000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2014-05-14</td>\n",
       "      <td>471396.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2014-05-21</td>\n",
       "      <td>559720.410000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2014-05-28</td>\n",
       "      <td>511963.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2014-06-04</td>\n",
       "      <td>651924.790000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2014-06-11</td>\n",
       "      <td>723426.110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2014-06-18</td>\n",
       "      <td>682107.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2014-06-25</td>\n",
       "      <td>590698.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2014-07-02</td>\n",
       "      <td>571980.410000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2014-07-09</td>\n",
       "      <td>537338.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2014-07-16</td>\n",
       "      <td>565170.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2014-07-23</td>\n",
       "      <td>617212.490000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2014-07-30</td>\n",
       "      <td>589454.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2014-08-06</td>\n",
       "      <td>732321.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2014-08-13</td>\n",
       "      <td>843496.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2014-08-20</td>\n",
       "      <td>587085.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2014-08-27</td>\n",
       "      <td>516225.870000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2014-09-03</td>\n",
       "      <td>488805.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2014-09-10</td>\n",
       "      <td>437336.370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2014-09-17</td>\n",
       "      <td>424838.640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2014-09-24</td>\n",
       "      <td>445500.370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2014-10-01</td>\n",
       "      <td>443444.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2014-10-08</td>\n",
       "      <td>372231.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2014-10-15</td>\n",
       "      <td>397833.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2014-10-22</td>\n",
       "      <td>425858.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2014-10-29</td>\n",
       "      <td>354666.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2014-11-05</td>\n",
       "      <td>315540.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2014-11-12</td>\n",
       "      <td>372694.210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2014-11-19</td>\n",
       "      <td>389977.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2014-11-26</td>\n",
       "      <td>656988.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2014-12-03</td>\n",
       "      <td>411314.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2014-12-10</td>\n",
       "      <td>365644.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2014-12-17</td>\n",
       "      <td>343702.610000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2014-12-24</td>\n",
       "      <td>449840.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2014-12-31</td>\n",
       "      <td>619707.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2015-01-07</td>\n",
       "      <td>432028.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2015-01-14</td>\n",
       "      <td>372269.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2015-01-21</td>\n",
       "      <td>419583.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2015-01-28</td>\n",
       "      <td>343562.970000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2015-02-04</td>\n",
       "      <td>317608.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2015-02-11</td>\n",
       "      <td>378319.110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2015-02-18</td>\n",
       "      <td>443072.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2015-02-25</td>\n",
       "      <td>472350.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2015-03-04</td>\n",
       "      <td>560008.970000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>2015-03-11</td>\n",
       "      <td>701939.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2015-03-18</td>\n",
       "      <td>507433.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2015-03-25</td>\n",
       "      <td>502231.490000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>513710.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2015-04-08</td>\n",
       "      <td>469174.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2015-04-15</td>\n",
       "      <td>584574.430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2015-04-22</td>\n",
       "      <td>438304.110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2015-04-29</td>\n",
       "      <td>527109.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2015-05-06</td>\n",
       "      <td>523192.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2015-05-13</td>\n",
       "      <td>601547.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>2015-05-20</td>\n",
       "      <td>582251.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>2015-05-27</td>\n",
       "      <td>520103.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>2015-06-03</td>\n",
       "      <td>567444.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2015-06-10</td>\n",
       "      <td>640840.140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2015-06-17</td>\n",
       "      <td>715649.310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>2015-06-24</td>\n",
       "      <td>630425.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>606112.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>2015-07-08</td>\n",
       "      <td>599926.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>2015-07-15</td>\n",
       "      <td>620324.210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>2015-07-22</td>\n",
       "      <td>645892.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>2015-07-29</td>\n",
       "      <td>592234.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>2015-08-05</td>\n",
       "      <td>691975.630000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>2015-08-12</td>\n",
       "      <td>814112.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>2015-08-19</td>\n",
       "      <td>597761.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>2015-08-26</td>\n",
       "      <td>522489.970000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>2015-09-02</td>\n",
       "      <td>497969.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>2015-09-09</td>\n",
       "      <td>433195.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>2015-09-16</td>\n",
       "      <td>410801.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>2015-09-23</td>\n",
       "      <td>460460.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>2015-09-30</td>\n",
       "      <td>483169.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>2015-10-07</td>\n",
       "      <td>487258.090000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>2015-10-14</td>\n",
       "      <td>518496.810000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>2015-10-21</td>\n",
       "      <td>475365.510000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>2015-10-28</td>\n",
       "      <td>409547.280000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>2015-11-04</td>\n",
       "      <td>353693.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>2015-11-11</td>\n",
       "      <td>444685.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>2015-11-18</td>\n",
       "      <td>424084.490000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>2015-11-25</td>\n",
       "      <td>794789.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2015-12-02</td>\n",
       "      <td>494037.970000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2015-12-09</td>\n",
       "      <td>397203.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2015-12-16</td>\n",
       "      <td>435368.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2015-12-23</td>\n",
       "      <td>514496.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2015-12-30</td>\n",
       "      <td>589491.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2016-01-06</td>\n",
       "      <td>433569.220000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>390239.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2016-01-20</td>\n",
       "      <td>401476.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>2016-01-27</td>\n",
       "      <td>371189.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2016-02-03</td>\n",
       "      <td>350681.430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>2016-02-10</td>\n",
       "      <td>373086.780000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>2016-02-17</td>\n",
       "      <td>474357.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>2016-02-24</td>\n",
       "      <td>493497.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>2016-03-03</td>\n",
       "      <td>545807.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>2016-03-10</td>\n",
       "      <td>698748.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>2016-03-17</td>\n",
       "      <td>572374.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>2016-03-24</td>\n",
       "      <td>546214.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>2016-03-31</td>\n",
       "      <td>607684.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>2016-04-07</td>\n",
       "      <td>499651.970000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>2016-04-14</td>\n",
       "      <td>498494.510000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2016-04-21</td>\n",
       "      <td>540235.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>2016-04-28</td>\n",
       "      <td>558563.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>2016-05-05</td>\n",
       "      <td>579892.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2016-05-12</td>\n",
       "      <td>665269.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>2016-05-19</td>\n",
       "      <td>630857.430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>2016-05-26</td>\n",
       "      <td>611207.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>2016-06-02</td>\n",
       "      <td>661876.540000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>2016-06-09</td>\n",
       "      <td>635274.370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>2016-06-16</td>\n",
       "      <td>738221.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>2016-06-23</td>\n",
       "      <td>679265.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>2016-06-30</td>\n",
       "      <td>626069.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>2016-07-07</td>\n",
       "      <td>615184.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>2016-07-14</td>\n",
       "      <td>669840.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>2016-07-21</td>\n",
       "      <td>777858.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>2016-07-28</td>\n",
       "      <td>642305.370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>2016-08-04</td>\n",
       "      <td>775938.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>2016-08-11</td>\n",
       "      <td>876809.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>2016-08-18</td>\n",
       "      <td>699019.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>2016-08-25</td>\n",
       "      <td>574054.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>567508.970000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>2016-09-08</td>\n",
       "      <td>537075.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>2016-09-15</td>\n",
       "      <td>451754.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>2016-09-22</td>\n",
       "      <td>497291.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>2016-09-29</td>\n",
       "      <td>482432.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>2016-10-06</td>\n",
       "      <td>440283.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>2016-10-13</td>\n",
       "      <td>482122.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>2016-10-20</td>\n",
       "      <td>472823.780000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>2016-10-27</td>\n",
       "      <td>400479.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>2016-11-03</td>\n",
       "      <td>374118.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>2016-11-10</td>\n",
       "      <td>381829.280000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>2016-11-17</td>\n",
       "      <td>449106.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>2016-11-24</td>\n",
       "      <td>801472.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>2016-12-01</td>\n",
       "      <td>473739.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>2016-12-08</td>\n",
       "      <td>414116.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>2016-12-15</td>\n",
       "      <td>458387.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>2016-12-22</td>\n",
       "      <td>483103.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>2016-12-29</td>\n",
       "      <td>546124.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>607941.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>2017-01-12</td>\n",
       "      <td>400762.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>2017-01-19</td>\n",
       "      <td>365048.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>2017-01-26</td>\n",
       "      <td>409598.390000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>2017-02-02</td>\n",
       "      <td>360035.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>2017-02-09</td>\n",
       "      <td>396348.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>2017-02-16</td>\n",
       "      <td>444552.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>2017-02-23</td>\n",
       "      <td>462946.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>2017-03-02</td>\n",
       "      <td>567800.870000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>2017-03-09</td>\n",
       "      <td>752613.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>2017-03-16</td>\n",
       "      <td>562509.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>2017-03-23</td>\n",
       "      <td>552955.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>2017-03-30</td>\n",
       "      <td>591507.610000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>2017-04-06</td>\n",
       "      <td>571705.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>2017-04-13</td>\n",
       "      <td>550712.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>2017-04-20</td>\n",
       "      <td>602938.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>2017-04-27</td>\n",
       "      <td>477272.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>2017-05-04</td>\n",
       "      <td>538224.780000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>2017-05-11</td>\n",
       "      <td>581886.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>2017-05-18</td>\n",
       "      <td>565407.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>2017-05-25</td>\n",
       "      <td>576454.790000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>598935.410000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>2017-06-08</td>\n",
       "      <td>621861.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>2017-06-15</td>\n",
       "      <td>667203.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>2017-06-22</td>\n",
       "      <td>652567.310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>2017-06-29</td>\n",
       "      <td>649337.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>2017-07-06</td>\n",
       "      <td>648991.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>2017-07-13</td>\n",
       "      <td>674738.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>2017-07-20</td>\n",
       "      <td>760370.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>2017-07-27</td>\n",
       "      <td>654907.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>2017-08-03</td>\n",
       "      <td>800815.170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>2017-08-10</td>\n",
       "      <td>930987.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>2017-08-17</td>\n",
       "      <td>703491.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>2017-08-24</td>\n",
       "      <td>651804.210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>615182.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>2017-09-07</td>\n",
       "      <td>557378.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>2017-09-14</td>\n",
       "      <td>487608.870000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>2017-09-21</td>\n",
       "      <td>504333.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>2017-09-28</td>\n",
       "      <td>490658.090000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>2017-10-05</td>\n",
       "      <td>471625.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>2017-10-12</td>\n",
       "      <td>448425.580000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>2017-10-19</td>\n",
       "      <td>489885.290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>2017-10-26</td>\n",
       "      <td>457828.457344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>2017-11-02</td>\n",
       "      <td>476925.730892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>2017-11-09</td>\n",
       "      <td>475460.450046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>2017-11-16</td>\n",
       "      <td>525248.687454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>2017-11-23</td>\n",
       "      <td>740162.759088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>2017-11-30</td>\n",
       "      <td>485967.762744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>2017-12-07</td>\n",
       "      <td>441729.802668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>2017-12-14</td>\n",
       "      <td>408503.483842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>2017-12-21</td>\n",
       "      <td>404598.500581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>2017-12-28</td>\n",
       "      <td>508634.295382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>473154.027779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>2018-01-11</td>\n",
       "      <td>363888.968885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>2018-01-18</td>\n",
       "      <td>384815.940517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>2018-01-25</td>\n",
       "      <td>360326.349960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>311909.022991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>2018-02-08</td>\n",
       "      <td>299349.748917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>2018-02-15</td>\n",
       "      <td>357442.683302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>2018-02-22</td>\n",
       "      <td>422303.274160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>2018-03-01</td>\n",
       "      <td>535169.992184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>2018-03-08</td>\n",
       "      <td>644557.570201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>2018-03-15</td>\n",
       "      <td>503305.158903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>2018-03-22</td>\n",
       "      <td>501321.801308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>2018-03-29</td>\n",
       "      <td>503728.293905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>2018-04-05</td>\n",
       "      <td>535217.319098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date          Sales\n",
       "0    2014-02-06  272996.200000\n",
       "1    2014-02-13  346172.760000\n",
       "2    2014-02-20  423308.320000\n",
       "3    2014-02-27  387812.840000\n",
       "4    2014-03-05  528118.230000\n",
       "5    2014-03-12  669367.640000\n",
       "6    2014-03-19  490228.600000\n",
       "7    2014-03-26  494630.550000\n",
       "8    2014-04-02  367991.150000\n",
       "9    2014-04-09  382757.480000\n",
       "10   2014-04-16  424015.930000\n",
       "11   2014-04-23  428185.820000\n",
       "12   2014-04-30  526028.750000\n",
       "13   2014-05-07  517240.540000\n",
       "14   2014-05-14  471396.000000\n",
       "15   2014-05-21  559720.410000\n",
       "16   2014-05-28  511963.550000\n",
       "17   2014-06-04  651924.790000\n",
       "18   2014-06-11  723426.110000\n",
       "19   2014-06-18  682107.150000\n",
       "20   2014-06-25  590698.070000\n",
       "21   2014-07-02  571980.410000\n",
       "22   2014-07-09  537338.070000\n",
       "23   2014-07-16  565170.890000\n",
       "24   2014-07-23  617212.490000\n",
       "25   2014-07-30  589454.080000\n",
       "26   2014-08-06  732321.500000\n",
       "27   2014-08-13  843496.010000\n",
       "28   2014-08-20  587085.480000\n",
       "29   2014-08-27  516225.870000\n",
       "30   2014-09-03  488805.030000\n",
       "31   2014-09-10  437336.370000\n",
       "32   2014-09-17  424838.640000\n",
       "33   2014-09-24  445500.370000\n",
       "34   2014-10-01  443444.720000\n",
       "35   2014-10-08  372231.830000\n",
       "36   2014-10-15  397833.130000\n",
       "37   2014-10-22  425858.990000\n",
       "38   2014-10-29  354666.900000\n",
       "39   2014-11-05  315540.520000\n",
       "40   2014-11-12  372694.210000\n",
       "41   2014-11-19  389977.200000\n",
       "42   2014-11-26  656988.900000\n",
       "43   2014-12-03  411314.020000\n",
       "44   2014-12-10  365644.100000\n",
       "45   2014-12-17  343702.610000\n",
       "46   2014-12-24  449840.050000\n",
       "47   2014-12-31  619707.200000\n",
       "48   2015-01-07  432028.300000\n",
       "49   2015-01-14  372269.360000\n",
       "50   2015-01-21  419583.160000\n",
       "51   2015-01-28  343562.970000\n",
       "52   2015-02-04  317608.560000\n",
       "53   2015-02-11  378319.110000\n",
       "54   2015-02-18  443072.710000\n",
       "55   2015-02-25  472350.700000\n",
       "56   2015-03-04  560008.970000\n",
       "57   2015-03-11  701939.820000\n",
       "58   2015-03-18  507433.750000\n",
       "59   2015-03-25  502231.490000\n",
       "60   2015-04-01  513710.770000\n",
       "61   2015-04-08  469174.720000\n",
       "62   2015-04-15  584574.430000\n",
       "63   2015-04-22  438304.110000\n",
       "64   2015-04-29  527109.720000\n",
       "65   2015-05-06  523192.880000\n",
       "66   2015-05-13  601547.830000\n",
       "67   2015-05-20  582251.850000\n",
       "68   2015-05-27  520103.260000\n",
       "69   2015-06-03  567444.050000\n",
       "70   2015-06-10  640840.140000\n",
       "71   2015-06-17  715649.310000\n",
       "72   2015-06-24  630425.440000\n",
       "73   2015-07-01  606112.840000\n",
       "74   2015-07-08  599926.700000\n",
       "75   2015-07-15  620324.210000\n",
       "76   2015-07-22  645892.760000\n",
       "77   2015-07-29  592234.920000\n",
       "78   2015-08-05  691975.630000\n",
       "79   2015-08-12  814112.900000\n",
       "80   2015-08-19  597761.200000\n",
       "81   2015-08-26  522489.970000\n",
       "82   2015-09-02  497969.040000\n",
       "83   2015-09-09  433195.020000\n",
       "84   2015-09-16  410801.340000\n",
       "85   2015-09-23  460460.860000\n",
       "86   2015-09-30  483169.420000\n",
       "87   2015-10-07  487258.090000\n",
       "88   2015-10-14  518496.810000\n",
       "89   2015-10-21  475365.510000\n",
       "90   2015-10-28  409547.280000\n",
       "91   2015-11-04  353693.920000\n",
       "92   2015-11-11  444685.760000\n",
       "93   2015-11-18  424084.490000\n",
       "94   2015-11-25  794789.960000\n",
       "95   2015-12-02  494037.970000\n",
       "96   2015-12-09  397203.860000\n",
       "97   2015-12-16  435368.760000\n",
       "98   2015-12-23  514496.320000\n",
       "99   2015-12-30  589491.360000\n",
       "100  2016-01-06  433569.220000\n",
       "101  2016-01-13  390239.360000\n",
       "102  2016-01-20  401476.930000\n",
       "103  2016-01-27  371189.530000\n",
       "104  2016-02-03  350681.430000\n",
       "105  2016-02-10  373086.780000\n",
       "106  2016-02-17  474357.350000\n",
       "107  2016-02-24  493497.710000\n",
       "108  2016-03-03  545807.930000\n",
       "109  2016-03-10  698748.530000\n",
       "110  2016-03-17  572374.200000\n",
       "111  2016-03-24  546214.060000\n",
       "112  2016-03-31  607684.760000\n",
       "113  2016-04-07  499651.970000\n",
       "114  2016-04-14  498494.510000\n",
       "115  2016-04-21  540235.740000\n",
       "116  2016-04-28  558563.940000\n",
       "117  2016-05-05  579892.040000\n",
       "118  2016-05-12  665269.960000\n",
       "119  2016-05-19  630857.430000\n",
       "120  2016-05-26  611207.060000\n",
       "121  2016-06-02  661876.540000\n",
       "122  2016-06-09  635274.370000\n",
       "123  2016-06-16  738221.440000\n",
       "124  2016-06-23  679265.400000\n",
       "125  2016-06-30  626069.330000\n",
       "126  2016-07-07  615184.230000\n",
       "127  2016-07-14  669840.710000\n",
       "128  2016-07-21  777858.900000\n",
       "129  2016-07-28  642305.370000\n",
       "130  2016-08-04  775938.350000\n",
       "131  2016-08-11  876809.020000\n",
       "132  2016-08-18  699019.100000\n",
       "133  2016-08-25  574054.980000\n",
       "134  2016-09-01  567508.970000\n",
       "135  2016-09-08  537075.260000\n",
       "136  2016-09-15  451754.740000\n",
       "137  2016-09-22  497291.600000\n",
       "138  2016-09-29  482432.420000\n",
       "139  2016-10-06  440283.340000\n",
       "140  2016-10-13  482122.980000\n",
       "141  2016-10-20  472823.780000\n",
       "142  2016-10-27  400479.260000\n",
       "143  2016-11-03  374118.160000\n",
       "144  2016-11-10  381829.280000\n",
       "145  2016-11-17  449106.400000\n",
       "146  2016-11-24  801472.960000\n",
       "147  2016-12-01  473739.100000\n",
       "148  2016-12-08  414116.450000\n",
       "149  2016-12-15  458387.940000\n",
       "150  2016-12-22  483103.240000\n",
       "151  2016-12-29  546124.960000\n",
       "152  2017-01-05  607941.670000\n",
       "153  2017-01-12  400762.710000\n",
       "154  2017-01-19  365048.840000\n",
       "155  2017-01-26  409598.390000\n",
       "156  2017-02-02  360035.930000\n",
       "157  2017-02-09  396348.800000\n",
       "158  2017-02-16  444552.840000\n",
       "159  2017-02-23  462946.080000\n",
       "160  2017-03-02  567800.870000\n",
       "161  2017-03-09  752613.050000\n",
       "162  2017-03-16  562509.000000\n",
       "163  2017-03-23  552955.860000\n",
       "164  2017-03-30  591507.610000\n",
       "165  2017-04-06  571705.120000\n",
       "166  2017-04-13  550712.550000\n",
       "167  2017-04-20  602938.230000\n",
       "168  2017-04-27  477272.050000\n",
       "169  2017-05-04  538224.780000\n",
       "170  2017-05-11  581886.890000\n",
       "171  2017-05-18  565407.100000\n",
       "172  2017-05-25  576454.790000\n",
       "173  2017-06-01  598935.410000\n",
       "174  2017-06-08  621861.960000\n",
       "175  2017-06-15  667203.890000\n",
       "176  2017-06-22  652567.310000\n",
       "177  2017-06-29  649337.150000\n",
       "178  2017-07-06  648991.150000\n",
       "179  2017-07-13  674738.960000\n",
       "180  2017-07-20  760370.420000\n",
       "181  2017-07-27  654907.000000\n",
       "182  2017-08-03  800815.170000\n",
       "183  2017-08-10  930987.050000\n",
       "184  2017-08-17  703491.010000\n",
       "185  2017-08-24  651804.210000\n",
       "186  2017-08-31  615182.680000\n",
       "187  2017-09-07  557378.150000\n",
       "188  2017-09-14  487608.870000\n",
       "189  2017-09-21  504333.400000\n",
       "190  2017-09-28  490658.090000\n",
       "191  2017-10-05  471625.420000\n",
       "192  2017-10-12  448425.580000\n",
       "193  2017-10-19  489885.290000\n",
       "194  2017-10-26  457828.457344\n",
       "195  2017-11-02  476925.730892\n",
       "196  2017-11-09  475460.450046\n",
       "197  2017-11-16  525248.687454\n",
       "198  2017-11-23  740162.759088\n",
       "199  2017-11-30  485967.762744\n",
       "200  2017-12-07  441729.802668\n",
       "201  2017-12-14  408503.483842\n",
       "202  2017-12-21  404598.500581\n",
       "203  2017-12-28  508634.295382\n",
       "204  2018-01-04  473154.027779\n",
       "205  2018-01-11  363888.968885\n",
       "206  2018-01-18  384815.940517\n",
       "207  2018-01-25  360326.349960\n",
       "208  2018-02-01  311909.022991\n",
       "209  2018-02-08  299349.748917\n",
       "210  2018-02-15  357442.683302\n",
       "211  2018-02-22  422303.274160\n",
       "212  2018-03-01  535169.992184\n",
       "213  2018-03-08  644557.570201\n",
       "214  2018-03-15  503305.158903\n",
       "215  2018-03-22  501321.801308\n",
       "216  2018-03-29  503728.293905\n",
       "217  2018-04-05  535217.319098"
      ]
     },
     "execution_count": 701,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thank you for reading!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf2.4]",
   "language": "python",
   "name": "conda-env-tf2.4-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
